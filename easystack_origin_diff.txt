diff --git a/README.md b/README.md
deleted file mode 100644
index 954ef36..0000000
--- a/README.md
+++ /dev/null
@@ -1,2 +0,0 @@
-# neutron_lbaas
-To compare the difference between neutron_lbaas_kilo and neutron_lbaas_mitaka
diff --git a/agent/agent_manager.py b/agent/agent_manager.py
index aa548d4..75c55f4 100644
--- a/agent/agent_manager.py
+++ b/agent/agent_manager.py
@@ -77,7 +77,7 @@ class LbaasAgentManager(periodic_task.PeriodicTasks):
         self.admin_state_up = True
 
         self._setup_state_rpc()
-        self.needs_resync = False
+        self.needs_resync = True
         # pool_id->device_driver_name mapping used to store known instances
         self.instance_mapping = {}
 
diff --git a/db/loadbalancer/loadbalancer_dbv2.py b/db/loadbalancer/loadbalancer_dbv2.py
index 9ca25dd..61d0891 100644
--- a/db/loadbalancer/loadbalancer_dbv2.py
+++ b/db/loadbalancer/loadbalancer_dbv2.py
@@ -13,6 +13,7 @@
 #    License for the specific language governing permissions and limitations
 #    under the License.
 
+from datetime import datetime
 import re
 
 from neutron.api.v2 import attributes
@@ -160,6 +161,14 @@ class LoadBalancerPluginDbv2(base_db.CommonDbMixin,
             if model == models.LoadBalancer:
                 db_lb = self._get_resource(context, model, id, for_update=True)
             else:
+                if model == models.PoolV2:
+                    pool = self._get_resource(context, model, id)
+                    if pool.healthmonitor and\
+                       status == constants.PENDING_DELETE:
+                        raise loadbalancerv2.EntityInUse(
+                            entity_using=models.HealthMonitorV2.NAME,
+                            id=pool.healthmonitor.id,
+                            entity_in_use=models.PoolV2.NAME)
                 db_lb_child = self._get_resource(context, model, id)
                 db_lb = self._get_resource(context, models.LoadBalancer,
                                            db_lb_child.root_loadbalancer.id)
@@ -213,6 +222,7 @@ class LoadBalancerPluginDbv2(base_db.CommonDbMixin,
             lb_db = models.LoadBalancer(**loadbalancer)
             context.session.add(lb_db)
             context.session.flush()
+            lb_db.create_time = datetime.now()
             lb_db.stats = self._create_loadbalancer_stats(
                 context, lb_db.id)
             context.session.add(lb_db)
@@ -393,6 +403,7 @@ class LoadBalancerPluginDbv2(base_db.CommonDbMixin,
                 if 'sni_container_ids' in listener:
                     sni_container_ids = listener.pop('sni_container_ids')
                 listener_db_entry = models.Listener(**listener)
+                listener_db_entry.create_time = datetime.now()
                 for container_id in sni_container_ids:
                     sni = models.SNI(listener_id=listener_db_entry.id,
                                      tls_container_id=container_id)
@@ -488,6 +499,7 @@ class LoadBalancerPluginDbv2(base_db.CommonDbMixin,
 
             session_info = pool.pop('session_persistence')
             pool_db = models.PoolV2(**pool)
+            pool_db.create_time = datetime.now()
 
             if session_info:
                 s_p = self._create_session_persistence_db(session_info,
diff --git a/db/loadbalancer/models.py b/db/loadbalancer/models.py
index 5c0c558..f535dcb 100644
--- a/db/loadbalancer/models.py
+++ b/db/loadbalancer/models.py
@@ -155,6 +155,7 @@ class LoadBalancer(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant):
     )
     flavor_id = sa.Column(sa.String(36), sa.ForeignKey(
         'flavors.id', name='fk_lbaas_loadbalancers_flavors_id'))
+    create_time = sa.Column(sa.DateTime(True))
 
     @property
     def root_loadbalancer(self):
@@ -203,6 +204,7 @@ class PoolV2(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant):
         LoadBalancer, uselist=False,
         backref=orm.backref("pools", uselist=True),
         lazy='joined')
+    create_time = sa.Column(sa.DateTime(True))
 
     @property
     def root_loadbalancer(self):
@@ -366,6 +368,7 @@ class Listener(model_base.BASEV2, models_v2.HasId, models_v2.HasTenant):
         foreign_keys=[L7Policy.listener_id],
         cascade="all, delete-orphan",
         backref=orm.backref("listener"))
+    create_time = sa.Column(sa.DateTime(True))
 
     @property
     def root_loadbalancer(self):
diff --git a/db/migration/alembic_migrations/versions/lbaasv2.py b/db/migration/alembic_migrations/versions/lbaasv2.py
index 630a0a4..4c8d841 100644
--- a/db/migration/alembic_migrations/versions/lbaasv2.py
+++ b/db/migration/alembic_migrations/versions/lbaasv2.py
@@ -69,6 +69,7 @@ def upgrade():
         sa.Column(u'healthmonitor_id', sa.String(36), nullable=True),
         sa.Column(u'status', sa.String(16), nullable=False),
         sa.Column(u'admin_state_up', sa.Boolean(), nullable=False),
+        sa.Column(u'create_time', sa.DateTime(True), nullable=True),
         sa.PrimaryKeyConstraint(u'id'),
         sa.UniqueConstraint(u'healthmonitor_id'),
         sa.ForeignKeyConstraint([u'healthmonitor_id'],
@@ -112,6 +113,7 @@ def upgrade():
         sa.Column(u'vip_address', sa.String(36), nullable=True),
         sa.Column(u'status', sa.String(16), nullable=False),
         sa.Column(u'admin_state_up', sa.Boolean(), nullable=False),
+        sa.Column(u'create_time', sa.DateTime(True), nullable=True),
         sa.ForeignKeyConstraint([u'vip_port_id'], [u'ports.id'],
                                 name=u'fk_lbaas_loadbalancers_ports_id'),
         sa.PrimaryKeyConstraint(u'id')
@@ -130,6 +132,7 @@ def upgrade():
         sa.Column(u'default_pool_id', sa.String(36), nullable=True),
         sa.Column(u'status', sa.String(16), nullable=False),
         sa.Column(u'admin_state_up', sa.Boolean(), nullable=False),
+        sa.Column(u'create_time', sa.DateTime(True), nullable=True),
         sa.ForeignKeyConstraint([u'loadbalancer_id'],
                                 [u'lbaas_loadbalancers.id']),
         sa.ForeignKeyConstraint([u'default_pool_id'],
diff --git a/drivers/common/agent_callbacks.py b/drivers/common/agent_callbacks.py
index b03954f..45e16e0 100644
--- a/drivers/common/agent_callbacks.py
+++ b/drivers/common/agent_callbacks.py
@@ -45,16 +45,16 @@ class LoadBalancerCallbacks(object):
             elif len(agents) > 1:
                 LOG.warning(_LW('Multiple lbaas agents found on host %s'),
                             host)
-            loadbalancers = self.plugin.db.list_loadbalancers_on_lbaas_agent(
-                context, agents[0].id)
-            loadbalancer_ids = [
-                l.id for l in loadbalancers]
+            #loadbalancers = self.plugin.db.list_loadbalancers_on_lbaas_agent(
+            #    context, agents[0].id)
+            #loadbalancer_ids = [
+            #    l.id for l in loadbalancers]
 
             qry = context.session.query(
                 loadbalancer_dbv2.models.LoadBalancer.id)
-            qry = qry.filter(
-                loadbalancer_dbv2.models.LoadBalancer.id.in_(
-                    loadbalancer_ids))
+            #qry = qry.filter(
+            #    loadbalancer_dbv2.models.LoadBalancer.id.in_(
+            #        loadbalancer_ids))
             qry = qry.filter(
                 loadbalancer_dbv2.models.LoadBalancer.provisioning_status.in_(
                     constants.ACTIVE_PENDING_STATUSES))
diff --git a/extensions/loadbalancerv2.py b/extensions/loadbalancerv2.py
index 3aeaeda..d975828 100644
--- a/extensions/loadbalancerv2.py
+++ b/extensions/loadbalancerv2.py
@@ -185,7 +185,9 @@ RESOURCE_ATTRIBUTE_MAP = {
         'flavor_id': {'allow_post': True, 'allow_put': False,
                       'is_visible': True,
                       'validate': {'type:string': attr.NAME_MAX_LEN},
-                      'default': attr.ATTR_NOT_SPECIFIED}
+                      'default': attr.ATTR_NOT_SPECIFIED},
+        'create_time': {'allow_post': False, 'allow_put': False,
+                        'is_visible': True}
     },
     'listeners': {
         'id': {'allow_post': False, 'allow_put': False,
@@ -238,7 +240,9 @@ RESOURCE_ATTRIBUTE_MAP = {
         'admin_state_up': {'allow_post': True, 'allow_put': True,
                            'default': True,
                            'convert_to': attr.convert_to_boolean,
-                           'is_visible': True}
+                           'is_visible': True},
+        'create_time': {'allow_post': False, 'allow_put': False,
+                        'is_visible': True}
     },
     'pools': {
         'id': {'allow_post': False, 'allow_put': False,
@@ -289,7 +293,9 @@ RESOURCE_ATTRIBUTE_MAP = {
         'admin_state_up': {'allow_post': True, 'allow_put': True,
                            'default': True,
                            'convert_to': attr.convert_to_boolean,
-                           'is_visible': True}
+                           'is_visible': True},
+        'create_time': {'allow_post': False, 'allow_put': False,
+                        'is_visible': True}
     },
     'healthmonitors': {
         'id': {'allow_post': False, 'allow_put': False,
diff --git a/services/loadbalancer/data_models.py b/services/loadbalancer/data_models.py
index 9832341..e122d8b 100644
--- a/services/loadbalancer/data_models.py
+++ b/services/loadbalancer/data_models.py
@@ -361,11 +361,12 @@ class HealthMonitor(BaseDataModel):
 
 class Pool(BaseDataModel):
 
+    #Modified by mall2, Bugzilla-76457, add 'create_time', 2016-12-6
     fields = ['id', 'tenant_id', 'name', 'description', 'healthmonitor_id',
               'protocol', 'lb_algorithm', 'admin_state_up', 'operating_status',
               'provisioning_status', 'members', 'healthmonitor',
               'session_persistence', 'loadbalancer_id', 'loadbalancer',
-              'listener', 'listeners', 'l7_policies']
+              'listener', 'listeners', 'l7_policies', 'create_time']
 
     # Map deprecated attribute names to new ones.
     attr_mapping = {'sessionpersistence': 'session_persistence'}
@@ -376,7 +377,7 @@ class Pool(BaseDataModel):
                  provisioning_status=None, members=None, healthmonitor=None,
                  session_persistence=None, loadbalancer_id=None,
                  loadbalancer=None, listener=None, listeners=None,
-                 l7_policies=None):
+                 l7_policies=None, create_time=None):
         self.id = id
         self.tenant_id = tenant_id
         self.name = name
@@ -398,6 +399,7 @@ class Pool(BaseDataModel):
         self.listener = listener
         self.listeners = listeners or []
         self.l7_policies = l7_policies or []
+        self.create_time = create_time
 
     def attached_to_loadbalancer(self):
         return bool(self.loadbalancer)
@@ -634,7 +636,7 @@ class Listener(BaseDataModel):
                  protocol_port=None, connection_limit=None,
                  admin_state_up=None, provisioning_status=None,
                  operating_status=None, default_pool=None, loadbalancer=None,
-                 l7_policies=None):
+                 l7_policies=None, create_time=None):
         self.id = id
         self.tenant_id = tenant_id
         self.name = name
@@ -652,6 +654,7 @@ class Listener(BaseDataModel):
         self.default_pool = default_pool
         self.loadbalancer = loadbalancer
         self.l7_policies = l7_policies or []
+        self.create_time = create_time
 
     def attached_to_loadbalancer(self):
         return bool(self.loadbalancer)
@@ -692,16 +695,18 @@ class Listener(BaseDataModel):
 
 class LoadBalancer(BaseDataModel):
 
+    #Modified by mall2, Bugzilla-76457, add 'create_time', 2016-12-6
     fields = ['id', 'tenant_id', 'name', 'description', 'vip_subnet_id',
               'vip_port_id', 'vip_address', 'provisioning_status',
               'operating_status', 'admin_state_up', 'vip_port', 'stats',
-              'provider', 'listeners', 'pools', 'flavor_id']
+              'provider', 'listeners', 'pools', 'flavor_id', 'create_time']
 
     def __init__(self, id=None, tenant_id=None, name=None, description=None,
                  vip_subnet_id=None, vip_port_id=None, vip_address=None,
                  provisioning_status=None, operating_status=None,
                  admin_state_up=None, vip_port=None, stats=None,
-                 provider=None, listeners=None, pools=None, flavor_id=None):
+                 provider=None, listeners=None, pools=None,
+                 flavor_id=None, create_time=None):
         self.id = id
         self.tenant_id = tenant_id
         self.name = name
@@ -718,6 +723,7 @@ class LoadBalancer(BaseDataModel):
         self.listeners = listeners or []
         self.flavor_id = flavor_id
         self.pools = pools or []
+        self.create_time = create_time
 
     def attached_to_loadbalancer(self):
         return True
diff --git a/services/loadbalancer/plugin.py b/services/loadbalancer/plugin.py
index b115e0c..118cc6d 100644
--- a/services/loadbalancer/plugin.py
+++ b/services/loadbalancer/plugin.py
@@ -603,16 +603,21 @@ class LoadBalancerPluginv2(loadbalancerv2.LoadBalancerPluginBaseV2):
 
     def delete_loadbalancer(self, context, id):
         old_lb = self.db.get_loadbalancer(context, id)
-        if old_lb.listeners:
-            raise loadbalancerv2.EntityInUse(
-                entity_using=models.Listener.NAME,
-                id=old_lb.listeners[0].id,
-                entity_in_use=models.LoadBalancer.NAME)
+        #begin: modified by mall2, Bugzilla-76167, 2016-12-6
+        #if old_lb.listeners:
+        #    raise loadbalancerv2.EntityInUse(
+        #        entity_using=models.Listener.NAME,
+        #        id=old_lb.listeners[0].id,
+        #        entity_in_use=models.LoadBalancer.NAME)
         if old_lb.pools:
             raise loadbalancerv2.EntityInUse(
                 entity_using=models.PoolV2.NAME,
                 id=old_lb.pools[0].id,
                 entity_in_use=models.LoadBalancer.NAME)
+        if old_lb.listeners:
+            for listener in old_lb.listeners:
+                self.delete_listener(context, listener.id)
+        #end: modified by mall2, Bugzilla-76167, 2016-12-6
         self.db.test_and_set_status(context, models.LoadBalancer, id,
                                     constants.PENDING_DELETE)
         driver = self._get_driver_for_provider(old_lb.provider.provider_name)
diff --git a/tests/__init__.py b/tests/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/base.py b/tests/base.py
deleted file mode 100644
index 2f24dd6..0000000
--- a/tests/base.py
+++ /dev/null
@@ -1,215 +0,0 @@
-# Copyright 2014 OpenStack Foundation.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-
-import mock
-
-from neutron.db import servicetype_db as st_db
-from neutron.tests import base as n_base
-from neutron.tests.unit.db import test_db_base_plugin_v2
-from neutron.tests.unit.extensions import base as ext_base
-from neutron.tests.unit.extensions import test_quotasv2
-from neutron.tests.unit import testlib_api
-from testtools import matchers
-
-
-class BaseTestCase(n_base.BaseTestCase):
-    pass
-
-
-class NeutronDbPluginV2TestCase(
-    test_db_base_plugin_v2.NeutronDbPluginV2TestCase):
-
-    def set_override(self, lbaas_provider):
-        # override the default service provider
-        self.service_providers = (
-            mock.patch.object(st_db.ServiceTypeManager,
-                              'get_service_providers').start())
-        self.service_providers.return_value = (
-            self._to_provider_dicts(lbaas_provider))
-
-        # need to reload provider configuration
-        st_db.ServiceTypeManager._instance = None
-
-    def new_list_request(self, resource, fmt=None, params=None, id=None,
-                         subresource=None):
-        return self._req(
-            'GET', resource, None, fmt, params=params, subresource=subresource,
-            id=id
-        )
-
-    def new_show_request(self, resource, id, fmt=None,
-                         subresource=None, sub_id=None, fields=None):
-        if fields:
-            params = "&".join(["fields=%s" % x for x in fields])
-        else:
-            params = None
-        return self._req('GET', resource, None, fmt, id=id,
-                         params=params, subresource=subresource, sub_id=sub_id)
-
-    def new_update_request(self, resource, data, id, fmt=None,
-                           subresource=None, context=None, sub_id=None):
-        return self._req(
-            'PUT', resource, data, fmt, id=id, subresource=subresource,
-            context=context, sub_id=sub_id
-        )
-
-    def _to_provider_dicts(self, lbaas_provider):
-        provider_dicts = []
-        for provider in lbaas_provider:
-            bits = provider.split(':')
-            p = {
-                'service_type': bits[0],
-                'name': bits[1],
-                'driver': bits[2]
-            }
-            if len(bits) == 4:
-                p['default'] = True
-            provider_dicts.append(p)
-        return provider_dicts
-
-    def _test_list_with_sort(self, resource,
-                             items, sorts, resources=None,
-                             query_params='',
-                             id=None,
-                             subresource=None,
-                             subresources=None):
-        query_str = query_params
-        for key, direction in sorts:
-            query_str = query_str + "&sort_key=%s&sort_dir=%s" % (key,
-                                                                  direction)
-        if not resources:
-            resources = '%ss' % resource
-        if subresource and not subresources:
-            subresources = '%ss' % subresource
-        req = self.new_list_request(resources,
-                                    params=query_str,
-                                    id=id,
-                                    subresource=subresources)
-        api = self._api_for_resource(resources)
-        res = self.deserialize(self.fmt, req.get_response(api))
-        if subresource:
-            resource = subresource
-        if subresources:
-            resources = subresources
-        resource = resource.replace('-', '_')
-        resources = resources.replace('-', '_')
-        expected_res = [item[resource]['id'] for item in items]
-        self.assertEqual(expected_res, [n['id'] for n in res[resources]])
-
-    def _test_list_with_pagination(self, resource, items, sort,
-                                   limit, expected_page_num,
-                                   resources=None,
-                                   query_params='',
-                                   verify_key='id',
-                                   id=None,
-                                   subresource=None,
-                                   subresources=None):
-        if not resources:
-            resources = '%ss' % resource
-        if subresource and not subresources:
-            subresources = '%ss' % subresource
-        query_str = query_params + '&' if query_params else ''
-        query_str = query_str + ("limit=%s&sort_key=%s&"
-                                 "sort_dir=%s") % (limit, sort[0], sort[1])
-        req = self.new_list_request(resources, params=query_str, id=id,
-                                    subresource=subresources)
-        items_res = []
-        page_num = 0
-        api = self._api_for_resource(resources)
-        if subresource:
-            resource = subresource
-        if subresources:
-            resources = subresources
-        resource = resource.replace('-', '_')
-        resources = resources.replace('-', '_')
-        while req:
-            page_num = page_num + 1
-            res = self.deserialize(self.fmt, req.get_response(api))
-            self.assertThat(len(res[resources]),
-                            matchers.LessThan(limit + 1))
-            items_res = items_res + res[resources]
-            req = None
-            if '%s_links' % resources in res:
-                for link in res['%s_links' % resources]:
-                    if link['rel'] == 'next':
-                        content_type = 'application/%s' % self.fmt
-                        req = testlib_api.create_request(link['href'],
-                                                         '', content_type)
-                        self.assertEqual(len(res[resources]),
-                                         limit)
-        self.assertEqual(expected_page_num, page_num)
-        self.assertEqual([item[resource][verify_key] for item in items],
-                         [n[verify_key] for n in items_res])
-
-    def _test_list_with_pagination_reverse(self, resource, items, sort,
-                                           limit, expected_page_num,
-                                           resources=None,
-                                           query_params='',
-                                           id=None,
-                                           subresource=None,
-                                           subresources=None):
-        if not resources:
-            resources = '%ss' % resource
-        if subresource and not subresources:
-            subresources = '%ss' % subresource
-        resource = resource.replace('-', '_')
-        api = self._api_for_resource(resources)
-        if subresource:
-            marker = items[-1][subresource]['id']
-        else:
-            marker = items[-1][resource]['id']
-        query_str = query_params + '&' if query_params else ''
-        query_str = query_str + ("limit=%s&page_reverse=True&"
-                                 "sort_key=%s&sort_dir=%s&"
-                                 "marker=%s") % (limit, sort[0], sort[1],
-                                                 marker)
-        req = self.new_list_request(resources, params=query_str, id=id,
-                                    subresource=subresources)
-        if subresource:
-            resource = subresource
-        if subresources:
-            resources = subresources
-        item_res = [items[-1][resource]]
-        page_num = 0
-        resources = resources.replace('-', '_')
-        while req:
-            page_num = page_num + 1
-            res = self.deserialize(self.fmt, req.get_response(api))
-            self.assertThat(len(res[resources]),
-                            matchers.LessThan(limit + 1))
-            res[resources].reverse()
-            item_res = item_res + res[resources]
-            req = None
-            if '%s_links' % resources in res:
-                for link in res['%s_links' % resources]:
-                    if link['rel'] == 'previous':
-                        content_type = 'application/%s' % self.fmt
-                        req = testlib_api.create_request(link['href'],
-                                                         '', content_type)
-                        self.assertEqual(len(res[resources]),
-                                         limit)
-        self.assertEqual(expected_page_num, page_num)
-        expected_res = [item[resource]['id'] for item in items]
-        expected_res.reverse()
-        self.assertEqual(expected_res, [n['id'] for n in item_res])
-
-
-class ExtensionTestCase(ext_base.ExtensionTestCase):
-    pass
-
-
-class QuotaExtensionTestCase(test_quotasv2.QuotaExtensionTestCase):
-    pass
diff --git a/tests/contrib/decode_args.sh b/tests/contrib/decode_args.sh
deleted file mode 100644
index ca9a343..0000000
--- a/tests/contrib/decode_args.sh
+++ /dev/null
@@ -1,58 +0,0 @@
-#!/bin/bash
-
-# This file is meant to be sourced by the other hooks
-
-# Legacy values for $1, $2 and $3:
-# $1 - dsvm-functional, tempest (testtype)
-# $2 - lbaasv2, lbaasv1 (lbaasversion)
-# $3 - scenario, minimal, api, healthmonitor, listener, loadbalancer, member, pool (lbaastest)
-
-# Args being phased in:
-# $1 - same
-# $2 - same
-# $3 - test-driver, with any missing -driver being "octavia"
-#    scenario-octavia
-#    minimal-octavia
-#    api-namespace
-#    api-{thirdparty}
-#    healthmonitor-octavia
-#    listener-octavia
-#    loadbalancer-octavia
-#    member-octavia
-#    pool-octavia
-
-
-
-
-testtype="$1"
-lbaasversion="$2"
-lbaastest="$3"
-lbaasenv=$(echo "$lbaastest" | perl -ne '/^(.*)-([^-]+)$/ && print "$1";')
-if [ -z "$lbaasenv" ]; then
-    lbaasenv=$lbaastest
-fi
-lbaasdriver=$(echo "$lbaastest" | perl -ne '/^(.*)-([^-]+)$/ && print "$2";')
-if [ -z "$lbaasdriver" ]; then
-    lbaasdriver='octavia'
-fi
-
-testenv=${lbaastest:-"apiv2"}
-
-if [ "$lbaasversion" = "lbaasv1" ]; then
-    testenv="apiv1"
-elif [ "$lbaasversion" = "lbaasv2" ]; then
-    case "$lbaasenv" in
-        "api"|"healthmonitor"|"listener"|"loadbalancer"|"member"|"minimal"|"pool")
-            testenv="apiv2"
-            ;;
-        "scenario")
-            testenv="scenario"
-            ;;
-        *)
-            echo "Unrecognized env $lbaasenv".
-            exit 1
-            ;;
-    esac
-fi
-
-
diff --git a/tests/contrib/gate_hook.sh b/tests/contrib/gate_hook.sh
deleted file mode 100755
index 1ca7d8b..0000000
--- a/tests/contrib/gate_hook.sh
+++ /dev/null
@@ -1,95 +0,0 @@
-#!/bin/bash
-
-set -ex
-
-GATE_DEST=$BASE/new
-DEVSTACK_PATH=$GATE_DEST/devstack
-
-export DEVSTACK_LOCAL_CONFIG+="
-enable_plugin neutron-lbaas https://git.openstack.org/openstack/neutron-lbaas
-enable_plugin barbican https://git.openstack.org/openstack/barbican
-"
-
-# Sort out our gate args
-. $(dirname "$0")/decode_args.sh
-
-
-function _setup_octavia {
-    export DEVSTACK_LOCAL_CONFIG+="
-        enable_plugin octavia https://git.openstack.org/openstack/octavia
-        "
-    if [ "$testenv" != "apiv1" ]; then
-        ENABLED_SERVICES+="octavia,o-cw,o-hk,o-hm,o-api,"
-    fi
-    if [ "$testenv" = "apiv2" ]; then
-       cat > "$DEVSTACK_PATH/local.conf" <<EOF
-[[post-config|/etc/octavia/octavia.conf]]
-[DEFAULT]
-debug = True
-
-[controller_worker]
-amphora_driver = amphora_noop_driver
-compute_driver = compute_noop_driver
-network_driver = network_noop_driver
-
-EOF
-
-    fi
-
-    if [ "$testenv" = "scenario" ]; then
-       cat > "$DEVSTACK_PATH/local.conf" <<EOF
-[[post-config|/etc/octavia/octavia.conf]]
-[DEFAULT]
-debug = True
-
-EOF
-
-    fi
-}
-
-
-case "$testtype" in
-
-    "tempest")
-        # These are not needed with either v1 or v2
-        ENABLED_SERVICES+="-c-api,-c-bak,-c-sch,-c-vol,-cinder,"
-        ENABLED_SERVICES+="-s-account,-s-container,-s-object,-s-proxy,"
-
-        if [ "$testenv" != "scenario" ]; then
-            export DEVSTACK_LOCAL_CONFIG+="
-        DISABLE_AMP_IMAGE_BUILD=True
-        "
-            # Not needed for API tests
-            ENABLED_SERVICES+="-horizon,-ceilometer-acentral,-ceilometer-acompute,"
-            ENABLED_SERVICES+="-ceilometer-alarm-evaluator,-ceilometer-alarm-notifier,"
-            ENABLED_SERVICES+="-ceilometer-anotification,-ceilometer-api,"
-            ENABLED_SERVICES+="-ceilometer-collector,"
-        fi
-
-        if [ "$testenv" != "apiv1" ]; then
-            # Override enabled services, so we can turn on lbaasv2.
-            # While we're at it, disable cinder and swift, since we don't need them.
-            ENABLED_SERVICES+="q-lbaasv2,-q-lbaas,"
-
-            if [ "$lbaasdriver" = "namespace" ]; then
-                export DEVSTACK_LOCAL_CONFIG+="
-        NEUTRON_LBAAS_SERVICE_PROVIDERV2=LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default
-        "
-             fi
-        fi
-
-        if [ "$lbaasdriver" = "octavia" ]; then
-            _setup_octavia
-        fi
-
-        export ENABLED_SERVICES
-        ;;
-
-    *)
-        echo "Unrecognized test type $testtype".
-        exit 1
-        ;;
-esac
-
-
-"$GATE_DEST"/devstack-gate/devstack-vm-gate.sh
diff --git a/tests/contrib/post_test_hook.sh b/tests/contrib/post_test_hook.sh
deleted file mode 100755
index 3bc5690..0000000
--- a/tests/contrib/post_test_hook.sh
+++ /dev/null
@@ -1,81 +0,0 @@
-#!/bin/bash
-
-set -xe
-
-NEUTRON_LBAAS_DIR="$BASE/new/neutron-lbaas"
-TEMPEST_CONFIG_DIR="$BASE/new/tempest/etc"
-SCRIPTS_DIR="/usr/os-testr-env/bin"
-OCTAVIA_DIR="$BASE/new/octavia"
-
-# Sort out our gate args
-. $(dirname "$0")/decode_args.sh
-
-if [ "$testenv" = "apiv2" ]; then
-    case "$lbaasenv" in
-        minimal)
-            # Temporarily just do the happy path
-            test_subset="neutron_lbaas.tests.tempest.v2.api.test_load_balancers_non_admin.LoadBalancersTestJSON.test_create_load_balancer(?!_) "
-            test_subset+="neutron_lbaas.tests.tempest.v2.api.test_load_balancers_non_admin.LoadBalancersTestJSON.test_get_load_balancer_stats(?!_) "
-            test_subset+="neutron_lbaas.tests.tempest.v2.api.test_load_balancers_non_admin.LoadBalancersTestJSON.test_get_load_balancer_status_tree(?!_) "
-            test_subset+="neutron_lbaas.tests.tempest.v2.api.test_listeners_non_admin.ListenersTestJSON.test_create_listener(?!_) "
-            test_subset+="neutron_lbaas.tests.tempest.v2.api.test_pools_non_admin.TestPools.test_create_pool(?!_) "
-            test_subset+="neutron_lbaas.tests.tempest.v2.api.test_members_non_admin.MemberTestJSON.test_add_member(?!_) "
-            test_subset+="neutron_lbaas.tests.tempest.v2.api.test_health_monitors_non_admin.TestHealthMonitors.test_create_health_monitor(?!_)"
-            ;;
-        healthmonitor)
-            test_subset="health_monitor"
-            ;;
-        listener)
-            test_subset="listeners"
-            ;;
-        loadbalancer)
-            test_subset="load_balancers"
-            ;;
-        member)
-            test_subset="members"
-            ;;
-        pool)
-            test_subset="pools"
-            ;;
-        scenario)
-            testenv="scenario"
-            ;;
-    esac
-fi
-
-function generate_testr_results {
-    # Give job user rights to access tox logs
-    sudo -H -u "$owner" chmod o+rw .
-    sudo -H -u "$owner" chmod o+rw -R .testrepository
-    if [ -f ".testrepository/0" ] ; then
-        subunit-1to2 < .testrepository/0 > ./testrepository.subunit
-        $SCRIPTS_DIR/subunit2html ./testrepository.subunit testr_results.html
-        gzip -9 ./testrepository.subunit
-        gzip -9 ./testr_results.html
-        sudo mv ./*.gz /opt/stack/logs/
-    fi
-}
-
-owner=tempest
-# Configure the api and scenario tests to use the tempest.conf set by devstack
-sudo_env="TEMPEST_CONFIG_DIR=$TEMPEST_CONFIG_DIR"
-
-# Set owner permissions according to job's requirements.
-cd "$NEUTRON_LBAAS_DIR"
-sudo chown -R $owner:stack "$NEUTRON_LBAAS_DIR"
-if [ "$lbaasdriver" = "octavia" ]; then
-    sudo chown -R $owner:stack "$OCTAVIA_DIR"
-fi
-
-# Run tests
-echo "Running neutron lbaas $testenv test suite"
-set +e
-
-sudo -H -u $owner $sudo_env tox -e $testenv -- $test_subset
-
-testr_exit_code=$?
-set -e
-
-# Collect and parse results
-generate_testr_results
-exit $testr_exit_code
diff --git a/tests/etc/neutron.conf b/tests/etc/neutron.conf
deleted file mode 100644
index fd78845..0000000
--- a/tests/etc/neutron.conf
+++ /dev/null
@@ -1,4 +0,0 @@
-[DEFAULT]
-
-[database]
-connection = 'sqlite://'
diff --git a/tests/tempest/README.rst b/tests/tempest/README.rst
deleted file mode 100644
index 6f0059a..0000000
--- a/tests/tempest/README.rst
+++ /dev/null
@@ -1,56 +0,0 @@
-Welcome!
-========
-
-This contains the Tempest testing code for the Neutron Load Balancer as a
-Service (LBaaS) service. The tests currently require Tempest to be installed
-with a working devstack instance.   It is assumed that you also have Neutron
-with the Neutron LBaaS service installed.
-
-Please see ``/neutron-lbaas/devstack/README.md`` for the required
-devstack configuration settings for Neutron-LBaaS.
-
-API and SCENARIO Testing with Tempest:
---------------------------------------
-
-Included in the repo are Tempest tests.  If you are familiar with the Tempest
-Testing Framework continue on, otherwise please see the
-Tempest README :
-
-https://github.com/openstack/tempest/blob/master/README.rst
-
-1. Using Devstack
-^^^^^^^^^^^^^^^^^
-If you have a running devstack environment, tempest will be automatically
-configured and placed in ``/opt/stack/tempest``. It will have a configuration
-file, tempest.conf, already set up to work with your devstack installation.
-
-Tests can be run in the following way but you need to have devstack running
-
-for apiv1 tests ::
-
-    $> tox -e apiv1
-
-for apiv2 tests ::
-
-    $> tox -e apiv2
-
-for scenario tests ::
-
-    $> tox -e scenario
-
-2. Not using Devstack
-^^^^^^^^^^^^^^^^^^^^^
-6/19/2015 - As we do not have an external OpenStack environment with
-Neutron_LBaaS V2 to test with, this is TBD
-
-3. Packages tempest vs. tempest-lib
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
-As of 6/19/2015, tests are being migrated to tempest-lib, and while both
-that library and these tests are in-progress, a specific subset of tempest
-is also included in this repo at neutron_lbaas/tests/tempest/lib.
-
-External Resources:
-===================
-
-For more information on the Tempest testing framework see:
-<https://github.com/openstack/tempest>
diff --git a/tests/tempest/__init__.py b/tests/tempest/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/etc/__init__.py b/tests/tempest/etc/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/lib/__init__.py b/tests/tempest/lib/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/lib/services/__init__.py b/tests/tempest/lib/services/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/lib/services/network/__init__.py b/tests/tempest/lib/services/network/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/lib/services/network/json/__init__.py b/tests/tempest/lib/services/network/json/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/lib/services/network/json/network_client.py b/tests/tempest/lib/services/network/json/network_client.py
deleted file mode 100644
index 18bc62f..0000000
--- a/tests/tempest/lib/services/network/json/network_client.py
+++ /dev/null
@@ -1,624 +0,0 @@
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import json
-import time
-
-from six.moves.urllib import parse
-from tempest.lib.common import rest_client
-from tempest.lib.common.utils import misc
-from tempest.lib import exceptions as lib_exc
-from tempest import exceptions
-
-
-class NetworkClientJSON(rest_client.RestClient):
-
-    """
-    Tempest REST client for Neutron. Uses v2 of the Neutron API, since the
-    V1 API has been removed from the code base.
-
-    Implements create, delete, update, list and show for the basic Neutron
-    abstractions (networks, sub-networks, routers, ports and floating IP):
-
-    Implements add/remove interface to router using subnet ID / port ID
-
-    It also implements list, show, update and reset for OpenStack Networking
-    quotas
-    """
-
-    version = '2.0'
-    uri_prefix = "v2.0"
-
-    def get_uri(self, plural_name):
-        # get service prefix from resource name
-
-        # The following list represents resource names that do not require
-        # changing underscore to a hyphen
-        hyphen_exceptions = ["health_monitors", "firewall_rules",
-                             "firewall_policies"]
-        # the following map is used to construct proper URI
-        # for the given neutron resource
-        service_resource_prefix_map = {
-            'networks': '',
-            'subnets': '',
-            'subnetpools': '',
-            'ports': '',
-            'pools': 'lb',
-            'vips': 'lb',
-            'health_monitors': 'lb',
-            'members': 'lb',
-            'ipsecpolicies': 'vpn',
-            'vpnservices': 'vpn',
-            'ikepolicies': 'vpn',
-            'ipsec-site-connections': 'vpn',
-            'metering_labels': 'metering',
-            'metering_label_rules': 'metering',
-            'firewall_rules': 'fw',
-            'firewall_policies': 'fw',
-            'firewalls': 'fw'
-        }
-        service_prefix = service_resource_prefix_map.get(
-            plural_name)
-        if plural_name not in hyphen_exceptions:
-            plural_name = plural_name.replace("_", "-")
-        if service_prefix:
-            uri = '%s/%s/%s' % (self.uri_prefix, service_prefix,
-                                plural_name)
-        else:
-            uri = '%s/%s' % (self.uri_prefix, plural_name)
-        return uri
-
-    def pluralize(self, resource_name):
-        # get plural from map or just add 's'
-
-        # map from resource name to a plural name
-        # needed only for those which can't be constructed as name + 's'
-        resource_plural_map = {
-            'security_groups': 'security_groups',
-            'security_group_rules': 'security_group_rules',
-            'ipsecpolicy': 'ipsecpolicies',
-            'ikepolicy': 'ikepolicies',
-            'ipsec_site_connection': 'ipsec-site-connections',
-            'quotas': 'quotas',
-            'firewall_policy': 'firewall_policies'
-        }
-        return resource_plural_map.get(resource_name, resource_name + 's')
-
-    def _lister(self, plural_name):
-        def _list(**filters):
-            uri = self.get_uri(plural_name)
-            if filters:
-                uri += '?' + parse.urlencode(filters, doseq=1)
-            resp, body = self.get(uri)
-            result = {plural_name: self.deserialize_list(body)}
-            self.expected_success(200, resp.status)
-            return rest_client.ResponseBody(resp, result)
-
-        return _list
-
-    def _deleter(self, resource_name):
-        def _delete(resource_id):
-            plural = self.pluralize(resource_name)
-            uri = '%s/%s' % (self.get_uri(plural), resource_id)
-            resp, body = self.delete(uri)
-            self.expected_success(204, resp.status)
-            return rest_client.ResponseBody(resp, body)
-
-        return _delete
-
-    def _shower(self, resource_name):
-        def _show(resource_id, **fields):
-            # fields is a dict which key is 'fields' and value is a
-            # list of field's name. An example:
-            # {'fields': ['id', 'name']}
-            plural = self.pluralize(resource_name)
-            uri = '%s/%s' % (self.get_uri(plural), resource_id)
-            if fields:
-                uri += '?' + parse.urlencode(fields, doseq=1)
-            resp, body = self.get(uri)
-            body = self.deserialize_single(body)
-            self.expected_success(200, resp.status)
-            return rest_client.ResponseBody(resp, body)
-
-        return _show
-
-    def _creater(self, resource_name):
-        def _create(**kwargs):
-            plural = self.pluralize(resource_name)
-            uri = self.get_uri(plural)
-            post_data = self.serialize({resource_name: kwargs})
-            resp, body = self.post(uri, post_data)
-            body = self.deserialize_single(body)
-            self.expected_success(201, resp.status)
-            return rest_client.ResponseBody(resp, body)
-
-        return _create
-
-    def _updater(self, resource_name):
-        def _update(res_id, **kwargs):
-            plural = self.pluralize(resource_name)
-            uri = '%s/%s' % (self.get_uri(plural), res_id)
-            post_data = self.serialize({resource_name: kwargs})
-            resp, body = self.put(uri, post_data)
-            body = self.deserialize_single(body)
-            self.expected_success(200, resp.status)
-            return rest_client.ResponseBody(resp, body)
-
-        return _update
-
-    def __getattr__(self, name):
-        method_prefixes = ["list_", "delete_", "show_", "create_", "update_"]
-        method_functors = [self._lister,
-                           self._deleter,
-                           self._shower,
-                           self._creater,
-                           self._updater]
-        for index, prefix in enumerate(method_prefixes):
-            prefix_len = len(prefix)
-            if name[:prefix_len] == prefix:
-                return method_functors[index](name[prefix_len:])
-        raise AttributeError(name)
-
-    # Subnetpool methods
-    def create_subnetpool(self, post_data):
-        body = self.serialize_list(post_data, "subnetpools", "subnetpool")
-        uri = self.get_uri("subnetpools")
-        resp, body = self.post(uri, body)
-        body = {'subnetpool': self.deserialize_list(body)}
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def get_subnetpool(self, id):
-        uri = self.get_uri("subnetpools")
-        subnetpool_uri = '%s/%s' % (uri, id)
-        resp, body = self.get(subnetpool_uri)
-        body = {'subnetpool': self.deserialize_list(body)}
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def delete_subnetpool(self, id):
-        uri = self.get_uri("subnetpools")
-        subnetpool_uri = '%s/%s' % (uri, id)
-        resp, body = self.delete(subnetpool_uri)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_subnetpools(self):
-        uri = self.get_uri("subnetpools")
-        resp, body = self.get(uri)
-        body = {'subnetpools': self.deserialize_list(body)}
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def update_subnetpool(self, id, post_data):
-        body = self.serialize_list(post_data, "subnetpools", "subnetpool")
-        uri = self.get_uri("subnetpools")
-        subnetpool_uri = '%s/%s' % (uri, id)
-        resp, body = self.put(subnetpool_uri, body)
-        body = {'subnetpool': self.deserialize_list(body)}
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    # Common methods that are hard to automate
-    def create_bulk_network(self, names, shared=False):
-        network_list = [{'name': name, 'shared': shared} for name in names]
-        post_data = {'networks': network_list}
-        body = self.serialize_list(post_data, "networks", "network")
-        uri = self.get_uri("networks")
-        resp, body = self.post(uri, body)
-        body = {'networks': self.deserialize_list(body)}
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def create_bulk_subnet(self, subnet_list):
-        post_data = {'subnets': subnet_list}
-        body = self.serialize_list(post_data, 'subnets', 'subnet')
-        uri = self.get_uri('subnets')
-        resp, body = self.post(uri, body)
-        body = {'subnets': self.deserialize_list(body)}
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def create_bulk_port(self, port_list):
-        post_data = {'ports': port_list}
-        body = self.serialize_list(post_data, 'ports', 'port')
-        uri = self.get_uri('ports')
-        resp, body = self.post(uri, body)
-        body = {'ports': self.deserialize_list(body)}
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def wait_for_resource_deletion(self, resource_type, id):
-        """Waits for a resource to be deleted."""
-        start_time = int(time.time())
-        while True:
-            if self.is_resource_deleted(resource_type, id):
-                return
-            if int(time.time()) - start_time >= self.build_timeout:
-                raise exceptions.TimeoutException
-            time.sleep(self.build_interval)
-
-    def is_resource_deleted(self, resource_type, id):
-        method = 'show_' + resource_type
-        try:
-            getattr(self, method)(id)
-        except AttributeError:
-            raise Exception("Unknown resource type %s " % resource_type)
-        except lib_exc.NotFound:
-            return True
-        return False
-
-    def wait_for_resource_status(self, fetch, status, interval=None,
-                                 timeout=None):
-        """
-        @summary: Waits for a network resource to reach a status
-        @param fetch: the callable to be used to query the resource status
-        @type fecth: callable that takes no parameters and returns the resource
-        @param status: the status that the resource has to reach
-        @type status: String
-        @param interval: the number of seconds to wait between each status
-          query
-        @type interval: Integer
-        @param timeout: the maximum number of seconds to wait for the resource
-          to reach the desired status
-        @type timeout: Integer
-        """
-        if not interval:
-            interval = self.build_interval
-        if not timeout:
-            timeout = self.build_timeout
-        start_time = time.time()
-
-        while time.time() - start_time <= timeout:
-            resource = fetch()
-            if resource['status'] == status:
-                return
-            time.sleep(interval)
-
-        # At this point, the wait has timed out
-        message = 'Resource %s' % (str(resource))
-        message += ' failed to reach status %s' % status
-        message += ' (current: %s)' % resource['status']
-        message += ' within the required time %s' % timeout
-        caller = misc.find_test_caller()
-        if caller:
-            message = '(%s) %s' % (caller, message)
-        raise exceptions.TimeoutException(message)
-
-    def deserialize_single(self, body):
-        return json.loads(body)
-
-    def deserialize_list(self, body):
-        res = json.loads(body)
-        # expecting response in form
-        # {'resources': [ res1, res2] } => when pagination disabled
-        # {'resources': [..], 'resources_links': {}} => if pagination enabled
-        for k in res.keys():
-            if k.endswith("_links"):
-                continue
-            return res[k]
-
-    def serialize(self, data):
-        return json.dumps(data)
-
-    def serialize_list(self, data, root=None, item=None):
-        return self.serialize(data)
-
-    def update_quotas(self, tenant_id, **kwargs):
-        put_body = {'quota': kwargs}
-        body = json.dumps(put_body)
-        uri = '%s/quotas/%s' % (self.uri_prefix, tenant_id)
-        resp, body = self.put(uri, body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body['quota'])
-
-    def reset_quotas(self, tenant_id):
-        uri = '%s/quotas/%s' % (self.uri_prefix, tenant_id)
-        resp, body = self.delete(uri)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def create_router(self, name, admin_state_up=True, **kwargs):
-        post_body = {'router': kwargs}
-        post_body['router']['name'] = name
-        post_body['router']['admin_state_up'] = admin_state_up
-        body = json.dumps(post_body)
-        uri = '%s/routers' % (self.uri_prefix)
-        resp, body = self.post(uri, body)
-        self.expected_success(201, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def _update_router(self, router_id, set_enable_snat, **kwargs):
-        uri = '%s/routers/%s' % (self.uri_prefix, router_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        update_body = {}
-        update_body['name'] = kwargs.get('name', body['router']['name'])
-        update_body['admin_state_up'] = kwargs.get(
-            'admin_state_up', body['router']['admin_state_up'])
-        cur_gw_info = body['router']['external_gateway_info']
-        if cur_gw_info:
-            # TODO(kevinbenton): setting the external gateway info is not
-            # allowed for a regular tenant. If the ability to update is also
-            # merged, a test case for this will need to be added similar to
-            # the SNAT case.
-            cur_gw_info.pop('external_fixed_ips', None)
-            if not set_enable_snat:
-                cur_gw_info.pop('enable_snat', None)
-        update_body['external_gateway_info'] = kwargs.get(
-            'external_gateway_info', body['router']['external_gateway_info'])
-        if 'distributed' in kwargs:
-            update_body['distributed'] = kwargs['distributed']
-        update_body = dict(router=update_body)
-        update_body = json.dumps(update_body)
-        resp, body = self.put(uri, update_body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def update_router(self, router_id, **kwargs):
-        """Update a router leaving enable_snat to its default value."""
-        # If external_gateway_info contains enable_snat the request will fail
-        # with 404 unless executed with admin client, and therefore we instruct
-        # _update_router to not set this attribute
-        # NOTE(salv-orlando): The above applies as long as Neutron's default
-        # policy is to restrict enable_snat usage to admins only.
-        return self._update_router(router_id, set_enable_snat=False, **kwargs)
-
-    def update_router_with_snat_gw_info(self, router_id, **kwargs):
-        """Update a router passing also the enable_snat attribute.
-
-        This method must be execute with admin credentials, otherwise the API
-        call will return a 404 error.
-        """
-        return self._update_router(router_id, set_enable_snat=True, **kwargs)
-
-    def add_router_interface_with_subnet_id(self, router_id, subnet_id):
-        uri = '%s/routers/%s/add_router_interface' % (self.uri_prefix,
-                                                      router_id)
-        update_body = {"subnet_id": subnet_id}
-        update_body = json.dumps(update_body)
-        resp, body = self.put(uri, update_body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def add_router_interface_with_port_id(self, router_id, port_id):
-        uri = '%s/routers/%s/add_router_interface' % (self.uri_prefix,
-                                                      router_id)
-        update_body = {"port_id": port_id}
-        update_body = json.dumps(update_body)
-        resp, body = self.put(uri, update_body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def remove_router_interface_with_subnet_id(self, router_id, subnet_id):
-        uri = '%s/routers/%s/remove_router_interface' % (self.uri_prefix,
-                                                         router_id)
-        update_body = {"subnet_id": subnet_id}
-        update_body = json.dumps(update_body)
-        resp, body = self.put(uri, update_body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def remove_router_interface_with_port_id(self, router_id, port_id):
-        uri = '%s/routers/%s/remove_router_interface' % (self.uri_prefix,
-                                                         router_id)
-        update_body = {"port_id": port_id}
-        update_body = json.dumps(update_body)
-        resp, body = self.put(uri, update_body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def associate_health_monitor_with_pool(self, health_monitor_id,
-                                           pool_id):
-        post_body = {
-            "health_monitor": {
-                "id": health_monitor_id,
-            }
-        }
-        body = json.dumps(post_body)
-        uri = '%s/lb/pools/%s/health_monitors' % (self.uri_prefix,
-                                                  pool_id)
-        resp, body = self.post(uri, body)
-        self.expected_success(201, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def disassociate_health_monitor_with_pool(self, health_monitor_id,
-                                              pool_id):
-        uri = '%s/lb/pools/%s/health_monitors/%s' % (self.uri_prefix, pool_id,
-                                                     health_monitor_id)
-        resp, body = self.delete(uri)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_router_interfaces(self, uuid):
-        uri = '%s/ports?device_id=%s' % (self.uri_prefix, uuid)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def update_agent(self, agent_id, agent_info):
-        """
-        :param agent_info: Agent update information.
-        E.g {"admin_state_up": True}
-        """
-        uri = '%s/agents/%s' % (self.uri_prefix, agent_id)
-        agent = {"agent": agent_info}
-        body = json.dumps(agent)
-        resp, body = self.put(uri, body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_pools_hosted_by_one_lbaas_agent(self, agent_id):
-        uri = '%s/agents/%s/loadbalancer-pools' % (self.uri_prefix, agent_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def show_lbaas_agent_hosting_pool(self, pool_id):
-        uri = ('%s/lb/pools/%s/loadbalancer-agent' %
-               (self.uri_prefix, pool_id))
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_routers_on_l3_agent(self, agent_id):
-        uri = '%s/agents/%s/l3-routers' % (self.uri_prefix, agent_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_l3_agents_hosting_router(self, router_id):
-        uri = '%s/routers/%s/l3-agents' % (self.uri_prefix, router_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def add_router_to_l3_agent(self, agent_id, router_id):
-        uri = '%s/agents/%s/l3-routers' % (self.uri_prefix, agent_id)
-        post_body = {"router_id": router_id}
-        body = json.dumps(post_body)
-        resp, body = self.post(uri, body)
-        self.expected_success(201, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def remove_router_from_l3_agent(self, agent_id, router_id):
-        uri = '%s/agents/%s/l3-routers/%s' % (
-            self.uri_prefix, agent_id, router_id)
-        resp, body = self.delete(uri)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_dhcp_agent_hosting_network(self, network_id):
-        uri = '%s/networks/%s/dhcp-agents' % (self.uri_prefix, network_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_networks_hosted_by_one_dhcp_agent(self, agent_id):
-        uri = '%s/agents/%s/dhcp-networks' % (self.uri_prefix, agent_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def remove_network_from_dhcp_agent(self, agent_id, network_id):
-        uri = '%s/agents/%s/dhcp-networks/%s' % (self.uri_prefix, agent_id,
-                                                 network_id)
-        resp, body = self.delete(uri)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def create_ikepolicy(self, name, **kwargs):
-        post_body = {
-            "ikepolicy": {
-                "name": name,
-            }
-        }
-        for key, val in kwargs.items():
-            post_body['ikepolicy'][key] = val
-        body = json.dumps(post_body)
-        uri = '%s/vpn/ikepolicies' % (self.uri_prefix)
-        resp, body = self.post(uri, body)
-        self.expected_success(201, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def update_extra_routes(self, router_id, nexthop, destination):
-        uri = '%s/routers/%s' % (self.uri_prefix, router_id)
-        put_body = {
-            'router': {
-                'routes': [{'nexthop': nexthop,
-                            "destination": destination}]
-            }
-        }
-        body = json.dumps(put_body)
-        resp, body = self.put(uri, body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def delete_extra_routes(self, router_id):
-        uri = '%s/routers/%s' % (self.uri_prefix, router_id)
-        null_routes = None
-        put_body = {
-            'router': {
-                'routes': null_routes
-            }
-        }
-        body = json.dumps(put_body)
-        resp, body = self.put(uri, body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def list_lb_pool_stats(self, pool_id):
-        uri = '%s/lb/pools/%s/stats' % (self.uri_prefix, pool_id)
-        resp, body = self.get(uri)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def add_dhcp_agent_to_network(self, agent_id, network_id):
-        post_body = {'network_id': network_id}
-        body = json.dumps(post_body)
-        uri = '%s/agents/%s/dhcp-networks' % (self.uri_prefix, agent_id)
-        resp, body = self.post(uri, body)
-        self.expected_success(201, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def insert_firewall_rule_in_policy(self, firewall_policy_id,
-                                       firewall_rule_id, insert_after="",
-                                       insert_before=""):
-        uri = '%s/fw/firewall_policies/%s/insert_rule' % (self.uri_prefix,
-                                                          firewall_policy_id)
-        body = {
-            "firewall_rule_id": firewall_rule_id,
-            "insert_after": insert_after,
-            "insert_before": insert_before
-        }
-        body = json.dumps(body)
-        resp, body = self.put(uri, body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
-
-    def remove_firewall_rule_from_policy(self, firewall_policy_id,
-                                         firewall_rule_id):
-        uri = '%s/fw/firewall_policies/%s/remove_rule' % (self.uri_prefix,
-                                                          firewall_policy_id)
-        update_body = {"firewall_rule_id": firewall_rule_id}
-        update_body = json.dumps(update_body)
-        resp, body = self.put(uri, update_body)
-        self.expected_success(200, resp.status)
-        body = json.loads(body)
-        return rest_client.ResponseBody(resp, body)
diff --git a/tests/tempest/requirements.txt b/tests/tempest/requirements.txt
deleted file mode 100644
index b6c5604..0000000
--- a/tests/tempest/requirements.txt
+++ /dev/null
@@ -1,7 +0,0 @@
-# Additional requirements for api tests
-
-# The order of packages is significant, because pip processes them in the order
-# of appearance. Changing the order has an impact on the overall integration
-# process, which may cause wedges in the gate later.
-
-tempest>=11.0.0,<12.1.0  # Apache-2.0
diff --git a/tests/tempest/v1/__init__.py b/tests/tempest/v1/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v1/api/__init__.py b/tests/tempest/v1/api/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v1/api/admin/__init__.py b/tests/tempest/v1/api/admin/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v1/api/admin/test_lbaas_agent_scheduler.py b/tests/tempest/v1/api/admin/test_lbaas_agent_scheduler.py
deleted file mode 100644
index 25280ac..0000000
--- a/tests/tempest/v1/api/admin/test_lbaas_agent_scheduler.py
+++ /dev/null
@@ -1,75 +0,0 @@
-# Copyright 2013 IBM Corp.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-from tempest.lib.common.utils import data_utils
-
-from neutron_lbaas.tests.tempest.v1.api import base
-
-
-class LBaaSAgentSchedulerTestJSON(base.BaseAdminNetworkTest):
-
-    """
-    Tests the following operations in the Neutron API using the REST client for
-    Neutron:
-
-        List pools the given LBaaS agent is hosting.
-        Show a LBaaS agent hosting the given pool.
-
-    v2.0 of the Neutron API is assumed. It is also assumed that the following
-    options are defined in the [networki-feature-enabled] section of
-    etc/tempest.conf:
-
-        api_extensions
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(LBaaSAgentSchedulerTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas_agent_scheduler', 'network'):
-            msg = "LBaaS Agent Scheduler Extension not enabled."
-            raise cls.skipException(msg)
-        cls.network = cls.create_network()
-        cls.subnet = cls.create_subnet(cls.network)
-        pool_name = data_utils.rand_name('pool-')
-        cls.pool = cls.create_pool(pool_name, "ROUND_ROBIN",
-                                   "HTTP", cls.subnet)
-
-    @test.attr(type='smoke')
-    @test.idempotent_id('e5ea8b15-4f44-4350-963c-e0fcb533ee79')
-    def test_list_pools_on_lbaas_agent(self):
-        found = False
-        body = self.admin_client.list_agents(
-            agent_type="Loadbalancer agent")
-        agents = body['agents']
-        for a in agents:
-            msg = 'Load Balancer agent expected'
-            self.assertEqual(a['agent_type'], 'Loadbalancer agent', msg)
-            body = (
-                self.admin_client.list_pools_hosted_by_one_lbaas_agent(
-                    a['id']))
-            pools = body['pools']
-            if self.pool['id'] in [p['id'] for p in pools]:
-                found = True
-        msg = 'Unable to find Load Balancer agent hosting pool'
-        self.assertTrue(found, msg)
-
-    @test.attr(type='smoke')
-    @test.idempotent_id('e2745593-fd79-4b98-a262-575fd7865796')
-    def test_show_lbaas_agent_hosting_pool(self):
-        body = self.admin_client.show_lbaas_agent_hosting_pool(
-            self.pool['id'])
-        self.assertEqual('Loadbalancer agent', body['agent']['agent_type'])
diff --git a/tests/tempest/v1/api/admin/test_load_balancer_admin_actions.py b/tests/tempest/v1/api/admin/test_load_balancer_admin_actions.py
deleted file mode 100644
index 37b7533..0000000
--- a/tests/tempest/v1/api/admin/test_load_balancer_admin_actions.py
+++ /dev/null
@@ -1,117 +0,0 @@
-# Copyright 2014 Mirantis.inc
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-from tempest.lib.common.utils import data_utils
-from tempest.lib import decorators
-
-from neutron_lbaas.tests.tempest.v1.api import base
-
-
-class LoadBalancerAdminTestJSON(base.BaseAdminNetworkTest):
-
-    """
-    Test admin actions for load balancer.
-
-    Create VIP for another tenant
-    Create health monitor for another tenant
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(LoadBalancerAdminTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        cls.force_tenant_isolation = True
-        manager = cls.get_client_manager()
-        cls.client = manager.network_client
-        cls.tenant_id = manager.credentials.tenant_id
-        cls.network = cls.create_network()
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.pool = cls.create_pool(data_utils.rand_name('pool-'),
-                                   "ROUND_ROBIN", "HTTP", cls.subnet)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('6b0a20d8-4fcd-455e-b54f-ec4db5199518')
-    def test_create_vip_as_admin_for_another_tenant(self):
-        name = data_utils.rand_name('vip-')
-        body = self.admin_client.create_pool(
-            name=data_utils.rand_name('pool-'),
-            lb_method="ROUND_ROBIN",
-            protocol="HTTP",
-            subnet_id=self.subnet['id'],
-            tenant_id=self.tenant_id)
-        pool = body['pool']
-        self.addCleanup(self.admin_client.delete_pool, pool['id'])
-        body = self.admin_client.create_vip(name=name,
-                                            protocol="HTTP",
-                                            protocol_port=80,
-                                            subnet_id=self.subnet['id'],
-                                            pool_id=pool['id'],
-                                            tenant_id=self.tenant_id)
-        vip = body['vip']
-        self.addCleanup(self.admin_client.delete_vip, vip['id'])
-        self.assertIsNotNone(vip['id'])
-        self.assertEqual(self.tenant_id, vip['tenant_id'])
-        body = self.client.show_vip(vip['id'])
-        show_vip = body['vip']
-        self.assertEqual(vip['id'], show_vip['id'])
-        self.assertEqual(vip['name'], show_vip['name'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('74552cfc-ab78-4fb6-825b-f67bca379921')
-    def test_create_health_monitor_as_admin_for_another_tenant(self):
-        body = (
-            self.admin_client.create_health_monitor(delay=4,
-                                                    max_retries=3,
-                                                    type="TCP",
-                                                    timeout=1,
-                                                    tenant_id=self.tenant_id))
-        health_monitor = body['health_monitor']
-        self.addCleanup(self.admin_client.delete_health_monitor,
-                        health_monitor['id'])
-        self.assertIsNotNone(health_monitor['id'])
-        self.assertEqual(self.tenant_id, health_monitor['tenant_id'])
-        body = self.client.show_health_monitor(health_monitor['id'])
-        show_health_monitor = body['health_monitor']
-        self.assertEqual(health_monitor['id'], show_health_monitor['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('266a192d-3c22-46c4-a8fb-802450301e82')
-    def test_create_pool_from_admin_user_other_tenant(self):
-        body = self.admin_client.create_pool(
-            name=data_utils.rand_name('pool-'),
-            lb_method="ROUND_ROBIN",
-            protocol="HTTP",
-            subnet_id=self.subnet['id'],
-            tenant_id=self.tenant_id)
-        pool = body['pool']
-        self.addCleanup(self.admin_client.delete_pool, pool['id'])
-        self.assertIsNotNone(pool['id'])
-        self.assertEqual(self.tenant_id, pool['tenant_id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('158bb272-b9ed-4cfc-803c-661dac46f783')
-    def test_create_member_from_admin_user_other_tenant(self):
-        body = self.admin_client.create_member(address="10.0.9.47",
-                                               protocol_port=80,
-                                               pool_id=self.pool['id'],
-                                               tenant_id=self.tenant_id)
-        member = body['member']
-        self.addCleanup(self.admin_client.delete_member, member['id'])
-        self.assertIsNotNone(member['id'])
-        self.assertEqual(self.tenant_id, member['tenant_id'])
diff --git a/tests/tempest/v1/api/admin/test_quotas.py b/tests/tempest/v1/api/admin/test_quotas.py
deleted file mode 100644
index 6912c22..0000000
--- a/tests/tempest/v1/api/admin/test_quotas.py
+++ /dev/null
@@ -1,96 +0,0 @@
-# Copyright 2013 OpenStack Foundation
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-from tempest.lib.common.utils import data_utils
-
-from neutron_lbaas.tests.tempest.v1.api import base
-
-
-class QuotasTest(base.BaseAdminNetworkTest):
-    _interface = 'json'
-
-    """
-    Tests the following operations in the Neutron API using the REST client for
-    Neutron:
-
-        list quotas for tenants who have non-default quota values
-        show quotas for a specified tenant
-        update quotas for a specified tenant
-        reset quotas to default values for a specified tenant
-
-    v2.0 of the API is assumed.
-    It is also assumed that the per-tenant quota extension API is configured
-    in /etc/neutron/neutron.conf as follows:
-
-        quota_driver = neutron.db.quota_db.DbQuotaDriver
-    """
-
-    @classmethod
-    def skip_checks(cls):
-        super(QuotasTest, cls).skip_checks()
-        if not test.is_extension_enabled('quotas', 'network'):
-            msg = "quotas extension not enabled."
-            raise cls.skipException(msg)
-
-    def _check_quotas(self, new_quotas):
-        # Add a tenant to conduct the test
-        test_tenant = data_utils.rand_name('test_tenant_')
-        test_description = data_utils.rand_name('desc_')
-        tenant = self.identity_admin_client.create_tenant(
-            name=test_tenant,
-            description=test_description)
-        tenant_id = tenant['tenant']['id']
-        self.addCleanup(self.identity_admin_client.delete_tenant, tenant_id)
-
-        # Change quotas for tenant
-        quota_set = self.admin_client.update_quotas(tenant_id,
-                                                    **new_quotas)
-        self.addCleanup(self.admin_client.reset_quotas, tenant_id)
-        for key, value in new_quotas.iteritems():
-            self.assertEqual(value, quota_set[key])
-
-        # Confirm our tenant is listed among tenants with non default quotas
-        non_default_quotas = self.admin_client.list_quotas()
-        found = False
-        for qs in non_default_quotas['quotas']:
-            if qs['tenant_id'] == tenant_id:
-                found = True
-        self.assertTrue(found)
-
-        # Confirm from API quotas were changed as requested for tenant
-        quota_set = self.admin_client.show_quotas(tenant_id)
-        quota_set = quota_set['quota']
-        for key, value in new_quotas.iteritems():
-            self.assertEqual(value, quota_set[key])
-
-        # Reset quotas to default and confirm
-        self.admin_client.reset_quotas(tenant_id)
-        non_default_quotas = self.admin_client.list_quotas()
-        for q in non_default_quotas['quotas']:
-            self.assertNotEqual(tenant_id, q['tenant_id'])
-
-    @test.attr(type='gate')
-    def test_quotas(self):
-        new_quotas = {'network': 0, 'security_group': 0}
-        self._check_quotas(new_quotas)
-
-    @test.requires_ext(extension='lbaas', service='network')
-    @test.attr(type='gate')
-    def test_lbaas_quotas(self):
-        new_quotas = {'vip': 1, 'pool': 2,
-                      'member': 3, 'health_monitor': 4}
-        self._check_quotas(new_quotas)
diff --git a/tests/tempest/v1/api/base.py b/tests/tempest/v1/api/base.py
deleted file mode 100644
index 16f80f0..0000000
--- a/tests/tempest/v1/api/base.py
+++ /dev/null
@@ -1,479 +0,0 @@
-# Copyright 2012 OpenStack Foundation
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import netaddr
-from tempest import config
-from tempest import exceptions
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as lib_exc
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v1.api import clients
-
-CONF = config.CONF
-
-
-class BaseNetworkTest(test.BaseTestCase):
-
-    """
-    Base class for the Neutron tests that use the Tempest Neutron REST client
-
-    Per the Neutron API Guide, API v1.x was removed from the source code tree
-    (docs.openstack.org/api/openstack-network/2.0/content/Overview-d1e71.html)
-    Therefore, v2.x of the Neutron API is assumed. It is also assumed that the
-    following options are defined in the [network] section of etc/tempest.conf:
-
-        tenant_network_cidr with a block of cidr's from which smaller blocks
-        can be allocated for tenant networks
-
-        tenant_network_mask_bits with the mask bits to be used to partition the
-        block defined by tenant-network_cidr
-
-    Finally, it is assumed that the following option is defined in the
-    [service_available] section of etc/tempest.conf
-
-        neutron as True
-    """
-
-    force_tenant_isolation = False
-    credentials = ['primary']
-
-    # Default to ipv4.
-    _ip_version = 4
-
-    @classmethod
-    def get_client_manager(cls, credential_type=None, roles=None,
-                           force_new=None):
-        manager = test.BaseTestCase.get_client_manager(
-            credential_type=credential_type,
-            roles=roles,
-            force_new=force_new)
-        # Neutron uses a different clients manager than the one in the Tempest
-        return clients.Manager(manager.credentials)
-
-    @classmethod
-    def skip_checks(cls):
-        # Create no network resources for these test.
-        cls.set_network_resources()
-        super(BaseNetworkTest, cls).resource_setup()
-        if not CONF.service_available.neutron:
-            raise cls.skipException("Neutron support is required")
-        if cls._ip_version == 6 and not CONF.network_feature_enabled.ipv6:
-            raise cls.skipException("IPv6 Tests are disabled.")
-
-    @classmethod
-    def setup_credentials(cls):
-        # Create no network resources for these test.
-        cls.set_network_resources()
-        super(BaseNetworkTest, cls).setup_credentials()
-
-    @classmethod
-    def setup_clients(cls):
-        super(BaseNetworkTest, cls).setup_clients()
-        cls.client = cls.os.network_client
-
-    @classmethod
-    def resource_setup(cls):
-        cls.networks = []
-        cls.shared_networks = []
-        cls.subnets = []
-        cls.ports = []
-        cls.routers = []
-        cls.pools = []
-        cls.vips = []
-        cls.members = []
-        cls.health_monitors = []
-        cls.vpnservices = []
-        cls.ikepolicies = []
-        cls.floating_ips = []
-        cls.metering_labels = []
-        cls.metering_label_rules = []
-        cls.fw_rules = []
-        cls.fw_policies = []
-        cls.ipsecpolicies = []
-        cls.ethertype = "IPv" + str(cls._ip_version)
-
-    @classmethod
-    def resource_cleanup(cls):
-        if CONF.service_available.neutron:
-            # Clean up ipsec policies
-            for ipsecpolicy in cls.ipsecpolicies:
-                cls._try_delete_resource(cls.client.delete_ipsecpolicy,
-                                         ipsecpolicy['id'])
-            # Clean up firewall policies
-            for fw_policy in cls.fw_policies:
-                cls._try_delete_resource(cls.client.delete_firewall_policy,
-                                         fw_policy['id'])
-            # Clean up firewall rules
-            for fw_rule in cls.fw_rules:
-                cls._try_delete_resource(cls.client.delete_firewall_rule,
-                                         fw_rule['id'])
-            # Clean up ike policies
-            for ikepolicy in cls.ikepolicies:
-                cls._try_delete_resource(cls.client.delete_ikepolicy,
-                                         ikepolicy['id'])
-            # Clean up vpn services
-            for vpnservice in cls.vpnservices:
-                cls._try_delete_resource(cls.client.delete_vpnservice,
-                                         vpnservice['id'])
-            # Clean up floating IPs
-            for floating_ip in cls.floating_ips:
-                cls._try_delete_resource(cls.client.delete_floatingip,
-                                         floating_ip['id'])
-            # Clean up routers
-            for router in cls.routers:
-                cls._try_delete_resource(cls.delete_router,
-                                         router)
-
-            # Clean up health monitors
-            for health_monitor in cls.health_monitors:
-                cls._try_delete_resource(cls.client.delete_health_monitor,
-                                         health_monitor['id'])
-            # Clean up members
-            for member in cls.members:
-                cls._try_delete_resource(cls.client.delete_member,
-                                         member['id'])
-            # Clean up vips
-            for vip in cls.vips:
-                cls._try_delete_resource(cls.client.delete_vip,
-                                         vip['id'])
-            # Clean up pools
-            for pool in cls.pools:
-                cls._try_delete_resource(cls.client.delete_pool,
-                                         pool['id'])
-            # Clean up metering label rules
-            for metering_label_rule in cls.metering_label_rules:
-                cls._try_delete_resource(
-                    cls.admin_client.delete_metering_label_rule,
-                    metering_label_rule['id'])
-            # Clean up metering labels
-            for metering_label in cls.metering_labels:
-                cls._try_delete_resource(
-                    cls.admin_client.delete_metering_label,
-                    metering_label['id'])
-            # Clean up ports
-            for port in cls.ports:
-                cls._try_delete_resource(cls.client.delete_port,
-                                         port['id'])
-            # Clean up subnets
-            for subnet in cls.subnets:
-                cls._try_delete_resource(cls.client.delete_subnet,
-                                         subnet['id'])
-            # Clean up networks
-            for network in cls.networks:
-                cls._try_delete_resource(cls.client.delete_network,
-                                         network['id'])
-
-            # Clean up shared networks
-            for network in cls.shared_networks:
-                cls._try_delete_resource(cls.admin_client.delete_network,
-                                         network['id'])
-
-        super(BaseNetworkTest, cls).resource_cleanup()
-
-    @classmethod
-    def _try_delete_resource(self, delete_callable, *args, **kwargs):
-        """Cleanup resources in case of test-failure
-
-        Some resources are explicitly deleted by the test.
-        If the test failed to delete a resource, this method will execute
-        the appropriate delete methods. Otherwise, the method ignores NotFound
-        exceptions thrown for resources that were correctly deleted by the
-        test.
-
-        :param delete_callable: delete method
-        :param args: arguments for delete method
-        :param kwargs: keyword arguments for delete method
-        """
-        try:
-            delete_callable(*args, **kwargs)
-        # if resource is not found, this means it was deleted in the test
-        except lib_exc.NotFound:
-            pass
-
-    @classmethod
-    def create_network(cls, network_name=None):
-        """Wrapper utility that returns a test network."""
-        network_name = network_name or data_utils.rand_name('test-network-')
-
-        body = cls.client.create_network(name=network_name)
-        network = body['network']
-        cls.networks.append(network)
-        return network
-
-    @classmethod
-    def create_shared_network(cls, network_name=None):
-        network_name = network_name or data_utils.rand_name('sharednetwork-')
-        post_body = {'name': network_name, 'shared': True}
-        body = cls.admin_client.create_network(**post_body)
-        network = body['network']
-        cls.shared_networks.append(network)
-        return network
-
-    @classmethod
-    def create_subnet(cls, network, gateway='', cidr=None, mask_bits=None,
-                      ip_version=None, client=None, **kwargs):
-        """Wrapper utility that returns a test subnet."""
-
-        # allow tests to use admin client
-        if not client:
-            client = cls.client
-
-        # The cidr and mask_bits depend on the ip version.
-        ip_version = ip_version if ip_version is not None else cls._ip_version
-        gateway_not_set = gateway == ''
-        if ip_version == 4:
-            cidr = cidr or netaddr.IPNetwork(CONF.network.project_network_cidr)
-            mask_bits = mask_bits or CONF.network.project_network_mask_bits
-        elif ip_version == 6:
-            cidr = (
-                cidr or netaddr.IPNetwork(
-                    CONF.network.project_network_v6_cidr))
-            mask_bits = mask_bits or CONF.network.project_network_v6_mask_bits
-        # Find a cidr that is not in use yet and create a subnet with it
-        for subnet_cidr in cidr.subnet(mask_bits):
-            if gateway_not_set:
-                gateway_ip = str(netaddr.IPAddress(subnet_cidr) + 1)
-            else:
-                gateway_ip = gateway
-            try:
-                body = client.create_subnet(
-                    network_id=network['id'],
-                    cidr=str(subnet_cidr),
-                    ip_version=ip_version,
-                    gateway_ip=gateway_ip,
-                    **kwargs)
-                break
-            except lib_exc.BadRequest as e:
-                is_overlapping_cidr = 'overlaps with another subnet' in str(e)
-                if not is_overlapping_cidr:
-                    raise
-        else:
-            message = 'Available CIDR for subnet creation could not be found'
-            raise exceptions.BuildErrorException(message)
-        subnet = body['subnet']
-        cls.subnets.append(subnet)
-        return subnet
-
-    @classmethod
-    def create_port(cls, network, **kwargs):
-        """Wrapper utility that returns a test port."""
-        body = cls.client.create_port(network_id=network['id'],
-                                      **kwargs)
-        port = body['port']
-        cls.ports.append(port)
-        return port
-
-    @classmethod
-    def update_port(cls, port, **kwargs):
-        """Wrapper utility that updates a test port."""
-        body = cls.client.update_port(port['id'],
-                                      **kwargs)
-        return body['port']
-
-    @classmethod
-    def create_router(cls, router_name=None, admin_state_up=False,
-                      external_network_id=None, enable_snat=None,
-                      **kwargs):
-        ext_gw_info = {}
-        if external_network_id:
-            ext_gw_info['network_id'] = external_network_id
-        if enable_snat:
-            ext_gw_info['enable_snat'] = enable_snat
-        body = cls.client.create_router(
-            router_name, external_gateway_info=ext_gw_info,
-            admin_state_up=admin_state_up, **kwargs)
-        router = body['router']
-        cls.routers.append(router)
-        return router
-
-    @classmethod
-    def create_floatingip(cls, external_network_id):
-        """Wrapper utility that returns a test floating IP."""
-        body = cls.client.create_floatingip(
-            floating_network_id=external_network_id)
-        fip = body['floatingip']
-        cls.floating_ips.append(fip)
-        return fip
-
-    @classmethod
-    def create_pool(cls, name, lb_method, protocol, subnet):
-        """Wrapper utility that returns a test pool."""
-        body = cls.client.create_pool(
-            name=name,
-            lb_method=lb_method,
-            protocol=protocol,
-            subnet_id=subnet['id'])
-        pool = body['pool']
-        cls.pools.append(pool)
-        return pool
-
-    @classmethod
-    def update_pool(cls, name):
-        """Wrapper utility that returns a test pool."""
-        body = cls.client.update_pool(name=name)
-        pool = body['pool']
-        return pool
-
-    @classmethod
-    def create_vip(cls, name, protocol, protocol_port, subnet, pool):
-        """Wrapper utility that returns a test vip."""
-        body = cls.client.create_vip(name=name,
-                                     protocol=protocol,
-                                     protocol_port=protocol_port,
-                                     subnet_id=subnet['id'],
-                                     pool_id=pool['id'])
-        vip = body['vip']
-        cls.vips.append(vip)
-        return vip
-
-    @classmethod
-    def update_vip(cls, name):
-        body = cls.client.update_vip(name=name)
-        vip = body['vip']
-        return vip
-
-    @classmethod
-    def create_member(cls, protocol_port, pool, ip_version=None):
-        """Wrapper utility that returns a test member."""
-        ip_version = ip_version if ip_version is not None else cls._ip_version
-        member_address = "fd00::abcd" if ip_version == 6 else "10.0.9.46"
-        body = cls.client.create_member(address=member_address,
-                                        protocol_port=protocol_port,
-                                        pool_id=pool['id'])
-        member = body['member']
-        cls.members.append(member)
-        return member
-
-    @classmethod
-    def update_member(cls, admin_state_up):
-        body = cls.client.update_member(admin_state_up=admin_state_up)
-        member = body['member']
-        return member
-
-    @classmethod
-    def create_health_monitor(cls, delay, max_retries, Type, timeout):
-        """Wrapper utility that returns a test health monitor."""
-        body = cls.client.create_health_monitor(delay=delay,
-                                                max_retries=max_retries,
-                                                type=Type,
-                                                timeout=timeout)
-        health_monitor = body['health_monitor']
-        cls.health_monitors.append(health_monitor)
-        return health_monitor
-
-    @classmethod
-    def update_health_monitor(cls, admin_state_up):
-        body = cls.client.update_vip(admin_state_up=admin_state_up)
-        health_monitor = body['health_monitor']
-        return health_monitor
-
-    @classmethod
-    def create_router_interface(cls, router_id, subnet_id):
-        """Wrapper utility that returns a router interface."""
-        interface = cls.client.add_router_interface_with_subnet_id(
-            router_id, subnet_id)
-        return interface
-
-    @classmethod
-    def create_vpnservice(cls, subnet_id, router_id):
-        """Wrapper utility that returns a test vpn service."""
-        body = cls.client.create_vpnservice(
-            subnet_id=subnet_id, router_id=router_id, admin_state_up=True,
-            name=data_utils.rand_name("vpnservice-"))
-        vpnservice = body['vpnservice']
-        cls.vpnservices.append(vpnservice)
-        return vpnservice
-
-    @classmethod
-    def create_ikepolicy(cls, name):
-        """Wrapper utility that returns a test ike policy."""
-        body = cls.client.create_ikepolicy(name=name)
-        ikepolicy = body['ikepolicy']
-        cls.ikepolicies.append(ikepolicy)
-        return ikepolicy
-
-    @classmethod
-    def create_firewall_rule(cls, action, protocol):
-        """Wrapper utility that returns a test firewall rule."""
-        body = cls.client.create_firewall_rule(
-            name=data_utils.rand_name("fw-rule"),
-            action=action,
-            protocol=protocol)
-        fw_rule = body['firewall_rule']
-        cls.fw_rules.append(fw_rule)
-        return fw_rule
-
-    @classmethod
-    def create_firewall_policy(cls):
-        """Wrapper utility that returns a test firewall policy."""
-        body = cls.client.create_firewall_policy(
-            name=data_utils.rand_name("fw-policy"))
-        fw_policy = body['firewall_policy']
-        cls.fw_policies.append(fw_policy)
-        return fw_policy
-
-    @classmethod
-    def delete_router(cls, router):
-        body = cls.client.list_router_interfaces(router['id'])
-        interfaces = body['ports']
-        for i in interfaces:
-            try:
-                cls.client.remove_router_interface_with_subnet_id(
-                    router['id'], i['fixed_ips'][0]['subnet_id'])
-            except lib_exc.NotFound:
-                pass
-        cls.client.delete_router(router['id'])
-
-    @classmethod
-    def create_ipsecpolicy(cls, name):
-        """Wrapper utility that returns a test ipsec policy."""
-        body = cls.client.create_ipsecpolicy(name=name)
-        ipsecpolicy = body['ipsecpolicy']
-        cls.ipsecpolicies.append(ipsecpolicy)
-        return ipsecpolicy
-
-
-class BaseAdminNetworkTest(BaseNetworkTest):
-
-    credentials = ['primary', 'admin']
-
-    @classmethod
-    def setup_clients(cls):
-        super(BaseAdminNetworkTest, cls).setup_clients()
-        cls.admin_client = cls.os_adm.network_client
-        cls.identity_admin_client = cls.os_adm.tenants_client
-
-    @classmethod
-    def create_metering_label(cls, name, description):
-        """Wrapper utility that returns a test metering label."""
-        body = cls.admin_client.create_metering_label(
-            description=description,
-            name=data_utils.rand_name("metering-label"))
-        metering_label = body['metering_label']
-        cls.metering_labels.append(metering_label)
-        return metering_label
-
-    @classmethod
-    def create_metering_label_rule(cls, remote_ip_prefix, direction,
-                                   metering_label_id):
-        """Wrapper utility that returns a test metering label rule."""
-        body = cls.admin_client.create_metering_label_rule(
-            remote_ip_prefix=remote_ip_prefix, direction=direction,
-            metering_label_id=metering_label_id)
-        metering_label_rule = body['metering_label_rule']
-        cls.metering_label_rules.append(metering_label_rule)
-        return metering_label_rule
diff --git a/tests/tempest/v1/api/clients.py b/tests/tempest/v1/api/clients.py
deleted file mode 100644
index e3e71b6..0000000
--- a/tests/tempest/v1/api/clients.py
+++ /dev/null
@@ -1,88 +0,0 @@
-# Copyright 2012 OpenStack Foundation
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest.common import cred_provider
-from tempest import config
-from tempest import manager
-from tempest.services.identity.v2.json.tenants_client import \
-    TenantsClient
-
-from neutron_lbaas.tests.tempest.lib.services.network.json.network_client import \
-    NetworkClientJSON
-
-
-CONF = config.CONF
-
-
-class Manager(manager.Manager):
-
-    """
-    Top level manager for OpenStack tempest clients
-    """
-
-    default_params = {
-        'disable_ssl_certificate_validation':
-            CONF.identity.disable_ssl_certificate_validation,
-        'ca_certs': CONF.identity.ca_certificates_file,
-        'trace_requests': CONF.debug.trace_requests
-    }
-
-    # NOTE: Tempest uses timeout values of compute API if project specific
-    # timeout values don't exist.
-    default_params_with_timeout_values = {
-        'build_interval': CONF.compute.build_interval,
-        'build_timeout': CONF.compute.build_timeout
-    }
-    default_params_with_timeout_values.update(default_params)
-
-    def __init__(self, credentials=None, service=None):
-        super(Manager, self).__init__(credentials=credentials)
-
-        self._set_identity_clients()
-
-        self.network_client = NetworkClientJSON(
-            self.auth_provider,
-            CONF.network.catalog_type,
-            CONF.network.region or CONF.identity.region,
-            endpoint_type=CONF.network.endpoint_type,
-            build_interval=CONF.network.build_interval,
-            build_timeout=CONF.network.build_timeout,
-            **self.default_params)
-
-    def _set_identity_clients(self):
-        params = {
-            'service': CONF.identity.catalog_type,
-            'region': CONF.identity.region,
-        }
-        params.update(self.default_params_with_timeout_values)
-        params_v2_admin = params.copy()
-        params_v2_admin['endpoint_type'] = CONF.identity.v2_admin_endpoint_type
-        self.tenants_client = TenantsClient(
-            self.auth_provider, **params_v2_admin)
-
-
-class AdminManager(Manager):
-
-    """
-    Manager object that uses the admin credentials for its
-    managed client objects
-    """
-
-    def __init__(self, service=None):
-        super(AdminManager, self).__init__(
-            credentials=cred_provider.get_configured_credentials(
-                'identity_admin'),
-            service=service)
diff --git a/tests/tempest/v1/api/test_load_balancer.py b/tests/tempest/v1/api/test_load_balancer.py
deleted file mode 100644
index 514fba9..0000000
--- a/tests/tempest/v1/api/test_load_balancer.py
+++ /dev/null
@@ -1,454 +0,0 @@
-# Copyright 2013 OpenStack Foundation
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-from tempest.lib.common.utils import data_utils
-from tempest.lib import decorators
-
-from neutron_lbaas.tests.tempest.v1.api import base
-
-
-class LoadBalancerTestJSON(base.BaseNetworkTest):
-
-    """
-    Tests the following operations in the Neutron API using the REST client for
-    Neutron:
-
-        create vIP, and Pool
-        show vIP
-        list vIP
-        update vIP
-        delete vIP
-        update pool
-        delete pool
-        show pool
-        list pool
-        health monitoring operations
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(LoadBalancerTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        cls.network = cls.create_network()
-        cls.name = cls.network['name']
-        cls.subnet = cls.create_subnet(cls.network)
-        pool_name = data_utils.rand_name('pool-')
-        vip_name = data_utils.rand_name('vip-')
-        cls.pool = cls.create_pool(pool_name, "ROUND_ROBIN",
-                                   "HTTP", cls.subnet)
-        cls.vip = cls.create_vip(name=vip_name,
-                                 protocol="HTTP",
-                                 protocol_port=80,
-                                 subnet=cls.subnet,
-                                 pool=cls.pool)
-        cls.member = cls.create_member(80, cls.pool, cls._ip_version)
-        cls.member_address = ("10.0.9.47" if cls._ip_version == 4
-                              else "2015::beef")
-        cls.health_monitor = cls.create_health_monitor(delay=4,
-                                                       max_retries=3,
-                                                       Type="TCP",
-                                                       timeout=1)
-
-    def _check_list_with_filter(self, obj_name, attr_exceptions, **kwargs):
-        create_obj = getattr(self.client, 'create_' + obj_name)
-        delete_obj = getattr(self.client, 'delete_' + obj_name)
-        list_objs = getattr(self.client, 'list_' + obj_name + 's')
-
-        body = create_obj(**kwargs)
-        obj = body[obj_name]
-        self.addCleanup(delete_obj, obj['id'])
-        for key, value in obj.iteritems():
-            # It is not relevant to filter by all arguments. That is why
-            # there is a list of attr to except
-            if key not in attr_exceptions:
-                body = list_objs(**{key: value})
-                objs = [v[key] for v in body[obj_name + 's']]
-                self.assertIn(value, objs)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('c96dbfab-4a80-4e74-a535-e950b5bedd47')
-    def test_list_vips(self):
-        # Verify the vIP exists in the list of all vIPs
-        body = self.client.list_vips()
-        vips = body['vips']
-        self.assertIn(self.vip['id'], [v['id'] for v in vips])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('b8853f65-5089-4e69-befd-041a143427ff')
-    def test_list_vips_with_filter(self):
-        name = data_utils.rand_name('vip-')
-        body = self.client.create_pool(name=data_utils.rand_name("pool-"),
-                                       lb_method="ROUND_ROBIN",
-                                       protocol="HTTPS",
-                                       subnet_id=self.subnet['id'])
-        pool = body['pool']
-        self.addCleanup(self.client.delete_pool, pool['id'])
-        attr_exceptions = ['status', 'session_persistence',
-                           'status_description']
-        self._check_list_with_filter(
-            'vip', attr_exceptions, name=name, protocol="HTTPS",
-            protocol_port=81, subnet_id=self.subnet['id'], pool_id=pool['id'],
-            description=data_utils.rand_name('description-'),
-            admin_state_up=False)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('27f56083-9af9-4a48-abe9-ca1bcc6c9035')
-    def test_create_update_delete_pool_vip(self):
-        # Creates a vip
-        name = data_utils.rand_name('vip-')
-        address = self.subnet['allocation_pools'][0]['end']
-        body = self.client.create_pool(
-            name=data_utils.rand_name("pool-"),
-            lb_method='ROUND_ROBIN',
-            protocol='HTTP',
-            subnet_id=self.subnet['id'])
-        pool = body['pool']
-        body = self.client.create_vip(name=name,
-                                      protocol="HTTP",
-                                      protocol_port=80,
-                                      subnet_id=self.subnet['id'],
-                                      pool_id=pool['id'],
-                                      address=address)
-        vip = body['vip']
-        vip_id = vip['id']
-        # Confirm VIP's address correctness with a show
-        body = self.client.show_vip(vip_id)
-        vip = body['vip']
-        self.assertEqual(address, vip['address'])
-        # Verification of vip update
-        new_name = "New_vip"
-        new_description = "New description"
-        persistence_type = "HTTP_COOKIE"
-        update_data = {"session_persistence": {
-            "type": persistence_type}}
-        body = self.client.update_vip(vip_id,
-                                      name=new_name,
-                                      description=new_description,
-                                      connection_limit=10,
-                                      admin_state_up=False,
-                                      **update_data)
-        updated_vip = body['vip']
-        self.assertEqual(new_name, updated_vip['name'])
-        self.assertEqual(new_description, updated_vip['description'])
-        self.assertEqual(10, updated_vip['connection_limit'])
-        self.assertFalse(updated_vip['admin_state_up'])
-        self.assertEqual(persistence_type,
-                         updated_vip['session_persistence']['type'])
-        self.client.delete_vip(vip['id'])
-        self.client.wait_for_resource_deletion('vip', vip['id'])
-        # Verification of pool update
-        new_name = "New_pool"
-        body = self.client.update_pool(pool['id'],
-                                       name=new_name,
-                                       description="new_description",
-                                       lb_method='LEAST_CONNECTIONS')
-        updated_pool = body['pool']
-        self.assertEqual(new_name, updated_pool['name'])
-        self.assertEqual('new_description', updated_pool['description'])
-        self.assertEqual('LEAST_CONNECTIONS', updated_pool['lb_method'])
-        self.client.delete_pool(pool['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('0435a95e-1d19-4d90-9e9f-3b979e9ad089')
-    def test_show_vip(self):
-        # Verifies the details of a vip
-        body = self.client.show_vip(self.vip['id'])
-        vip = body['vip']
-        for key, value in vip.iteritems():
-            # 'status' should not be confirmed in api tests
-            if key != 'status':
-                self.assertEqual(self.vip[key], value)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('6e7a7d31-8451-456d-b24a-e50479ce42a7')
-    def test_show_pool(self):
-        # Here we need to new pool without any dependence with vips
-        body = self.client.create_pool(name=data_utils.rand_name("pool-"),
-                                       lb_method='ROUND_ROBIN',
-                                       protocol='HTTP',
-                                       subnet_id=self.subnet['id'])
-        pool = body['pool']
-        self.addCleanup(self.client.delete_pool, pool['id'])
-        # Verifies the details of a pool
-        body = self.client.show_pool(pool['id'])
-        shown_pool = body['pool']
-        for key, value in pool.iteritems():
-            # 'status' should not be confirmed in api tests
-            if key != 'status':
-                self.assertEqual(value, shown_pool[key])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('d1ab1ffa-e06a-487f-911f-56418cb27727')
-    def test_list_pools(self):
-        # Verify the pool exists in the list of all pools
-        body = self.client.list_pools()
-        pools = body['pools']
-        self.assertIn(self.pool['id'], [p['id'] for p in pools])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('27cc4c1a-caac-4273-b983-2acb4afaad4f')
-    def test_list_pools_with_filters(self):
-        attr_exceptions = ['status', 'vip_id', 'members', 'provider',
-                           'status_description']
-        self._check_list_with_filter(
-            'pool', attr_exceptions, name=data_utils.rand_name("pool-"),
-            lb_method="ROUND_ROBIN", protocol="HTTPS",
-            subnet_id=self.subnet['id'],
-            description=data_utils.rand_name('description-'),
-            admin_state_up=False)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('282d0dfd-5c3a-4c9b-b39c-c99782f39193')
-    def test_list_members(self):
-        # Verify the member exists in the list of all members
-        body = self.client.list_members()
-        members = body['members']
-        self.assertIn(self.member['id'], [m['id'] for m in members])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('243b5126-24c6-4879-953e-7c7e32d8a57f')
-    def test_list_members_with_filters(self):
-        attr_exceptions = ['status', 'status_description']
-        self._check_list_with_filter('member', attr_exceptions,
-                                     address=self.member_address,
-                                     protocol_port=80,
-                                     pool_id=self.pool['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('fb833ee8-9e69-489f-b540-a409762b78b2')
-    def test_create_update_delete_member(self):
-        # Creates a member
-        body = self.client.create_member(address=self.member_address,
-                                         protocol_port=80,
-                                         pool_id=self.pool['id'])
-        member = body['member']
-        # Verification of member update
-        body = self.client.update_member(member['id'],
-                                         admin_state_up=False)
-        updated_member = body['member']
-        self.assertFalse(updated_member['admin_state_up'])
-        # Verification of member delete
-        self.client.delete_member(member['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('893cd71f-a7dd-4485-b162-f6ab9a534914')
-    def test_show_member(self):
-        # Verifies the details of a member
-        body = self.client.show_member(self.member['id'])
-        member = body['member']
-        for key, value in member.iteritems():
-            # 'status' should not be confirmed in api tests
-            if key != 'status':
-                self.assertEqual(self.member[key], value)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('8e5822c5-68a4-4224-8d6c-a617741ebc2d')
-    def test_list_health_monitors(self):
-        # Verify the health monitor exists in the list of all health monitors
-        body = self.client.list_health_monitors()
-        health_monitors = body['health_monitors']
-        self.assertIn(self.health_monitor['id'],
-                      [h['id'] for h in health_monitors])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('49bac58a-511c-4875-b794-366698211d25')
-    def test_list_health_monitors_with_filters(self):
-        attr_exceptions = ['status', 'status_description', 'pools']
-        self._check_list_with_filter('health_monitor', attr_exceptions,
-                                     delay=5, max_retries=4, type="TCP",
-                                     timeout=2)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('e8ce05c4-d554-4d1e-a257-ad32ce134bb5')
-    def test_create_update_delete_health_monitor(self):
-        # Creates a health_monitor
-        body = self.client.create_health_monitor(delay=4,
-                                                 max_retries=3,
-                                                 type="TCP",
-                                                 timeout=1)
-        health_monitor = body['health_monitor']
-        # Verification of health_monitor update
-        body = (self.client.update_health_monitor
-                (health_monitor['id'],
-                 admin_state_up=False))
-        updated_health_monitor = body['health_monitor']
-        self.assertFalse(updated_health_monitor['admin_state_up'])
-        # Verification of health_monitor delete
-        body = self.client.delete_health_monitor(health_monitor['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('d3e1aebc-06c2-49b3-9816-942af54012eb')
-    def test_create_health_monitor_http_type(self):
-        hm_type = "HTTP"
-        body = self.client.create_health_monitor(delay=4,
-                                                 max_retries=3,
-                                                 type=hm_type,
-                                                 timeout=1)
-        health_monitor = body['health_monitor']
-        self.addCleanup(self.client.delete_health_monitor,
-                        health_monitor['id'])
-        self.assertEqual(hm_type, health_monitor['type'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('0eff9f67-90fb-4bb1-b4ed-c5fda99fff0c')
-    def test_update_health_monitor_http_method(self):
-        body = self.client.create_health_monitor(delay=4,
-                                                 max_retries=3,
-                                                 type="HTTP",
-                                                 timeout=1)
-        health_monitor = body['health_monitor']
-        self.addCleanup(self.client.delete_health_monitor,
-                        health_monitor['id'])
-        body = (self.client.update_health_monitor
-                (health_monitor['id'],
-                 http_method="POST",
-                 url_path="/home/user",
-                 expected_codes="290"))
-        updated_health_monitor = body['health_monitor']
-        self.assertEqual("POST", updated_health_monitor['http_method'])
-        self.assertEqual("/home/user", updated_health_monitor['url_path'])
-        self.assertEqual("290", updated_health_monitor['expected_codes'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('08e126ab-1407-483f-a22e-b11cc032ca7c')
-    def test_show_health_monitor(self):
-        # Verifies the details of a health_monitor
-        body = self.client.show_health_monitor(self.health_monitor['id'])
-        health_monitor = body['health_monitor']
-        for key, value in health_monitor.iteritems():
-            # 'status' should not be confirmed in api tests
-            if key != 'status':
-                self.assertEqual(self.health_monitor[key], value)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('87f7628e-8918-493d-af50-0602845dbb5b')
-    def test_associate_disassociate_health_monitor_with_pool(self):
-        # Verify that a health monitor can be associated with a pool
-        self.client.associate_health_monitor_with_pool(
-            self.health_monitor['id'], self.pool['id'])
-        body = self.client.show_health_monitor(
-            self.health_monitor['id'])
-        health_monitor = body['health_monitor']
-        body = self.client.show_pool(self.pool['id'])
-        pool = body['pool']
-        self.assertIn(pool['id'],
-                      [p['pool_id'] for p in health_monitor['pools']])
-        self.assertIn(health_monitor['id'], pool['health_monitors'])
-        # Verify that a health monitor can be disassociated from a pool
-        (self.client.disassociate_health_monitor_with_pool
-            (self.health_monitor['id'], self.pool['id']))
-        body = self.client.show_pool(self.pool['id'])
-        pool = body['pool']
-        body = self.client.show_health_monitor(
-            self.health_monitor['id'])
-        health_monitor = body['health_monitor']
-        self.assertNotIn(health_monitor['id'], pool['health_monitors'])
-        self.assertNotIn(pool['id'],
-                         [p['pool_id'] for p in health_monitor['pools']])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('525fc7dc-be24-408d-938d-822e9783e027')
-    def test_get_lb_pool_stats(self):
-        # Verify the details of pool stats
-        body = self.client.list_lb_pool_stats(self.pool['id'])
-        stats = body['stats']
-        self.assertIn("bytes_in", stats)
-        self.assertIn("total_connections", stats)
-        self.assertIn("active_connections", stats)
-        self.assertIn("bytes_out", stats)
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('66236be2-5121-4047-8cde-db4b83b110a5')
-    def test_update_list_of_health_monitors_associated_with_pool(self):
-        (self.client.associate_health_monitor_with_pool
-            (self.health_monitor['id'], self.pool['id']))
-        self.client.update_health_monitor(
-            self.health_monitor['id'], admin_state_up=False)
-        body = self.client.show_pool(self.pool['id'])
-        health_monitors = body['pool']['health_monitors']
-        for health_monitor_id in health_monitors:
-            body = self.client.show_health_monitor(health_monitor_id)
-            self.assertFalse(body['health_monitor']['admin_state_up'])
-            (self.client.disassociate_health_monitor_with_pool
-                (self.health_monitor['id'], self.pool['id']))
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('44ec9b40-b501-41e2-951f-4fc673b15ac0')
-    def test_update_admin_state_up_of_pool(self):
-        self.client.update_pool(self.pool['id'],
-                                admin_state_up=False)
-        body = self.client.show_pool(self.pool['id'])
-        pool = body['pool']
-        self.assertFalse(pool['admin_state_up'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('466a9d4c-37c6-4ea2-b807-133437beb48c')
-    def test_show_vip_associated_with_pool(self):
-        body = self.client.show_pool(self.pool['id'])
-        pool = body['pool']
-        body = self.client.show_vip(pool['vip_id'])
-        vip = body['vip']
-        self.assertEqual(self.vip['name'], vip['name'])
-        self.assertEqual(self.vip['id'], vip['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('7b97694e-69d0-4151-b265-e1052a465aa8')
-    def test_show_members_associated_with_pool(self):
-        body = self.client.show_pool(self.pool['id'])
-        members = body['pool']['members']
-        for member_id in members:
-            body = self.client.show_member(member_id)
-            self.assertIsNotNone(body['member']['status'])
-            self.assertEqual(member_id, body['member']['id'])
-            self.assertIsNotNone(body['member']['admin_state_up'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('73ed6f27-595b-4b2c-969c-dbdda6b8ab34')
-    def test_update_pool_related_to_member(self):
-        # Create new pool
-        body = self.client.create_pool(name=data_utils.rand_name("pool-"),
-                                       lb_method='ROUND_ROBIN',
-                                       protocol='HTTP',
-                                       subnet_id=self.subnet['id'])
-        new_pool = body['pool']
-        self.addCleanup(self.client.delete_pool, new_pool['id'])
-        # Update member with new pool's id
-        body = self.client.update_member(self.member['id'],
-                                         pool_id=new_pool['id'])
-        # Confirm with show that pool_id change
-        body = self.client.show_member(self.member['id'])
-        member = body['member']
-        self.assertEqual(member['pool_id'], new_pool['id'])
-        # Update member with old pool id, this is needed for clean up
-        body = self.client.update_member(self.member['id'],
-                                         pool_id=self.pool['id'])
-
-    @test.attr(type='smoke')
-    @decorators.idempotent_id('cf63f071-bbe3-40ba-97a0-a33e11923162')
-    def test_update_member_weight(self):
-        self.client.update_member(self.member['id'],
-                                  weight=2)
-        body = self.client.show_member(self.member['id'])
-        member = body['member']
-        self.assertEqual(2, member['weight'])
-
-
-@decorators.skip_because(bug="1402007")
-class LoadBalancerIpV6TestJSON(LoadBalancerTestJSON):
-    _ip_version = 6
diff --git a/tests/tempest/v1/scenario/__init__.py b/tests/tempest/v1/scenario/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v2/__init__.py b/tests/tempest/v2/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v2/api/__init__.py b/tests/tempest/v2/api/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v2/api/base.py b/tests/tempest/v2/api/base.py
deleted file mode 100644
index fba797f..0000000
--- a/tests/tempest/v2/api/base.py
+++ /dev/null
@@ -1,378 +0,0 @@
-# Copyright 2015, 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import time
-
-from oslo_log import log as logging
-from tempest.api.network import base
-from tempest import config
-from tempest.lib import exceptions
-
-from neutron_lbaas._i18n import _, _LI
-from neutron_lbaas.tests.tempest.v2.clients import health_monitors_client
-from neutron_lbaas.tests.tempest.v2.clients import listeners_client
-from neutron_lbaas.tests.tempest.v2.clients import load_balancers_client
-from neutron_lbaas.tests.tempest.v2.clients import members_client
-from neutron_lbaas.tests.tempest.v2.clients import pools_client
-
-CONF = config.CONF
-
-LOG = logging.getLogger(__name__)
-
-
-def _setup_client_args(auth_provider):
-    """Set up ServiceClient arguments using config settings. """
-    service = CONF.network.catalog_type or 'network'
-    region = CONF.network.region or 'regionOne'
-    endpoint_type = CONF.network.endpoint_type
-    build_interval = CONF.network.build_interval
-    build_timeout = CONF.network.build_timeout
-
-    # The disable_ssl appears in identity
-    disable_ssl_certificate_validation = (
-        CONF.identity.disable_ssl_certificate_validation)
-    ca_certs = None
-
-    # Trace in debug section
-    trace_requests = CONF.debug.trace_requests
-
-    return [auth_provider, service, region, endpoint_type,
-            build_interval, build_timeout,
-            disable_ssl_certificate_validation, ca_certs,
-            trace_requests]
-
-
-class BaseTestCase(base.BaseNetworkTest):
-
-    # This class picks non-admin credentials and run the tempest tests
-
-    _lbs_to_delete = []
-
-    @classmethod
-    def resource_setup(cls):
-        super(BaseTestCase, cls).resource_setup()
-
-        mgr = cls.get_client_manager()
-        auth_provider = mgr.auth_provider
-        client_args = _setup_client_args(auth_provider)
-
-        cls.load_balancers_client = (
-            load_balancers_client.LoadBalancersClientJSON(*client_args))
-        cls.listeners_client = (
-            listeners_client.ListenersClientJSON(*client_args))
-        cls.pools_client = pools_client.PoolsClientJSON(*client_args)
-        cls.members_client = members_client.MembersClientJSON(*client_args)
-        cls.health_monitors_client = (
-            health_monitors_client.HealthMonitorsClientJSON(*client_args))
-
-    @classmethod
-    def resource_cleanup(cls):
-
-        for lb_id in cls._lbs_to_delete:
-            try:
-                lb = cls.load_balancers_client.get_load_balancer_status_tree(
-                    lb_id).get('loadbalancer')
-            except exceptions.NotFound:
-                continue
-            for listener in lb.get('listeners'):
-                for pool in listener.get('pools'):
-                    hm = pool.get('healthmonitor')
-                    if hm:
-                        cls._try_delete_resource(
-                            cls.health_monitors_client.delete_health_monitor,
-                            pool.get('healthmonitor').get('id'))
-                        cls._wait_for_load_balancer_status(lb_id)
-                    cls._try_delete_resource(cls.pools_client.delete_pool,
-                                             pool.get('id'))
-                    cls._wait_for_load_balancer_status(lb_id)
-                    health_monitor = pool.get('healthmonitor')
-                    if health_monitor:
-                        cls._try_delete_resource(
-                            cls.health_monitors_client.delete_health_monitor,
-                            health_monitor.get('id'))
-                    cls._wait_for_load_balancer_status(lb_id)
-                cls._try_delete_resource(cls.listeners_client.delete_listener,
-                                         listener.get('id'))
-                cls._wait_for_load_balancer_status(lb_id)
-            cls._try_delete_resource(cls._delete_load_balancer, lb_id)
-
-        super(BaseTestCase, cls).resource_cleanup()
-
-    @classmethod
-    def setUpClass(cls):
-        cls.LOG = logging.getLogger(cls._get_full_case_name())
-        super(BaseTestCase, cls).setUpClass()
-
-    def setUp(cls):
-        cls.LOG.info(_LI('Starting: {0}').format(cls._testMethodName))
-        super(BaseTestCase, cls).setUp()
-
-    def tearDown(cls):
-        super(BaseTestCase, cls).tearDown()
-        cls.LOG.info(_LI('Finished: {0}\n').format(cls._testMethodName))
-
-    @classmethod
-    def _create_load_balancer(cls, wait=True, **lb_kwargs):
-        lb = cls.load_balancers_client.create_load_balancer(**lb_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(lb.get('id'))
-
-        cls._lbs_to_delete.append(lb.get('id'))
-        port = cls.ports_client.show_port(lb['vip_port_id'])
-        cls.ports.append(port['port'])
-        return lb
-
-    @classmethod
-    def _create_active_load_balancer(cls, **kwargs):
-        lb = cls._create_load_balancer(**kwargs)
-        lb = cls._wait_for_load_balancer_status(lb.get('id'))
-        return lb
-
-    @classmethod
-    def _delete_load_balancer(cls, load_balancer_id, wait=True):
-        cls.load_balancers_client.delete_load_balancer(load_balancer_id)
-        if wait:
-            cls._wait_for_load_balancer_status(
-                load_balancer_id, delete=True)
-
-    @classmethod
-    def _update_load_balancer(cls, load_balancer_id, wait=True, **lb_kwargs):
-        lb = cls.load_balancers_client.update_load_balancer(
-            load_balancer_id, **lb_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(
-                load_balancer_id)
-        return lb
-
-    @classmethod
-    def _wait_for_load_balancer_status(cls, load_balancer_id,
-                                       provisioning_status='ACTIVE',
-                                       operating_status='ONLINE',
-                                       delete=False):
-        interval_time = 1
-        timeout = 600
-        end_time = time.time() + timeout
-        lb = {}
-        while time.time() < end_time:
-            try:
-                lb = cls.load_balancers_client.get_load_balancer(
-                    load_balancer_id)
-                if not lb:
-                        # loadbalancer not found
-                    if delete:
-                        break
-                    else:
-                        raise Exception(
-                            _("loadbalancer {lb_id} not"
-                              " found").format(
-                                  lb_id=load_balancer_id))
-                if (lb.get('provisioning_status') == provisioning_status and
-                        lb.get('operating_status') == operating_status):
-                    break
-                time.sleep(interval_time)
-            except exceptions.NotFound as e:
-                # if wait is for delete operation do break
-                if delete:
-                    break
-                else:
-                    # raise original exception
-                    raise e
-        else:
-            if delete:
-                raise exceptions.TimeoutException(
-                    _("Waited for load balancer {lb_id} to be deleted for "
-                      "{timeout} seconds but can still observe that it "
-                      "exists.").format(
-                          lb_id=load_balancer_id,
-                          timeout=timeout))
-            else:
-                raise exceptions.TimeoutException(
-                    _("Wait for load balancer ran for {timeout} seconds and "
-                      "did not observe {lb_id} reach {provisioning_status} "
-                      "provisioning status and {operating_status} "
-                      "operating status.").format(
-                          timeout=timeout,
-                          lb_id=load_balancer_id,
-                          provisioning_status=provisioning_status,
-                          operating_status=operating_status))
-        return lb
-
-    @classmethod
-    def _create_listener(cls, wait=True, **listener_kwargs):
-        listener = cls.listeners_client.create_listener(**listener_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(cls.load_balancer.get('id'))
-        return listener
-
-    @classmethod
-    def _delete_listener(cls, listener_id, wait=True):
-        cls.listeners_client.delete_listener(listener_id)
-        if wait:
-            cls._wait_for_load_balancer_status(cls.load_balancer.get('id'))
-
-    @classmethod
-    def _update_listener(cls, listener_id, wait=True, **listener_kwargs):
-        listener = cls.listeners_client.update_listener(
-            listener_id, **listener_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(
-                cls.load_balancer.get('id'))
-        return listener
-
-    @classmethod
-    def _create_pool(cls, wait=True, **pool_kwargs):
-        pool = cls.pools_client.create_pool(**pool_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(cls.load_balancer.get('id'))
-        return pool
-
-    @classmethod
-    def _delete_pool(cls, pool_id, wait=True):
-        cls.pools_client.delete_pool(pool_id)
-        if wait:
-            cls._wait_for_load_balancer_status(cls.load_balancer.get('id'))
-
-    @classmethod
-    def _update_pool(cls, pool_id, wait=True, **pool_kwargs):
-        pool = cls.pools_client.update_pool(pool_id, **pool_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(
-                cls.load_balancer.get('id'))
-        return pool
-
-    def _create_health_monitor(self, wait=True, cleanup=True,
-                               **health_monitor_kwargs):
-        hm = self.health_monitors_client.create_health_monitor(
-            **health_monitor_kwargs)
-        if cleanup:
-            self.addCleanup(self._delete_health_monitor, hm.get('id'))
-        if wait:
-            self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        return hm
-
-    def _delete_health_monitor(self, health_monitor_id, wait=True):
-        self.health_monitors_client.delete_health_monitor(health_monitor_id)
-        if wait:
-            self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-
-    def _update_health_monitor(self, health_monitor_id, wait=True,
-                               **health_monitor_kwargs):
-        health_monitor = self.health_monitors_client.update_health_monitor(
-            health_monitor_id, **health_monitor_kwargs)
-        if wait:
-            self._wait_for_load_balancer_status(
-                self.load_balancer.get('id'))
-        return health_monitor
-
-    @classmethod
-    def _create_member(cls, pool_id, wait=True, **member_kwargs):
-        member = cls.members_client.create_member(pool_id, **member_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(cls.load_balancer.get('id'))
-        return member
-
-    @classmethod
-    def _delete_member(cls, pool_id, member_id, wait=True):
-        cls.members_client.delete_member(pool_id, member_id)
-        if wait:
-            cls._wait_for_load_balancer_status(cls.load_balancer.get('id'))
-
-    @classmethod
-    def _update_member(cls, pool_id, member_id, wait=True,
-                       **member_kwargs):
-        member = cls.members_client.update_member(
-            pool_id, member_id, **member_kwargs)
-        if wait:
-            cls._wait_for_load_balancer_status(
-                cls.load_balancer.get('id'))
-        return member
-
-    @classmethod
-    def _check_status_tree(cls, load_balancer_id, listener_ids=None,
-                           pool_ids=None, health_monitor_id=None,
-                           member_ids=None):
-        statuses = cls.load_balancers_client.get_load_balancer_status_tree(
-            load_balancer_id=load_balancer_id)
-        load_balancer = statuses['loadbalancer']
-        assert 'ONLINE' == load_balancer['operating_status']
-        assert 'ACTIVE' == load_balancer['provisioning_status']
-
-        if listener_ids:
-            cls._check_status_tree_thing(listener_ids,
-                                         load_balancer['listeners'])
-        if pool_ids:
-            cls._check_status_tree_thing(pool_ids,
-                                         load_balancer['listeners']['pools'])
-        if member_ids:
-            cls._check_status_tree_thing(
-                member_ids,
-                load_balancer['listeners']['pools']['members'])
-        if health_monitor_id:
-            health_monitor = (
-                load_balancer['listeners']['pools']['health_monitor'])
-            assert health_monitor_id == health_monitor['id']
-            assert 'ACTIVE' == health_monitor['provisioning_status']
-
-    @classmethod
-    def _check_status_tree_thing(cls, actual_thing_ids, status_tree_things):
-        found_things = 0
-        status_tree_things = status_tree_things
-        assert len(actual_thing_ids) == len(status_tree_things)
-        for actual_thing_id in actual_thing_ids:
-            for status_tree_thing in status_tree_things:
-                if status_tree_thing['id'] == actual_thing_id:
-                    assert 'ONLINE' == (
-                        status_tree_thing['operating_status'])
-                    assert 'ACTIVE' == (
-                        status_tree_thing['provisioning_status'])
-                    found_things += 1
-        assert len(actual_thing_ids) == found_things
-
-    @classmethod
-    def _get_full_case_name(cls):
-        name = '{module}:{case_name}'.format(
-            module=cls.__module__,
-            case_name=cls.__name__
-        )
-        return name
-
-
-class BaseAdminTestCase(BaseTestCase):
-
-    # This class picks admin credentials and run the tempest tests
-
-    @classmethod
-    def resource_setup(cls):
-
-        super(BaseAdminTestCase, cls).resource_setup()
-
-        mgr = cls.get_client_manager(credential_type='admin')
-        auth_provider_admin = mgr.auth_provider
-        client_args = _setup_client_args(auth_provider_admin)
-
-        cls.load_balancers_client = (
-            load_balancers_client.LoadBalancersClientJSON(*client_args))
-        cls.listeners_client = (
-            listeners_client.ListenersClientJSON(*client_args))
-        cls.pools_client = (
-            pools_client.PoolsClientJSON(*client_args))
-        cls.members_client = (
-            members_client.MembersClientJSON(*client_args))
-        cls.health_monitors_client = (
-            health_monitors_client.HealthMonitorsClientJSON(*client_args))
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(BaseAdminTestCase, cls).resource_cleanup()
diff --git a/tests/tempest/v2/api/test_health_monitor_admin.py b/tests/tempest/v2/api/test_health_monitor_admin.py
deleted file mode 100644
index 9efae7b..0000000
--- a/tests/tempest/v2/api/test_health_monitor_admin.py
+++ /dev/null
@@ -1,102 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-
-from oslo_utils import uuidutils
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-CONF = config.CONF
-
-
-class TestHealthMonitors(base.BaseAdminTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Health Monitors with ADMIN role:
-
-    create health monitor with missing tenant_id
-    create health monitor with empty tenant id
-    create health monitor with another tenant_id
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(TestHealthMonitors, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.load_balancer = cls._create_load_balancer(
-            tenant_id=cls.subnet.get('tenant_id'),
-            vip_subnet_id=cls.subnet.get('id'))
-        cls.listener = cls._create_listener(
-            loadbalancer_id=cls.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=80)
-        cls.pool = cls._create_pool(
-            protocol='HTTP', lb_algorithm='ROUND_ROBIN',
-            listener_id=cls.listener.get('id'))
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(TestHealthMonitors, cls).resource_cleanup()
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_tenant_id_field(self):
-        """
-        Test if admin user can create health monitor with a missing tenant id
-        field.
-        """
-        hm = self._create_health_monitor(type='HTTP', delay=3, max_retries=10,
-                                         timeout=5,
-                                         pool_id=self.pool.get('id'))
-
-        admin_hm = self.health_monitors_client.get_health_monitor(hm.get('id'))
-        admin_tenant_id = admin_hm.get('tenant_id')
-        hm_tenant_id = hm.get('tenant_id')
-        self.assertEqual(admin_tenant_id, hm_tenant_id)
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_tenant_id_field(self):
-        """
-        Test with admin user creating health monitor with an empty tenant id
-        field should fail.
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10,
-                          timeout=5,
-                          pool_id=self.pool.get('id'),
-                          tenant_id="")
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_for_another_tenant_id_field(self):
-        """Test with admin user create health monitor for another tenant id.
-        """
-
-        tenantid = uuidutils.generate_uuid()
-        hm = self._create_health_monitor(type='HTTP', delay=3, max_retries=10,
-                                         timeout=5,
-                                         pool_id=self.pool.get('id'),
-                                         tenant_id=tenantid)
-
-        self.assertEqual(hm.get('tenant_id'), tenantid)
-        self.assertNotEqual(hm.get('tenant_id'),
-                            self.subnet.get('tenant_id'))
diff --git a/tests/tempest/v2/api/test_health_monitors_non_admin.py b/tests/tempest/v2/api/test_health_monitors_non_admin.py
deleted file mode 100644
index 73e0192..0000000
--- a/tests/tempest/v2/api/test_health_monitors_non_admin.py
+++ /dev/null
@@ -1,530 +0,0 @@
-# Copyright 2015, 2016 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-
-class TestHealthMonitors(base.BaseTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Health Monitors:
-        list pools
-        create pool
-        get pool
-        update pool
-        delete pool
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(TestHealthMonitors, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.load_balancer = cls._create_load_balancer(
-            tenant_id=cls.subnet.get('tenant_id'),
-            vip_subnet_id=cls.subnet.get('id'))
-        cls.listener = cls._create_listener(
-            loadbalancer_id=cls.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=80)
-        cls.pool = cls._create_pool(
-            protocol='HTTP', lb_algorithm='ROUND_ROBIN',
-            listener_id=cls.listener.get('id'))
-        cls.create_basic_hm_kwargs = {'type': 'HTTP', 'delay': 3,
-                                      'max_retries': 10, 'timeout': 5,
-                                      'pool_id': cls.pool.get('id')}
-
-    @test.attr(type='smoke')
-    def test_list_health_monitors_empty(self):
-        hm_list = self.health_monitors_client.list_health_monitors()
-        self.assertEmpty(hm_list)
-
-    @test.attr(type='smoke')
-    def test_list_health_monitors_one(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        hm_list = self.health_monitors_client.list_health_monitors()
-        self.assertIn(hm, hm_list)
-
-    @test.attr(type='smoke')
-    def test_list_health_monitors_two(self):
-        hm1 = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_listener = self._create_listener(
-            loadbalancer_id=self.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=88)
-        self.addCleanup(self._delete_listener, new_listener.get('id'))
-        new_pool = self._create_pool(
-            protocol='HTTP', lb_algorithm='ROUND_ROBIN',
-            listener_id=new_listener.get('id'))
-        self.addCleanup(self._delete_pool, new_pool.get('id'))
-        hm2 = self._create_health_monitor(
-            type='HTTPS',
-            max_retries=3,
-            delay=1,
-            timeout=2,
-            pool_id=new_pool.get('id'))
-        hm_list = self.health_monitors_client.list_health_monitors()
-        self.assertEqual(2, len(hm_list))
-        self.assertIn(hm1, hm_list)
-        self.assertIn(hm2, hm_list)
-
-    @test.attr(type='smoke')
-    def test_get_health_monitor(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        hm_test = self.health_monitors_client.get_health_monitor(hm.get('id'))
-        self.assertEqual(hm, hm_test)
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor(self):
-        new_hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        hm = self.health_monitors_client.get_health_monitor(new_hm.get('id'))
-        self.assertEqual(new_hm, hm)
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_attribute(self):
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_required_field_type(self):
-        """Test if a non_admin user can create a health monitor with type
-        missing
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_required_field_delay(self):
-        """Test if a non_admin user can create a health monitor with delay
-        missing
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_required_field_timeout(self):
-        """Test if a non_admin user can create a health monitor with timeout
-        missing
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_required_field_max_retries(self):
-        """Test if a non_admin user can create a health monitor with max_retries
-        missing
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_required_field_pool_id(self):
-        """Test if a non_admin user can create a health monitor with pool_id
-        missing
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5)
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_admin_state_up(self):
-        """Test if a non_admin user can create a health monitor with
-        admin_state_up missing
-        """
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        hm_test = self.health_monitors_client.get_health_monitor(hm.get('id'))
-        self.assertEqual(hm, hm_test)
-        self.assertTrue(hm_test.get('admin_state_up'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_http_method(self):
-        """Test if a non_admin user can create a health monitor with
-        http_method missing
-        """
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-
-        hm_test = self.health_monitors_client.get_health_monitor(hm.get('id'))
-        self.assertEqual(hm, hm_test)
-        self.assertEqual('GET', hm_test.get('http_method'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_url_path(self):
-        """Test if a non_admin user can create a health monitor with
-        url_path missing
-        """
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        hm_test = self.health_monitors_client.get_health_monitor(hm.get('id'))
-        self.assertEqual(hm, hm_test)
-        self.assertEqual('/', hm_test.get('url_path'))
-
-    @test.attr(type='smoke')
-    def test_create_health_monitor_missing_expected_codes(self):
-        """Test if a non_admin user can create a health monitor with
-        expected_codes missing
-        """
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-
-        hm_test = self.health_monitors_client.get_health_monitor(hm.get('id'))
-        self.assertEqual(hm, hm_test)
-        self.assertEqual('200', hm_test.get('expected_codes'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_tenant_id(self):
-        """Test create health monitor with invalid tenant_id"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          tenant_id='blah',
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_type(self):
-        """Test create health monitor with invalid type"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='blah', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_delay(self):
-        """Test create health monitor with invalid delay"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay='blah', max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_max_retries(self):
-        """Test create health monitor with invalid max_retries"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries='blah', timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_timeout(self):
-        """Test create health monitor with invalid timeout"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout='blah',
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_pool_id(self):
-        """Test create health monitor with invalid pool id"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id='blah')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_admin_state_up(self):
-        """Test if a non_admin user can create a health monitor with invalid
-        admin_state_up
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), admin_state_up='blah'
-                          )
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_expected_codes(self):
-        """Test if a non_admin user can create a health monitor with invalid
-        expected_codes
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), expected_codes='blah'
-                          )
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_url_path(self):
-        """Test if a non_admin user can create a health monitor with invalid
-        url_path
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), url_path='blah'
-                          )
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_http_method(self):
-        """Test if a non_admin user can create a health monitor with invalid
-        http_method
-        """
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), http_method='blah')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_type(self):
-        """Test create health monitor with empty type"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_delay(self):
-        """Test create health monitor with empty delay"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay='', max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_timeout(self):
-        """Test create health monitor with empty timeout"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout='',
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_max_retries(self):
-        """Test create health monitor with empty max_retries"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries='', timeout=5,
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_max_pool_id(self):
-        """Test create health monitor with empty pool_id"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id='')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_max_admin_state_up(self):
-        """Test create health monitor with empty admin_state_up"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), admin_state_up='')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_max_http_method(self):
-        """Test create health monitor with empty http_method"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), http_method='')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_max_url_path(self):
-        """Test create health monitor with empty url_path"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), url_path='')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_empty_expected_codes(self):
-        """Test create health monitor with empty expected_codes"""
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10, timeout=5,
-                          pool_id=self.pool.get('id'), expected_codes='')
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_invalid_attribute(self):
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries='twenty one',
-                          pool_id=self.pool.get('id'))
-
-    @test.attr(type='negative')
-    def test_create_health_monitor_extra_attribute(self):
-        self.assertRaises(ex.BadRequest, self._create_health_monitor,
-                          type='HTTP', delay=3, max_retries=10,
-                          pool_id=self.pool.get('id'), subnet_id=10)
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor(self):
-        hm = self._create_health_monitor(type='HTTP', delay=3, max_retries=10,
-                                         timeout=5,
-                                         pool_id=self.pool.get('id'))
-        max_retries = 1
-        new_hm = self._update_health_monitor(
-            hm.get('id'), max_retries=max_retries)
-        self.assertEqual(max_retries, new_hm.get('max_retries'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_admin_state_up(self):
-        """Test update health monitor with missing admin state field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertTrue(new_hm.get('admin_state_up'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_delay(self):
-        """Test update health monitor with missing delay field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertEqual(hm.get('delay'), new_hm.get('delay'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_timeout(self):
-        """Test update health monitor with missing timeout field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertEqual(hm.get('timeout'), new_hm.get('timeout'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_max_retries(self):
-        """Test update health monitor with missing max retries field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertEqual(hm.get('max_retries'), new_hm.get('max_retries'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_http_method(self):
-        """Test update health monitor with missing http_method field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertEqual(hm.get('http_method'), new_hm.get('http_method'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_url_path(self):
-        """Test update health monitor with missing url_path field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertEqual(hm.get('url_path'), new_hm.get('url_path'))
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_missing_expected_codes(self):
-        """Test update health monitor with missing expected_codes field"""
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        new_hm = self._update_health_monitor(hm.get('id'))
-        self.assertEqual(hm.get('expected_codes'),
-                         new_hm.get('expected_codes'))
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_attribute(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), max_retries='blue')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_admin_state_up(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), admin_state_up='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_delay(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), delay='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_timeout(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), timeout='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_max_retries(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), max_retries='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_http_method(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), http_method='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_url_path(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), url_path='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_invalid_expected_codes(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), expected_codes='blah')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_admin_state_up(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), admin_state_up='')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_delay(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), empty_delay='')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_timeout(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), timeout='')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_max_retries(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), max_retries='')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_empty_http_method(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), http_method='')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_url_path(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), http_method='')
-
-    @test.attr(type='negative')
-    def test_update_health_monitor_empty_expected_codes(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), expected_codes='')
-
-    @test.attr(type='smoke')
-    def test_update_health_monitor_extra_attribute(self):
-        hm = self._create_health_monitor(**self.create_basic_hm_kwargs)
-        self.assertRaises(ex.BadRequest,
-                          self._update_health_monitor,
-                          hm.get('id'), protocol='UDP')
-
-    @test.attr(type='smoke')
-    def test_delete_health_monitor(self):
-        hm = self._create_health_monitor(cleanup=False, type='HTTP', delay=3,
-                                         max_retries=10, timeout=5,
-                                         pool_id=self.pool.get('id'))
-        self._delete_health_monitor(hm.get('id'))
-        self.assertRaises(ex.NotFound,
-                          self.health_monitors_client.get_health_monitor,
-                          hm.get('id'))
diff --git a/tests/tempest/v2/api/test_listeners_admin.py b/tests/tempest/v2/api/test_listeners_admin.py
deleted file mode 100644
index 79a80e7..0000000
--- a/tests/tempest/v2/api/test_listeners_admin.py
+++ /dev/null
@@ -1,110 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-
-class ListenersTestJSON(base.BaseAdminTestCase):
-
-    """
-    Tests the listener creation operation in admin scope in the
-    Neutron-LBaaS API using the REST client for Listeners:
-
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(ListenersTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.create_lb_kwargs = {'tenant_id': cls.subnet['tenant_id'],
-                                'vip_subnet_id': cls.subnet['id']}
-        cls.load_balancer = cls._create_active_load_balancer(
-            **cls.create_lb_kwargs)
-        cls.protocol = 'HTTP'
-        cls.port = 80
-        cls.load_balancer_id = cls.load_balancer['id']
-        cls.create_listener_kwargs = {'loadbalancer_id': cls.load_balancer_id,
-                                      'protocol': cls.protocol,
-                                      'protocol_port': cls.port}
-        cls.listener = cls._create_listener(
-            **cls.create_listener_kwargs)
-        cls.listener_id = cls.listener['id']
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(ListenersTestJSON, cls).resource_cleanup()
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_tenant_id(self):
-        """Test create listener with an empty tenant id should fail"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        create_new_listener_kwargs['tenant_id'] = ""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          **create_new_listener_kwargs)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_create_listener_invalid_tenant_id(self):
-        """Test create listener with an invalid tenant id"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        create_new_listener_kwargs['tenant_id'] = "&^%123"
-        new_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self.addCleanup(self._delete_listener, new_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listener = self.listeners_client.get_listener(
-            new_listener_id)
-        self.assertEqual(new_listener, listener)
-
-    @test.attr(type='smoke')
-    def test_create_listener_missing_tenant_id(self):
-        """Test create listener with an missing tenant id.
-
-        Verify that creating a listener in admin scope with
-        a missing tenant_id creates the listener with admin
-        tenant_id.
-        """
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        admin_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        admin_listener_id = admin_listener['id']
-        self.addCleanup(self._delete_listener, admin_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, admin_listener_id])
-        listener = self.listeners_client.get_listener(
-            admin_listener_id)
-        self.assertEqual(admin_listener, listener)
-        self.assertEqual(admin_listener.get('tenant_id'),
-                         listener.get('tenant_id'))
diff --git a/tests/tempest/v2/api/test_listeners_non_admin.py b/tests/tempest/v2/api/test_listeners_non_admin.py
deleted file mode 100644
index def12e8..0000000
--- a/tests/tempest/v2/api/test_listeners_non_admin.py
+++ /dev/null
@@ -1,570 +0,0 @@
-# Copyright 2015, 2016 Rackspace US Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-CONF = config.CONF
-
-
-class ListenersTestJSON(base.BaseTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Listeners:
-
-        list listeners
-        create listener
-        get listener
-        update listener
-        delete listener
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(ListenersTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.create_lb_kwargs = {'tenant_id': cls.subnet['tenant_id'],
-                                'vip_subnet_id': cls.subnet['id']}
-        cls.load_balancer = cls._create_active_load_balancer(
-            **cls.create_lb_kwargs)
-        cls.protocol = 'HTTP'
-        cls.port = 80
-        cls.load_balancer_id = cls.load_balancer['id']
-        cls.create_listener_kwargs = {'loadbalancer_id': cls.load_balancer_id,
-                                      'protocol': cls.protocol,
-                                      'protocol_port': cls.port}
-        cls.listener = cls._create_listener(**cls.create_listener_kwargs)
-        cls.listener_id = cls.listener['id']
-
-    @test.attr(type='smoke')
-    def test_get_listener(self):
-        """Test get listener"""
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(self.listener, listener)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_list_listeners(self):
-        """Test get listeners with one listener"""
-        listeners = self.listeners_client.list_listeners()
-        self.assertEqual(len(listeners), 1)
-        self.assertIn(self.listener, listeners)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_list_listeners_two(self):
-        """Test get listeners with two listeners"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8080
-        new_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self.addCleanup(self._delete_listener, new_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listeners = self.listeners_client.list_listeners()
-        self.assertEqual(len(listeners), 2)
-        self.assertIn(self.listener, listeners)
-        self.assertIn(new_listener, listeners)
-        self.assertNotEqual(self.listener, new_listener)
-
-    @test.attr(type='smoke')
-    def test_create_listener(self):
-        """Test create listener"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        new_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self.addCleanup(self._delete_listener, new_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listener = self.listeners_client.get_listener(
-            new_listener_id)
-        self.assertEqual(new_listener, listener)
-        self.assertNotEqual(self.listener, new_listener)
-
-    @test.attr(type='negative')
-    def test_create_listener_missing_field_loadbalancer(self):
-        """Test create listener with a missing required field loadbalancer"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          protocol_port=self.port,
-                          protocol=self.protocol)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_missing_field_protocol(self):
-        """Test create listener with a missing required field protocol"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_missing_field_protocol_port(self):
-        """Test create listener with a missing required field protocol_port"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol=self.protocol)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_create_listener_missing_admin_state_up(self):
-        """Test create listener with a missing admin_state_up field"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        new_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self.addCleanup(self._delete_listener, new_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listener = self.listeners_client.get_listener(
-            new_listener_id)
-        self.assertEqual(new_listener, listener)
-        self.assertTrue(new_listener['admin_state_up'])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_load_balancer_id(self):
-        """Test create listener with an invalid load_balancer_id"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id="234*",
-                          protocol_port=self.port,
-                          protocol=self.protocol)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_protocol(self):
-        """Test create listener with an invalid protocol"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol="UDP")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_protocol_port(self):
-        """Test create listener with an invalid protocol_port"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port="9999999",
-                          protocol=self.protocol)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_admin_state_up(self):
-        """Test update listener with an invalid admin_state_up"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          admin_state_up="abc123")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_tenant_id(self):
-        """Test create listener with an invalid tenant id"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          tenant_id="&^%123")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_name(self):
-        """Test create listener with an invalid name"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          name='a' * 256)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_description(self):
-        """Test create listener with an invalid description"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          description='a' * 256)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_invalid_connection_limit(self):
-        """Test create listener with an invalid value for connection
-        _limit field
-        """
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          connection_limit="&^%123")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_load_balancer_id(self):
-        """Test create listener with an empty load_balancer_id"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id="",
-                          protocol_port=self.port,
-                          protocol=self.protocol)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_protocol(self):
-        """Test create listener with an empty protocol"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_protocol_port(self):
-        """Test create listener with an empty protocol_port"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port="",
-                          protocol=self.protocol)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_admin_state_up(self):
-        """Test update listener with an empty  admin_state_up"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          admin_state_up="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_tenant_id(self):
-        """Test create listener with an empty tenant id"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          tenant_id="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_create_listener_empty_name(self):
-        """Test create listener with an empty name"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        create_new_listener_kwargs['name'] = ""
-        new_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self.addCleanup(self._delete_listener, new_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listener = self.listeners_client.get_listener(
-            new_listener_id)
-        self.assertEqual(new_listener, listener)
-
-    @test.attr(type='smoke')
-    def test_create_listener_empty_description(self):
-        """Test create listener with an empty description"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8081
-        create_new_listener_kwargs['description'] = ""
-        new_listener = self._create_listener(
-            **create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self.addCleanup(self._delete_listener, new_listener_id)
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listener = self.listeners_client.get_listener(
-            new_listener_id)
-        self.assertEqual(new_listener, listener)
-
-    @test.attr(type='negative')
-    def test_create_listener_empty_connection_limit(self):
-        """Test create listener with an empty connection
-        _limit field
-        """
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          loadbalancer_id=self.load_balancer_id,
-                          protocol_port=self.port,
-                          protocol=self.protocol,
-                          connection_limit="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_create_listener_incorrect_attribute(self):
-        """Test create a listener with an extra, incorrect field"""
-        self.assertRaises(ex.BadRequest,
-                          self._create_listener,
-                          incorrect_attribute="incorrect_attribute",
-                          **self.create_listener_kwargs)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_update_listener(self):
-        """Test update listener"""
-        self._update_listener(self.listener_id,
-                              name='new_name')
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('name'), 'new_name')
-
-    @test.attr(type='negative')
-    def test_update_listener_invalid_tenant_id(self):
-        """Test update listener with an invalid tenant id"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          tenant_id="&^%123")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_update_listener_invalid_admin_state_up(self):
-        """Test update a listener with an invalid admin_state_up"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          admin_state_up="$23")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_update_listener_invalid_name(self):
-        """Test update a listener with an invalid name"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          name='a' * 256)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_update_listener_invalid_description(self):
-        """Test update a listener with an invalid description"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          description='a' * 256)
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_update_listener_invalid_connection_limit(self):
-        """Test update a listener with an invalid connection_limit"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          connection_limit="$23")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_update_listener_incorrect_attribute(self):
-        """Test update a listener with an extra, incorrect field"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          name="listener_name123",
-                          description="listener_description123",
-                          admin_state_up=True,
-                          connection_limit=10,
-                          vip_subnet_id="123321123")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_update_listener_missing_name(self):
-        """Test update listener with a missing name"""
-        old_listener = self.listeners_client.get_listener(
-            self.listener_id)
-        old_name = old_listener['name']
-        self._update_listener(self.listener_id,
-                              description='updated')
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('name'), old_name)
-
-    @test.attr(type='smoke')
-    def test_update_listener_missing_description(self):
-        """Test update listener with a missing description"""
-        old_listener = self.listeners_client.get_listener(
-            self.listener_id)
-        old_description = old_listener['description']
-        self._update_listener(self.listener_id,
-                              name='updated_name')
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('description'), old_description)
-
-    @test.attr(type='smoke')
-    def test_update_listener_missing_admin_state_up(self):
-        """Test update listener with a missing admin_state_up"""
-        old_listener = self.listeners_client.get_listener(
-            self.listener_id)
-        old_admin_state_up = old_listener['admin_state_up']
-        self._update_listener(self.listener_id,
-                              name='updated_name')
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('admin_state_up'), old_admin_state_up)
-
-    @test.attr(type='smoke')
-    def test_update_listener_missing_connection_limit(self):
-        """Test update listener with a missing connection_limit"""
-        old_listener = self.listeners_client.get_listener(
-            self.listener_id)
-        old_connection_limit = old_listener['connection_limit']
-        self._update_listener(self.listener_id,
-                              name='updated_name')
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('connection_limit'),
-                         old_connection_limit)
-
-    @test.attr(type='negative')
-    def test_update_listener_empty_tenant_id(self):
-        """Test update listener with an empty tenant id"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          tenant_id="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='negative')
-    def test_update_listener_empty_admin_state_up(self):
-        """Test update a listener with an empty admin_state_up"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          admin_state_up="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_update_listener_empty_name(self):
-        """Test update a listener with an empty name"""
-        self._update_listener(self.listener_id,
-                              name="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('name'), "")
-
-    @test.attr(type='smoke')
-    def test_update_listener_empty_description(self):
-        """Test update a listener with an empty description"""
-        self._update_listener(self.listener_id,
-                              description="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-        listener = self.listeners_client.get_listener(
-            self.listener_id)
-        self.assertEqual(listener.get('description'), "")
-
-    @test.attr(type='negative')
-    def test_update_listener_empty_connection_limit(self):
-        """Test update a listener with an empty connection_limit"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_listener,
-                          listener_id=self.listener_id,
-                          connection_limit="")
-        self._check_status_tree(load_balancer_id=self.load_balancer_id,
-                                listener_ids=[self.listener_id])
-
-    @test.attr(type='smoke')
-    def test_delete_listener(self):
-        """Test delete listener"""
-        create_new_listener_kwargs = self.create_listener_kwargs
-        create_new_listener_kwargs['protocol_port'] = 8083
-        new_listener = self._create_listener(**create_new_listener_kwargs)
-        new_listener_id = new_listener['id']
-        self._check_status_tree(
-            load_balancer_id=self.load_balancer_id,
-            listener_ids=[self.listener_id, new_listener_id])
-        listener = self.listeners_client.get_listener(
-            new_listener_id)
-        self.assertEqual(new_listener, listener)
-        self.assertNotEqual(self.listener, new_listener)
-        self._delete_listener(new_listener_id)
-        self.assertRaises(ex.NotFound,
-                          self.listeners_client.get_listener,
-                          new_listener_id)
diff --git a/tests/tempest/v2/api/test_load_balancers_admin.py b/tests/tempest/v2/api/test_load_balancers_admin.py
deleted file mode 100644
index e74e9a6..0000000
--- a/tests/tempest/v2/api/test_load_balancers_admin.py
+++ /dev/null
@@ -1,103 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-CONF = config.CONF
-
-
-class LoadBalancersTestJSON(base.BaseAdminTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Load Balancers with default credentials:
-
-        list load balancers
-        create load balancer
-        get load balancer
-        update load balancer
-        delete load balancer
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(LoadBalancersTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.create_lb_kwargs = {'tenant_id': cls.subnet['tenant_id'],
-                                'vip_subnet_id': cls.subnet['id']}
-        cls.load_balancer = \
-            cls._create_active_load_balancer(**cls.create_lb_kwargs)
-        cls.load_balancer_id = cls.load_balancer['id']
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_tenant_id_field_for_admin(self):
-        """
-        Test create load balancer with a missing tenant id field.
-        Verify tenant_id matches when creating loadbalancer vs.
-        load balancer(admin tenant)
-        """
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        admin_lb = self.load_balancers_client.get_load_balancer(
-            load_balancer.get('id'))
-        self.assertEqual(load_balancer.get('tenant_id'),
-                         admin_lb.get('tenant_id'))
-        self._wait_for_load_balancer_status(load_balancer['id'])
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_tenant_id_for_other_tenant(self):
-        """
-        Test create load balancer with a missing tenant id field. Verify
-        tenant_id does not match of subnet(non-admin tenant) vs.
-        load balancer(admin tenant)
-        """
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertNotEqual(load_balancer.get('tenant_id'),
-                            self.subnet['tenant_id'])
-        self._wait_for_load_balancer_status(load_balancer['id'])
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_empty_tenant_id_field(self):
-        """Test create load balancer with empty tenant_id field should fail"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          vip_subnet_id=self.subnet['id'],
-                          wait=False,
-                          tenant_id="")
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_for_another_tenant(self):
-        """Test create load balancer for other tenant"""
-        tenant = 'deffb4d7c0584e89a8ec99551565713c'
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'],
-            tenant_id=tenant)
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('tenant_id'), tenant)
-        self._wait_for_load_balancer_status(load_balancer['id'])
diff --git a/tests/tempest/v2/api/test_load_balancers_non_admin.py b/tests/tempest/v2/api/test_load_balancers_non_admin.py
deleted file mode 100644
index dda4d54..0000000
--- a/tests/tempest/v2/api/test_load_balancers_non_admin.py
+++ /dev/null
@@ -1,444 +0,0 @@
-# Copyright 2015, 2016 Rackspace US Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from netaddr import IPAddress
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-CONF = config.CONF
-
-
-class LoadBalancersTestJSON(base.BaseTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Load Balancers with default credentials:
-
-        list load balancers
-        create load balancer
-        get load balancer
-        update load balancer
-        delete load balancer
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(LoadBalancersTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.create_lb_kwargs = {'tenant_id': cls.subnet['tenant_id'],
-                                'vip_subnet_id': cls.subnet['id']}
-        cls.load_balancer = \
-            cls._create_active_load_balancer(**cls.create_lb_kwargs)
-        cls.load_balancer_id = cls.load_balancer['id']
-
-    @test.attr(type='smoke')
-    def test_list_load_balancers(self):
-        """Test list load balancers with one load balancer"""
-        load_balancers = self.load_balancers_client.list_load_balancers()
-        self.assertEqual(len(load_balancers), 1)
-        self.assertIn(self.load_balancer, load_balancers)
-
-    @test.attr(type='smoke')
-    def test_list_load_balancers_two(self):
-        """Test list load balancers with two load balancers"""
-        new_load_balancer = self._create_active_load_balancer(
-            **self.create_lb_kwargs)
-        new_load_balancer_id = new_load_balancer['id']
-        self.addCleanup(self._delete_load_balancer, new_load_balancer_id)
-        load_balancers = self.load_balancers_client.list_load_balancers()
-        self.assertEqual(len(load_balancers), 2)
-        self.assertIn(self.load_balancer, load_balancers)
-        self.assertIn(new_load_balancer, load_balancers)
-        self.assertNotEqual(self.load_balancer, new_load_balancer)
-
-    @test.attr(type='smoke')
-    def test_get_load_balancer(self):
-        """Test get load balancer"""
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        self.assertEqual(self.load_balancer, load_balancer)
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer(self):
-        """Test create load balancer"""
-        new_load_balancer = self._create_active_load_balancer(
-            **self.create_lb_kwargs)
-        new_load_balancer_id = new_load_balancer['id']
-        self.addCleanup(self._delete_load_balancer, new_load_balancer_id)
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            new_load_balancer_id)
-        self.assertEqual(new_load_balancer, load_balancer)
-        self.assertNotEqual(self.load_balancer, new_load_balancer)
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_missing_vip_subnet_id_field(self):
-        """
-        Test create load balancer with a missing
-        required vip_subnet_id field
-        """
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          tenant_id=self.subnet['tenant_id'])
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_empty_provider_field(self):
-        """Test create load balancer with an empty provider field"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          provider="")
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_empty_description_field(self):
-        """Test create load balancer with an empty description field"""
-        load_balancer = self._create_active_load_balancer(
-            vip_subnet_id=self.subnet['id'], description="")
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('description'), "")
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_empty_vip_address_field(self):
-        """Test create load balancer with empty vip_address field"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          vip_subnet_id=self.subnet['id'],
-                          vip_address="")
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_admin_state_up(self):
-        """Test create load balancer with a missing admin_state_up field"""
-        load_balancer = self._create_active_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('admin_state_up'), True)
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_empty_admin_state_up_field(self):
-        """Test create load balancer with empty admin_state_up field"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          vip_subnet_id=self.subnet['id'],
-                          admin_state_up="")
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_name(self):
-        """Test create load balancer with a missing name field"""
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('name'), '')
-        self._wait_for_load_balancer_status(load_balancer['id'])
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_empty_name(self):
-        """Test create load balancer with an empty name field"""
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'], name="")
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('name'), "")
-        self._wait_for_load_balancer_status(load_balancer['id'])
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_description(self):
-        """Test create load balancer with a missing description field"""
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('description'), '')
-        self._wait_for_load_balancer_status(load_balancer['id'])
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_vip_address(self):
-        """
-        Test create load balancer with a missing vip_address field,checks for
-        ipversion and actual ip address
-        """
-        load_balancer = self._create_active_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        load_balancer_ip_initial = load_balancer['vip_address']
-        ip = IPAddress(load_balancer_ip_initial)
-        self.assertEqual(ip.version, 4)
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            load_balancer['id'])
-        load_balancer_final = load_balancer['vip_address']
-        self.assertEqual(load_balancer_ip_initial, load_balancer_final)
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_provider_field(self):
-        """Test create load balancer with a missing provider field"""
-        load_balancer = self._create_active_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        load_balancer_initial = load_balancer['provider']
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            load_balancer['id'])
-        load_balancer_final = load_balancer['provider']
-        self.assertEqual(load_balancer_initial, load_balancer_final)
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_invalid_vip_subnet_id(self):
-        """Test create load balancer with an invalid vip subnet id"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          vip_subnet_id="abc123")
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_empty_vip_subnet_id(self):
-        """Test create load balancer with an empty vip subnet id"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          vip_subnet_id="")
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_invalid_tenant_id(self):
-        """Test create load balancer with an invalid tenant id"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          tenant_id="&^%123")
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_invalid_name(self):
-        """Test create load balancer with an invalid name"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          tenant_id=self.subnet['tenant_id'],
-                          vip_subnet_id=self.subnet['id'],
-                          name='n' * 256)
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_invalid_description(self):
-        """Test create load balancer with an invalid description"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          tenant_id=self.subnet['tenant_id'],
-                          vip_subnet_id=self.subnet['id'],
-                          description='d' * 256)
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_incorrect_attribute(self):
-        """Test create a load balancer with an extra, incorrect field"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          tenant_id=self.subnet['tenant_id'],
-                          vip_subnet_id=self.subnet['id'],
-                          protocol_port=80)
-
-    @test.attr(type='smoke')
-    def test_create_load_balancer_missing_tenant_id_field(self):
-        """Test create load balancer with a missing tenant id field"""
-        load_balancer = self.load_balancers_client.create_load_balancer(
-            vip_subnet_id=self.subnet['id'])
-        self.addCleanup(self._delete_load_balancer, load_balancer['id'])
-        self.assertEqual(load_balancer.get('tenant_id'),
-                         self.subnet['tenant_id'])
-        self._wait_for_load_balancer_status(load_balancer['id'])
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_empty_tenant_id_field(self):
-        """Test create load balancer with empty tenant_id field"""
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          vip_subnet_id=self.subnet['id'],
-                          wait=False,
-                          tenant_id="")
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_other_tenant_id_field(self):
-        """Test create load balancer for other tenant"""
-        tenant = 'deffb4d7c0584e89a8ec99551565713c'
-        self.assertRaises(ex.BadRequest,
-                          self.load_balancers_client.create_load_balancer,
-                          wait=False,
-                          vip_subnet_id=self.subnet['id'],
-                          tenant_id=tenant)
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_invalid_flavor_field(self):
-        """Test create load balancer with an invalid flavor field"""
-        self.assertRaises(ex.NotFound,
-                          self.load_balancers_client.create_load_balancer,
-                          vip_subnet_id=self.subnet['id'],
-                          flavor_id="NO_SUCH_FLAVOR")
-
-    @test.attr(type='negative')
-    def test_create_load_balancer_provider_flavor_conflict(self):
-        """Test create load balancer with both a provider and a flavor"""
-        self.assertRaises(ex.Conflict,
-                          self.load_balancers_client.create_load_balancer,
-                          vip_subnet_id=self.subnet['id'],
-                          flavor_id="NO_SUCH_FLAVOR",
-                          provider="NO_SUCH_PROVIDER")
-
-    @test.attr(type='smoke')
-    def test_update_load_balancer(self):
-        """Test update load balancer"""
-        self._update_load_balancer(self.load_balancer_id,
-                                   name='new_name')
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        self.assertEqual(load_balancer.get('name'), 'new_name')
-
-    @test.attr(type='smoke')
-    def test_update_load_balancer_empty_name(self):
-        """Test update load balancer with empty name"""
-        self._update_load_balancer(self.load_balancer_id,
-                                   name="")
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        self.assertEqual(load_balancer.get('name'), "")
-
-    @test.attr(type='negative')
-    def test_update_load_balancer_invalid_name(self):
-        """Test update load balancer with invalid name"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_load_balancer,
-                          load_balancer_id=self.load_balancer_id,
-                          wait=False,
-                          name='a' * 256)
-
-    @test.attr(type='smoke')
-    def test_update_load_balancer_missing_name(self):
-        """Test update load balancer with missing name"""
-        loadbalancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        load_balancer_initial = loadbalancer['name']
-        self._update_load_balancer(self.load_balancer_id)
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        load_balancer_new = load_balancer['name']
-        self.assertEqual(load_balancer_initial, load_balancer_new)
-
-    @test.attr(type='negative')
-    def test_update_load_balancer_invalid_description(self):
-        """Test update load balancer with invalid description"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_load_balancer,
-                          load_balancer_id=self.load_balancer_id,
-                          wait=False,
-                          description='a' * 256)
-
-    @test.attr(type='smoke')
-    def test_update_load_balancer_empty_description(self):
-        """Test update load balancer with empty description"""
-        self._update_load_balancer(self.load_balancer_id,
-                                   description="")
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        self.assertEqual(load_balancer.get('description'), "")
-
-    @test.attr(type='smoke')
-    def test_update_load_balancer_missing_description(self):
-        """Test update load balancer with missing description"""
-        loadbalancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        load_balancer_initial = loadbalancer['description']
-        self._update_load_balancer(self.load_balancer_id)
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        load_balancer_new = load_balancer['description']
-        self.assertEqual(load_balancer_initial, load_balancer_new)
-
-    @test.attr(type='negative')
-    def test_update_load_balancer_invalid_admin_state_up_field(self):
-        """Test update load balancer with an invalid admin_state_up"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_load_balancer,
-                          load_balancer_id=self.load_balancer_id,
-                          wait=False,
-                          admin_state_up="a&^%$jbc123")
-
-    @test.attr(type='negative')
-    def test_update_load_balancer_empty_admin_state_up_field(self):
-        """Test update load balancer with an empty admin_state_up"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_load_balancer,
-                          load_balancer_id=self.load_balancer_id,
-                          wait=False,
-                          admin_state_up="")
-
-    @test.attr(type='smoke')
-    def test_update_load_balancer_missing_admin_state_up(self):
-        """Test update load balancer with missing admin state field"""
-        loadbalancer = self.load_balancers_client.get_load_balancer(
-            self.load_balancer_id)
-        load_balancer_initial = loadbalancer['admin_state_up']
-        self._update_load_balancer(self.load_balancer_id)
-        self.assertEqual(load_balancer_initial, True)
-
-    @test.attr(type='negative')
-    def test_update_load_balancer_incorrect_attribute(self):
-        """Test update a load balancer with an extra, invalid attribute"""
-        self.assertRaises(ex.BadRequest,
-                          self._update_load_balancer,
-                          load_balancer_id=self.load_balancer_id,
-                          wait=False,
-                          name="lb_name",
-                          description="lb_name_description",
-                          admin_state_up=True,
-                          port=80)
-
-    @test.attr(type='smoke')
-    def test_get_load_balancer_status_tree(self):
-        """Test get load balancer status tree"""
-        statuses = self.load_balancers_client.get_load_balancer_status_tree(
-            self.load_balancer_id)
-        load_balancer = statuses['loadbalancer']
-        self.assertEqual("ONLINE", load_balancer['operating_status'])
-        self.assertEqual("ACTIVE", load_balancer['provisioning_status'])
-        self.assertEqual([], load_balancer['listeners'])
-
-    @test.attr(type='smoke')
-    def test_get_load_balancer_stats(self):
-        """Test get load balancer stats"""
-        stats = self.load_balancers_client.get_load_balancer_stats(
-            self.load_balancer_id)
-        self.assertEqual(0, stats['bytes_in'])
-        self.assertEqual(0, stats['bytes_out'])
-        self.assertEqual(0, stats['total_connections'])
-        self.assertEqual(0, stats['active_connections'])
-
-    @test.attr(type='smoke')
-    def test_delete_load_balancer(self):
-        """Test delete load balancer"""
-        new_load_balancer = self._create_active_load_balancer(
-            **self.create_lb_kwargs)
-        new_load_balancer_id = new_load_balancer['id']
-        load_balancer = self.load_balancers_client.get_load_balancer(
-            new_load_balancer_id)
-        self.assertEqual(new_load_balancer, load_balancer)
-        self.assertNotEqual(self.load_balancer, new_load_balancer)
-        self._delete_load_balancer(new_load_balancer_id)
-        self.assertRaises(ex.NotFound,
-                          self.load_balancers_client.get_load_balancer,
-                          new_load_balancer_id)
diff --git a/tests/tempest/v2/api/test_members_admin.py b/tests/tempest/v2/api/test_members_admin.py
deleted file mode 100644
index d6fe16e..0000000
--- a/tests/tempest/v2/api/test_members_admin.py
+++ /dev/null
@@ -1,85 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-CONF = config.CONF
-
-
-class MemberTestJSON(base.BaseAdminTestCase):
-    """
-    Test the member creation operation in admin scope in
-    Neutron-LBaaS API using the REST client for members:
-
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(MemberTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled("lbaas", "network"):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.tenant_id = cls.subnet.get('tenant_id')
-        cls.subnet_id = cls.subnet.get('id')
-        cls.load_balancer = cls._create_active_load_balancer(
-            tenant_id=cls.tenant_id,
-            vip_subnet_id=cls.subnet.get('id'))
-        cls.load_balancer_id = cls.load_balancer.get("id")
-        cls._wait_for_load_balancer_status(cls.load_balancer_id)
-        cls.listener = cls._create_listener(
-            loadbalancer_id=cls.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=80)
-        cls.listener_id = cls.listener.get('id')
-        cls.pool = cls._create_pool(protocol='HTTP',
-                                    tenant_id=cls.tenant_id,
-                                    lb_algorithm='ROUND_ROBIN',
-                                    listener_id=cls.listener_id)
-        cls.pool_id = cls.pool.get('id')
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(MemberTestJSON, cls).resource_cleanup()
-
-    @test.attr(type='smoke')
-    def test_create_member_invalid_tenant_id(self):
-        """Test create member with invalid tenant_id"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['tenant_id'] = "$232!$pw"
-        member = self._create_member(self.pool_id, **member_opts)
-        self.addCleanup(self._delete_member, self.pool_id, member['id'])
-        self.assertEqual(member['subnet_id'], self.subnet_id)
-        self.assertEqual(member['tenant_id'], "$232!$pw")
-
-    @test.attr(type='negative')
-    def test_create_member_empty_tenant_id(self):
-        """Test create member with an empty tenant_id should fail"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['tenant_id'] = ""
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
diff --git a/tests/tempest/v2/api/test_members_non_admin.py b/tests/tempest/v2/api/test_members_non_admin.py
deleted file mode 100644
index 742296f..0000000
--- a/tests/tempest/v2/api/test_members_non_admin.py
+++ /dev/null
@@ -1,453 +0,0 @@
-# Copyright 2015, 2016 Rackspace US Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-CONF = config.CONF
-
-
-class MemberTestJSON(base.BaseTestCase):
-
-    """
-    Test the following operations in Neutron-LBaaS API using the
-    REST client for members:
-
-        list members of a pool
-        create a member of a Pool
-        update a pool member
-        delete a member
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(MemberTestJSON, cls).resource_setup()
-        if not test.is_extension_enabled("lbaas", "network"):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.tenant_id = cls.subnet.get('tenant_id')
-        cls.subnet_id = cls.subnet.get('id')
-        cls.load_balancer = cls._create_active_load_balancer(
-            tenant_id=cls.tenant_id,
-            vip_subnet_id=cls.subnet.get('id'))
-        cls.load_balancer_id = cls.load_balancer.get("id")
-        cls.listener = cls._create_listener(
-            loadbalancer_id=cls.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=80)
-        cls.listener_id = cls.listener.get('id')
-        cls.pool = cls._create_pool(protocol='HTTP',
-                                    tenant_id=cls.tenant_id,
-                                    lb_algorithm='ROUND_ROBIN',
-                                    listener_id=cls.listener_id)
-        cls.pool_id = cls.pool.get('id')
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(MemberTestJSON, cls).resource_cleanup()
-
-    @test.attr(type='smoke')
-    def test_list_empty_members(self):
-        """Test that pool members are empty."""
-        members = self.members_client.list_members(self.pool_id)
-        self.assertEmpty(members,
-                         msg='Initial pool was supposed to be empty')
-
-    @test.attr(type='smoke')
-    def test_list_3_members(self):
-        """Test that we can list members. """
-        member_ips_exp = set([u"127.0.0.0", u"127.0.0.1", u"127.0.0.2"])
-        for ip in member_ips_exp:
-            member_opts = self.build_member_opts()
-            member_opts["address"] = ip
-            member = self._create_member(self.pool_id, **member_opts)
-            self.addCleanup(self._delete_member, self.pool_id, member['id'])
-        members = self.members_client.list_members(self.pool_id)
-        self.assertEqual(3, len(members))
-        for member in members:
-            self.assertEqual(member["tenant_id"], self.tenant_id)
-            self.assertEqual(member["protocol_port"], 80)
-            self.assertEqual(member["subnet_id"], self.subnet_id)
-        found_member_ips = set([m["address"] for m in members])
-        self.assertEqual(found_member_ips, member_ips_exp)
-
-    @test.attr(type='smoke')
-    def test_add_member(self):
-        """Test that we can add a single member."""
-        expect_empty_members = self.members_client.list_members(self.pool_id)
-        self.assertEmpty(expect_empty_members)
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id, **member_opts)
-        member_id = member.get("id")
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertEqual(member_opts["address"], member["address"])
-        self.assertEqual(self.tenant_id, member["tenant_id"])
-        self.assertEqual(80, member["protocol_port"])
-        self.assertEqual(self.subnet_id, member["subnet_id"])
-        # Should have default values for admin_state_up and weight
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-
-    @test.attr(type='smoke')
-    def test_get_member(self):
-        """Test that we can fetch a member by id."""
-        member_opts = self.build_member_opts()
-        member_id = self._create_member(self.pool_id,
-                                        **member_opts)["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        member = self.members_client.get_member(self.pool_id, member_id)
-        self.assertEqual(member_id, member["id"])
-        self.assertEqual(member_opts["address"], member["address"])
-        self.assertEqual(member_opts["tenant_id"], member["tenant_id"])
-        self.assertEqual(member_opts["protocol_port"], member["protocol_port"])
-        self.assertEqual(member_opts["subnet_id"], member["subnet_id"])
-
-    @test.attr(type='smoke')
-    def test_create_member_missing_required_field_tenant_id(self):
-        """Test if a non_admin user can create a member with tenant_id
-        missing
-        """
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member = self._create_member(self.pool_id, **member_opts)
-        self.addCleanup(self._delete_member, self.pool_id, member['id'])
-
-    @test.attr(type='negative')
-    def test_create_member_missing_required_field_address(self):
-        """Test create a member with missing field address"""
-        member_opts = {}
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_missing_required_field_protocol_port(self):
-        """Test create a member with missing field protocol_port"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['subnet_id'] = self.subnet_id
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_missing_required_field_subnet_id(self):
-        """Test create a member with missing field subnet_id """
-        member_opts = {}
-        member_opts['protocol_port'] = 80
-        member_opts['address'] = "127.0.0.1"
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_raises_BadRequest_when_missing_attrs_during_member_create(self):
-        """Test failure on missing attributes on member create."""
-        member_opts = {}
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_invalid_tenant_id(self):
-        """Test create member with invalid tenant_id"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['tenant_id'] = "$232!$pw"
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_invalid_address(self):
-        """Test create member with invalid address"""
-        member_opts = {}
-        member_opts['address'] = "127$%<ki"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_invalid_protocol_port(self):
-        """Test create member with invalid protocol_port"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 8090000
-        member_opts['subnet_id'] = self.subnet_id
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_invalid_subnet_id(self):
-        """Test create member with invalid subnet_id"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = "45k%^"
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_invalid_admin_state_up(self):
-        """Test create member with invalid admin_state_up"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['admin_state_up'] = "$232!$pw"
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_invalid_weight(self):
-        """Test create member with invalid weight"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['weight'] = "$232!$pw"
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_empty_tenant_id(self):
-        """Test create member with an empty tenant_id"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['tenant_id'] = ""
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_empty_address(self):
-        """Test create member with an empty address"""
-        member_opts = {}
-        member_opts['address'] = ""
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_empty_protocol_port(self):
-        """Test create member with an empty protocol_port"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = ""
-        member_opts['subnet_id'] = self.subnet_id
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_empty_subnet_id(self):
-        """Test create member with empty subnet_id"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = ""
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_empty_admin_state_up(self):
-        """Test create member with an empty admin_state_up"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['admin_state_up'] = ""
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_create_member_empty_weight(self):
-        """Test create member with an empty weight"""
-        member_opts = {}
-        member_opts['address'] = "127.0.0.1"
-        member_opts['protocol_port'] = 80
-        member_opts['subnet_id'] = self.subnet_id
-        member_opts['weight'] = ""
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='smoke')
-    def test_delete_member(self):
-        """Test that we can delete a member by id."""
-        member_opts = self.build_member_opts()
-        member_id = self._create_member(self.pool_id,
-                                        **member_opts)["id"]
-        members = self.members_client.list_members(self.pool_id)
-        self.assertEqual(1, len(members))
-        self._delete_member(self.pool_id, member_id)
-        members = self.members_client.list_members(self.pool_id)
-        self.assertEmpty(members)
-
-    @test.attr(type='smoke')
-    def test_update_member(self):
-        """Test that we can update a member."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member['id'])
-        # Make sure the defaults are correct
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        # Lets overwrite the defaults
-        member_opts = {"weight": 10, "admin_state_up": False}
-        member = self._update_member(self.pool_id, member_id,
-                                     **member_opts)
-        # And make sure they stick
-        self.assertFalse(member["admin_state_up"])
-        self.assertEqual(10, member["weight"])
-
-    @test.attr(type='smoke')
-    def test_update_member_missing_admin_state_up(self):
-        """Test that we can update a member with missing admin_state_up."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        member_opts = {"weight": 10}
-        member = self._update_member(self.pool_id, member_id,
-                                     **member_opts)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(10, member["weight"])
-
-    @test.attr(type='smoke')
-    def test_update_member_missing_weight(self):
-        """Test that we can update a member with missing weight."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        member_opts = {"admin_state_up": False}
-        member = self._update_member(self.pool_id, member_id,
-                                     **member_opts)
-        self.assertFalse(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-
-    @test.attr(type='negative')
-    def test_update_member_invalid_admin_state_up(self):
-        """Test that we can update a member with empty admin_state_up."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        member_opts = {"weight": 10, "admin_state_up": "%^67"}
-        self.assertRaises(ex.BadRequest, self._update_member,
-                          self.pool_id, member_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_update_member_invalid_weight(self):
-        """Test that we can update a member with an empty weight."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        member_opts = {"admin_state_up": False, "weight": "*^$df"}
-        self.assertRaises(ex.BadRequest, self._update_member,
-                          self.pool_id, member_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_update_member_empty_admin_state_up(self):
-        """Test that we can update a member with empty admin_state_up."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        member_opts = {"weight": 10, "admin_state_up": ""}
-        self.assertRaises(ex.BadRequest, self._update_member,
-                          self.pool_id, member_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_update_member_empty_weight(self):
-        """Test that we can update a member with an empty weight."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id,
-                                     **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        self.assertTrue(member["admin_state_up"])
-        self.assertEqual(1, member["weight"])
-        member_opts = {"admin_state_up": False, "weight": ""}
-        self.assertRaises(ex.BadRequest, self._update_member,
-                          self.pool_id, member_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_raises_immutable_when_updating_immutable_attrs_on_member(self):
-        """Test failure on immutable attribute on member create."""
-        member_opts = self.build_member_opts()
-        member_id = self._create_member(self.pool_id,
-                                        **member_opts)["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        member_opts = {"address": "127.0.0.69"}
-        # The following code actually raises a 400 instead of a 422 as expected
-        # Will need to consult with blogan as to what to fix
-        self.assertRaises(ex.BadRequest, self._update_member,
-                          self.pool_id, member_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_raises_exception_on_invalid_attr_on_create(self):
-        """Test failure on invalid attribute on member create."""
-        member_opts = self.build_member_opts()
-        member_opts["invalid_op"] = "should_break_request"
-        self.assertRaises(ex.BadRequest, self._create_member,
-                          self.pool_id, **member_opts)
-
-    @test.attr(type='negative')
-    def test_raises_exception_on_invalid_attr_on_update(self):
-        """Test failure on invalid attribute on member update."""
-        member_opts = self.build_member_opts()
-        member = self._create_member(self.pool_id, **member_opts)
-        member_id = member["id"]
-        self.addCleanup(self._delete_member, self.pool_id, member_id)
-        member_opts["invalid_op"] = "watch_this_break"
-        self.assertRaises(ex.BadRequest, self._update_member,
-                          self.pool_id, member_id, **member_opts)
-
-    @classmethod
-    def build_member_opts(cls, **kw):
-        """Build out default member dictionary """
-        opts = {"address": kw.get("address", "127.0.0.1"),
-                "tenant_id": kw.get("tenant_id", cls.tenant_id),
-                "protocol_port": kw.get("protocol_port", 80),
-                "subnet_id": kw.get("subnet_id", cls.subnet_id)}
-        return opts
diff --git a/tests/tempest/v2/api/test_pools_admin.py b/tests/tempest/v2/api/test_pools_admin.py
deleted file mode 100644
index 893df0b..0000000
--- a/tests/tempest/v2/api/test_pools_admin.py
+++ /dev/null
@@ -1,123 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-
-from tempest.lib.common.utils import data_utils
-from tempest.lib import decorators
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-
-PROTOCOL_PORT = 80
-
-
-class TestPools(base.BaseAdminTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Pools:
-
-        list pools
-        create pool
-        get pool
-        update pool
-        delete pool
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(TestPools, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.load_balancer = cls._create_load_balancer(
-            tenant_id=cls.subnet.get('tenant_id'),
-            vip_subnet_id=cls.subnet.get('id'))
-
-    def increment_protocol_port(self):
-        global PROTOCOL_PORT
-        PROTOCOL_PORT += 1
-
-    def _prepare_and_create_pool(self, protocol=None, lb_algorithm=None,
-                                 listener_id=None, **kwargs):
-        self.increment_protocol_port()
-        if not protocol:
-            protocol = 'HTTP'
-        if not lb_algorithm:
-            lb_algorithm = 'ROUND_ROBIN'
-        if not listener_id:
-            listener = self._create_listener(
-                loadbalancer_id=self.load_balancer.get('id'),
-                protocol='HTTP', protocol_port=PROTOCOL_PORT, **kwargs)
-            listener_id = listener.get('id')
-        response = self._create_pool(protocol=protocol,
-                                     lb_algorithm=lb_algorithm,
-                                     listener_id=listener_id,
-                                     **kwargs)
-        self.addCleanup(self._delete_pool, response['id'])
-        return response
-
-    @test.attr(type='negative')
-    def test_create_pool_using_empty_tenant_field(self):
-        """Test create pool with empty tenant field should fail"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          tenant_id="",
-                          lb_algorithm='ROUND_ROBIN')
-
-    @decorators.skip_because(bug="1468457")
-    @test.attr(type='smoke')
-    def test_create_pool_missing_tenant_id_for_other_tenant(self):
-        """
-        Test create pool with a missing tenant id field. Verify
-        tenant_id does not match when creating pool vs.
-        pool (admin client)
-        """
-        new_pool = self._prepare_and_create_pool(
-            protocol='HTTP',
-            lb_algorithm='ROUND_ROBIN')
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        pool_tenant = pool['tenant_id']
-        self.assertNotEqual(pool_tenant, self.subnet['tenant_id'])
-
-    @decorators.skip_because(bug="1468457")
-    @test.attr(type='smoke')
-    def test_create_pool_missing_tenant_id_for_admin(self):
-        """
-        Test create pool with a missing tenant id field. Verify
-        tenant_id matches when creating pool vs. pool (admin client)
-        """
-        new_pool = self._prepare_and_create_pool(
-            protocol='HTTP',
-            lb_algorithm='ROUND_ROBIN')
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        pool_tenant = pool['tenant_id']
-        self.assertEqual(pool_tenant, pool.get('tenant_id'))
-
-    @decorators.skip_because(bug="1468457")
-    @test.attr(type='smoke')
-    def test_create_pool_for_another_tenant(self):
-        """Test create pool for other tenant field"""
-        tenant = 'deffb4d7c0584e89a8ec99551565713c'
-        new_pool = self._prepare_and_create_pool(
-            tenant_id=tenant)
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        pool_tenant = pool.get('tenant_id')
-        self.assertEqual(pool_tenant, tenant)
diff --git a/tests/tempest/v2/api/test_pools_non_admin.py b/tests/tempest/v2/api/test_pools_non_admin.py
deleted file mode 100644
index 898398d..0000000
--- a/tests/tempest/v2/api/test_pools_non_admin.py
+++ /dev/null
@@ -1,579 +0,0 @@
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest.lib.common.utils import data_utils
-from tempest.lib import exceptions as ex
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-PROTOCOL_PORT = 80
-
-
-class TestPools(base.BaseTestCase):
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for Pools:
-
-        list pools
-        create pool
-        get pool
-        update pool
-        delete pool
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(TestPools, cls).resource_setup()
-        if not test.is_extension_enabled('lbaas', 'network'):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.load_balancer = cls._create_load_balancer(
-            tenant_id=cls.subnet.get('tenant_id'),
-            vip_subnet_id=cls.subnet.get('id'),
-            wait=True)
-        cls.listener = cls._create_listener(
-            loadbalancer_id=cls.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=80)
-
-    def increment_protocol_port(self):
-        global PROTOCOL_PORT
-        PROTOCOL_PORT += 1
-
-    def _prepare_and_create_pool(self, protocol=None, lb_algorithm=None,
-                                 listener_id=None, cleanup=True, **kwargs):
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        self.increment_protocol_port()
-        if not protocol:
-            protocol = 'HTTP'
-        if not lb_algorithm:
-            lb_algorithm = 'ROUND_ROBIN'
-        if not listener_id:
-            listener = self._create_listener(
-                loadbalancer_id=self.load_balancer.get('id'),
-                protocol='HTTP', protocol_port=PROTOCOL_PORT,
-                wait=True)
-            listener_id = listener.get('id')
-        response = self._create_pool(protocol=protocol,
-                                     lb_algorithm=lb_algorithm,
-                                     listener_id=listener_id,
-                                     wait=True,
-                                     **kwargs)
-        if cleanup:
-            self.addCleanup(self._delete_pool, response['id'])
-        return response
-
-    @test.attr(type='smoke')
-    def test_list_pools_empty(self):
-        """Test get pools when empty"""
-        pools = self.pools_client.list_pools()
-        self.assertEqual([], pools)
-
-    @test.attr(type='smoke')
-    def test_list_pools_one(self):
-        """Test get pools with one pool"""
-        new_pool = self._prepare_and_create_pool()
-        new_pool = self.pools_client.get_pool(new_pool['id'])
-        pools = self.pools_client.list_pools()
-        self.assertEqual(1, len(pools))
-        self.assertIn(new_pool, pools)
-
-    @test.attr(type='smoke')
-    def test_list_pools_two(self):
-        """Test get pools with two pools"""
-        new_pool1 = self._prepare_and_create_pool()
-        new_pool2 = self._prepare_and_create_pool()
-        pools = self.pools_client.list_pools()
-        self.assertEqual(2, len(pools))
-        self.assertIn(new_pool1, pools)
-        self.assertIn(new_pool2, pools)
-
-    @test.attr(type='smoke')
-    def test_get_pool(self):
-        """Test get pool"""
-        new_pool = self._prepare_and_create_pool()
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        self.assertEqual(new_pool, pool)
-
-    @test.attr(type='smoke')
-    def test_create_pool(self):
-        """Test create pool"""
-        new_pool = self._prepare_and_create_pool()
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        self.assertEqual(new_pool, pool)
-
-    @test.attr(type='negative')
-    def test_create_pool_missing_required_fields(self):
-        """Test create pool with a missing required fields"""
-        tenant_id = self.subnet.get('tenant_id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id=tenant_id,
-                          lb_algorithm='ROUND_ROBIN')
-
-    @test.attr(type='smoke')
-    def test_create_pool_missing_tenant_field(self):
-        """Test create pool with a missing required tenant field"""
-        tenant_id = self.subnet.get('tenant_id')
-        new_pool = self._prepare_and_create_pool(
-            protocol='HTTP',
-            lb_algorithm='ROUND_ROBIN')
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        pool_tenant = pool['tenant_id']
-        self.assertEqual(tenant_id, pool_tenant)
-
-    @test.attr(type='negative')
-    def test_create_pool_missing_protocol_field(self):
-        """Test create pool with a missing required protocol field"""
-        self.increment_protocol_port()
-        listener = self.listeners_client.create_listener(
-            loadbalancer_id=self.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=PROTOCOL_PORT)
-        self.addCleanup(self._delete_listener, listener['id'])
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        listener_id = listener.get('id')
-        tenant_id = self.subnet.get('tenant_id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id=tenant_id,
-                          listener_id=listener_id,
-                          lb_algorithm='ROUND_ROBIN')
-
-    @test.attr(type='negative')
-    def test_create_pool_missing_lb_algorithm_field(self):
-        """Test create pool with a missing required lb algorithm field"""
-        self.increment_protocol_port()
-        listener = self.listeners_client.create_listener(
-            loadbalancer_id=self.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=PROTOCOL_PORT)
-        self.addCleanup(self._delete_listener, listener['id'])
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        listener_id = listener.get('id')
-        tenant_id = self.subnet.get('tenant_id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id=tenant_id,
-                          listener_id=listener_id,
-                          protocol='HTTP')
-
-    @test.attr(type='negative')
-    def test_create_pool_missing_listener_id_field(self):
-        """Test create pool with a missing required listener id field"""
-        tenant_id = self.subnet.get('tenant_id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id=tenant_id,
-                          lb_algorithm='ROUND_ROBIN',
-                          protocol='HTTP')
-
-    @test.attr(type='smoke')
-    def test_create_pool_missing_description_field(self):
-        """Test create pool with missing description field"""
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        desc = pool_initial.get('description')
-        self.assertEqual(desc, "")
-
-    @test.attr(type='smoke')
-    def test_create_pool_missing_name_field(self):
-        """Test create pool with a missing name field"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        name = pool_initial.get('name')
-        self.assertEqual(name, "")
-
-    @test.attr(type='smoke')
-    def test_create_pool_missing_admin_state_up_field(self):
-        """Test create pool with a missing admin_state_up field"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        state = pool_initial.get('admin_state_up')
-        self.assertEqual(state, True)
-
-    @test.attr(type='smoke')
-    def test_create_pool_missing_session_pers_field(self):
-        """Test create pool with a missing session_pers field"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        sess = pool_initial.get('session_persistence')
-        self.assertIsNone(sess)
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_protocol(self):
-        """Test create pool with an invalid protocol"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='UDP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_session_persistence_field(self):
-        """Test create pool with invalid session persistance field"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          session_persistence={'type': 'HTTP'},
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_algorithm(self):
-        """Test create pool with an invalid algorithm"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          lb_algorithm='LEAST_CON',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_admin_state_up(self):
-        """Test create pool with an invalid admin state up field"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          admin_state_up="$!1%9823",
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_listener_field(self):
-        """Test create pool with invalid listener field"""
-        tenant_id = self.subnet.get('tenant_id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id=tenant_id,
-                          lb_algorithm='ROUND_ROBIN',
-                          protocol='HTTP',
-                          listener_id="$@5$%$7863")
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_tenant_id_field(self):
-        """Test create pool with invalid tenant_id field"""
-        self.increment_protocol_port()
-        listener = self.listeners_client.create_listener(
-            loadbalancer_id=self.load_balancer.get('id'),
-            protocol='HTTP', protocol_port=PROTOCOL_PORT)
-        self.addCleanup(self._delete_listener, listener['id'])
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        listener_id = listener.get('id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id="*&7653^%&",
-                          lb_algorithm='ROUND_ROBIN',
-                          protocol='HTTP',
-                          listener_id=listener_id)
-
-    @test.attr(type='negative')
-    def test_create_pool_incorrect_attribute(self):
-        """Test create a pool with an extra, incorrect field"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          protocol_port=80,
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_empty_listener_field(self):
-        """Test create pool with empty listener field"""
-        tenant_id = self.subnet.get('tenant_id')
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          tenant_id=tenant_id,
-                          lb_algorithm='ROUND_ROBIN',
-                          protocol='HTTP',
-                          listener_id="")
-
-    @test.attr(type='smoke')
-    def test_create_pool_empty_description_field(self):
-        """Test create pool with empty description field"""
-        new_pool = self._prepare_and_create_pool(description="")
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        pool_desc = pool.get('description')
-        self.assertEqual(pool_desc, '')
-
-    @test.attr(type='smoke')
-    def test_create_pool_empty_name_field(self):
-        """Test create pool with empty name field"""
-        new_pool = self._prepare_and_create_pool(name="")
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        pool_name = pool.get('name')
-        self.assertEqual(pool_name, '')
-
-    @test.attr(type='negative')
-    def test_create_pool_empty_protocol(self):
-        """Test create pool with an empty protocol"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol="",
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_empty_session_persistence_field(self):
-        """Test create pool with empty session persistence field"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          session_persistence="",
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_empty_algorithm(self):
-        """Test create pool with an empty algorithm"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          lb_algorithm="",
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_empty_admin_state_up(self):
-        """Test create pool with an invalid admin state up field"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          admin_state_up="",
-                          lb_algorithm='ROUND_ROBIN')
-
-    @test.attr(type='negative')
-    def test_create_pool_empty_tenant_field(self):
-        """Test create pool with empty tenant field"""
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          tenant_id="",
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_for_other_tenant_field(self):
-        """Test create pool for other tenant field"""
-        tenant = 'deffb4d7c0584e89a8ec99551565713c'
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          tenant_id=tenant,
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_name_field(self):
-        """
-        known bug with input more than 255 chars
-        Test create pool with invalid name field
-        """
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'],
-                          name='n' * 256)
-
-    @test.attr(type='negative')
-    def test_create_pool_invalid_desc_field(self):
-        """
-        known bug with input more than 255 chars
-        Test create pool with invalid desc field
-        """
-        self.assertRaises(ex.BadRequest, self._prepare_and_create_pool,
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'],
-                          description='d' * 256)
-
-    @test.attr(type='negative')
-    def test_create_pool_with_session_persistence_unsupported_type(self):
-        """Test create a pool with an incorrect type value
-        for session persistence
-        """
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          session_persistence={'type': 'UNSUPPORTED'},
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='smoke')
-    def test_create_pool_with_session_persistence_http_cookie(self):
-        """Test create a pool with session_persistence type=HTTP_COOKIE"""
-        new_pool = self._prepare_and_create_pool(
-            session_persistence={'type': 'HTTP_COOKIE'})
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        self.assertEqual(new_pool, pool)
-
-    @test.attr(type='smoke')
-    def test_create_pool_with_session_persistence_app_cookie(self):
-        """Test create a pool with session_persistence type=APP_COOKIE"""
-        new_pool = self._prepare_and_create_pool(
-            session_persistence={'type': 'APP_COOKIE',
-                                 'cookie_name': 'sessionId'})
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        self.assertEqual(new_pool, pool)
-
-    @test.attr(type='negative')
-    def test_create_pool_with_session_persistence_redundant_cookie_name(self):
-        """Test create a pool with session_persistence with cookie_name
-        for type=HTTP_COOKIE
-        """
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          session_persistence={'type': 'HTTP_COOKIE',
-                                               'cookie_name': 'sessionId'},
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='negative')
-    def test_create_pool_with_session_persistence_without_cookie_name(self):
-        """Test create a pool with session_persistence without
-        cookie_name for type=APP_COOKIE
-        """
-        self.assertRaises(ex.BadRequest, self._create_pool,
-                          session_persistence={'type': 'APP_COOKIE'},
-                          protocol='HTTP',
-                          lb_algorithm='ROUND_ROBIN',
-                          listener_id=self.listener['id'])
-
-    @test.attr(type='smoke')
-    def test_update_pool(self):
-        """Test update pool"""
-        new_pool = self._prepare_and_create_pool()
-        desc = 'testing update with new description'
-        pool = self._update_pool(new_pool.get('id'),
-                                 description=desc,
-                                 wait=True)
-        self.assertEqual(desc, pool.get('description'))
-
-    @test.attr(type='smoke')
-    def test_update_pool_missing_name(self):
-        """Test update pool with missing name"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        name = pool_initial.get('name')
-        pool = self.pools_client.update_pool(new_pool.get('id'))
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        self.assertEqual(name, pool.get('name'))
-
-    @test.attr(type='smoke')
-    def test_update_pool_missing_description(self):
-        """Test update pool with missing description"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        desc = pool_initial.get('description')
-        pool = self.pools_client.update_pool(new_pool.get('id'))
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        self.assertEqual(desc, pool.get('description'))
-
-    @test.attr(type='smoke')
-    def test_update_pool_missing_admin_state_up(self):
-        """Test update pool with missing admin state up field"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        admin = pool_initial.get('admin_state_up')
-        pool = self.pools_client.update_pool(new_pool.get('id'))
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        self.assertEqual(admin, pool.get('admin_state_up'))
-
-    @test.attr(type='smoke')
-    def test_update_pool_missing_session_persistence(self):
-        """Test update pool with missing session persistence"""
-        new_pool = self._prepare_and_create_pool()
-        pool_initial = self.pools_client.get_pool(new_pool.get('id'))
-        sess_pers = pool_initial.get('session_persistence')
-        pool = self._update_pool(new_pool.get('id'))
-        self.assertAlmostEqual(sess_pers, pool.get('session_persistence'))
-
-    @test.attr(type='negative')
-    def test_update_pool_invalid_name(self):
-        """Test update pool with invalid name"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self.pools_client.update_pool,
-                          new_pool.get('id'), name='n' * 256)
-
-    @test.attr(type='negative')
-    def test_update_pool_invalid_desc(self):
-        """Test update pool with invalid desc"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self.pools_client.update_pool,
-                          new_pool.get('id'),
-                          description='d' * 256)
-
-    @test.attr(type='negative')
-    def test_update_pool_invalid_admin_state_up(self):
-        """Test update pool with an invalid admin_state_up"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self.pools_client.update_pool,
-                          new_pool.get('id'), admin_state_up='hello')
-
-    @test.attr(type='negative')
-    def test_update_pool_invalid_session_persistence(self):
-        """Test update pool with an invalid session pers. field"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self.pools_client.update_pool,
-                          new_pool.get('id'),
-                          session_persistence={'type': 'Hello'})
-
-    @test.attr(type='smoke')
-    def test_update_pool_empty_name(self):
-        """Test update pool with empty name"""
-        new_pool = self._prepare_and_create_pool()
-        pool = self.pools_client.update_pool(new_pool.get('id'), name="")
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        self.assertEqual(pool.get('name'), "")
-
-    @test.attr(type='smoke')
-    def test_update_pool_empty_description(self):
-        """Test update pool with empty description"""
-        new_pool = self._prepare_and_create_pool()
-        pool = self.pools_client.update_pool(new_pool.get('id'),
-                                             description="")
-        self._wait_for_load_balancer_status(self.load_balancer.get('id'))
-        self.assertEqual(pool.get('description'), "")
-
-    @test.attr(type='negative')
-    def test_update_pool_empty_admin_state_up(self):
-        """Test update pool with empty admin state up"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self.pools_client.update_pool,
-                          new_pool.get('id'), admin_state_up="")
-
-    @test.attr(type='negative')
-    def test_update_pool_empty_session_persistence(self):
-        """Test update pool with empty session persistence field"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self.pools_client.update_pool,
-                          new_pool.get('id'),
-                          session_persistence="")
-
-    @test.attr(type='negative')
-    def test_update_pool_invalid_attribute(self):
-        """Test update pool with an invalid attribute"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self._update_pool,
-                          new_pool.get('id'), lb_algorithm='ROUNDED')
-
-    @test.attr(type='negative')
-    def test_update_pool_incorrect_attribute(self):
-        """Test update a pool with an extra, incorrect field"""
-        new_pool = self._prepare_and_create_pool()
-        self.assertRaises(ex.BadRequest, self._update_pool,
-                          new_pool.get('id'), protocol='HTTPS')
-
-    @test.attr(type='smoke')
-    def test_delete_pool(self):
-        """Test delete pool"""
-        new_pool = self._prepare_and_create_pool(cleanup=False)
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        self.assertEqual(new_pool, pool)
-        self._delete_pool(new_pool.get('id'))
-        self.assertRaises(ex.NotFound, self.pools_client.get_pool,
-                          new_pool.get('id'))
-
-    @test.attr(type='smoke')
-    def test_delete_invalid_pool(self):
-        """Test delete pool that doesn't exist"""
-        new_pool = self._prepare_and_create_pool(cleanup=False)
-        pool = self.pools_client.get_pool(new_pool.get('id'))
-        self.assertEqual(new_pool, pool)
-        self._delete_pool(new_pool.get('id'))
-        self.assertRaises(ex.NotFound, self._delete_pool,
-                          new_pool.get('id'))
diff --git a/tests/tempest/v2/clients/__init__.py b/tests/tempest/v2/clients/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v2/clients/health_monitors_client.py b/tests/tempest/v2/clients/health_monitors_client.py
deleted file mode 100644
index cfdaf13..0000000
--- a/tests/tempest/v2/clients/health_monitors_client.py
+++ /dev/null
@@ -1,68 +0,0 @@
-# Copyright 2014, 2016 Rackspace US Inc.  All rights reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from oslo_serialization import jsonutils
-from six.moves.urllib import parse
-from tempest.lib.common import rest_client
-
-
-class HealthMonitorsClientJSON(rest_client.RestClient):
-    """
-    Tests Health Monitors API
-    """
-
-    def list_health_monitors(self, params=None):
-        """List all health monitors."""
-        url = 'v2.0/lbaas/healthmonitors'
-        if params:
-            url = "{0}?{1}".format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBodyList(resp, body['healthmonitors'])
-
-    def get_health_monitor(self, health_monitor_id, params=None):
-        """Get health monitor details."""
-        url = 'v2.0/lbaas/healthmonitors/{0}'.format(health_monitor_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body["healthmonitor"])
-
-    def create_health_monitor(self, **kwargs):
-        """Create a health monitor."""
-        url = 'v2.0/lbaas/healthmonitors'
-        post_body = jsonutils.dumps({"healthmonitor": kwargs})
-        resp, body = self.post(url, post_body)
-        body = jsonutils.loads(body)
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body["healthmonitor"])
-
-    def update_health_monitor(self, health_monitor_id, **kwargs):
-        """Update a health monitor."""
-        url = 'v2.0/lbaas/healthmonitors/{0}'.format(health_monitor_id)
-        put_body = jsonutils.dumps({"healthmonitor": kwargs})
-        resp, body = self.put(url, put_body)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body["healthmonitor"])
-
-    def delete_health_monitor(self, health_monitor_id):
-        """Delete an existing health monitor."""
-        url = 'v2.0/lbaas/healthmonitors/{0}'.format(health_monitor_id)
-        resp, body = self.delete(url)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
diff --git a/tests/tempest/v2/clients/listeners_client.py b/tests/tempest/v2/clients/listeners_client.py
deleted file mode 100644
index c37cfbb..0000000
--- a/tests/tempest/v2/clients/listeners_client.py
+++ /dev/null
@@ -1,67 +0,0 @@
-# Copyright 2015, 2016 Rackspace US Inc.  All rights reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from oslo_serialization import jsonutils
-from six.moves.urllib import parse
-from tempest.lib.common import rest_client
-
-
-class ListenersClientJSON(rest_client.RestClient):
-    """
-    Tests Listeners API
-    """
-
-    def list_listeners(self, params=None):
-        """List all listeners."""
-        url = 'v2.0/lbaas/listeners'
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBodyList(resp, body['listeners'])
-
-    def get_listener(self, listener_id, params=None):
-        """Get listener details."""
-        url = 'v2.0/lbaas/listeners/{0}'.format(listener_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['listener'])
-
-    def create_listener(self, **kwargs):
-        """Create a listener build."""
-        post_body = jsonutils.dumps({'listener': kwargs})
-        resp, body = self.post('v2.0/lbaas/listeners', post_body)
-        body = jsonutils.loads(body)
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body['listener'])
-
-    def update_listener(self, listener_id, **kwargs):
-        """Update an listener build."""
-        put_body = jsonutils.dumps({'listener': kwargs})
-        resp, body = self.put('v2.0/lbaas/listeners/{0}'
-                              .format(listener_id), put_body)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['listener'])
-
-    def delete_listener(self, listener_id):
-        """Delete an existing listener build."""
-        resp, body = self.delete("v2.0/lbaas/listeners/{0}"
-                                 .format(listener_id))
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
diff --git a/tests/tempest/v2/clients/load_balancers_client.py b/tests/tempest/v2/clients/load_balancers_client.py
deleted file mode 100644
index b5fd1e0..0000000
--- a/tests/tempest/v2/clients/load_balancers_client.py
+++ /dev/null
@@ -1,87 +0,0 @@
-# Copyright 2014, 2016 Rackspace US Inc.  All rights reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from oslo_serialization import jsonutils
-from six.moves.urllib import parse
-from tempest.lib.common import rest_client
-
-
-class LoadBalancersClientJSON(rest_client.RestClient):
-    """
-    Tests Load Balancers API
-    """
-
-    def list_load_balancers(self, params=None):
-        """List all load balancers."""
-        url = 'v2.0/lbaas/loadbalancers'
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBodyList(resp, body['loadbalancers'])
-
-    def get_load_balancer(self, load_balancer_id, params=None):
-        """Get load balancer details."""
-        url = 'v2.0/lbaas/loadbalancers/{0}'.format(load_balancer_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['loadbalancer'])
-
-    def create_load_balancer(self, **kwargs):
-        """Create a load balancer build."""
-        post_body = jsonutils.dumps({'loadbalancer': kwargs})
-        resp, body = self.post('v2.0/lbaas/loadbalancers', post_body)
-        body = jsonutils.loads(body)
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body['loadbalancer'])
-
-    def update_load_balancer(self, load_balancer_id, **kwargs):
-        """Update a load balancer build."""
-        put_body = jsonutils.dumps({'loadbalancer': kwargs})
-        resp, body = self.put('v2.0/lbaas/loadbalancers/{0}'
-                              .format(load_balancer_id), put_body)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['loadbalancer'])
-
-    def delete_load_balancer(self, load_balancer_id):
-        """Delete an existing load balancer build."""
-        resp, body = self.delete('v2.0/lbaas/loadbalancers/{0}'
-                                 .format(load_balancer_id))
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
-
-    def get_load_balancer_status_tree(self, load_balancer_id, params=None):
-        """Get a load balancer's status tree."""
-        url = 'v2.0/lbaas/loadbalancers/{0}/statuses'.format(load_balancer_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['statuses'])
-
-    def get_load_balancer_stats(self, load_balancer_id, params=None):
-        """Get a load balancer's stats."""
-        url = 'v2.0/lbaas/loadbalancers/{0}/stats'.format(load_balancer_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['stats'])
diff --git a/tests/tempest/v2/clients/members_client.py b/tests/tempest/v2/clients/members_client.py
deleted file mode 100644
index a614582..0000000
--- a/tests/tempest/v2/clients/members_client.py
+++ /dev/null
@@ -1,65 +0,0 @@
-# Copyright 2014, 2016 Rackspace US Inc.  All rights reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from oslo_serialization import jsonutils
-from six.moves.urllib import parse
-from tempest.lib.common import rest_client
-
-
-class MembersClientJSON(rest_client.RestClient):
-    """
-    Tests Members API
-    """
-
-    def list_members(self, pool_id, params=None):
-        """
-        List all Members
-        """
-        url = 'v2.0/lbaas/pools/{0}/members'.format(pool_id)
-        if params:
-            url = "{0}?{1}".format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBodyList(resp, body['members'])
-
-    def get_member(self, pool_id, member_id, params=None):
-        url = 'v2.0/lbaas/pools/{0}/members/{1}'.format(pool_id, member_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body["member"])
-
-    def create_member(self, pool_id, **kwargs):
-        url = 'v2.0/lbaas/pools/{0}/members'.format(pool_id)
-        post_body = jsonutils.dumps({"member": kwargs})
-        resp, body = self.post(url, post_body)
-        body = jsonutils.loads(body)
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body["member"])
-
-    def update_member(self, pool_id, member_id, **kwargs):
-        url = 'v2.0/lbaas/pools/{0}/members/{1}'.format(pool_id, member_id)
-        put_body = jsonutils.dumps({"member": kwargs})
-        resp, body = self.put(url, put_body)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body["member"])
-
-    def delete_member(self, pool_id, member_id, **kwargs):
-        url = 'v2.0/lbaas/pools/{0}/members/{1}'.format(pool_id, member_id)
-        resp, body = self.delete(url)
-        self.expected_success(204, resp.status)
diff --git a/tests/tempest/v2/clients/pools_client.py b/tests/tempest/v2/clients/pools_client.py
deleted file mode 100644
index 65de8d0..0000000
--- a/tests/tempest/v2/clients/pools_client.py
+++ /dev/null
@@ -1,69 +0,0 @@
-# Copyright 2015, 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from oslo_serialization import jsonutils
-from six.moves.urllib import parse
-from tempest.lib.common import rest_client
-
-
-class PoolsClientJSON(rest_client.RestClient):
-    """
-    Test Pools API
-    """
-
-    def list_pools(self, params=None):
-        """List all pools"""
-        url = 'v2.0/lbaas/pools'
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBodyList(resp, body['pools'])
-
-    def get_pool(self, pool_id, params=None):
-        """List details of a pool"""
-        url = 'v2.0/lbaas/pools/{pool_id}'.format(pool_id=pool_id)
-        if params:
-            url = '{0}?{1}'.format(url, parse.urlencode(params))
-        resp, body = self.get(url)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['pool'])
-
-    def create_pool(self, **kwargs):
-        """Create a pool"""
-        url = 'v2.0/lbaas/pools'
-        post_body = jsonutils.dumps({'pool': kwargs})
-        resp, body = self.post(url, post_body)
-        body = jsonutils.loads(body)
-        self.expected_success(201, resp.status)
-        return rest_client.ResponseBody(resp, body['pool'])
-
-    def update_pool(self, pool_id, **kwargs):
-        """Update a pool"""
-        url = 'v2.0/lbaas/pools/{pool_id}'.format(pool_id=pool_id)
-        post_body = jsonutils.dumps({'pool': kwargs})
-        resp, body = self.put(url, post_body)
-        body = jsonutils.loads(body)
-        self.expected_success(200, resp.status)
-        return rest_client.ResponseBody(resp, body['pool'])
-
-    def delete_pool(self, pool_id):
-        """Delete Pool"""
-        url = 'v2.0/lbaas/pools/{pool_id}'.format(pool_id=pool_id)
-        resp, body = self.delete(url)
-        self.expected_success(204, resp.status)
-        return rest_client.ResponseBody(resp, body)
diff --git a/tests/tempest/v2/ddt/__init__.py b/tests/tempest/v2/ddt/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v2/ddt/base_ddt.py b/tests/tempest/v2/ddt/base_ddt.py
deleted file mode 100644
index b0bfa61..0000000
--- a/tests/tempest/v2/ddt/base_ddt.py
+++ /dev/null
@@ -1,229 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import os
-
-from tempest import config
-from tempest.lib.common.utils import data_utils
-from tempest import test
-import testscenarios
-
-from neutron_lbaas.tests.tempest.v2.api import base
-
-CONF = config.CONF
-
-
-# Use local tempest conf if one is available.
-# This usually means we're running tests outside of devstack
-if os.path.exists('./tests/tempest/etc/dev_tempest.conf'):
-    CONF.set_config_path('./tests/tempest/etc/dev_tempest.conf')
-
-
-class AdminStateTests(testscenarios.TestWithScenarios,
-                      base.BaseTestCase):
-    """
-      Scenario Tests(admin_state_up tests):
-
-      This class supplies the resource set up methods and the check
-      operating status methods for the admin_sate_up tests.
-
-    """
-
-    @classmethod
-    def resource_setup(cls):
-        super(AdminStateTests, cls).resource_setup()
-        if not test.is_extension_enabled("lbaasv2", "network"):
-            msg = "lbaas extension not enabled."
-            raise cls.skipException(msg)
-        network_name = data_utils.rand_name('network-')
-        cls.network = cls.create_network(network_name)
-        cls.subnet = cls.create_subnet(cls.network)
-        cls.tenant_id = cls.subnet.get('tenant_id')
-        cls.subnet_id = cls.subnet.get('id')
-        cls.protocol = 'HTTP'
-        cls.port = 8081
-        cls.lb_algorithm = 'ROUND_ROBIN'
-        cls.address = '127.0.0.1'
-
-    @classmethod
-    def resource_setup_load_balancer(cls, admin_state_up_flag):
-        cls.create_lb_kwargs = {'tenant_id': cls.tenant_id,
-                                'vip_subnet_id': cls.subnet_id,
-                                'admin_state_up': admin_state_up_flag}
-        cls.load_balancer = cls._create_active_load_balancer(
-            **cls.create_lb_kwargs)
-        cls.load_balancer_id = cls.load_balancer['id']
-
-    @classmethod
-    def resource_setup_listener(cls, admin_state_up_flag):
-        cls.create_listener_kwargs = {'loadbalancer_id': cls.load_balancer_id,
-                                      'protocol': cls.protocol,
-                                      'protocol_port': cls.port,
-                                      'admin_state_up': admin_state_up_flag
-                                      }
-        cls.listener = cls._create_listener(
-            **cls.create_listener_kwargs)
-        cls.listener_id = cls.listener['id']
-
-    @classmethod
-    def resource_setup_pool(cls, admin_state_up_flag):
-        cls.create_pool_kwargs = {'protocol': cls.protocol,
-                                  'lb_algorithm': cls.lb_algorithm,
-                                  'listener_id': cls.listener_id,
-                                  'admin_state_up': admin_state_up_flag
-                                  }
-        cls.pool = cls._create_pool(
-            **cls.create_pool_kwargs)
-        cls.pool_id = cls.pool['id']
-
-    @classmethod
-    def resource_setup_member(cls, admin_state_up_flag):
-        cls.create_member_kwargs = {'address': cls.address,
-                                    'protocol_port': cls.port,
-                                    'subnet_id': cls.subnet_id,
-                                    'admin_state_up': admin_state_up_flag}
-        cls.member = cls._create_member(
-            cls.pool_id, **cls.create_member_kwargs)
-        cls.member_id = cls.member['id']
-
-    @classmethod
-    def resource_set_health_monitor(cls, admin_state_up_flag):
-        cls.create_hm_kwargs = {'type': cls.protocol,
-                                'delay': 3,
-                                'max_retries': 10,
-                                'timeout': 5,
-                                'pool_id': cls.pool_id,
-                                'admin_state_up': admin_state_up_flag}
-        cls.health_monitor = cls._create_health_monitor(
-            **cls.create_hm_kwargs)
-        cls.health_monitor_id = cls.health_monitor['id']
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(AdminStateTests, cls).resource_cleanup()
-
-    def check_lb_operating_status(self,
-                                  load_balancer,
-                                  listeners=None,
-                                  pools=None,
-                                  members=None):
-        if bool(load_balancer) and self.load_balancer.get('admin_state_up'):
-            self.assertEqual(
-                load_balancer.get('operating_status'), 'ONLINE')
-            return True
-
-        elif bool(load_balancer):
-            self.assertEqual(
-                load_balancer.get('operating_status'), 'DISABLED')
-            if bool(listeners):
-                self.assertEqual(listeners[0].
-                                 get('operating_status'), 'DISABLED')
-                if bool(pools):
-                    self.assertEqual(pools[0].
-                                     get('operating_status'), 'DISABLED')
-                    if bool(members):
-                        self.assertEqual(members[0].
-                                         get('operating_status'), 'DISABLED')
-
-            return False
-
-    def check_listener_operating_status(self,
-                                        listeners,
-                                        pools=None,
-                                        members=None):
-        if bool(listeners) and self.listener.get('admin_state_up'):
-            self.assertEqual(listeners[0].
-                             get('operating_status'), 'ONLINE')
-            return True
-
-        elif bool(listeners):
-            self.assertEqual(listeners[0].
-                             get('operating_status'), 'DISABLED')
-            if bool(pools):
-                self.assertEqual(pools[0].
-                                 get('operating_status'), 'DISABLED')
-                if bool(members):
-                    self.assertEqual(members[0].
-                                     get('operating_status'), 'DISABLED')
-
-            return False
-
-    def check_pool_operating_status(self,
-                                    pools,
-                                    members=None):
-        if bool(pools) and self.pool.get('admin_state_up'):
-            self.assertEqual(pools[0].
-                             get('operating_status'), 'ONLINE')
-            return True
-
-        elif bool(pools):
-            self.assertEqual(pools[0].
-                             get('operating_status'), 'DISABLED')
-            if bool(members):
-                        self.assertEqual(members[0].
-                                         get('operating_status'), 'DISABLED')
-
-            return False
-
-    def check_member_operating_status(self, members):
-        if bool(members) and self.member.get('admin_state_up'):
-            self.assertEqual(members[0].
-                             get('operating_status'), 'ONLINE')
-            return True
-        elif bool(members):
-            self.assertEqual(members[0].
-                             get('operating_status'), 'DISABLED')
-            return False
-
-    def check_health_monitor_provisioning_status(self, health_monitor):
-        if bool(health_monitor) and self.health_monitor.get('admin_state_up'):
-            self.assertEqual(health_monitor.get('provisioning_status'),
-                             'ACTIVE')
-            return True
-        elif bool(health_monitor):
-            self.assertEqual(health_monitor.get('provisioning_status'),
-                             'DISABLED')
-            return False
-
-    def check_operating_status(self):
-        statuses = (self.load_balancers_client.
-                    get_load_balancer_status_tree
-                    (self.load_balancer_id))
-
-        load_balancer = statuses['loadbalancer']
-        listeners = load_balancer['listeners']
-        pools = None
-        members = None
-        health_monitor = None
-
-        if bool(listeners):
-            pools = listeners[0]['pools']
-        if bool(pools):
-            members = pools[0]['members']
-            health_monitor = pools[0]['healthmonitor']
-
-        if self.check_lb_operating_status(load_balancer,
-                                          listeners,
-                                          pools,
-                                          members):
-            if self.check_listener_operating_status(listeners,
-                                                    pools,
-                                                    members):
-                if self.check_pool_operating_status(pools,
-                                                    members):
-                    self.check_member_operating_status(members)
-                    self.check_health_monitor_provisioning_status(
-                        health_monitor)
diff --git a/tests/tempest/v2/ddt/test_health_monitor_admin_state_up.py b/tests/tempest/v2/ddt/test_health_monitor_admin_state_up.py
deleted file mode 100644
index 762331f..0000000
--- a/tests/tempest/v2/ddt/test_health_monitor_admin_state_up.py
+++ /dev/null
@@ -1,146 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import config
-from tempest.lib import decorators
-import testscenarios
-
-from neutron_lbaas.tests.tempest.v2.ddt import base_ddt
-
-CONF = config.CONF
-
-scenario_lb_T = ('lb_T', {'lb_flag': True})
-scenario_lb_F = ('lb_F', {'lb_flag': False})
-
-scenario_listener_T = ('listener_T', {'listener_flag': True})
-scenario_listener_F = ('listener_F', {'listener_flag': False})
-
-scenario_pool_T = ('pool_T', {'pool_flag': True})
-scenario_pool_F = ('pool_F', {'pool_flag': False})
-
-scenario_healthmonitor_T = ('healthmonitor_T', {'healthmonitor_flag': True})
-scenario_healthmonitor_F = ('healthmonitor_F', {'healthmonitor_flag': False})
-
-scenario_healthmonitor_to_flag_T = ('healthmonitor_to_flag_T', {
-    'healthmonitor_to_flag': True})
-scenario_healthmonitor_to_flag_F = ('healthmonitor_to_flag_F', {
-    'healthmonitor_to_flag': False})
-
-# The following command creates 16 unique scenarios
-scenario_create_health_monitor = testscenarios.multiply_scenarios(
-    [scenario_lb_T, scenario_lb_F],
-    [scenario_listener_T, scenario_listener_F],
-    [scenario_pool_T, scenario_pool_F],
-    [scenario_healthmonitor_T, scenario_healthmonitor_F])
-
-# The following command creates 32 unique scenarios
-scenario_update_health_monitor = testscenarios.multiply_scenarios(
-    [scenario_healthmonitor_to_flag_T, scenario_healthmonitor_to_flag_F],
-    scenario_create_health_monitor)
-
-
-class BaseHealthMonitorAdminStateTest(base_ddt.AdminStateTests):
-    @classmethod
-    def resource_setup(cls):
-        super(BaseHealthMonitorAdminStateTest, cls).resource_setup()
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(BaseHealthMonitorAdminStateTest, cls).resource_cleanup()
-
-    def setUp(self):
-        """Set up resources.
-
-        Including :load balancer, listener, and pool and
-        health_monitor with scenarios.
-        """
-        super(BaseHealthMonitorAdminStateTest, self).setUp()
-        self.resource_setup_load_balancer(self.lb_flag)
-        self.resource_setup_listener(self.listener_flag)
-        self.resource_setup_pool(self.pool_flag)
-        self.resource_set_health_monitor(self.healthmonitor_flag)
-
-    def tearDown(self):
-        """Clean up health monitor, pools, listener and lb."""
-        self._delete_health_monitor(self.health_monitor.get('id'))
-        self._delete_pool(self.pool.get('id'))
-        self._delete_listener(self.listener.get('id'))
-        self._delete_load_balancer(self.load_balancer.get('id'))
-        super(BaseHealthMonitorAdminStateTest, self).tearDown()
-
-    @classmethod
-    def resource_setup_listener(cls, admin_state_up_flag):
-        """Set up resources for listener."""
-        (super(BaseHealthMonitorAdminStateTest, cls).
-         resource_setup_listener(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_pool(cls, admin_state_up_flag):
-        """Set up resources for pool."""
-        (super(BaseHealthMonitorAdminStateTest, cls).
-         resource_setup_pool(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_load_balancer(cls, admin_state_up_flag):
-        """Set up resources for load balancer."""
-        (super(BaseHealthMonitorAdminStateTest, cls).
-         resource_setup_load_balancer(admin_state_up_flag))
-
-
-class CreateHealthMonitorAdminStateTest(BaseHealthMonitorAdminStateTest):
-    scenarios = scenario_create_health_monitor
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for health monitor with testscenarios, the goal is to test
-    the various admin_state_up boolean combinations and their expected
-    operating_status and provision_status results from the status tree.
-
-        create healthmonitor
-    """
-
-    # @decorators.skip_because(bug="1449775")
-    def test_create_health_monitor_with_scenarios(self):
-        """Test creating healthmonitor with 16 scenarios.
-
-        Compare the status tree before and after setting up admin_state_up flag
-        for health monitor.
-        """
-        self.check_operating_status()
-
-
-class UpdateHealthMonitorAdminStateTest(BaseHealthMonitorAdminStateTest):
-    scenarios = scenario_update_health_monitor
-
-    """
-    Tests the following operations in the Neutron-LBaaS API using the
-    REST client for health monitor with testscenarios, the goal is to test
-    the various admin_state_up boolean combinations and their expected
-    operating_status and provision_status results from the status tree.
-
-        update healthmonitor
-    """
-
-    @decorators.skip_because(bug="1449775")
-    def test_update_health_monitor_with_admin_state_up(self):
-        """Test update a monitor.
-        Compare the status tree before and after setting the admin_state_up
-        flag for health_monitor.
-
-        """
-        self.create_health_monitor_kwargs = {
-            'admin_state_up': self.healthmonitor_to_flag}
-        self.health_monitor = self._update_health_monitor(
-            self.health_monitor_id, **self.create_health_monitor_kwargs)
-        self.check_operating_status()
diff --git a/tests/tempest/v2/ddt/test_listeners_admin_state.py b/tests/tempest/v2/ddt/test_listeners_admin_state.py
deleted file mode 100644
index 4a4c7f0..0000000
--- a/tests/tempest/v2/ddt/test_listeners_admin_state.py
+++ /dev/null
@@ -1,132 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-
-from tempest import config
-import testscenarios
-
-from neutron_lbaas.tests.tempest.v2.ddt import base_ddt
-
-CONF = config.CONF
-
-
-"""
-Tests the following operations in the Neutron-LBaaS API using the
-REST client for Listeners:
-
-    |-----|------------------|------------------|-------------------------|
-    |S.No |Action            |LB admin_state_up | Listener admin_state_up |
-    |-----|------------------|------------------|-------------------------|
-    | 1   | Create Listener  | True             | True                    |
-    | 2   |                  | True             | False                   |
-    | 3   |                  | False            | True                    |
-    | 4   |                  | False            | False                   |
-    | 5   | Update Listener  | True             | True  --> True          |
-    | 6   |                  | True             | True  --> False         |
-    | 7   |                  | True             | False --> True          |
-    | 8   |                  | True             | False --> False         |
-    | 9   |                  | False            | True  --> True          |
-    | 10  |                  | False            | True  --> False         |
-    | 11  |                  | False            | False --> True          |
-    | 12  |                  | False            | False --> False         |
-    |-----|------------------|------------------|-------------------------|
-
-"""
-# set up the scenarios
-scenario_lb_T = ('lb_T', {'lb_flag': True})
-scenario_lb_F = ('lb_F', {'lb_flag': False})
-
-scenario_listener_T = ('listener_T', {'listener_flag': True})
-scenario_listener_F = ('listener_F', {'listener_flag': False})
-
-scenario_lis_to_flag_T = ('listener_to_flag_T', {'listener_to_flag': True})
-scenario_lis_to_flag_F = ('listener_to_flag_F', {'listener_to_flag': False})
-
-# The following command creates 4 unique scenarios
-scenario_create_member = testscenarios.multiply_scenarios(
-        [scenario_lb_T, scenario_lb_F],
-        [scenario_listener_T, scenario_listener_F])
-
-# The following command creates 8 unique scenarios
-scenario_update_member = testscenarios.multiply_scenarios(
-    [scenario_lis_to_flag_T, scenario_lis_to_flag_F],
-    scenario_create_member)
-
-
-class CreateListenerAdminStateTests(base_ddt.AdminStateTests):
-
-    scenarios = scenario_create_member
-
-    @classmethod
-    def resource_setup(cls):
-        super(CreateListenerAdminStateTests, cls).resource_setup()
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(CreateListenerAdminStateTests, cls).resource_cleanup()
-
-    @classmethod
-    def setup_load_balancer(cls, **kwargs):
-        super(CreateListenerAdminStateTests,
-              cls).setup_load_balancer(**kwargs)
-
-    def test_create_listener_with_lb_and_listener_admin_states_up(self):
-        """Test create a listener.
-
-        Create a listener with various combinations of
-        values for admin_state_up field of the listener and
-        the load-balancer.
-        """
-
-        self.resource_setup_load_balancer(self.lb_flag)
-        self.resource_setup_listener(self.listener_flag)
-        self.check_operating_status()
-        self._delete_listener(self.listener_id)
-        self._delete_load_balancer(self.load_balancer_id)
-
-
-class UpdateListenerAdminStateTests(base_ddt.AdminStateTests):
-
-    scenarios = scenario_update_member
-
-    @classmethod
-    def resource_setup(cls):
-        super(UpdateListenerAdminStateTests, cls).resource_setup()
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(UpdateListenerAdminStateTests, cls).resource_cleanup()
-
-    @classmethod
-    def setup_load_balancer(cls, **kwargs):
-        super(UpdateListenerAdminStateTests,
-              cls).setup_load_balancer(**kwargs)
-
-    def test_update_listener_with_listener_admin_state_up(self):
-        """Test updating a listener.
-
-        Update a listener with various combinations of
-        admin_state_up field of the listener and the
-        load-balancer.
-        """
-
-        self.resource_setup_load_balancer(self.lb_flag)
-        self.resource_setup_listener(self.listener_flag)
-        self.check_operating_status()
-        self.listener = (self._update_listener(
-            self.listener_id,
-            name='new_name',
-            admin_state_up=self.listener_to_flag))
-        self.check_operating_status()
-        self._delete_listener(self.listener_id)
-        self._delete_load_balancer(self.load_balancer_id)
diff --git a/tests/tempest/v2/ddt/test_members_admin_state_up.py b/tests/tempest/v2/ddt/test_members_admin_state_up.py
deleted file mode 100644
index dba7fe7..0000000
--- a/tests/tempest/v2/ddt/test_members_admin_state_up.py
+++ /dev/null
@@ -1,169 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-
-from tempest import config
-import testscenarios
-
-from neutron_lbaas.tests.tempest.v2.ddt import base_ddt
-
-CONF = config.CONF
-
-
-"""
-Tests the following operations in the Neutron-LBaaS API using the
-REST client with various combinations of values for the
-admin_state_up field of lb, listener, pool and member.
-
-    create member
-    update member
-
-"""
-# set up the scenarios
-scenario_lb_T = ('lb_T', {'lb_flag': True})
-scenario_lb_F = ('lb_F', {'lb_flag': False})
-
-scenario_listener_T = ('listener_T', {'listener_flag': True})
-scenario_listener_F = ('listener_F', {'listener_flag': False})
-
-scenario_pool_T = ('pool_T', {'pool_flag': True})
-scenario_pool_F = ('pool_F', {'pool_flag': False})
-
-scenario_member_T = ('member_T', {'member_flag': True})
-scenario_member_F = ('member_F', {'member_flag': False})
-
-
-scenario_mem_to_flag_T = ('member_to_flag_T', {'member_to_flag': True})
-scenario_mem_to_flag_F = ('member_to_flag_F', {'member_to_flag': False})
-
-# The following command creates 16 unique scenarios
-scenario_create_member = testscenarios.multiply_scenarios(
-        [scenario_lb_T, scenario_lb_F],
-        [scenario_listener_T, scenario_listener_F],
-        [scenario_pool_T, scenario_pool_F],
-        [scenario_member_T, scenario_member_F])
-
-# The following command creates 32 unique scenarios
-scenario_update_member = testscenarios.multiply_scenarios(
-    [scenario_mem_to_flag_T, scenario_mem_to_flag_F],
-    scenario_create_member)
-
-
-class CreateMemberAdminStateTests(base_ddt.AdminStateTests):
-
-    scenarios = scenario_create_member
-
-    @classmethod
-    def resource_setup(cls):
-        super(CreateMemberAdminStateTests, cls).resource_setup()
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(CreateMemberAdminStateTests, cls).resource_cleanup()
-
-    def setUp(self):
-        """Set up load balancer, listener,  pool and member."""
-        super(CreateMemberAdminStateTests, self).setUp()
-        self.resource_setup_load_balancer(self.lb_flag)
-        self.resource_setup_listener(self.listener_flag)
-        self.resource_setup_pool(self.pool_flag)
-        self.resource_setup_member(self.member_flag)
-
-    def tearDown(self):
-        """Tearing down pools, listener and lb resources"""
-        self._delete_member(self.pool_id, self.member_id)
-        self._delete_pool(self.pool_id)
-        self._delete_listener(self.listener_id)
-        self._delete_load_balancer(self.load_balancer_id)
-        super(CreateMemberAdminStateTests, self).tearDown()
-
-    @classmethod
-    def resource_setup_load_balancer(cls, admin_state_up_flag):
-        (super(CreateMemberAdminStateTests, cls).
-         resource_setup_load_balancer(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_listener(cls, admin_state_up_flag):
-        (super(CreateMemberAdminStateTests, cls).
-         resource_setup_listener(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_pool(cls, admin_state_up_flag):
-        (super(CreateMemberAdminStateTests, cls).
-         resource_setup_pool(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_member(cls, admin_state_up_flag):
-        (super(CreateMemberAdminStateTests, cls).
-         resource_setup_member(admin_state_up_flag))
-
-    def test_create_member_with_admin_state_up(self):
-        """Test create a member. """
-        self.check_operating_status()
-
-
-class UpdateMemberAdminStateTests(base_ddt.AdminStateTests):
-
-    scenarios = scenario_update_member
-
-    @classmethod
-    def resource_setup(cls):
-        super(UpdateMemberAdminStateTests, cls).resource_setup()
-
-    @classmethod
-    def resource_cleanup(cls):
-        super(UpdateMemberAdminStateTests, cls).resource_cleanup()
-
-    def setUp(self):
-        """Set up load balancer, listener,  pool and member resources."""
-        super(UpdateMemberAdminStateTests, self).setUp()
-        self.resource_setup_load_balancer(self.lb_flag)
-        self.resource_setup_listener(self.listener_flag)
-        self.resource_setup_pool(self.pool_flag)
-        self.resource_setup_member(self.member_flag)
-
-    def tearDown(self):
-        """Tearing down member, pool, listener and lb resources."""
-        self._delete_member(self.pool_id, self.member_id)
-        self._delete_pool(self.pool_id)
-        self._delete_listener(self.listener_id)
-        self._delete_load_balancer(self.load_balancer_id)
-        super(UpdateMemberAdminStateTests, self).tearDown()
-
-    @classmethod
-    def resource_setup_load_balancer(cls, admin_state_up_flag):
-        (super(UpdateMemberAdminStateTests, cls).
-            resource_setup_load_balancer(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_listener(cls, admin_state_up_flag):
-        (super(UpdateMemberAdminStateTests, cls).
-         resource_setup_listener(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_pool(cls, admin_state_up_flag):
-        (super(UpdateMemberAdminStateTests, cls).
-         resource_setup_pool(admin_state_up_flag))
-
-    @classmethod
-    def resource_setup_member(cls, admin_state_up_flag):
-        (super(UpdateMemberAdminStateTests, cls).
-         resource_setup_member(admin_state_up_flag))
-
-    def test_update_member_with_admin_state_up(self):
-        """Test update a member. """
-        self.create_member_kwargs = {'admin_state_up': self.member_to_flag}
-        self.member = self._update_member(self.pool_id,
-                                          self.member_id,
-                                          **self.create_member_kwargs)
-        self.check_operating_status()
diff --git a/tests/tempest/v2/scenario/__init__.py b/tests/tempest/v2/scenario/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/tempest/v2/scenario/base.py b/tests/tempest/v2/scenario/base.py
deleted file mode 100644
index a4edfd0..0000000
--- a/tests/tempest/v2/scenario/base.py
+++ /dev/null
@@ -1,619 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# Copyright 2016 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import cookielib
-import shlex
-import socket
-import subprocess
-import tempfile
-import time
-
-from oslo_log import log as logging
-import six
-from six.moves.urllib import error
-from six.moves.urllib import request as urllib2
-from tempest.common import waiters
-from tempest import config
-from tempest import exceptions
-from tempest.lib import exceptions as lib_exc
-from tempest.scenario import manager
-from tempest.scenario import network_resources as net_resources
-from tempest import test
-
-from neutron_lbaas._i18n import _
-from neutron_lbaas.tests.tempest.v2.clients import health_monitors_client
-from neutron_lbaas.tests.tempest.v2.clients import listeners_client
-from neutron_lbaas.tests.tempest.v2.clients import load_balancers_client
-from neutron_lbaas.tests.tempest.v2.clients import members_client
-from neutron_lbaas.tests.tempest.v2.clients import pools_client
-
-config = config.CONF
-
-LOG = logging.getLogger(__name__)
-
-
-def _setup_config_args(auth_provider):
-    """Set up ServiceClient arguments using config settings. """
-    service = config.network.catalog_type
-    region = config.network.region or config.identity.region
-    endpoint_type = config.network.endpoint_type
-    build_interval = config.network.build_interval
-    build_timeout = config.network.build_timeout
-
-    # The disable_ssl appears in identity
-    disable_ssl_certificate_validation = (
-        config.identity.disable_ssl_certificate_validation)
-    ca_certs = None
-
-    # Trace in debug section
-    trace_requests = config.debug.trace_requests
-
-    return [auth_provider, service, region, endpoint_type, build_interval,
-            build_timeout, disable_ssl_certificate_validation, ca_certs,
-            trace_requests]
-
-
-class BaseTestCase(manager.NetworkScenarioTest):
-
-    def setUp(self):
-        super(BaseTestCase, self).setUp()
-        self.servers_keypairs = {}
-        self.servers = {}
-        self.members = []
-        self.floating_ips = {}
-        self.servers_floating_ips = {}
-        self.server_ips = {}
-        self.port1 = 80
-        self.port2 = 88
-        self.num = 50
-        self.server_fixed_ips = {}
-
-        self._create_security_group_for_test()
-        self._set_net_and_subnet()
-
-        mgr = self.get_client_manager()
-        auth_provider = mgr.auth_provider
-        self.client_args = _setup_config_args(auth_provider)
-
-        self.load_balancers_client = (
-            load_balancers_client.LoadBalancersClientJSON(*self.client_args))
-        self.listeners_client = (
-            listeners_client.ListenersClientJSON(*self.client_args))
-        self.pools_client = pools_client.PoolsClientJSON(*self.client_args)
-        self.members_client = members_client.MembersClientJSON(
-            *self.client_args)
-        self.health_monitors_client = (
-            health_monitors_client.HealthMonitorsClientJSON(
-                *self.client_args))
-
-    @classmethod
-    def skip_checks(cls):
-        super(BaseTestCase, cls).skip_checks()
-        cfg = config.network
-        if not test.is_extension_enabled('lbaasv2', 'network'):
-            msg = 'LBaaS Extension is not enabled'
-            raise cls.skipException(msg)
-        if not (cfg.project_networks_reachable or cfg.public_network_id):
-            msg = ('Either tenant_networks_reachable must be "true", or '
-                   'public_network_id must be defined.')
-            raise cls.skipException(msg)
-
-    def _set_net_and_subnet(self):
-        """
-        Query and set appropriate network and subnet attributes to be used
-        for the test. Existing tenant networks are used if they are found.
-        The configured private network and associated subnet is used as a
-        fallback in absence of tenant networking.
-        """
-        try:
-            tenant_net = self._list_networks(tenant_id=self.tenant_id)[0]
-        except IndexError:
-            tenant_net = None
-
-        if tenant_net:
-            tenant_subnet = self._list_subnets(tenant_id=self.tenant_id)[0]
-            self.subnet = net_resources.DeletableSubnet(
-                subnets_client=self.subnets_client,
-                routers_client=self.routers_client,
-                **tenant_subnet)
-            self.network = tenant_net
-        else:
-            self.network = self._get_network_by_name(
-                config.compute.fixed_network_name)
-            # We are assuming that the first subnet associated
-            # with the fixed network is the one we want.  In the future, we
-            # should instead pull a subnet id from config, which is set by
-            # devstack/admin/etc.
-            subnet = self._list_subnets(network_id=self.network['id'])[0]
-            self.subnet = net_resources.AttributeDict(subnet)
-
-    def _create_security_group_for_test(self):
-        self.security_group = self._create_security_group(
-            tenant_id=self.tenant_id)
-        self._create_security_group_rules_for_port(self.port1)
-        self._create_security_group_rules_for_port(self.port2)
-
-    def _create_security_group_rules_for_port(self, port):
-        rule = {
-            'direction': 'ingress',
-            'protocol': 'tcp',
-            'port_range_min': port,
-            'port_range_max': port,
-        }
-        self._create_security_group_rule(
-            secgroup=self.security_group,
-            tenant_id=self.tenant_id,
-            **rule)
-
-    def _ipv6_subnet(self, address6_mode):
-        router = self._get_router(tenant_id=self.tenant_id)
-        self.network = self._create_network(tenant_id=self.tenant_id)
-        self.subnet = self._create_subnet(network=self.network,
-                                          namestart='sub6',
-                                          ip_version=6,
-                                          ipv6_ra_mode=address6_mode,
-                                          ipv6_address_mode=address6_mode)
-        self.subnet.add_to_router(router_id=router['id'])
-        self.addCleanup(self.subnet.delete)
-
-    def _create_server(self, name):
-        keypair = self.create_keypair()
-        security_groups = [{'name': self.security_group['name']}]
-        create_kwargs = {
-            'networks': [
-                {'uuid': self.network['id']},
-            ],
-            'key_name': keypair['name'],
-            'security_groups': security_groups,
-            'name': name
-        }
-        net_name = self.network['name']
-        server = self.create_server(**create_kwargs)
-        waiters.wait_for_server_status(self.servers_client,
-                                       server['id'], 'ACTIVE')
-        server = self.servers_client.show_server(server['id'])
-        server = server['server']
-        self.servers_keypairs[server['id']] = keypair
-        if (config.network.public_network_id and not
-                config.network.project_networks_reachable):
-            public_network_id = config.network.public_network_id
-            floating_ip = self.create_floating_ip(
-                server, public_network_id)
-            self.floating_ips[floating_ip] = server
-            self.server_ips[server['id']] = floating_ip.floating_ip_address
-        else:
-            self.server_ips[server['id']] =\
-                server['addresses'][net_name][0]['addr']
-        self.server_fixed_ips[server['id']] =\
-            server['addresses'][net_name][0]['addr']
-        self.assertTrue(self.servers_keypairs)
-        return server
-
-    def _create_servers(self):
-        for count in range(2):
-            self.server = self._create_server(name=("server%s" % (count + 1)))
-            if count == 0:
-                self.servers['primary'] = self.server['id']
-            else:
-                self.servers['secondary'] = self.server['id']
-        self.assertEqual(len(self.servers_keypairs), 2)
-
-    def _stop_server(self):
-        for name, value in six.iteritems(self.servers):
-            if name == 'primary':
-                self.servers_client.stop_server(value)
-                waiters.wait_for_server_status(self.servers_client,
-                                               value, 'SHUTOFF')
-
-    def _start_server(self):
-        for name, value in six.iteritems(self.servers):
-            if name == 'primary':
-                self.servers_client.start(value)
-                waiters.wait_for_server_status(self.servers_client,
-                                               value, 'ACTIVE')
-
-    def _start_servers(self):
-        """
-        Start two backends
-        1. SSH to the instance
-        2. Start two http backends listening on ports 80 and 88 respectively
-        """
-        for server_id, ip in six.iteritems(self.server_ips):
-            private_key = self.servers_keypairs[server_id]['private_key']
-            server = self.servers_client.show_server(server_id)['server']
-            server_name = server['name']
-            username = config.validation.image_ssh_user
-            ssh_client = self.get_remote_client(
-                ip_address=ip,
-                private_key=private_key)
-
-            # Write a backend's response into a file
-            resp = ('echo -ne "HTTP/1.1 200 OK\r\nContent-Length: 7\r\n'
-                    'Set-Cookie:JSESSIONID=%(s_id)s\r\nConnection: close\r\n'
-                    'Content-Type: text/html; '
-                    'charset=UTF-8\r\n\r\n%(server)s"; cat >/dev/null')
-
-            with tempfile.NamedTemporaryFile() as script:
-                script.write(resp % {'s_id': server_name[-1],
-                                     'server': server_name})
-                script.flush()
-                with tempfile.NamedTemporaryFile() as key:
-                    key.write(private_key)
-                    key.flush()
-                    self.copy_file_to_host(script.name,
-                                           "/tmp/script1",
-                                           ip,
-                                           username, key.name)
-
-            # Start netcat
-            start_server = ('while true; do '
-                            'sudo nc -ll -p %(port)s -e sh /tmp/%(script)s; '
-                            'done > /dev/null &')
-            cmd = start_server % {'port': self.port1,
-                                  'script': 'script1'}
-            ssh_client.exec_command(cmd)
-
-            if len(self.server_ips) == 1:
-                with tempfile.NamedTemporaryFile() as script:
-                    script.write(resp % {'s_id': 2,
-                                         'server': 'server2'})
-                    script.flush()
-                    with tempfile.NamedTemporaryFile() as key:
-                        key.write(private_key)
-                        key.flush()
-                        self.copy_file_to_host(script.name,
-                                               "/tmp/script2", ip,
-                                               username, key.name)
-                cmd = start_server % {'port': self.port2,
-                                      'script': 'script2'}
-                ssh_client.exec_command(cmd)
-
-    def _create_listener(self, load_balancer_id):
-        """Create a listener with HTTP protocol listening on port 80."""
-        self.listener = self.listeners_client.create_listener(
-            loadbalancer_id=load_balancer_id,
-            protocol='HTTP', protocol_port=80)
-        self.assertTrue(self.listener)
-        self.addCleanup(self._cleanup_listener, self.listener.get('id'),
-                        load_balancer_id=load_balancer_id)
-        return self.listener
-
-    def _create_health_monitor(self):
-        """Create a pool with ROUND_ROBIN algorithm."""
-        self.hm = self.health_monitors_client.create_health_monitor(
-            type='HTTP', max_retries=5, delay=3, timeout=5,
-            pool_id=self.pool['id'])
-        self.assertTrue(self.hm)
-        self.addCleanup(self._cleanup_health_monitor,
-                        self.hm.get('id'),
-                        load_balancer_id=self.load_balancer['id'])
-
-    def _create_pool(self, listener_id, persistence_type=None,
-                     cookie_name=None):
-        """Create a pool with ROUND_ROBIN algorithm."""
-        pool = {
-            "listener_id": listener_id,
-            "lb_algorithm": "ROUND_ROBIN",
-            "protocol": "HTTP"
-        }
-        if persistence_type:
-            pool.update({'session_persistence': {'type': persistence_type}})
-        if cookie_name:
-            pool.update({'session_persistence': {"cookie_name": cookie_name}})
-        self.pool = self.pools_client.create_pool(**pool)
-        self.assertTrue(self.pool)
-        self.addCleanup(self._cleanup_pool, self.pool['id'],
-                        load_balancer_id=self.load_balancer['id'])
-        return self.pool
-
-    def _cleanup_load_balancer(self, load_balancer_id):
-        self.delete_wrapper(self.load_balancers_client.delete_load_balancer,
-                            load_balancer_id)
-        self._wait_for_load_balancer_status(load_balancer_id, delete=True)
-
-    def _cleanup_listener(self, listener_id, load_balancer_id=None):
-        self.delete_wrapper(self.listeners_client.delete_listener, listener_id)
-        if load_balancer_id:
-            self._wait_for_load_balancer_status(load_balancer_id)
-
-    def _cleanup_pool(self, pool_id, load_balancer_id=None):
-        self.delete_wrapper(self.pools_client.delete_pool, pool_id)
-        if load_balancer_id:
-            self._wait_for_load_balancer_status(load_balancer_id)
-
-    def _cleanup_health_monitor(self, hm_id, load_balancer_id=None):
-        self.delete_wrapper(self.health_monitors_client.delete_health_monitor,
-                            hm_id)
-        if load_balancer_id:
-            self._wait_for_load_balancer_status(load_balancer_id)
-
-    def _create_members(self, load_balancer_id=None, pool_id=None,
-                        subnet_id=None):
-        """
-        Create two members.
-
-        In case there is only one server, create both members with the same ip
-        but with different ports to listen on.
-        """
-        for server_id, ip in six.iteritems(self.server_fixed_ips):
-            if len(self.server_fixed_ips) == 1:
-                member1 = self.members_client.create_member(
-                    pool_id=pool_id,
-                    address=ip,
-                    protocol_port=self.port1,
-                    subnet_id=subnet_id)
-                self._wait_for_load_balancer_status(load_balancer_id)
-                member2 = self.members_client.create_member(
-                    pool_id=pool_id,
-                    address=ip,
-                    protocol_port=self.port2,
-                    subnet_id=subnet_id)
-                self._wait_for_load_balancer_status(load_balancer_id)
-                self.members.extend([member1, member2])
-            else:
-                member = self.members_client.create_member(
-                    pool_id=pool_id,
-                    address=ip,
-                    protocol_port=self.port1,
-                    subnet_id=subnet_id)
-                self._wait_for_load_balancer_status(load_balancer_id)
-                self.members.append(member)
-        self.assertTrue(self.members)
-
-    def _assign_floating_ip_to_lb_vip(self, lb):
-        public_network_id = config.network.public_network_id
-        port_id = lb.vip_port_id
-        floating_ip = self.create_floating_ip(lb, public_network_id,
-                                              port_id=port_id)
-        self.floating_ips.setdefault(lb.id, [])
-        self.floating_ips[lb.id].append(floating_ip)
-        # Check for floating ip status before you check load-balancer
-        self.check_floating_ip_status(floating_ip, "ACTIVE")
-
-    def _create_load_balancer(self, ip_version=4, persistence_type=None):
-        self.create_lb_kwargs = {'tenant_id': self.tenant_id,
-                                 'vip_subnet_id': self.subnet['id']}
-        self.load_balancer = self.load_balancers_client.create_load_balancer(
-            **self.create_lb_kwargs)
-        load_balancer_id = self.load_balancer['id']
-        self.addCleanup(self._cleanup_load_balancer, load_balancer_id)
-        self._wait_for_load_balancer_status(load_balancer_id)
-
-        listener = self._create_listener(load_balancer_id=load_balancer_id)
-        self._wait_for_load_balancer_status(load_balancer_id)
-
-        self.pool = self._create_pool(listener_id=listener.get('id'),
-                                      persistence_type=persistence_type)
-        self._wait_for_load_balancer_status(load_balancer_id)
-
-        self._create_members(load_balancer_id=load_balancer_id,
-                             pool_id=self.pool['id'],
-                             subnet_id=self.subnet['id'])
-
-        self.vip_ip = self.load_balancer.get('vip_address')
-
-        # if the ipv4 is used for lb, then fetch the right values from
-        # tempest.conf file
-        if ip_version == 4:
-            if (config.network.public_network_id and not
-                    config.network.project_networks_reachable):
-                load_balancer = net_resources.AttributeDict(self.load_balancer)
-                self._assign_floating_ip_to_lb_vip(load_balancer)
-                self.vip_ip = self.floating_ips[
-                    load_balancer.id][0]['floating_ip_address']
-
-        # Currently the ovs-agent is not enforcing security groups on the
-        # vip port - see https://bugs.launchpad.net/neutron/+bug/1163569
-        # However the linuxbridge-agent does, and it is necessary to add a
-        # security group with a rule that allows tcp port 80 to the vip port.
-        self.ports_client.update_port(
-            self.load_balancer.get('vip_port_id'),
-            security_groups=[self.security_group.id])
-
-    def _wait_for_load_balancer_status(self, load_balancer_id,
-                                       provisioning_status='ACTIVE',
-                                       operating_status='ONLINE',
-                                       delete=False):
-        interval_time = 1
-        timeout = 600
-        end_time = time.time() + timeout
-        while time.time() < end_time:
-            try:
-                lb = self.load_balancers_client.get_load_balancer(
-                    load_balancer_id)
-            except lib_exc.NotFound as e:
-                if delete:
-                    return
-                else:
-                    raise e
-            if (lb.get('provisioning_status') == provisioning_status and
-                    lb.get('operating_status') == operating_status):
-                break
-            elif (lb.get('provisioning_status') == 'ERROR' or
-                    lb.get('operating_status') == 'ERROR'):
-                raise Exception(
-                    _("Wait for load balancer for load balancer: {lb_id} "
-                      "ran for {timeout} seconds and an ERROR was encountered "
-                      "with provisioning status: {provisioning_status} and "
-                      "operating status: {operating_status}").format(
-                          timeout=timeout,
-                          lb_id=lb.get('id'),
-                          provisioning_status=provisioning_status,
-                          operating_status=operating_status))
-            time.sleep(interval_time)
-        else:
-            raise Exception(
-                _("Wait for load balancer ran for {timeout} seconds and did "
-                  "not observe {lb_id} reach {provisioning_status} "
-                  "provisioning status and {operating_status} "
-                  "operating status.").format(
-                      timeout=timeout,
-                      lb_id=lb.get('id'),
-                      provisioning_status=provisioning_status,
-                      operating_status=operating_status))
-        return lb
-
-    def _wait_for_pool_session_persistence(self, pool_id, sp_type=None):
-        interval_time = 1
-        timeout = 10
-        end_time = time.time() + timeout
-        while time.time() < end_time:
-            pool = self.pools_client.get_pool(pool_id)
-            sp = pool.get('session_persistence', None)
-            if (not (sp_type or sp) or
-                    pool['session_persistence']['type'] == sp_type):
-                return pool
-            time.sleep(interval_time)
-        raise Exception(
-            _("Wait for pool ran for {timeout} seconds and did "
-              "not observe {pool_id} update session persistence type "
-              "to {type}.").format(
-                  timeout=timeout,
-                  pool_id=pool_id,
-                  type=sp_type))
-
-    def _check_load_balancing(self):
-        """
-        1. Send NUM requests on the floating ip associated with the VIP
-        2. Check that the requests are shared between the two servers
-        """
-
-        self._check_connection(self.vip_ip)
-        counters = self._send_requests(self.vip_ip, ["server1", "server2"])
-        for member, counter in six.iteritems(counters):
-            self.assertGreater(counter, 0, 'Member %s never balanced' % member)
-
-    def _check_connection(self, check_ip, port=80):
-        def try_connect(check_ip, port):
-            try:
-                resp = urllib2.urlopen("http://{0}:{1}/".format(check_ip,
-                                                                port))
-                if resp.getcode() == 200:
-                    return True
-                return False
-            except IOError:
-                return False
-            except error.HTTPError:
-                return False
-        timeout = config.validation .ping_timeout
-        start = time.time()
-        while not try_connect(check_ip, port):
-            if (time.time() - start) > timeout:
-                message = "Timed out trying to connect to %s" % check_ip
-                raise exceptions.TimeoutException(message)
-
-    def _send_requests(self, vip_ip, servers):
-        counters = dict.fromkeys(servers, 0)
-        for i in range(self.num):
-            try:
-                server = urllib2.urlopen("http://{0}/".format(vip_ip),
-                                         None, 2).read()
-                counters[server] += 1
-            # HTTP exception means fail of server, so don't increase counter
-            # of success and continue connection tries
-            except (error.HTTPError, error.URLError, socket.timeout):
-                continue
-        return counters
-
-    def _traffic_validation_after_stopping_server(self):
-        """Check that the requests are sent to the only ACTIVE server."""
-        counters = self._send_requests(self.vip_ip, ["server1", "server2"])
-
-        # Assert that no traffic is sent to server1.
-        for member, counter in six.iteritems(counters):
-            if member == 'server1':
-                self.assertEqual(counter, 0,
-                                 'Member %s is not balanced' % member)
-
-    def _check_load_balancing_after_deleting_resources(self):
-        """
-        Check that the requests are not sent to any servers
-        Assert that no traffic is sent to any servers
-        """
-        counters = self._send_requests(self.vip_ip, ["server1", "server2"])
-        for member, counter in six.iteritems(counters):
-            self.assertEqual(counter, 0, 'Member %s is balanced' % member)
-
-    def _check_source_ip_persistence(self):
-        """Check source ip session persistence.
-
-        Verify that all requests from our ip are answered by the same server
-        that handled it the first time.
-        """
-        # Check that backends are reachable
-        self._check_connection(self.vip_ip)
-
-        resp = []
-        for count in range(10):
-            resp.append(
-                urllib2.urlopen("http://{0}/".format(self.vip_ip)).read())
-        self.assertEqual(len(set(resp)), 1)
-
-    def _update_pool_session_persistence(self, persistence_type=None,
-                                         cookie_name=None):
-        """Update a pool with new session persistence type and cookie name."""
-
-        update_data = {}
-        if persistence_type:
-            update_data = {"session_persistence": {
-                "type": persistence_type}}
-        if cookie_name:
-            update_data['session_persistence'].update(
-                {"cookie_name": cookie_name})
-        self.pools_client.update_pool(self.pool['id'], **update_data)
-        self.pool = self._wait_for_pool_session_persistence(self.pool['id'],
-                                                            persistence_type)
-        self._wait_for_load_balancer_status(self.load_balancer['id'])
-        if persistence_type:
-            self.assertEqual(persistence_type,
-                             self.pool['session_persistence']['type'])
-        if cookie_name:
-            self.assertEqual(cookie_name,
-                             self.pool['session_persistence']['cookie_name'])
-
-    def _check_cookie_session_persistence(self):
-        """Check cookie persistence types by injecting cookies in requests."""
-
-        # Send first request and get cookie from the server's response
-        cj = cookielib.CookieJar()
-        opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
-        opener.open("http://{0}/".format(self.vip_ip))
-        resp = []
-        # Send 10 subsequent requests with the cookie inserted in the headers.
-        for count in range(10):
-            request = urllib2.Request("http://{0}/".format(self.vip_ip))
-            cj.add_cookie_header(request)
-            response = urllib2.urlopen(request)
-            resp.append(response.read())
-        self.assertEqual(len(set(resp)), 1, message=resp)
-
-    def copy_file_to_host(self, file_from, dest, host, username, pkey):
-        dest = "%s@%s:%s" % (username, host, dest)
-        cmd = ("scp -v -o UserKnownHostsFile=/dev/null "
-               "-o StrictHostKeyChecking=no "
-               "-i %(pkey)s %(file1)s %(dest)s" % {'pkey': pkey,
-                                                   'file1': file_from,
-                                                   'dest': dest})
-        args = shlex.split(cmd.encode('utf-8'))
-        subprocess_args = {'stdout': subprocess.PIPE,
-                           'stderr': subprocess.STDOUT}
-        proc = subprocess.Popen(args, **subprocess_args)
-        stdout, stderr = proc.communicate()
-        if proc.returncode != 0:
-            LOG.error(("Command {0} returned with exit status {1},"
-                      "output {2}, error {3}").format(cmd, proc.returncode,
-                                                      stdout, stderr))
-        return stdout
diff --git a/tests/tempest/v2/scenario/test_healthmonitor_basic.py b/tests/tempest/v2/scenario/test_healthmonitor_basic.py
deleted file mode 100644
index 2fb911e..0000000
--- a/tests/tempest/v2/scenario/test_healthmonitor_basic.py
+++ /dev/null
@@ -1,46 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.scenario import base
-
-
-class TestHealthMonitorBasic(base.BaseTestCase):
-
-    @test.services('compute', 'network')
-    def test_health_monitor_basic(self):
-        """This test checks load balancing with health monitor.
-
-        The following is the scenario outline:
-        1. Create two instances.
-        2. SSH to the instances and start two servers: primary and secondary.
-        3. Create a load balancer, with two members and with
-           ROUND_ROBIN algorithm, associate the VIP with a floating ip.
-        4. Create a health monitor.
-        5. Send NUM requests to the floating ip and check that they are shared
-           between the two servers.
-        6. Disable the primary server and validate the traffic is being sent
-           only to the secondary server.
-        """
-        self._create_servers()
-        self._start_servers()
-        self._create_load_balancer()
-        self._create_health_monitor()
-        self._check_load_balancing()
-        # stopping the primary server
-        self._stop_server()
-        # Asserting the traffic is sent only to the secondary server
-        self._traffic_validation_after_stopping_server()
diff --git a/tests/tempest/v2/scenario/test_listener_basic.py b/tests/tempest/v2/scenario/test_listener_basic.py
deleted file mode 100644
index e8dcbab..0000000
--- a/tests/tempest/v2/scenario/test_listener_basic.py
+++ /dev/null
@@ -1,46 +0,0 @@
-# Copyright 2015 Hewlett-Packard Development Company, L.P.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.scenario import base
-
-
-class TestListenerBasic(base.BaseTestCase):
-    """
-    This test checks load balancing and validates traffic
-    The following is the scenario outline:
-    1. Create an instance
-    2. SSH to the instance and start two servers: primary, secondary
-    3. Create a load balancer, listener and pool with two members using
-    ROUND_ROBIN algorithm, associate the VIP with a floating ip
-    4. Send NUM requests to the floating ip and check that they are shared
-       between the two servers.
-    5. Delete listener and validate the traffic is not sent to any members
-    """
-
-    def _delete_listener(self):
-        """Delete a listener to test listener scenario."""
-        self._cleanup_pool(self.pool['id'], self.load_balancer['id'])
-        self._cleanup_listener(self.listener['id'], self.load_balancer['id'])
-
-    @test.services('compute', 'network')
-    def test_listener_basic(self):
-        self._create_server('server1')
-        self._start_servers()
-        self._create_load_balancer()
-        self._check_load_balancing()
-        self._delete_listener()
-        self._check_load_balancing_after_deleting_resources()
diff --git a/tests/tempest/v2/scenario/test_load_balancer_basic.py b/tests/tempest/v2/scenario/test_load_balancer_basic.py
deleted file mode 100644
index fbbd7f0..0000000
--- a/tests/tempest/v2/scenario/test_load_balancer_basic.py
+++ /dev/null
@@ -1,39 +0,0 @@
-# Copyright 2015 Rackspace Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.scenario import base
-
-
-class TestLoadBalancerBasic(base.BaseTestCase):
-
-    @test.services('compute', 'network')
-    def test_load_balancer_basic(self):
-        """This test checks basic load balancing.
-
-        The following is the scenario outline:
-        1. Create an instance.
-        2. SSH to the instance and start two servers.
-        3. Create a load balancer with two members and with ROUND_ROBIN
-           algorithm.
-        4. Associate the VIP with a floating ip.
-        5. Send NUM requests to the floating ip and check that they are shared
-           between the two servers.
-        """
-        self._create_server('server1')
-        self._start_servers()
-        self._create_load_balancer()
-        self._check_load_balancing()
diff --git a/tests/tempest/v2/scenario/test_session_persistence.py b/tests/tempest/v2/scenario/test_session_persistence.py
deleted file mode 100644
index af3c28a..0000000
--- a/tests/tempest/v2/scenario/test_session_persistence.py
+++ /dev/null
@@ -1,55 +0,0 @@
-# Copyright 2015 Mirantis Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from tempest import test
-
-from neutron_lbaas.tests.tempest.v2.scenario import base
-
-
-class TestSessionPersistence(base.BaseTestCase):
-
-    @test.services('compute', 'network')
-    def test_session_persistence(self):
-        """This test checks checks load balancing with session persistence.
-
-        The following is the scenario outline:
-        1. Boot two instances.
-        2. SSH to the instance and start two servers.
-        3. Create a pool with SOURCE_IP session persistence type.
-        4. Create a load balancer with two members and with ROUND_ROBIN
-           algorithm.
-        5. Send 10 requests to the floating ip, associated with the VIP,
-           and make sure all the requests from the same ip
-           are processed by the same member of the pool.
-        6. Change session persistence type of the pool to HTTP_COOKIE.
-        7. Check that this session persistence type also forces all
-           the requests containing the same cookie to hit the same
-           member of the pool.
-        8. Change session persistence type of the pool to APP_COOKIE.
-        9. Perform the same check.
-        10. Turn session persistence off and check that the requests
-            are again distributed according to the ROUND_ROBIN algorithm.
-        """
-        self._create_server('server1')
-        self._start_servers()
-        self._create_load_balancer(persistence_type="SOURCE_IP")
-        self._check_source_ip_persistence()
-        self._update_pool_session_persistence("HTTP_COOKIE")
-        self._check_cookie_session_persistence()
-        self._update_pool_session_persistence("APP_COOKIE",
-                                              cookie_name="JSESSIONID")
-        self._check_cookie_session_persistence()
-        self._update_pool_session_persistence()
-        self._check_load_balancing()
diff --git a/tests/tools.py b/tests/tools.py
deleted file mode 100644
index b588009..0000000
--- a/tests/tools.py
+++ /dev/null
@@ -1,20 +0,0 @@
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-# implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-import random
-import string
-
-
-# NOTE(ihrachys): this function is copied from neutron tree
-def get_random_string(n=10):
-        return ''.join(random.choice(string.ascii_lowercase) for _ in range(n))
diff --git a/tests/unit/__init__.py b/tests/unit/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/agent/__init__.py b/tests/unit/agent/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/agent/test_agent.py b/tests/unit/agent/test_agent.py
deleted file mode 100644
index 2f3206f..0000000
--- a/tests/unit/agent/test_agent.py
+++ /dev/null
@@ -1,48 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-# Copyright 2015 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import mock
-from oslo_config import cfg
-
-from neutron_lbaas.agent import agent
-from neutron_lbaas.tests import base
-
-
-class TestLbaasService(base.BaseTestCase):
-    def test_start(self):
-        with mock.patch.object(
-            agent.n_rpc.Service, 'start'
-        ) as mock_start:
-
-            mgr = mock.Mock()
-            cfg.CONF.periodic_interval = mock.Mock(return_value=10)
-            agent_service = agent.LbaasAgentService('host', 'topic', mgr)
-            agent_service.start()
-
-            self.assertTrue(mock_start.called)
-
-    def test_main(self):
-        logging_str = 'neutron.agent.common.config.setup_logging'
-        with contextlib.nested(
-            mock.patch(logging_str),
-            mock.patch.object(agent.service, 'launch'),
-            mock.patch('sys.argv'),
-            mock.patch.object(agent.manager, 'LbaasAgentManager'),
-            mock.patch.object(cfg.CONF, 'register_opts')
-        ) as (mock_logging, mock_launch, sys_argv, mgr_cls, ro):
-            agent.main()
-
-            mock_launch.assert_called_once_with(mock.ANY, mock.ANY)
diff --git a/tests/unit/agent/test_agent_api.py b/tests/unit/agent/test_agent_api.py
deleted file mode 100644
index 56c6530..0000000
--- a/tests/unit/agent/test_agent_api.py
+++ /dev/null
@@ -1,86 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-# Copyright 2015 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import copy
-import mock
-
-from neutron_lbaas.agent import agent_api as api
-from neutron_lbaas.tests import base
-
-
-class TestApiCache(base.BaseTestCase):
-    def setUp(self):
-        super(TestApiCache, self).setUp()
-
-        self.api = api.LbaasAgentApi('topic', mock.sentinel.context, 'host')
-
-    def test_init(self):
-        self.assertEqual('host', self.api.host)
-        self.assertEqual(mock.sentinel.context, self.api.context)
-
-    def _test_method(self, method, **kwargs):
-        add_host = ('get_ready_devices', 'plug_vip_port', 'unplug_vip_port')
-        expected_kwargs = copy.copy(kwargs)
-        if method in add_host:
-            expected_kwargs['host'] = self.api.host
-
-        with contextlib.nested(
-            mock.patch.object(self.api.client, 'call'),
-            mock.patch.object(self.api.client, 'prepare'),
-        ) as (
-            rpc_mock, prepare_mock
-        ):
-            prepare_mock.return_value = self.api.client
-            rpc_mock.return_value = 'foo'
-            rv = getattr(self.api, method)(**kwargs)
-
-        self.assertEqual('foo', rv)
-
-        prepare_args = {}
-        prepare_mock.assert_called_once_with(**prepare_args)
-
-        rpc_mock.assert_called_once_with(mock.sentinel.context, method,
-                                         **expected_kwargs)
-
-    def test_get_ready_devices(self):
-        self._test_method('get_ready_devices')
-
-    def test_get_loadbalancer(self):
-        self._test_method('get_loadbalancer',
-                          loadbalancer_id='loadbalancer_id')
-
-    def test_loadbalancer_destroyed(self):
-        self._test_method('loadbalancer_destroyed',
-                          loadbalancer_id='loadbalancer_id')
-
-    def test_loadbalancer_deployed(self):
-        self._test_method('loadbalancer_deployed',
-                          loadbalancer_id='loadbalancer_id')
-
-    def test_update_status(self):
-        self._test_method('update_status', obj_type='type', obj_id='id',
-                          provisioning_status='p_status',
-                          operating_status='o_status')
-
-    def test_plug_vip_port(self):
-        self._test_method('plug_vip_port', port_id='port_id')
-
-    def test_unplug_vip_port(self):
-        self._test_method('unplug_vip_port', port_id='port_id')
-
-    def test_update_loadbalancer_stats(self):
-        self._test_method('update_loadbalancer_stats', loadbalancer_id='id',
-                          stats='stats')
diff --git a/tests/unit/agent/test_agent_manager.py b/tests/unit/agent/test_agent_manager.py
deleted file mode 100644
index d2eb32d..0000000
--- a/tests/unit/agent/test_agent_manager.py
+++ /dev/null
@@ -1,661 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-# Copyright 2015 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-
-import mock
-from neutron.plugins.common import constants
-
-from neutron_lbaas.agent import agent_manager as manager
-from neutron_lbaas.services.loadbalancer import constants as lb_const
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests import base
-
-
-class TestManager(base.BaseTestCase):
-    def setUp(self):
-        super(TestManager, self).setUp()
-
-        mock_conf = mock.Mock()
-        mock_conf.device_driver = ['devdriver']
-
-        self.mock_importer = mock.patch.object(manager, 'importutils').start()
-
-        rpc_mock_cls = mock.patch(
-            'neutron_lbaas.agent.agent_api.LbaasAgentApi'
-        ).start()
-
-        # disable setting up periodic state reporting
-        mock_conf.AGENT.report_interval = 0
-
-        self.mgr = manager.LbaasAgentManager(mock_conf)
-        self.rpc_mock = rpc_mock_cls.return_value
-        self.log = mock.patch.object(manager, 'LOG').start()
-        self.driver_mock = mock.Mock()
-        self.mgr.device_drivers = {'devdriver': self.driver_mock}
-        self.mgr.instance_mapping = {'1': 'devdriver', '2': 'devdriver'}
-        self.mgr.needs_resync = False
-        self.update_statuses_patcher = mock.patch.object(
-            self.mgr, '_update_statuses')
-        self.update_statuses = self.update_statuses_patcher.start()
-
-    def test_initialize_service_hook(self):
-        with mock.patch.object(self.mgr, 'sync_state') as sync:
-            self.mgr.initialize_service_hook(mock.Mock())
-            sync.assert_called_once_with()
-
-    def test_periodic_resync_needs_sync(self):
-        with mock.patch.object(self.mgr, 'sync_state') as sync:
-            self.mgr.needs_resync = True
-            self.mgr.periodic_resync(mock.Mock())
-            sync.assert_called_once_with()
-
-    def test_periodic_resync_no_sync(self):
-        with mock.patch.object(self.mgr, 'sync_state') as sync:
-            self.mgr.needs_resync = False
-            self.mgr.periodic_resync(mock.Mock())
-            self.assertFalse(sync.called)
-
-    def test_collect_stats(self):
-        self.mgr.collect_stats(mock.Mock())
-        self.rpc_mock.update_loadbalancer_stats.assert_has_calls([
-            mock.call('1', mock.ANY),
-            mock.call('2', mock.ANY)
-        ], any_order=True)
-
-    def test_collect_stats_exception(self):
-        self.driver_mock.loadbalancer.get_stats.side_effect = Exception
-
-        self.mgr.collect_stats(mock.Mock())
-
-        self.assertFalse(self.rpc_mock.called)
-        self.assertTrue(self.mgr.needs_resync)
-        self.assertTrue(self.log.exception.called)
-
-    def _sync_state_helper(self, ready, reloaded, destroyed):
-        with contextlib.nested(
-            mock.patch.object(self.mgr, '_reload_loadbalancer'),
-            mock.patch.object(self.mgr, '_destroy_loadbalancer')
-        ) as (reload, destroy):
-
-            self.rpc_mock.get_ready_devices.return_value = ready
-
-            self.mgr.sync_state()
-
-            self.assertEqual(len(reloaded), len(reload.mock_calls))
-            self.assertEqual(len(destroyed), len(destroy.mock_calls))
-
-            reload.assert_has_calls([mock.call(i) for i in reloaded],
-                                    any_order=True)
-            destroy.assert_has_calls([mock.call(i) for i in destroyed],
-                                     any_order=True)
-            self.assertFalse(self.mgr.needs_resync)
-
-    def test_sync_state_all_known(self):
-        self._sync_state_helper(['1', '2'], ['1', '2'], [])
-
-    def test_sync_state_all_unknown(self):
-        self.mgr.instance_mapping = {}
-        self._sync_state_helper(['1', '2'], ['1', '2'], [])
-
-    def test_sync_state_destroy_all(self):
-        self._sync_state_helper([], [], ['1', '2'])
-
-    def test_sync_state_both(self):
-        self.mgr.instance_mapping = {'1': 'devdriver'}
-        self._sync_state_helper(['2'], ['2'], ['1'])
-
-    def test_sync_state_exception(self):
-        self.rpc_mock.get_ready_devices.side_effect = Exception
-
-        self.mgr.sync_state()
-
-        self.assertTrue(self.log.exception.called)
-        self.assertTrue(self.mgr.needs_resync)
-
-    def test_reload_loadbalancer(self):
-        lb = data_models.LoadBalancer(id='1').to_dict()
-        lb['provider'] = {'device_driver': 'devdriver'}
-        self.rpc_mock.get_loadbalancer.return_value = lb
-        lb_id = 'new_id'
-        self.assertNotIn(lb_id, self.mgr.instance_mapping)
-
-        self.mgr._reload_loadbalancer(lb_id)
-
-        calls = self.driver_mock.deploy_instance.call_args_list
-        self.assertEqual(1, len(calls))
-        called_lb = calls[0][0][0]
-        self.assertEqual(lb['id'], called_lb.id)
-        self.assertIn(lb['id'], self.mgr.instance_mapping)
-        self.rpc_mock.loadbalancer_deployed.assert_called_once_with(lb_id)
-
-    def test_reload_loadbalancer_driver_not_found(self):
-        lb = data_models.LoadBalancer(id='1').to_dict()
-        lb['provider'] = {'device_driver': 'unknowndriver'}
-        self.rpc_mock.get_loadbalancer.return_value = lb
-        lb_id = 'new_id'
-        self.assertNotIn(lb_id, self.mgr.instance_mapping)
-
-        self.mgr._reload_loadbalancer(lb_id)
-
-        self.assertTrue(self.log.error.called)
-        self.assertFalse(self.driver_mock.deploy_instance.called)
-        self.assertNotIn(lb_id, self.mgr.instance_mapping)
-        self.assertFalse(self.rpc_mock.loadbalancer_deployed.called)
-
-    def test_reload_loadbalancer_exception_on_driver(self):
-        lb = data_models.LoadBalancer(id='3').to_dict()
-        lb['provider'] = {'device_driver': 'devdriver'}
-        self.rpc_mock.get_loadbalancer.return_value = lb
-        self.driver_mock.deploy_instance.side_effect = Exception
-        lb_id = 'new_id'
-        self.assertNotIn(lb_id, self.mgr.instance_mapping)
-
-        self.mgr._reload_loadbalancer(lb_id)
-
-        calls = self.driver_mock.deploy_instance.call_args_list
-        self.assertEqual(1, len(calls))
-        called_lb = calls[0][0][0]
-        self.assertEqual(lb['id'], called_lb.id)
-        self.assertNotIn(lb['id'], self.mgr.instance_mapping)
-        self.assertFalse(self.rpc_mock.loadbalancer_deployed.called)
-        self.assertTrue(self.log.exception.called)
-        self.assertTrue(self.mgr.needs_resync)
-
-    def test_destroy_loadbalancer(self):
-        lb_id = '1'
-        self.assertIn(lb_id, self.mgr.instance_mapping)
-
-        self.mgr._destroy_loadbalancer(lb_id)
-
-        self.driver_mock.undeploy_instance.assert_called_once_with(
-            lb_id, delete_namespace=True)
-        self.assertNotIn(lb_id, self.mgr.instance_mapping)
-        self.rpc_mock.loadbalancer_destroyed.assert_called_once_with(lb_id)
-        self.assertFalse(self.mgr.needs_resync)
-
-    def test_destroy_loadbalancer_exception_on_driver(self):
-        lb_id = '1'
-        self.assertIn(lb_id, self.mgr.instance_mapping)
-        self.driver_mock.undeploy_instance.side_effect = Exception
-
-        self.mgr._destroy_loadbalancer(lb_id)
-
-        self.driver_mock.undeploy_instance.assert_called_once_with(
-            lb_id, delete_namespace=True)
-        self.assertIn(lb_id, self.mgr.instance_mapping)
-        self.assertFalse(self.rpc_mock.loadbalancer_destroyed.called)
-        self.assertTrue(self.log.exception.called)
-        self.assertTrue(self.mgr.needs_resync)
-
-    def test_get_driver_unknown_device(self):
-        self.assertRaises(manager.DeviceNotFoundOnAgent,
-                          self.mgr._get_driver, 'unknown')
-
-    def test_remove_orphans(self):
-        self.mgr.remove_orphans()
-        orphans = {'1': "Fake", '2': "Fake"}
-        self.driver_mock.remove_orphans.assert_called_once_with(orphans.keys())
-
-    def test_agent_disabled(self):
-        payload = {'admin_state_up': False}
-        self.mgr.agent_updated(mock.Mock(), payload)
-        self.driver_mock.undeploy_instance.assert_has_calls(
-            [mock.call('1', delete_namespace=True),
-             mock.call('2', delete_namespace=True)],
-            any_order=True
-        )
-
-    def test_update_statuses_loadbalancer(self):
-        self.update_statuses_patcher.stop()
-        lb = data_models.LoadBalancer(id='1')
-        self.mgr._update_statuses(lb)
-        self.rpc_mock.update_status.assert_called_once_with(
-            'loadbalancer', lb.id, provisioning_status=constants.ACTIVE,
-            operating_status=lb_const.ONLINE)
-
-        self.rpc_mock.update_status.reset_mock()
-        self.mgr._update_statuses(lb, error=True)
-        self.rpc_mock.update_status.assert_called_once_with(
-            'loadbalancer', lb.id, provisioning_status=constants.ERROR,
-            operating_status=lb_const.OFFLINE)
-
-    def test_update_statuses_listener(self):
-        self.update_statuses_patcher.stop()
-        listener = data_models.Listener(id='1')
-        lb = data_models.LoadBalancer(id='1', listeners=[listener])
-        listener.loadbalancer = lb
-        self.mgr._update_statuses(listener)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('listener', listener.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=lb_const.ONLINE),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-        self.rpc_mock.update_status.reset_mock()
-        self.mgr._update_statuses(listener, error=True)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('listener', listener.id,
-                           provisioning_status=constants.ERROR,
-                           operating_status=lb_const.OFFLINE),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-    def test_update_statuses_pool(self):
-        self.update_statuses_patcher.stop()
-        pool = data_models.Pool(id='1')
-        listener = data_models.Listener(id='1', default_pool=pool)
-        lb = data_models.LoadBalancer(id='1', listeners=[listener])
-        listener.loadbalancer = lb
-        pool.loadbalancer = lb
-        self.mgr._update_statuses(pool)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('pool', pool.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=lb_const.ONLINE),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-        self.rpc_mock.update_status.reset_mock()
-        self.mgr._update_statuses(pool, error=True)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('pool', pool.id,
-                           provisioning_status=constants.ERROR,
-                           operating_status=lb_const.OFFLINE),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-    def test_update_statuses_member(self):
-        self.update_statuses_patcher.stop()
-        member = data_models.Member(id='1')
-        pool = data_models.Pool(id='1', members=[member])
-        member.pool = pool
-        listener = data_models.Listener(id='1', default_pool=pool)
-        lb = data_models.LoadBalancer(id='1', listeners=[listener])
-        listener.loadbalancer = lb
-        pool.loadbalancer = lb
-        self.mgr._update_statuses(member)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('member', member.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=lb_const.ONLINE),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-        self.rpc_mock.update_status.reset_mock()
-        self.mgr._update_statuses(member, error=True)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('member', member.id,
-                           provisioning_status=constants.ERROR,
-                           operating_status=lb_const.OFFLINE),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-    def test_update_statuses_healthmonitor(self):
-        self.update_statuses_patcher.stop()
-        hm = data_models.HealthMonitor(id='1')
-        pool = data_models.Pool(id='1', healthmonitor=hm)
-        hm.pool = pool
-        listener = data_models.Listener(id='1', default_pool=pool)
-        lb = data_models.LoadBalancer(id='1', listeners=[listener])
-        listener.loadbalancer = lb
-        pool.loadbalancer = lb
-        self.mgr._update_statuses(hm)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('healthmonitor', hm.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-        self.rpc_mock.update_status.reset_mock()
-        self.mgr._update_statuses(hm, error=True)
-        self.assertEqual(2, self.rpc_mock.update_status.call_count)
-        calls = [mock.call('healthmonitor', hm.id,
-                           provisioning_status=constants.ERROR,
-                           operating_status=None),
-                 mock.call('loadbalancer', lb.id,
-                           provisioning_status=constants.ACTIVE,
-                           operating_status=None)]
-        self.rpc_mock.update_status.assert_has_calls(calls)
-
-    @mock.patch.object(data_models.LoadBalancer, 'from_dict')
-    def test_create_loadbalancer(self, mlb):
-        loadbalancer = data_models.LoadBalancer(id='1')
-
-        self.assertIn(loadbalancer.id, self.mgr.instance_mapping)
-        mlb.return_value = loadbalancer
-        self.mgr.create_loadbalancer(mock.Mock(), loadbalancer.to_dict(),
-                                     'devdriver')
-        self.driver_mock.loadbalancer.create.assert_called_once_with(
-            loadbalancer)
-        self.update_statuses.assert_called_once_with(loadbalancer)
-
-    @mock.patch.object(data_models.LoadBalancer, 'from_dict')
-    def test_create_loadbalancer_failed(self, mlb):
-        loadbalancer = data_models.LoadBalancer(id='1')
-
-        self.assertIn(loadbalancer.id, self.mgr.instance_mapping)
-        self.driver_mock.loadbalancer.create.side_effect = Exception
-        mlb.return_value = loadbalancer
-        self.mgr.create_loadbalancer(mock.Mock(), loadbalancer.to_dict(),
-                                     'devdriver')
-        self.driver_mock.loadbalancer.create.assert_called_once_with(
-            loadbalancer)
-        self.update_statuses.assert_called_once_with(loadbalancer, error=True)
-
-    @mock.patch.object(data_models.LoadBalancer, 'from_dict')
-    def test_update_loadbalancer(self, mlb):
-
-        loadbalancer = data_models.LoadBalancer(id='1',
-                                                vip_address='10.0.0.1')
-        old_loadbalancer = data_models.LoadBalancer(id='1',
-                                                    vip_address='10.0.0.2')
-
-        mlb.side_effect = [loadbalancer, old_loadbalancer]
-        self.mgr.update_loadbalancer(mock.Mock(), old_loadbalancer.to_dict(),
-                                     loadbalancer.to_dict())
-        self.driver_mock.loadbalancer.update.assert_called_once_with(
-            old_loadbalancer, loadbalancer)
-        self.update_statuses.assert_called_once_with(loadbalancer)
-
-    @mock.patch.object(data_models.LoadBalancer, 'from_dict')
-    def test_update_loadbalancer_failed(self, mlb):
-        loadbalancer = data_models.LoadBalancer(id='1',
-                                                vip_address='10.0.0.1')
-        old_loadbalancer = data_models.LoadBalancer(id='1',
-                                                    vip_address='10.0.0.2')
-
-        mlb.side_effect = [loadbalancer, old_loadbalancer]
-        self.driver_mock.loadbalancer.update.side_effect = Exception
-        self.mgr.update_loadbalancer(mock.Mock(), old_loadbalancer,
-                                     loadbalancer)
-        self.driver_mock.loadbalancer.update.assert_called_once_with(
-            old_loadbalancer, loadbalancer)
-        self.update_statuses.assert_called_once_with(loadbalancer, error=True)
-
-    @mock.patch.object(data_models.LoadBalancer, 'from_dict')
-    def test_delete_loadbalancer(self, mlb):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        mlb.return_value = loadbalancer
-        self.assertIn(loadbalancer.id, self.mgr.instance_mapping)
-        self.mgr.delete_loadbalancer(mock.Mock(), loadbalancer.to_dict())
-        self.driver_mock.loadbalancer.delete.assert_called_once_with(
-            loadbalancer)
-        self.assertNotIn(loadbalancer.id, self.mgr.instance_mapping)
-
-    @mock.patch.object(data_models.Listener, 'from_dict')
-    def test_create_listener(self, mlistener):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                        loadbalancer=loadbalancer)
-
-        self.assertIn(loadbalancer.id, self.mgr.instance_mapping)
-        mlistener.return_value = listener
-        self.mgr.create_listener(mock.Mock(), listener.to_dict())
-        self.driver_mock.listener.create.assert_called_once_with(listener)
-        self.update_statuses.assert_called_once_with(listener)
-
-    @mock.patch.object(data_models.Listener, 'from_dict')
-    def test_create_listener_failed(self, mlistener):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                        loadbalancer=loadbalancer)
-
-        self.assertIn(loadbalancer.id, self.mgr.instance_mapping)
-        self.driver_mock.listener.create.side_effect = Exception
-        mlistener.return_value = listener
-        self.mgr.create_listener(mock.Mock(), listener.to_dict())
-        self.driver_mock.listener.create.assert_called_once_with(listener)
-        self.update_statuses.assert_called_once_with(listener, error=True)
-
-    @mock.patch.object(data_models.Listener, 'from_dict')
-    def test_update_listener(self, mlistener):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        old_listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                            loadbalancer=loadbalancer,
-                                            protocol_port=80)
-        listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                        loadbalancer=loadbalancer,
-                                        protocol_port=81)
-
-        mlistener.side_effect = [listener, old_listener]
-        self.mgr.update_listener(mock.Mock(), old_listener.to_dict(),
-                                 listener.to_dict())
-        self.driver_mock.listener.update.assert_called_once_with(
-            old_listener, listener)
-        self.update_statuses.assert_called_once_with(listener)
-
-    @mock.patch.object(data_models.Listener, 'from_dict')
-    def test_update_listener_failed(self, mlistener):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        old_listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                            loadbalancer=loadbalancer,
-                                            protocol_port=80)
-        listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                        loadbalancer=loadbalancer,
-                                        protocol_port=81)
-        mlistener.side_effect = [listener, old_listener]
-        self.driver_mock.listener.update.side_effect = Exception
-        self.mgr.update_listener(mock.Mock(), old_listener, listener)
-        self.driver_mock.listener.update.assert_called_once_with(old_listener,
-                                                                 listener)
-        self.update_statuses.assert_called_once_with(listener, error=True)
-
-    @mock.patch.object(data_models.Listener, 'from_dict')
-    def test_delete_listener(self, mlistener):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        listener = data_models.Listener(id=1, loadbalancer_id='1',
-                                        loadbalancer=loadbalancer,
-                                        protocol_port=80)
-        mlistener.return_value = listener
-        self.mgr.delete_listener(mock.Mock(), listener.to_dict())
-        self.driver_mock.listener.delete.assert_called_once_with(listener)
-
-    @mock.patch.object(data_models.Pool, 'from_dict')
-    def test_create_pool(self, mpool):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer)
-
-        mpool.return_value = pool
-        self.mgr.create_pool(mock.Mock(), pool.to_dict())
-        self.driver_mock.pool.create.assert_called_once_with(pool)
-        self.update_statuses.assert_called_once_with(pool)
-
-    @mock.patch.object(data_models.Pool, 'from_dict')
-    def test_create_pool_failed(self, mpool):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer)
-
-        mpool.return_value = pool
-        self.driver_mock.pool.create.side_effect = Exception
-        self.mgr.create_pool(mock.Mock(), pool)
-        self.driver_mock.pool.create.assert_called_once_with(pool)
-        self.update_statuses.assert_called_once_with(pool, error=True)
-
-    @mock.patch.object(data_models.Pool, 'from_dict')
-    def test_update_pool(self, mpool):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        old_pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                    protocol='HTTP')
-        mpool.side_effect = [pool, old_pool]
-        self.mgr.update_pool(mock.Mock(), old_pool.to_dict(), pool.to_dict())
-        self.driver_mock.pool.update.assert_called_once_with(old_pool, pool)
-        self.update_statuses.assert_called_once_with(pool)
-
-    @mock.patch.object(data_models.Pool, 'from_dict')
-    def test_update_pool_failed(self, mpool):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        old_pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                    protocol='HTTP')
-        mpool.side_effect = [pool, old_pool]
-        self.driver_mock.pool.update.side_effect = Exception
-        self.mgr.update_pool(mock.Mock(), old_pool.to_dict(), pool.to_dict())
-        self.driver_mock.pool.update.assert_called_once_with(old_pool, pool)
-        self.update_statuses.assert_called_once_with(pool, error=True)
-
-    @mock.patch.object(data_models.Pool, 'from_dict')
-    def test_delete_pool(self, mpool):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        mpool.return_value = pool
-        self.mgr.delete_pool(mock.Mock(), pool.to_dict())
-        self.driver_mock.pool.delete.assert_called_once_with(pool)
-
-    @mock.patch.object(data_models.Member, 'from_dict')
-    def test_create_member(self, mmember):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        member = data_models.Member(id='1', pool=pool)
-        mmember.return_value = member
-        self.mgr.create_member(mock.Mock(), member.to_dict())
-        self.driver_mock.member.create.assert_called_once_with(member)
-        self.update_statuses.assert_called_once_with(member)
-
-    @mock.patch.object(data_models.Member, 'from_dict')
-    def test_create_member_failed(self, mmember):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        member = data_models.Member(id='1', pool=pool)
-        mmember.return_value = member
-        self.driver_mock.member.create.side_effect = Exception
-        self.mgr.create_member(mock.Mock(), member.to_dict())
-        self.driver_mock.member.create.assert_called_once_with(member)
-        self.update_statuses.assert_called_once_with(member, error=True)
-
-    @mock.patch.object(data_models.Member, 'from_dict')
-    def test_update_member(self, mmember):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        member = data_models.Member(id='1', pool=pool, weight=1)
-        old_member = data_models.Member(id='1', pool=pool, weight=2)
-        mmember.side_effect = [member, old_member]
-        self.mgr.update_member(mock.Mock(), old_member.to_dict(),
-                               member.to_dict())
-        self.driver_mock.member.update.assert_called_once_with(old_member,
-                                                               member)
-        self.update_statuses.assert_called_once_with(member)
-
-    @mock.patch.object(data_models.Member, 'from_dict')
-    def test_update_member_failed(self, mmember):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        member = data_models.Member(id='1', pool=pool, weight=1)
-        old_member = data_models.Member(id='1', pool=pool, weight=2)
-        mmember.side_effect = [member, old_member]
-        self.driver_mock.member.update.side_effect = Exception
-        self.mgr.update_member(mock.Mock(), old_member.to_dict(),
-                               member.to_dict())
-        self.driver_mock.member.update.assert_called_once_with(old_member,
-                                                               member)
-        self.update_statuses.assert_called_once_with(member, error=True)
-
-    @mock.patch.object(data_models.Member, 'from_dict')
-    def test_delete_member(self, mmember):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        member = data_models.Member(id='1', pool=pool, weight=1)
-        mmember.return_value = member
-        self.mgr.delete_member(mock.Mock(), member.to_dict())
-        self.driver_mock.member.delete.assert_called_once_with(member)
-
-    @mock.patch.object(data_models.HealthMonitor, 'from_dict')
-    def test_create_monitor(self, mmonitor):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        monitor = data_models.HealthMonitor(id='1', pool=pool)
-        mmonitor.return_value = monitor
-        self.mgr.create_healthmonitor(mock.Mock(), monitor.to_dict())
-        self.driver_mock.healthmonitor.create.assert_called_once_with(
-            monitor)
-        self.update_statuses.assert_called_once_with(monitor)
-
-    @mock.patch.object(data_models.HealthMonitor, 'from_dict')
-    def test_create_monitor_failed(self, mmonitor):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        monitor = data_models.HealthMonitor(id='1', pool=pool)
-        mmonitor.return_value = monitor
-        self.driver_mock.healthmonitor.create.side_effect = Exception
-        self.mgr.create_healthmonitor(mock.Mock(), monitor.to_dict())
-        self.driver_mock.healthmonitor.create.assert_called_once_with(monitor)
-        self.update_statuses.assert_called_once_with(monitor, error=True)
-
-    @mock.patch.object(data_models.HealthMonitor, 'from_dict')
-    def test_update_monitor(self, mmonitor):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        monitor = data_models.HealthMonitor(id='1', pool=pool, delay=1)
-        old_monitor = data_models.HealthMonitor(id='1', pool=pool, delay=2)
-        mmonitor.side_effect = [monitor, old_monitor]
-        self.mgr.update_healthmonitor(mock.Mock(), old_monitor.to_dict(),
-                                      monitor.to_dict())
-        self.driver_mock.healthmonitor.update.assert_called_once_with(
-            old_monitor, monitor)
-        self.update_statuses.assert_called_once_with(monitor)
-
-    @mock.patch.object(data_models.HealthMonitor, 'from_dict')
-    def test_update_monitor_failed(self, mmonitor):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        monitor = data_models.HealthMonitor(id='1', pool=pool, delay=1)
-        old_monitor = data_models.HealthMonitor(id='1', pool=pool, delay=2)
-        mmonitor.side_effect = [monitor, old_monitor]
-        self.driver_mock.healthmonitor.update.side_effect = Exception
-        self.mgr.update_healthmonitor(mock.Mock(), monitor.to_dict(),
-                                      monitor.to_dict())
-        self.driver_mock.healthmonitor.update.assert_called_once_with(
-            old_monitor, monitor)
-        self.update_statuses.assert_called_once_with(monitor, error=True)
-
-    @mock.patch.object(data_models.HealthMonitor, 'from_dict')
-    def test_delete_monitor(self, mmonitor):
-        loadbalancer = data_models.LoadBalancer(id='1')
-        pool = data_models.Pool(id='1', loadbalancer=loadbalancer,
-                                protocol='HTTPS')
-        monitor = data_models.HealthMonitor(id='1', pool=pool)
-        mmonitor.return_value = monitor
-        self.mgr.delete_healthmonitor(mock.Mock(), monitor.to_dict())
-        self.driver_mock.healthmonitor.delete.assert_called_once_with(
-            monitor)
diff --git a/tests/unit/common/__init__.py b/tests/unit/common/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/common/cert_manager/__init__.py b/tests/unit/common/cert_manager/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/common/cert_manager/barbican_auth/__init__.py b/tests/unit/common/cert_manager/barbican_auth/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/common/cert_manager/barbican_auth/test_barbican_acl.py b/tests/unit/common/cert_manager/barbican_auth/test_barbican_acl.py
deleted file mode 100644
index 8bad178..0000000
--- a/tests/unit/common/cert_manager/barbican_auth/test_barbican_acl.py
+++ /dev/null
@@ -1,53 +0,0 @@
-# Copyright 2014-2016 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from barbicanclient import client as barbican_client
-import mock
-
-from neutron_lbaas.common.cert_manager.barbican_auth import barbican_acl
-from neutron_lbaas.common.cert_manager import barbican_cert_manager
-from neutron_lbaas.common import keystone
-import neutron_lbaas.tests.base as base
-
-
-class TestBarbicanACLAuth(base.BaseTestCase):
-    def setUp(self):
-        # Reset the client
-        keystone._SESSION = None
-
-        super(TestBarbicanACLAuth, self).setUp()
-
-    def test_get_barbican_client(self):
-        # There should be no existing client
-        self.assertIsNone(keystone._SESSION)
-
-        # Mock out the keystone session and get the client
-        keystone._SESSION = mock.MagicMock()
-        acl_auth_object = barbican_acl.BarbicanACLAuth()
-        bc1 = acl_auth_object.get_barbican_client()
-
-        # Our returned client should be an instance of barbican_client.Client
-        self.assertIsInstance(
-            bc1,
-            barbican_client.Client
-        )
-
-        # Getting the session again with new class should get the same object
-        acl_auth_object2 = barbican_acl.BarbicanACLAuth()
-        bc2 = acl_auth_object2.get_barbican_client()
-        self.assertIs(bc1, bc2)
-
-    def test_load_auth_driver(self):
-        bcm = barbican_cert_manager.CertManager()
-        self.assertTrue(isinstance(bcm.auth, barbican_acl.BarbicanACLAuth))
diff --git a/tests/unit/common/cert_manager/test_barbican.py b/tests/unit/common/cert_manager/test_barbican.py
deleted file mode 100644
index 1b8f203..0000000
--- a/tests/unit/common/cert_manager/test_barbican.py
+++ /dev/null
@@ -1,67 +0,0 @@
-# Copyright 2014 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from barbicanclient import client as barbican_client
-import mock
-
-import neutron_lbaas.common.cert_manager.barbican_cert_manager as bbq_common
-import neutron_lbaas.tests.base as base
-
-
-class TestBarbicanCert(base.BaseTestCase):
-    def setUp(self):
-        # Certificate data
-        self.certificate = "My Certificate"
-        self.intermediates = "My Intermediates"
-        self.private_key = "My Private Key"
-        self.private_key_passphrase = "My Private Key Passphrase"
-
-        self.certificate_secret = barbican_client.secrets.Secret(
-            api=mock.MagicMock(),
-            payload=self.certificate
-        )
-        self.intermediates_secret = barbican_client.secrets.Secret(
-            api=mock.MagicMock(),
-            payload=self.intermediates
-        )
-        self.private_key_secret = barbican_client.secrets.Secret(
-            api=mock.MagicMock(),
-            payload=self.private_key
-        )
-        self.private_key_passphrase_secret = barbican_client.secrets.Secret(
-            api=mock.MagicMock(),
-            payload=self.private_key_passphrase
-        )
-
-        super(TestBarbicanCert, self).setUp()
-
-    def test_barbican_cert(self):
-        container = barbican_client.containers.CertificateContainer(
-            api=mock.MagicMock(),
-            certificate=self.certificate_secret,
-            intermediates=self.intermediates_secret,
-            private_key=self.private_key_secret,
-            private_key_passphrase=self.private_key_passphrase_secret
-        )
-        # Create a cert
-        cert = bbq_common.Cert(
-            cert_container=container
-        )
-
-        # Validate the cert functions
-        self.assertEqual(self.certificate, cert.get_certificate())
-        self.assertEqual(self.intermediates, cert.get_intermediates())
-        self.assertEqual(self.private_key, cert.get_private_key())
-        self.assertEqual(self.private_key_passphrase,
-                         cert.get_private_key_passphrase())
diff --git a/tests/unit/common/cert_manager/test_cert_manager.py b/tests/unit/common/cert_manager/test_cert_manager.py
deleted file mode 100644
index bb3ab53..0000000
--- a/tests/unit/common/cert_manager/test_cert_manager.py
+++ /dev/null
@@ -1,58 +0,0 @@
-# Copyright 2015 NEC Corporation.  All rights reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-# a copy of the License at
-#
-#      http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-# License for the specific language governing permissions and limitations
-# under the License.
-
-from oslo_config import cfg
-
-from neutron_lbaas.common import cert_manager
-from neutron_lbaas.common.cert_manager import barbican_cert_manager as bcm
-from neutron_lbaas.common.cert_manager import cert_manager as cmi
-from neutron_lbaas.common.cert_manager import local_cert_manager as lcm
-from neutron_lbaas.tests import base
-
-
-class TestCertManager(base.BaseTestCase):
-
-    def setUp(self):
-        cert_manager._CERT_MANAGER_PLUGIN = None
-        super(TestCertManager, self).setUp()
-
-    def test_get_service_url(self):
-        # Format: <servicename>://<region>/<resource>/<object_id>
-        cfg.CONF.set_override('service_name',
-                              'lbaas',
-                              'service_auth',
-                              enforce_type=True)
-        cfg.CONF.set_override('region',
-                              'RegionOne',
-                              'service_auth',
-                              enforce_type=True)
-        self.assertEqual(
-            'lbaas://RegionOne/loadbalancer/LB-ID',
-            cmi.CertManager.get_service_url('LB-ID'))
-
-    def test_barbican_cert_manager(self):
-        cfg.CONF.set_override(
-            'cert_manager_type',
-            'barbican',
-            group='certificates')
-        self.assertEqual(cert_manager.get_backend().CertManager,
-                         bcm.CertManager)
-
-    def test_local_cert_manager(self):
-        cfg.CONF.set_override(
-            'cert_manager_type',
-            'local',
-            group='certificates')
-        self.assertEqual(cert_manager.get_backend().CertManager,
-                         lcm.CertManager)
diff --git a/tests/unit/common/cert_manager/test_local.py b/tests/unit/common/cert_manager/test_local.py
deleted file mode 100644
index 8f960e7..0000000
--- a/tests/unit/common/cert_manager/test_local.py
+++ /dev/null
@@ -1,160 +0,0 @@
-# Copyright 2014 Rackspace US, Inc
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-import os
-
-import mock
-from oslo_config import cfg
-from oslo_config import fixture as oslo_fixture
-
-from neutron_lbaas.common.cert_manager import cert_manager
-from neutron_lbaas.common.cert_manager import local_cert_manager
-from neutron_lbaas.tests import base
-
-
-class TestLocalCert(base.BaseTestCase):
-
-    def setUp(self):
-        self.certificate = "My Certificate"
-        self.intermediates = "My Intermediates"
-        self.private_key = "My Private Key"
-        self.private_key_passphrase = "My Private Key Passphrase"
-
-        super(TestLocalCert, self).setUp()
-
-    def test_local_cert(self):
-        # Create a cert
-        cert = local_cert_manager.Cert(
-            certificate=self.certificate,
-            intermediates=self.intermediates,
-            private_key=self.private_key,
-            private_key_passphrase=self.private_key_passphrase
-        )
-
-        # Validate the cert functions
-        self.assertEqual(self.certificate, cert.get_certificate())
-        self.assertEqual(self.intermediates, cert.get_intermediates())
-        self.assertEqual(self.private_key, cert.get_private_key())
-        self.assertEqual(self.private_key_passphrase,
-                         cert.get_private_key_passphrase())
-
-
-class TestLocalManager(base.BaseTestCase):
-
-    def setUp(self):
-        self.project_id = "12345"
-        self.certificate = "My Certificate"
-        self.intermediates = "My Intermediates"
-        self.private_key = "My Private Key"
-        self.private_key_passphrase = "My Private Key Passphrase"
-
-        conf = oslo_fixture.Config(cfg.CONF)
-        conf.config(group="certificates", storage_path="/tmp/")
-
-        self.cert_manager = local_cert_manager.CertManager()
-
-        super(TestLocalManager, self).setUp()
-
-    def _store_cert(self):
-        file_mock = mock.mock_open()
-        # Attempt to store the cert
-        with mock.patch('six.moves.builtins.open', file_mock, create=True):
-            cert_id = self.cert_manager.store_cert(
-                project_id=self.project_id,
-                certificate=self.certificate,
-                intermediates=self.intermediates,
-                private_key=self.private_key,
-                private_key_passphrase=self.private_key_passphrase
-            )
-
-        # Check that something came back
-        self.assertIsNotNone(cert_id)
-
-        # Verify the correct files were opened
-        file_mock.assert_has_calls([
-            mock.call(os.path.join('/tmp/{0}.crt'.format(cert_id)), 'w'),
-            mock.call(os.path.join('/tmp/{0}.key'.format(cert_id)), 'w'),
-            mock.call(os.path.join('/tmp/{0}.int'.format(cert_id)), 'w'),
-            mock.call(os.path.join('/tmp/{0}.pass'.format(cert_id)), 'w')
-        ], any_order=True)
-
-        # Verify the writes were made
-        file_mock().write.assert_has_calls([
-            mock.call(self.certificate),
-            mock.call(self.intermediates),
-            mock.call(self.private_key),
-            mock.call(self.private_key_passphrase)
-        ], any_order=True)
-
-        return cert_id
-
-    def _get_cert(self, cert_id):
-        file_mock = mock.mock_open()
-        # Attempt to retrieve the cert
-        with mock.patch('six.moves.builtins.open', file_mock, create=True):
-            data = self.cert_manager.get_cert(
-                project_id=self.project_id,
-                cert_ref=cert_id,
-                resource_ref=None
-            )
-
-        # Verify the correct files were opened
-        file_mock.assert_has_calls([
-            mock.call(os.path.join('/tmp/{0}.crt'.format(cert_id)), 'r'),
-            mock.call(os.path.join('/tmp/{0}.key'.format(cert_id)), 'r'),
-            mock.call(os.path.join('/tmp/{0}.int'.format(cert_id)), 'r'),
-            mock.call(os.path.join('/tmp/{0}.pass'.format(cert_id)), 'r')
-        ], any_order=True)
-
-        # The returned data should be a Cert object
-        self.assertIsInstance(data, cert_manager.Cert)
-
-        return data
-
-    def _delete_cert(self, cert_id):
-        remove_mock = mock.Mock()
-        # Delete the cert
-        with mock.patch('os.remove', remove_mock):
-            self.cert_manager.delete_cert(
-                project_id=self.project_id,
-                cert_ref=cert_id,
-                resource_ref=None
-            )
-
-        # Verify the correct files were removed
-        remove_mock.assert_has_calls([
-            mock.call(os.path.join('/tmp/{0}.crt'.format(cert_id))),
-            mock.call(os.path.join('/tmp/{0}.key'.format(cert_id))),
-            mock.call(os.path.join('/tmp/{0}.int'.format(cert_id))),
-            mock.call(os.path.join('/tmp/{0}.pass'.format(cert_id)))
-        ], any_order=True)
-
-    def test_store_cert(self):
-        self._store_cert()
-
-    def test_get_cert(self):
-        # Store a cert
-        cert_id = self._store_cert()
-
-        # Get the cert
-        self._get_cert(cert_id)
-
-    def test_delete_cert(self):
-        # Store a cert
-        cert_id = self._store_cert()
-
-        # Verify the cert exists
-        self._get_cert(cert_id)
-
-        # Delete the cert
-        self._delete_cert(cert_id)
diff --git a/tests/unit/common/tls_utils/__init__.py b/tests/unit/common/tls_utils/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/common/tls_utils/test_cert_parser.py b/tests/unit/common/tls_utils/test_cert_parser.py
deleted file mode 100644
index 6148405..0000000
--- a/tests/unit/common/tls_utils/test_cert_parser.py
+++ /dev/null
@@ -1,312 +0,0 @@
-#
-# Copyright 2014 OpenStack Foundation.  All rights reserved
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from cryptography import x509
-import six
-
-import neutron_lbaas.common.exceptions as exceptions
-import neutron_lbaas.common.tls_utils.cert_parser as cert_parser
-from neutron_lbaas.tests import base
-
-
-ALT_EXT_CRT = """-----BEGIN CERTIFICATE-----
-MIIGqjCCBZKgAwIBAgIJAIApBg8slSSiMA0GCSqGSIb3DQEBBQUAMIGLMQswCQYD
-VQQGEwJVUzEOMAwGA1UECAwFVGV4YXMxFDASBgNVBAcMC1NhbiBBbnRvbmlvMR4w
-HAYDVQQKDBVPcGVuU3RhY2sgRXhwZXJpbWVudHMxFjAUBgNVBAsMDU5ldXRyb24g
-TGJhYXMxHjAcBgNVBAMMFXd3dy5DTkZyb21TdWJqZWN0Lm9yZzAeFw0xNTA1MjEy
-MDMzMjNaFw0yNTA1MTgyMDMzMjNaMIGLMQswCQYDVQQGEwJVUzEOMAwGA1UECAwF
-VGV4YXMxFDASBgNVBAcMC1NhbiBBbnRvbmlvMR4wHAYDVQQKDBVPcGVuU3RhY2sg
-RXhwZXJpbWVudHMxFjAUBgNVBAsMDU5ldXRyb24gTGJhYXMxHjAcBgNVBAMMFXd3
-dy5DTkZyb21TdWJqZWN0Lm9yZzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoC
-ggEBALL1nmbDPUDps84i1sM3rhHrc+Dlu0N/wKQWKZFeiWUtF/pot19V3o0yXDps
-g7W5RkLMTFkZEcnQpyGdpAGjTjzmNXMZw99EzxsmrR3l6hUEISifVbvEuftYZT6j
-PxM5ML6WAjFNaBEZPWtZi8CgX5xdjdrDNndwyHob49n7Nc/h1kVqqBqMILabTqC6
-yEcxS/B+DugVuuYbEdYYYElQUMfM+mUdULrSqIVl2n5AvvSFjWzWzfgPyp4QKn+f
-7HVRT62bh/XjQ88n1tMYNAEqixRZTPgqY1LFl9VJVgRp9fdL6ttMurOR3C0STJ5q
-CdKBL7LrpbY4u8dEragRC6YAyI8CAwEAAaOCAw0wggMJMAkGA1UdEwQCMAAwCwYD
-VR0PBAQDAgXgMIIC7QYDVR0RBIIC5DCCAuCCGHd3dy5ob3N0RnJvbUROU05hbWUx
-LmNvbYIYd3d3Lmhvc3RGcm9tRE5TTmFtZTIuY29tghh3d3cuaG9zdEZyb21ETlNO
-YW1lMy5jb22CGHd3dy5ob3N0RnJvbUROU05hbWU0LmNvbYcECgECA4cQASNFZ4mr
-ze/3s9WR5qLEgIYWaHR0cDovL3d3dy5leGFtcGxlLmNvbaSBjzCBjDELMAkGA1UE
-BhMCVVMxDjAMBgNVBAgMBVRleGFzMRQwEgYDVQQHDAtTYW4gQW50b25pbzEeMBwG
-A1UECgwVT3BlblN0YWNrIEV4cGVyaW1lbnRzMRYwFAYDVQQLDA1OZXV0cm9uIExi
-YWFzMR8wHQYDVQQDDBZ3d3cuY25Gcm9tQWx0TmFtZTEub3JnpIGPMIGMMQswCQYD
-VQQGEwJVUzEOMAwGA1UECAwFVGV4YXMxFDASBgNVBAcMC1NhbiBBbnRvbmlvMR4w
-HAYDVQQKDBVPcGVuU3RhY2sgRXhwZXJpbWVudHMxFjAUBgNVBAsMDU5ldXRyb24g
-TGJhYXMxHzAdBgNVBAMMFnd3dy5jbkZyb21BbHROYW1lMi5vcmekgY8wgYwxCzAJ
-BgNVBAYTAlVTMQ4wDAYDVQQIDAVUZXhhczEUMBIGA1UEBwwLU2FuIEFudG9uaW8x
-HjAcBgNVBAoMFU9wZW5TdGFjayBFeHBlcmltZW50czEWMBQGA1UECwwNTmV1dHJv
-biBMYmFhczEfMB0GA1UEAwwWd3d3LmNuRnJvbUFsdE5hbWUzLm9yZ6SBjzCBjDEL
-MAkGA1UEBhMCVVMxDjAMBgNVBAgMBVRleGFzMRQwEgYDVQQHDAtTYW4gQW50b25p
-bzEeMBwGA1UECgwVT3BlblN0YWNrIEV4cGVyaW1lbnRzMRYwFAYDVQQLDA1OZXV0
-cm9uIExiYWFzMR8wHQYDVQQDDBZ3d3cuY25Gcm9tQWx0TmFtZTQub3JnMA0GCSqG
-SIb3DQEBBQUAA4IBAQCS6iDn6R3C+qJLZibaqrBSkM9yu5kwRsQ6lQ+DODvVYGWq
-eGkkh5o2c6WbJlH44yF280+HvnJcuISD7epPHJN0vUM9+WMtXfEli9avFHgu2JxP
-3P0ixK2kaJnqKQkSEdnA/v/eWP1Cd2v6rbKCIo9d2gSP0cnpdtlX9Zk3SzEh0V7s
-RjSdfZoAvz0aAnpDHlTerLcz5T2aiRae2wSt/RLA3qDO1Ji05tWvQBmKuepxS6A1
-tL4Drm+OCXJwTrE7ClTMCwcrZnLl4tI+Z+X3DV92WQB8ldST/QFjz1hgs/4zrADA
-elu2c/X7MR4ObOjhDfaVGQ8kMhYf5hx69qyNDsGi
------END CERTIFICATE-----
-"""
-
-SOME_OTHER_RSA_KEY = """
------BEGIN RSA PRIVATE KEY-----
-MIICWwIBAAKBgQDDnJL9dAdDpjoq4tksTJmdM0AjIHa7Y2yc8XwU7YkgrOR0m4Po
-r7El0NwWf5i/LFudX1cOkfwemMIPwQ+67k0BVu/W3SR+g9ZzVKZtTBJnDoqMZ4RJ
-jBk4gfwhnQYKPIQvdilDZReH3hFcBvPUkYWSHMn17FBTGmNzp2AnMdLpQQIDAQAB
-AoGAIlew7tKaG+RpPfJJ0p84MQM4dXJTph6UiRFUiZASjSwNh/Ntu0JtRYhfu4t3
-U8kD5KNCc4ppyy1ilMV+b4E6/3ydz6syMeJ7G24/PMU8d44zDgZXdM1pf5Nlosh1
-BVv1Fvb0PBW2xs9VRlO6W62IWVtsZCGXYNayrXDiRZ50IGkCQQDkmOVEqffz3GeD
-A+XWp9YrXeMqOmtPcrOuvMIO9DwrlXb8eNwvG5GxbuHGuZfOp01tiPyQrkxM0JzU
-y8iD1pjrAkEA2w9topUzYS/NZt45OD9t5ZBVMfP15AwWRVv7V5uTksTqfZ9tFfh6
-pN4oWe6xK/kgKAdE9hkjubGKQBjJSC27gwJAGZlRm1XZUXKuGMrX8yjKYALcjH8M
-Q1JZ8shqhtgs4MiVEYLLTW8t6ou7NtDTwi2UCx8bAWyzWKrH1UCYzMK8TwJAMngU
-fz+2ra5wuUF7l1ztudUN+8tEHH04aFRvzNhYIJljmPuxCz3LK87PJyEaCpKD+RTr
-q3NRSsf/nRLY1NtMdwJAVKOdUCwZKGpGyOUZPRbZZAPlojIff2CxJ6E2Pr0RbShD
-31icKmhIY+e2rP6v5W7hzTGge5PA0hRfCiwyd+zLoQ==
------END RSA PRIVATE KEY-----
-"""
-
-ALT_EXT_CRT_KEY = """
------BEGIN RSA PRIVATE KEY-----
-MIIEowIBAAKCAQEAsvWeZsM9QOmzziLWwzeuEetz4OW7Q3/ApBYpkV6JZS0X+mi3
-X1XejTJcOmyDtblGQsxMWRkRydCnIZ2kAaNOPOY1cxnD30TPGyatHeXqFQQhKJ9V
-u8S5+1hlPqM/EzkwvpYCMU1oERk9a1mLwKBfnF2N2sM2d3DIehvj2fs1z+HWRWqo
-GowgtptOoLrIRzFL8H4O6BW65hsR1hhgSVBQx8z6ZR1QutKohWXafkC+9IWNbNbN
-+A/KnhAqf5/sdVFPrZuH9eNDzyfW0xg0ASqLFFlM+CpjUsWX1UlWBGn190vq20y6
-s5HcLRJMnmoJ0oEvsuultji7x0StqBELpgDIjwIDAQABAoIBAC3DX6FZtfU+jgtd
-n1vGhk3wzu4o8S0+ow2S2UhiS3JDCMmxM4s+ky26Phl2nGvBGDWGttNl9MWOBN80
-x7bfgudR20M2yH70wp1n04c8vxJmvu/7ZtogYYrjvOg6qKuKyWtDQwZGjCErOiiU
-eodku25qAhd6Khh7D9kh/q9EbSteYFXsqJiNrY4ul1+cROMZpHx63xY6AzPmkvSU
-garkgY4rw9E71t7it2laWkRKVsd+kEjayritdEEliNMVFFtrGEgplYkmLxGf0HLi
-ROFVMCLRW/P12JpXllFPrBb8rlPL4w1c/s+yStohT0K+o4FLXhsf/inxmfc9XnZX
-dJm0k/ECgYEA47FpV1caMk+TNPfu318VCGRmjwpXdmkNaUiX2Uvs3xIKQ6KJmpo3
-sj0YjQEmQVz8s6geStvU1LdPxgsWZfbDt31M6SNwylh82ABQF1bZyrcMRxM8bHhe
-bhDITM1dAn6aROkS1cBpfR9NJOFD850lmJvBGR9ORVBGyucTKH5uXxkCgYEAyTU0
-zQKW2aU3J7mTCC9cp+eSD3fubJpa3ML5XfQ8YNID4PsxWglNKPcOTC4yaSfxVmyk
-S0WIQUazCstszQsvwy9YyHtpkMq+0lyCPvrYnmRV0zx5zT155V2zcEh/oj64eoee
-W5kvJSs/x6vT+lEN0TDEJ2gKEaJuBt6JG6P04ecCgYBSNw1CbEEZSYJt7dhi74I4
-tYgSvjk2mFgvW/b4j2HIaksqgNYO7QCPa2AiCfg2Qc09UcceYKJI7Kfxaq97wc6J
-wsSyqglgBvONSw+gXcvmVpIoV9nJkO0H8SdiFAUxkWVC3KXgaMmuVE8WsgBHRsb8
-g8EFwTgR7xqgyS8xv/U6gQKBgQCdUr/dSJgAx6EPq5degAHXu0ZGWAUR38MJ+F2Y
-6/5FyhCEWoRlHP66+CmywTBjbnrSk5IG1PBL8ebOmu6QiJ2o5R1rbKvHLe/0dabV
-bbfwaQ1+ZDvskZP9Fr3WHqnFh3shO2dDwcvOKTnuetj9UWEXXyUQltXAohubvWbB
-OPqhowKBgB3t2oUSFJI8fSNQnQNkcespJTddr0oLEwgsIl4Q7rdFHLr+/c46svjJ
-kPMtpfxDQvkgK2aWpS4OP0E2vSU/IfMEDmlypfKe2SaTtFehZSUwR4R1/ZhSL3iS
-iMwJYgm98P27s4TEMdhlPNVJrj1FrD+4VrgpOsoM20EkZnTvel9s
------END RSA PRIVATE KEY-----
-"""
-
-ENCRYPTED_PKCS8_CRT_KEY_PASSPHRASE = "test_passphrase"
-
-ENCRYPTED_PKCS8_CRT_KEY = """-----BEGIN ENCRYPTED PRIVATE KEY-----
-MIIE6TAbBgkqhkiG9w0BBQMwDgQIT04zko6pmJICAggABIIEyL/79sqzTQ7BsEjY
-ao2Uhh3//mpNJfCDhjSZOmWL7s4+161cEqpxrfxo4bHH8fkZ60VZUQP8CjwwQUhP
-4iwpv2bYbQwzlttZwTC6s28wh7FRtgVoVPTwvXJa6fl2zAjLtsjwLZ/556ez9xIJ
-67hxkIK2EzGQaeEKI1+vVF5EKsgKiPEmgspOBxRPoVWTx49NooiakGnwaBoDyTob
-8FMr8mF1EheNQ4kl1bPrl+csD7PPnfbWUdNVvMljEhS3cYamQDPEWyAzvaIr0rHh
-/6h80L/G2+0fensrTspWJcjX+XDBwQPk+YMic0TJ3KvkC7p2iNJhjNrjhQ+APZWq
-xYrjfcmdK0RaaoqN+1zeE1P2kWIJx9CQZVMeGhVzzcmPwJPDnJFpkU+8cgTWnUr/
-Fh8YtDoDzLiAUcmV1Kk7LYtYPHuU8epuz5PYm49TbWzdS7PX5wqFAFmrVt5jysm4
-D/Ox0r4KV1t7D/1gc1WRIu8oUXkIglCHWNpTyMK0kFPctAf/ua+DUFRE4eSx3rsX
-ZKIymdF9v/WF1Ud0tsNeudQbVeXWS6UCR8m/rqe81W4npQm/uqUNla+6yaYUmHlk
-tvw/m6pt+jKhn0XIRkMwHrTpIaMVvInMg0xpkRuc7Xj5A7vNnkypZRNZJHgy7WWC
-6GpOCWJOltYaNy7tmAkSUHJ6kNjXK5a4fi30HknEaqKjFTQNGvcybulJ3MXUzds0
-MJoTpvQfLzYQbMYZ/XRGND4lgeEbs29nWLPae8D5XlDeZQMin8EukPko8u8+YGbU
-eWGOvDc+4/xrWrsq1i6R0uWq+Cyoql8oh0PNBlM04S7GAbu1pOD/tPcq/GNYcv/Q
-vJcIz9KA3BNepq7tC8D88ggEvFjTsHKeW/OnuCxKducSna4Mq+GebU52tKjkLjFC
-eLG4Vx0BY5xPH3gd7iyuAf7S+08BbinNZWjHLpdmR3vKK5YbLPiGSfcYQdClr6BK
-9vNWH4TXmZMV+rWtfSeM/cbhCHwxT5Jx6N0OFAxOblQClWnUD79nGkEgn/GoY/Aj
-FPNj8u2U/mJHgFHH3ClidYL9jJUvhGpTixB8nGgMjJ0wvFcp+5OysG3TsjqYkwR6
-RRNBmM+iLEUFTrMZYb+edHvGJsMEMZ0qvjmZDsfDz6ax5M9zH/ORFcGplgIec8kj
-I106+dqAVVrv1CrBf2N/pxV0OXVhgl6ECe/Ee1xYC2e2CiEgUnQtedu8ekgPgp73
-tHcAiWMamLPTwXuL7jFtvWaQfkYBmrBdEx54+eZOfH/NgV3o8gbaWNHSxbfbwlXN
-MvyJidZGkXU0DJtUUnO5i2S7ftKCdOzrrSA8HDTvxFUhxretYpF3NzPYpYkM7WJX
-GM7bTMn37AWYqLZmdYYdjh1ZOH/wsM/3uxGBpyEyy4Urrr1ux7X1P0cL0O2P/72h
-GRd499JLrRMrmmtQ4KrN7GCHdctvujhDP8zvmnaEyGVzg88XmDg50ZF3+8DmOOgX
-EMZEYHO2Wi2uyFotFtZCuqoOJmGPPeGV8QrsRs82hnL1bcd6REUTWk0KsTt13lvF
-WwMJugHFk5NQuse3P4Hh9smQrRrv1dvnpt7s4yKStKolXUaFWcXJvXVaDfR5266Y
-p7cuYY1cAyI7gFfl5A==
------END ENCRYPTED PRIVATE KEY-----
-"""
-
-UNENCRYPTED_PKCS8_CRT_KEY = """-----BEGIN PRIVATE KEY-----
-MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCy9Z5mwz1A6bPO
-ItbDN64R63Pg5btDf8CkFimRXollLRf6aLdfVd6NMlw6bIO1uUZCzExZGRHJ0Kch
-naQBo0485jVzGcPfRM8bJq0d5eoVBCEon1W7xLn7WGU+oz8TOTC+lgIxTWgRGT1r
-WYvAoF+cXY3awzZ3cMh6G+PZ+zXP4dZFaqgajCC2m06gushHMUvwfg7oFbrmGxHW
-GGBJUFDHzPplHVC60qiFZdp+QL70hY1s1s34D8qeECp/n+x1UU+tm4f140PPJ9bT
-GDQBKosUWUz4KmNSxZfVSVYEafX3S+rbTLqzkdwtEkyeagnSgS+y66W2OLvHRK2o
-EQumAMiPAgMBAAECggEALcNfoVm19T6OC12fW8aGTfDO7ijxLT6jDZLZSGJLckMI
-ybEziz6TLbo+GXaca8EYNYa202X0xY4E3zTHtt+C51HbQzbIfvTCnWfThzy/Ema+
-7/tm2iBhiuO86Dqoq4rJa0NDBkaMISs6KJR6h2S7bmoCF3oqGHsP2SH+r0RtK15g
-VeyomI2tji6XX5xE4xmkfHrfFjoDM+aS9JSBquSBjivD0TvW3uK3aVpaREpWx36Q
-SNrKuK10QSWI0xUUW2sYSCmViSYvEZ/QcuJE4VUwItFb8/XYmleWUU+sFvyuU8vj
-DVz+z7JK2iFPQr6jgUteGx/+KfGZ9z1edld0mbST8QKBgQDjsWlXVxoyT5M09+7f
-XxUIZGaPCld2aQ1pSJfZS+zfEgpDoomamjeyPRiNASZBXPyzqB5K29TUt0/GCxZl
-9sO3fUzpI3DKWHzYAFAXVtnKtwxHEzxseF5uEMhMzV0CfppE6RLVwGl9H00k4UPz
-nSWYm8EZH05FUEbK5xMofm5fGQKBgQDJNTTNApbZpTcnuZMIL1yn55IPd+5smlrc
-wvld9Dxg0gPg+zFaCU0o9w5MLjJpJ/FWbKRLRYhBRrMKy2zNCy/DL1jIe2mQyr7S
-XII++tieZFXTPHnNPXnlXbNwSH+iPrh6h55bmS8lKz/Hq9P6UQ3RMMQnaAoRom4G
-3okbo/Th5wKBgFI3DUJsQRlJgm3t2GLvgji1iBK+OTaYWC9b9viPYchqSyqA1g7t
-AI9rYCIJ+DZBzT1Rxx5gokjsp/Fqr3vBzonCxLKqCWAG841LD6Bdy+ZWkihX2cmQ
-7QfxJ2IUBTGRZULcpeBoya5UTxayAEdGxvyDwQXBOBHvGqDJLzG/9TqBAoGBAJ1S
-v91ImADHoQ+rl16AAde7RkZYBRHfwwn4XZjr/kXKEIRahGUc/rr4KbLBMGNuetKT
-kgbU8Evx5s6a7pCInajlHWtsq8ct7/R1ptVtt/BpDX5kO+yRk/0WvdYeqcWHeyE7
-Z0PBy84pOe562P1RYRdfJRCW1cCiG5u9ZsE4+qGjAoGAHe3ahRIUkjx9I1CdA2Rx
-6yklN12vSgsTCCwiXhDut0Ucuv79zjqy+MmQ8y2l/ENC+SArZpalLg4/QTa9JT8h
-8wQOaXKl8p7ZJpO0V6FlJTBHhHX9mFIveJKIzAliCb3w/buzhMQx2GU81UmuPUWs
-P7hWuCk6ygzbQSRmdO96X2w=
------END PRIVATE KEY-----
-"""
-
-EXPECTED_IMD_SUBJS = ["IMD3", "IMD2", "IMD1"]
-
-X509_IMDS = """Junk
------BEGIN CERTIFICATE-----
-MIIBhDCCAS6gAwIBAgIGAUo7hO/eMA0GCSqGSIb3DQEBCwUAMA8xDTALBgNVBAMT
-BElNRDIwHhcNMTQxMjExMjI0MjU1WhcNMjUxMTIzMjI0MjU1WjAPMQ0wCwYDVQQD
-EwRJTUQzMFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAKHIPXo2pfD5dpnpVDVz4n43
-zn3VYsjz/mgOZU0WIWjPA97mvulb7mwb4/LB4ijOMzHj9XfwP75GiOFxYFs8O80C
-AwEAAaNwMG4wDwYDVR0TAQH/BAUwAwEB/zA8BgNVHSMENTAzgBS6rfnABCO3oHEz
-NUUtov2hfXzfVaETpBEwDzENMAsGA1UEAxMESU1EMYIGAUo7hO/DMB0GA1UdDgQW
-BBRiLW10LVJiFO/JOLsQFev0ToAcpzANBgkqhkiG9w0BAQsFAANBABtdF+89WuDi
-TC0FqCocb7PWdTucaItD9Zn55G8KMd93eXrOE/FQDf1ScC+7j0jIHXjhnyu6k3NV
-8el/x5gUHlc=
------END CERTIFICATE-----
-Junk should be ignored by x509 splitter
------BEGIN CERTIFICATE-----
-MIIBhDCCAS6gAwIBAgIGAUo7hO/DMA0GCSqGSIb3DQEBCwUAMA8xDTALBgNVBAMT
-BElNRDEwHhcNMTQxMjExMjI0MjU1WhcNMjUxMTIzMjI0MjU1WjAPMQ0wCwYDVQQD
-EwRJTUQyMFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAJYHqnsisVKTlwVaCSa2wdrv
-CeJJzqpEVV0RVgAAF6FXjX2Tioii+HkXMR9zFgpE1w4yD7iu9JDb8yTdNh+NxysC
-AwEAAaNwMG4wDwYDVR0TAQH/BAUwAwEB/zA8BgNVHSMENTAzgBQt3KvN8ncGj4/s
-if1+wdvIMCoiE6ETpBEwDzENMAsGA1UEAxMEcm9vdIIGAUo7hO+mMB0GA1UdDgQW
-BBS6rfnABCO3oHEzNUUtov2hfXzfVTANBgkqhkiG9w0BAQsFAANBAIlJODvtmpok
-eoRPOb81MFwPTTGaIqafebVWfBlR0lmW8IwLhsOUdsQqSzoeypS3SJUBpYT1Uu2v
-zEDOmgdMsBY=
------END CERTIFICATE-----
-Junk should be thrown out like junk
------BEGIN CERTIFICATE-----
-MIIBfzCCASmgAwIBAgIGAUo7hO+mMA0GCSqGSIb3DQEBCwUAMA8xDTALBgNVBAMT
-BHJvb3QwHhcNMTQxMjExMjI0MjU1WhcNMjUxMTIzMjI0MjU1WjAPMQ0wCwYDVQQD
-EwRJTUQxMFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAI+tSJxr60ogwXFmgqbLMW7K
-3fkQnh9sZBi7Qo6AzUnfe/AhXoisib651fOxKXCbp57IgzLTv7O9ygq3I+5fQqsC
-AwEAAaNrMGkwDwYDVR0TAQH/BAUwAwEB/zA3BgNVHSMEMDAugBR73ZKSpjbsz9tZ
-URkvFwpIO7gB4KETpBEwDzENMAsGA1UEAxMEcm9vdIIBATAdBgNVHQ4EFgQULdyr
-zfJ3Bo+P7In9fsHbyDAqIhMwDQYJKoZIhvcNAQELBQADQQBenkZ2k7RgZqgj+dxA
-D7BF8MN1oUAOpyYqAjkGddSEuMyNmwtHKZI1dyQ0gBIQdiU9yAG2oTbUIK4msbBV
-uJIQ
------END CERTIFICATE-----"""
-
-
-def _get_rsa_numbers(private_key, private_key_passphrase=None):
-    """
-    Grabs the private and public numbers as a dictionary
-    from an RSA private key used for the dump_private_key test case
-
-    :param private_key:
-    :param private_key_passphrase:
-    :returns: a dictionary with keys (p,q,e,d,t,e,n)
-    """
-    kw = {"private_key_passphrase": private_key_passphrase}
-    pk = cert_parser._read_pyca_private_key(private_key, **kw)
-    p = pk.private_numbers().p
-    q = pk.private_numbers().q
-    d = pk.private_numbers().d
-    t = (p - 1) * (q - 1)
-    e = pk.private_numbers().public_numbers.e
-    n = pk.private_numbers().public_numbers.n  # should be p*q
-    # Force a canonical representation for comparison algos
-    # by swapping p and q if q is bigger
-    if p < q:
-        (p, q) = (q, p)
-    return {"p": p, "q": q, "d": d, "t": t, "e": e, "n": n}
-
-
-class TestTLSParseUtils(base.BaseTestCase):
-    def test_alt_subject_name_parses(self):
-        hosts = cert_parser.get_host_names(ALT_EXT_CRT)
-        self.assertEqual('www.cnfromsubject.org', hosts['cn'])
-        self.assertEqual('www.hostfromdnsname1.com', hosts['dns_names'][0])
-        self.assertEqual('www.hostfromdnsname2.com', hosts['dns_names'][1])
-        self.assertEqual('www.hostfromdnsname3.com', hosts['dns_names'][2])
-        self.assertEqual('www.hostfromdnsname4.com', hosts['dns_names'][3])
-
-    def test_x509_parses(self):
-        self.assertRaises(exceptions.UnreadableCert,
-                          cert_parser.validate_cert, "BAD CERT")
-        self.assertTrue(cert_parser.validate_cert(six.u(ALT_EXT_CRT)))
-        self.assertTrue(cert_parser.validate_cert(ALT_EXT_CRT))
-        self.assertTrue(cert_parser.validate_cert(ALT_EXT_CRT,
-                        private_key=UNENCRYPTED_PKCS8_CRT_KEY))
-
-    def test_x509_parses_intermediates(self):
-        # Should not throw error when parsing with intermediates
-        cert_parser.validate_cert(ALT_EXT_CRT,
-                                  UNENCRYPTED_PKCS8_CRT_KEY,
-                                  intermediates=X509_IMDS)
-
-    def test_read_private_key(self):
-        self.assertRaises(exceptions.NeedsPassphrase,
-                          cert_parser._read_privatekey,
-                          ENCRYPTED_PKCS8_CRT_KEY)
-        cert_parser._read_privatekey(
-            str(ENCRYPTED_PKCS8_CRT_KEY),
-            passphrase=ENCRYPTED_PKCS8_CRT_KEY_PASSPHRASE)
-
-    def test_read_private_key_unicode(self):
-        self.assertRaises(exceptions.NeedsPassphrase,
-                          cert_parser._read_privatekey,
-                          ENCRYPTED_PKCS8_CRT_KEY)
-        cert_parser._read_privatekey(
-            six.u(ENCRYPTED_PKCS8_CRT_KEY),
-            passphrase=ENCRYPTED_PKCS8_CRT_KEY_PASSPHRASE)
-        cert_parser._read_privatekey(
-            ENCRYPTED_PKCS8_CRT_KEY,
-            passphrase=six.u(ENCRYPTED_PKCS8_CRT_KEY_PASSPHRASE))
-
-    def test_dump_private_key(self):
-        self.assertRaises(exceptions.NeedsPassphrase,
-                          cert_parser.dump_private_key,
-                          ENCRYPTED_PKCS8_CRT_KEY)
-        striped_rsa_key = _get_rsa_numbers(
-            UNENCRYPTED_PKCS8_CRT_KEY)
-        decrypted_rsa_key = _get_rsa_numbers(
-            cert_parser.dump_private_key(ENCRYPTED_PKCS8_CRT_KEY,
-                                         ENCRYPTED_PKCS8_CRT_KEY_PASSPHRASE))
-
-        self.assertEqual(striped_rsa_key, decrypted_rsa_key)
-        self.assertIsNot(ENCRYPTED_PKCS8_CRT_KEY,
-                         cert_parser.dump_private_key(
-                             ENCRYPTED_PKCS8_CRT_KEY,
-                             ENCRYPTED_PKCS8_CRT_KEY_PASSPHRASE))
-
-    def test_validate_cert_and_key_match(self):
-        self.assertTrue(cert_parser.validate_cert(ALT_EXT_CRT,
-                                                  private_key=ALT_EXT_CRT_KEY))
-        self.assertRaises(exceptions.MisMatchedKey,
-                          cert_parser.validate_cert,
-                          ALT_EXT_CRT, private_key=SOME_OTHER_RSA_KEY)
-
-    def test_split_x509s(self):
-        imds = []
-        for x509Pem in cert_parser._split_x509s(X509_IMDS):
-            imds.append(cert_parser._get_x509_from_pem_bytes(x509Pem))
-
-        for i in range(0, len(imds)):
-            self.assertEqual(EXPECTED_IMD_SUBJS[i],
-                             imds[i].subject.get_attributes_for_oid(
-                                 x509.OID_COMMON_NAME)[0].value)
diff --git a/tests/unit/db/__init__.py b/tests/unit/db/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/db/loadbalancer/__init__.py b/tests/unit/db/loadbalancer/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/db/loadbalancer/test_db_loadbalancer.py b/tests/unit/db/loadbalancer/test_db_loadbalancer.py
deleted file mode 100644
index 2518b65..0000000
--- a/tests/unit/db/loadbalancer/test_db_loadbalancer.py
+++ /dev/null
@@ -1,1660 +0,0 @@
-# Copyright (c) 2012 OpenStack Foundation.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-# implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-import contextlib
-
-import mock
-from neutron.api import extensions
-from neutron.callbacks import events
-from neutron.callbacks import registry
-from neutron.callbacks import resources
-from neutron.common import config
-from neutron import context
-from neutron.db import servicetype_db as sdb
-from neutron import manager
-from neutron.plugins.common import constants
-from neutron.services import provider_configuration as pconf
-from neutron.tests.unit.db import test_db_base_plugin_v2
-from neutron_lib import constants as n_constants
-from neutron_lib import exceptions as n_exc
-import testtools
-import webob.exc
-
-from neutron_lbaas._i18n import _
-from neutron_lbaas.db.loadbalancer import loadbalancer_db as ldb
-import neutron_lbaas.extensions
-from neutron_lbaas.extensions import loadbalancer
-from neutron_lbaas.services.loadbalancer import (
-    plugin as loadbalancer_plugin
-)
-from neutron_lbaas.services.loadbalancer.drivers import abstract_driver
-from neutron_lbaas.tests import base
-
-
-DB_CORE_PLUGIN_KLASS = 'neutron.db.db_base_plugin_v2.NeutronDbPluginV2'
-DB_LB_PLUGIN_KLASS = (
-    "neutron_lbaas.services.loadbalancer."
-    "plugin.LoadBalancerPlugin"
-)
-NOOP_DRIVER_KLASS = ('neutron_lbaas.tests.unit.db.loadbalancer.'
-                     'test_db_loadbalancer.NoopLbaaSDriver')
-
-extensions_path = ':'.join(neutron_lbaas.extensions.__path__)
-
-_subnet_id = "0c798ed8-33ba-11e2-8b28-000c291c4d14"
-
-
-class NoopLbaaSDriver(abstract_driver.LoadBalancerAbstractDriver):
-    """A dummy lbass driver that that only performs object deletion."""
-
-    def __init__(self, plugin):
-        self.plugin = plugin
-
-    def create_vip(self, context, vip):
-        pass
-
-    def update_vip(self, context, old_vip, vip):
-        pass
-
-    def delete_vip(self, context, vip):
-        self.plugin._delete_db_vip(context, vip["id"])
-
-    def create_pool(self, context, pool):
-        pass
-
-    def update_pool(self, context, old_pool, pool):
-        pass
-
-    def delete_pool(self, context, pool):
-        self.plugin._delete_db_pool(context, pool["id"])
-
-    def stats(self, context, pool_id):
-        return {"bytes_in": 0,
-                "bytes_out": 0,
-                "active_connections": 0,
-                "total_connections": 0}
-
-    def create_member(self, context, member):
-        pass
-
-    def update_member(self, context, old_member, member):
-        pass
-
-    def delete_member(self, context, member):
-        self.plugin._delete_db_member(context, member["id"])
-
-    def update_pool_health_monitor(self, context, old_health_monitor,
-                                   health_monitor,
-                                   pool_association):
-        pass
-
-    def create_pool_health_monitor(self, context,
-                                   health_monitor, pool_id):
-        pass
-
-    def delete_pool_health_monitor(self, context, health_monitor, pool_id):
-        self.plugin._delete_db_pool_health_monitor(
-            context, health_monitor["id"],
-            pool_id
-        )
-
-
-class LoadBalancerTestMixin(object):
-    resource_prefix_map = dict(
-        (k, loadbalancer.LOADBALANCER_PREFIX)
-        for k in loadbalancer.RESOURCE_ATTRIBUTE_MAP.keys()
-    )
-
-    def _get_vip_optional_args(self):
-        return ('description', 'subnet_id', 'address',
-                'session_persistence', 'connection_limit')
-
-    def _create_vip(self, fmt, name, pool_id, protocol, protocol_port,
-                    admin_state_up, expected_res_status=None, **kwargs):
-        data = {'vip': {'name': name,
-                        'pool_id': pool_id,
-                        'protocol': protocol,
-                        'protocol_port': protocol_port,
-                        'admin_state_up': admin_state_up,
-                        'tenant_id': self._tenant_id}}
-        args = self._get_vip_optional_args()
-        for arg in args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data['vip'][arg] = kwargs[arg]
-
-        vip_req = self.new_create_request('vips', data, fmt)
-        vip_res = vip_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, vip_res.status_int)
-
-        return vip_res
-
-    def _create_pool(self, fmt, name, lb_method, protocol, admin_state_up,
-                     subnet_id, expected_res_status=None, **kwargs):
-        data = {'pool': {'name': name,
-                         'subnet_id': subnet_id,
-                         'lb_method': lb_method,
-                         'protocol': protocol,
-                         'admin_state_up': admin_state_up,
-                         'tenant_id': self._tenant_id}}
-        for arg in ('description', 'provider', 'subnet_id'):
-            if arg in kwargs and kwargs[arg] is not None:
-                data['pool'][arg] = kwargs[arg]
-        pool_req = self.new_create_request('pools', data, fmt)
-        pool_res = pool_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, pool_res.status_int)
-
-        return pool_res
-
-    def _create_member(self, fmt, address, protocol_port, admin_state_up,
-                       expected_res_status=None, **kwargs):
-        data = {'member': {'address': address,
-                           'protocol_port': protocol_port,
-                           'admin_state_up': admin_state_up,
-                           'tenant_id': self._tenant_id}}
-        for arg in ('weight', 'pool_id'):
-            if arg in kwargs and kwargs[arg] is not None:
-                data['member'][arg] = kwargs[arg]
-
-        member_req = self.new_create_request('members', data, fmt)
-        member_res = member_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, member_res.status_int)
-
-        return member_res
-
-    def _create_health_monitor(self, fmt, type, delay, timeout, max_retries,
-                               admin_state_up, expected_res_status=None,
-                               **kwargs):
-        data = {'health_monitor': {'type': type,
-                                   'delay': delay,
-                                   'timeout': timeout,
-                                   'max_retries': max_retries,
-                                   'admin_state_up': admin_state_up,
-                                   'tenant_id': self._tenant_id}}
-        for arg in ('http_method', 'path', 'expected_code'):
-            if arg in kwargs and kwargs[arg] is not None:
-                data['health_monitor'][arg] = kwargs[arg]
-
-        req = self.new_create_request('health_monitors', data, fmt)
-
-        res = req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, res.status_int)
-
-        return res
-
-    @contextlib.contextmanager
-    def vip(self, fmt=None, name='vip1', pool=None, subnet=None,
-            protocol='HTTP', protocol_port=80, admin_state_up=True,
-            do_delete=True, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-
-        with test_db_base_plugin_v2.optional_ctx(
-            subnet, self.subnet) as tmp_subnet:
-            with test_db_base_plugin_v2.optional_ctx(
-                pool, self.pool) as tmp_pool:
-
-                pool_id = tmp_pool['pool']['id']
-                res = self._create_vip(fmt,
-                                       name,
-                                       pool_id,
-                                       protocol,
-                                       protocol_port,
-                                       admin_state_up,
-                                       subnet_id=tmp_subnet['subnet']['id'],
-                                       **kwargs)
-                if res.status_int >= webob.exc.HTTPClientError.code:
-                    raise webob.exc.HTTPClientError(
-                        explanation=_("Unexpected error code: %s") %
-                        res.status_int
-                    )
-                vip = self.deserialize(fmt or self.fmt, res)
-                yield vip
-                if do_delete:
-                    self._delete('vips', vip['vip']['id'])
-
-    @contextlib.contextmanager
-    def pool(self, fmt=None, name='pool1', lb_method='ROUND_ROBIN',
-             protocol='HTTP', admin_state_up=True, do_delete=True,
-             subnet_id=None, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-        subnet_id = subnet_id or _subnet_id
-        res = self._create_pool(fmt,
-                                name,
-                                lb_method,
-                                protocol,
-                                admin_state_up,
-                                subnet_id,
-                                **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-        pool = self.deserialize(fmt or self.fmt, res)
-        yield pool
-        if do_delete:
-            self._delete('pools', pool['pool']['id'])
-
-    @contextlib.contextmanager
-    def member(self, fmt=None, address='192.168.1.100', protocol_port=80,
-               admin_state_up=True, do_delete=True, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-        res = self._create_member(fmt,
-                                  address,
-                                  protocol_port,
-                                  admin_state_up,
-                                  **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-        member = self.deserialize(fmt or self.fmt, res)
-        yield member
-        if do_delete:
-            self._delete('members', member['member']['id'])
-
-    @contextlib.contextmanager
-    def health_monitor(self, fmt=None, type='TCP',
-                       delay=30, timeout=10, max_retries=3,
-                       admin_state_up=True,
-                       do_delete=True, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-        res = self._create_health_monitor(fmt,
-                                          type,
-                                          delay,
-                                          timeout,
-                                          max_retries,
-                                          admin_state_up,
-                                          **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-        health_monitor = self.deserialize(fmt or self.fmt, res)
-        the_health_monitor = health_monitor['health_monitor']
-        # make sure:
-        # 1. When the type is HTTP/S we have HTTP related attributes in
-        #    the result
-        # 2. When the type is not HTTP/S we do not have HTTP related
-        #    attributes in the result
-        http_related_attributes = ('http_method', 'url_path', 'expected_codes')
-        if type in ['HTTP', 'HTTPS']:
-            for arg in http_related_attributes:
-                self.assertIsNotNone(the_health_monitor.get(arg))
-        else:
-            for arg in http_related_attributes:
-                self.assertIsNone(the_health_monitor.get(arg))
-        yield health_monitor
-        if do_delete:
-            self._delete('health_monitors', the_health_monitor['id'])
-
-
-class LoadBalancerPluginDbTestCase(LoadBalancerTestMixin,
-                                   base.NeutronDbPluginV2TestCase):
-    def setUp(self, core_plugin=None, lb_plugin=None, lbaas_provider=None,
-              ext_mgr=None):
-        service_plugins = {'lb_plugin_name': DB_LB_PLUGIN_KLASS}
-        if not lbaas_provider:
-            lbaas_provider = (
-                constants.LOADBALANCER +
-                ':lbaas:' + NOOP_DRIVER_KLASS + ':default')
-
-        # override the default service provider
-        self.set_override([lbaas_provider])
-
-        # removing service-type because it resides in neutron and tests
-        # dont care
-        LBPlugin = loadbalancer_plugin.LoadBalancerPlugin
-        sea_index = None
-        for index, sea in enumerate(LBPlugin.supported_extension_aliases):
-            if sea == 'service-type':
-                sea_index = index
-        if sea_index:
-            del LBPlugin.supported_extension_aliases[sea_index]
-        super(LoadBalancerPluginDbTestCase, self).setUp(
-            ext_mgr=ext_mgr,
-            service_plugins=service_plugins
-        )
-        if not ext_mgr:
-            self.plugin = loadbalancer_plugin.LoadBalancerPlugin()
-            ext_mgr = extensions.PluginAwareExtensionManager(
-                extensions_path,
-                {constants.LOADBALANCER: self.plugin}
-            )
-            app = config.load_paste_app('extensions_test_app')
-            self.ext_api = extensions.ExtensionMiddleware(app, ext_mgr=ext_mgr)
-
-        get_lbaas_agent_patcher = mock.patch(
-            'neutron_lbaas.services.loadbalancer.agent_scheduler'
-            '.LbaasAgentSchedulerDbMixin.get_lbaas_agent_hosting_pool')
-        mock_lbaas_agent = mock.MagicMock()
-        get_lbaas_agent_patcher.start().return_value = mock_lbaas_agent
-        mock_lbaas_agent.__getitem__.return_value = {'host': 'host'}
-
-        self._subnet_id = _subnet_id
-
-
-class TestLoadBalancer(LoadBalancerPluginDbTestCase):
-
-    def test_create_vip(self, **extras):
-        expected = {
-            'name': 'vip1',
-            'description': '',
-            'protocol_port': 80,
-            'protocol': 'HTTP',
-            'connection_limit': -1,
-            'admin_state_up': True,
-            'status': 'PENDING_CREATE',
-            'tenant_id': self._tenant_id,
-        }
-
-        expected.update(extras)
-
-        with self.subnet() as subnet:
-            expected['subnet_id'] = subnet['subnet']['id']
-            name = expected['name']
-
-            with self.vip(name=name, subnet=subnet, **extras) as vip:
-                for k in ('id', 'address', 'port_id', 'pool_id'):
-                    self.assertTrue(vip['vip'].get(k, None))
-
-                self.assertEqual(
-                    expected,
-                    dict((k, v)
-                         for k, v in vip['vip'].items() if k in expected)
-                )
-            return vip
-
-    def test_create_vip_create_port_fails(self):
-        with self.subnet() as subnet:
-            with self.pool() as pool:
-                lb_plugin = (manager.NeutronManager.
-                             get_instance().
-                             get_service_plugins()[constants.LOADBALANCER])
-                with mock.patch.object(
-                    lb_plugin, '_create_port_for_vip') as cp:
-                    #some exception that can show up in port creation
-                    cp.side_effect = n_exc.IpAddressGenerationFailure(
-                        net_id=subnet['subnet']['network_id'])
-                    self._create_vip(self.fmt, "vip",
-                                     pool['pool']['id'], "HTTP", "80", True,
-                                     subnet_id=subnet['subnet']['id'],
-                                     expected_res_status=409)
-                req = self.new_list_request('vips')
-                res = self.deserialize(self.fmt,
-                                       req.get_response(self.ext_api))
-                self.assertFalse(res['vips'])
-
-    def test_create_vip_twice_for_same_pool(self):
-        """Test loadbalancer db plugin via extension and directly."""
-        with self.subnet() as subnet:
-            with self.pool(name="pool1") as pool:
-                with self.vip(name='vip1', subnet=subnet, pool=pool):
-                    vip_data = {
-                        'name': 'vip1',
-                        'pool_id': pool['pool']['id'],
-                        'description': '',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'connection_limit': -1,
-                        'admin_state_up': True,
-                        'status': 'PENDING_CREATE',
-                        'tenant_id': self._tenant_id,
-                        'session_persistence': ''
-                    }
-                    self.assertRaises(loadbalancer.VipExists,
-                                      self.plugin.create_vip,
-                                      context.get_admin_context(),
-                                      {'vip': vip_data})
-
-    def test_update_vip_raises_vip_exists(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(
-                self.pool(name="pool1"),
-                self.pool(name="pool2")
-            ) as (pool1, pool2):
-                with contextlib.nested(
-                    self.vip(name='vip1', subnet=subnet, pool=pool1),
-                    self.vip(name='vip2', subnet=subnet, pool=pool2)
-                ) as (vip1, vip2):
-                    vip_data = {
-                        'id': vip2['vip']['id'],
-                        'name': 'vip1',
-                        'pool_id': pool1['pool']['id'],
-                    }
-                    self.assertRaises(loadbalancer.VipExists,
-                                      self.plugin.update_vip,
-                                      context.get_admin_context(),
-                                      vip2['vip']['id'],
-                                      {'vip': vip_data})
-
-    def test_update_vip_change_pool(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(
-                self.pool(name="pool1"),
-                self.pool(name="pool2")
-            ) as (pool1, pool2):
-                with self.vip(name='vip1', subnet=subnet, pool=pool1) as vip:
-                    # change vip from pool1 to pool2
-                    vip_data = {
-                        'id': vip['vip']['id'],
-                        'name': 'vip1',
-                        'pool_id': pool2['pool']['id'],
-                    }
-                    ctx = context.get_admin_context()
-                    self.plugin.update_vip(ctx,
-                                           vip['vip']['id'],
-                                           {'vip': vip_data})
-                    db_pool2 = (ctx.session.query(ldb.Pool).
-                                filter_by(id=pool2['pool']['id']).one())
-                    db_pool1 = (ctx.session.query(ldb.Pool).
-                                filter_by(id=pool1['pool']['id']).one())
-                    # check that pool1.vip became None
-                    self.assertIsNone(db_pool1.vip)
-                    # and pool2 got vip
-                    self.assertEqual(vip['vip']['id'], db_pool2.vip.id)
-
-    def test_create_vip_with_invalid_values(self):
-        invalid = {
-            'protocol': 'UNSUPPORTED',
-            'protocol_port': 'NOT_AN_INT',
-            'protocol_port': 1000500,
-            'subnet': {'subnet': {'id': 'invalid-subnet'}}
-        }
-
-        for param, value in invalid.items():
-            kwargs = {'name': 'the-vip', param: value}
-            with testtools.ExpectedException(webob.exc.HTTPClientError):
-                with self.vip(**kwargs):
-                    pass
-
-    def test_create_vip_with_address(self):
-        self.test_create_vip(address='10.0.0.7')
-
-    def test_create_vip_with_address_outside_subnet(self):
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_vip(address='9.9.9.9')
-
-    def test_create_vip_with_session_persistence(self):
-        self.test_create_vip(session_persistence={'type': 'HTTP_COOKIE'})
-
-    def test_create_vip_with_session_persistence_with_app_cookie(self):
-        sp = {'type': 'APP_COOKIE', 'cookie_name': 'sessionId'}
-        self.test_create_vip(session_persistence=sp)
-
-    def test_create_vip_with_session_persistence_unsupported_type(self):
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_vip(session_persistence={'type': 'UNSUPPORTED'})
-
-    def test_create_vip_with_unnecessary_cookie_name(self):
-        sp = {'type': "SOURCE_IP", 'cookie_name': 'sessionId'}
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_vip(session_persistence=sp)
-
-    def test_create_vip_with_session_persistence_without_cookie_name(self):
-        sp = {'type': "APP_COOKIE"}
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_vip(session_persistence=sp)
-
-    def test_create_vip_with_protocol_mismatch(self):
-        with self.pool(protocol='TCP') as pool:
-            with testtools.ExpectedException(webob.exc.HTTPClientError):
-                self.test_create_vip(pool=pool, protocol='HTTP')
-
-    def test_create_vip_with_gateway_ip(self):
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_vip(address='10.0.0.1')
-
-    def test_update_vip_with_protocol_mismatch(self):
-        with self.pool(protocol='TCP') as pool:
-            with self.vip(protocol='HTTP') as vip:
-                data = {'vip': {'pool_id': pool['pool']['id']}}
-                req = self.new_update_request('vips', data, vip['vip']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPClientError.code,
-                                 res.status_int)
-
-    def test_reset_session_persistence(self):
-        name = 'vip4'
-        session_persistence = {'type': "HTTP_COOKIE"}
-
-        update_info = {'vip': {'session_persistence': None}}
-
-        with self.vip(name=name, session_persistence=session_persistence) as v:
-            # Ensure that vip has been created properly
-            self.assertEqual(session_persistence,
-                             v['vip']['session_persistence'])
-
-            # Try resetting session_persistence
-            req = self.new_update_request('vips', update_info, v['vip']['id'])
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-
-            self.assertIsNone(res['vip']['session_persistence'])
-
-    def test_update_vip(self):
-        name = 'new_vip'
-        keys = [('name', name),
-                ('address', "10.0.0.2"),
-                ('protocol_port', 80),
-                ('connection_limit', 100),
-                ('admin_state_up', False),
-                ('status', 'PENDING_UPDATE')]
-
-        with self.vip(name=name) as vip:
-            keys.append(('subnet_id', vip['vip']['subnet_id']))
-            data = {'vip': {'name': name,
-                            'connection_limit': 100,
-                            'session_persistence':
-                            {'type': "APP_COOKIE",
-                             'cookie_name': "jesssionId"},
-                            'admin_state_up': False}}
-            req = self.new_update_request('vips', data, vip['vip']['id'])
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            for k, v in keys:
-                self.assertEqual(v, res['vip'][k])
-
-    def test_delete_vip(self):
-        with self.pool():
-            with self.vip(do_delete=False) as vip:
-                req = self.new_delete_request('vips',
-                                              vip['vip']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPNoContent.code, res.status_int)
-
-    def test_show_vip(self):
-        name = "vip_show"
-        keys = [('name', name),
-                ('address', "10.0.0.10"),
-                ('protocol_port', 80),
-                ('protocol', 'HTTP'),
-                ('connection_limit', -1),
-                ('admin_state_up', True),
-                ('status', 'PENDING_CREATE')]
-        with self.vip(name=name, address='10.0.0.10') as vip:
-            req = self.new_show_request('vips',
-                                        vip['vip']['id'])
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            for k, v in keys:
-                self.assertEqual(v, res['vip'][k])
-
-    def test_list_vips(self):
-        name = "vips_list"
-        keys = [('name', name),
-                ('address', "10.0.0.2"),
-                ('protocol_port', 80),
-                ('protocol', 'HTTP'),
-                ('connection_limit', -1),
-                ('admin_state_up', True),
-                ('status', 'PENDING_CREATE')]
-        with self.vip(name=name) as vip:
-            keys.append(('subnet_id', vip['vip']['subnet_id']))
-            req = self.new_list_request('vips')
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            self.assertEqual(1, len(res['vips']))
-            for k, v in keys:
-                self.assertEqual(v, res['vips'][0][k])
-
-    def test_list_vips_with_sort_emulated(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(
-                self.vip(name='vip1', subnet=subnet, protocol_port=81),
-                self.vip(name='vip2', subnet=subnet, protocol_port=82),
-                self.vip(name='vip3', subnet=subnet, protocol_port=82)
-            ) as (vip1, vip2, vip3):
-                self._test_list_with_sort(
-                    'vip',
-                    (vip1, vip3, vip2),
-                    [('protocol_port', 'asc'), ('name', 'desc')]
-                )
-
-    def test_list_vips_with_pagination_emulated(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(self.vip(name='vip1', subnet=subnet),
-                                   self.vip(name='vip2', subnet=subnet),
-                                   self.vip(name='vip3', subnet=subnet)
-                                   ) as (vip1, vip2, vip3):
-                self._test_list_with_pagination('vip',
-                                                (vip1, vip2, vip3),
-                                                ('name', 'asc'), 2, 2)
-
-    def test_list_vips_with_pagination_reverse_emulated(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(self.vip(name='vip1', subnet=subnet),
-                                   self.vip(name='vip2', subnet=subnet),
-                                   self.vip(name='vip3', subnet=subnet)
-                                   ) as (vip1, vip2, vip3):
-                self._test_list_with_pagination_reverse('vip',
-                                                        (vip1, vip2, vip3),
-                                                        ('name', 'asc'), 2, 2)
-
-    def test_create_pool_with_invalid_values(self):
-        name = 'pool3'
-
-        pool = self.pool(name=name, protocol='UNSUPPORTED')
-        self.assertRaises(webob.exc.HTTPClientError, pool.__enter__)
-
-        pool = self.pool(name=name, lb_method='UNSUPPORTED')
-        self.assertRaises(webob.exc.HTTPClientError, pool.__enter__)
-
-    def _create_pool_directly_via_plugin(self, provider_name):
-        #default provider will be haproxy
-        prov1 = (constants.LOADBALANCER +
-                 ':lbaas:' + NOOP_DRIVER_KLASS)
-        prov2 = (constants.LOADBALANCER +
-                 ':haproxy:neutron_lbaas.services.loadbalancer.'
-                 'drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver'
-                 ':default')
-        # override the default service provider
-        self.set_override([prov1, prov2])
-
-        self.plugin = loadbalancer_plugin.LoadBalancerPlugin()
-        with self.subnet() as subnet:
-            ctx = context.get_admin_context()
-            #create pool with another provider - lbaas
-            #which is noop driver
-            pool = {'name': 'pool1',
-                    'subnet_id': subnet['subnet']['id'],
-                    'lb_method': 'ROUND_ROBIN',
-                    'protocol': 'HTTP',
-                    'admin_state_up': True,
-                    'tenant_id': self._tenant_id,
-                    'provider': provider_name,
-                    'description': ''}
-            self.plugin.create_pool(ctx, {'pool': pool})
-            assoc = ctx.session.query(sdb.ProviderResourceAssociation).one()
-            self.assertEqual(pconf.normalize_provider_name(provider_name),
-                             assoc.provider_name)
-
-    def test_create_pool_another_provider(self):
-        self._create_pool_directly_via_plugin('lbaas')
-
-    def test_create_pool_unnormalized_provider_name(self):
-        self._create_pool_directly_via_plugin('LBAAS')
-
-    def test_create_pool_unexisting_provider(self):
-        self.assertRaises(
-            pconf.ServiceProviderNotFound,
-            self._create_pool_directly_via_plugin, 'unexisting')
-
-    def test_create_pool(self):
-        name = "pool1"
-        keys = [('name', name),
-                ('subnet_id', self._subnet_id),
-                ('tenant_id', self._tenant_id),
-                ('protocol', 'HTTP'),
-                ('lb_method', 'ROUND_ROBIN'),
-                ('admin_state_up', True),
-                ('status', 'PENDING_CREATE')]
-
-        with self.pool(name=name) as pool:
-            for k, v in keys:
-                self.assertEqual(v, pool['pool'][k])
-
-    def test_create_pool_with_members(self):
-        name = "pool2"
-        with self.pool(name=name) as pool:
-            pool_id = pool['pool']['id']
-            res1 = self._create_member(self.fmt,
-                                       '192.168.1.100',
-                                       '80',
-                                       True,
-                                       pool_id=pool_id,
-                                       weight=1)
-            req = self.new_show_request('pools',
-                                        pool_id,
-                                        fmt=self.fmt)
-            pool_updated = self.deserialize(
-                self.fmt,
-                req.get_response(self.ext_api)
-            )
-
-            member1 = self.deserialize(self.fmt, res1)
-            self.assertEqual(member1['member']['id'],
-                             pool_updated['pool']['members'][0])
-            self.assertEqual(1, len(pool_updated['pool']['members']))
-
-            keys = [('address', '192.168.1.100'),
-                    ('protocol_port', 80),
-                    ('weight', 1),
-                    ('pool_id', pool_id),
-                    ('admin_state_up', True),
-                    ('status', 'PENDING_CREATE')]
-            for k, v in keys:
-                self.assertEqual(v, member1['member'][k])
-            self._delete('members', member1['member']['id'])
-
-    def test_delete_pool(self):
-        with self.pool(do_delete=False) as pool:
-            with self.member(do_delete=False,
-                             pool_id=pool['pool']['id']):
-                req = self.new_delete_request('pools',
-                                              pool['pool']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPNoContent.code, res.status_int)
-
-    def test_delete_pool_preserve_state(self):
-        with self.pool(do_delete=False) as pool:
-            with self.vip(pool=pool):
-                req = self.new_delete_request('pools',
-                                              pool['pool']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPConflict.code, res.status_int)
-                req = self.new_show_request('pools',
-                                            pool['pool']['id'],
-                                            fmt=self.fmt)
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPOk.code, res.status_int)
-                res = self.deserialize(self.fmt,
-                                       req.get_response(self.ext_api))
-                self.assertEqual(constants.PENDING_CREATE,
-                                 res['pool']['status'])
-            req = self.new_delete_request('pools',
-                                          pool['pool']['id'])
-
-    def test_delete_subnet_with_pool(self):
-        registry.subscribe(ldb.is_subnet_in_use_callback,
-                           resources.SUBNET, events.BEFORE_DELETE)
-
-        try:
-            with self.subnet() as subnet:
-                with self.pool(subnet_id=subnet['subnet']['id']):
-                    req = self.new_delete_request('subnets',
-                                                  subnet['subnet']['id'])
-                    res = req.get_response(self.api)
-
-                    self.assertIn('NeutronError', res.json)
-                    self.assertEqual('SubnetInUse',
-                                     res.json['NeutronError']['type'])
-                    self.assertEqual(409, res.status_code)
-        finally:
-            registry.unsubscribe(ldb.is_subnet_in_use_callback,
-                                 resources.SUBNET, events.BEFORE_DELETE)
-
-    def test_show_pool(self):
-        name = "pool1"
-        keys = [('name', name),
-                ('subnet_id', self._subnet_id),
-                ('tenant_id', self._tenant_id),
-                ('protocol', 'HTTP'),
-                ('lb_method', 'ROUND_ROBIN'),
-                ('admin_state_up', True),
-                ('status', 'PENDING_CREATE')]
-        with self.pool(name=name) as pool:
-            req = self.new_show_request('pools',
-                                        pool['pool']['id'],
-                                        fmt=self.fmt)
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            for k, v in keys:
-                self.assertEqual(v, res['pool'][k])
-
-    def test_list_pools_with_sort_emulated(self):
-        with contextlib.nested(self.pool(name='p1'),
-                               self.pool(name='p2'),
-                               self.pool(name='p3')
-                               ) as (p1, p2, p3):
-            self._test_list_with_sort('pool', (p3, p2, p1),
-                                      [('name', 'desc')])
-
-    def test_list_pools_with_pagination_emulated(self):
-        with contextlib.nested(self.pool(name='p1'),
-                               self.pool(name='p2'),
-                               self.pool(name='p3')
-                               ) as (p1, p2, p3):
-            self._test_list_with_pagination('pool',
-                                            (p1, p2, p3),
-                                            ('name', 'asc'), 2, 2)
-
-    def test_list_pools_with_pagination_reverse_emulated(self):
-        with contextlib.nested(self.pool(name='p1'),
-                               self.pool(name='p2'),
-                               self.pool(name='p3')
-                               ) as (p1, p2, p3):
-            self._test_list_with_pagination_reverse('pool',
-                                                    (p1, p2, p3),
-                                                    ('name', 'asc'), 2, 2)
-
-    def test_create_member(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            with self.member(address='192.168.1.100',
-                             protocol_port=80,
-                             pool_id=pool_id) as member1:
-                with self.member(address='192.168.1.101',
-                                 protocol_port=80,
-                                 pool_id=pool_id) as member2:
-                    req = self.new_show_request('pools',
-                                                pool_id,
-                                                fmt=self.fmt)
-                    pool_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertIn(member1['member']['id'],
-                                  pool_update['pool']['members'])
-                    self.assertIn(member2['member']['id'],
-                                  pool_update['pool']['members'])
-
-    def test_create_same_member_in_same_pool_raises_member_exists(self):
-        with self.subnet():
-            with self.pool(name="pool1") as pool:
-                pool_id = pool['pool']['id']
-                with self.member(address='192.168.1.100',
-                                 protocol_port=80,
-                                 pool_id=pool_id):
-                    member_data = {
-                        'address': '192.168.1.100',
-                        'protocol_port': 80,
-                        'weight': 1,
-                        'admin_state_up': True,
-                        'pool_id': pool_id,
-                        'tenant_id': self._tenant_id
-                    }
-                    self.assertRaises(loadbalancer.MemberExists,
-                                      self.plugin.create_member,
-                                      context.get_admin_context(),
-                                      {'member': member_data})
-
-    def test_update_member(self):
-        with self.pool(name="pool1") as pool1:
-            with self.pool(name="pool2") as pool2:
-                keys = [('address', "192.168.1.100"),
-                        ('tenant_id', self._tenant_id),
-                        ('protocol_port', 80),
-                        ('weight', 10),
-                        ('pool_id', pool2['pool']['id']),
-                        ('admin_state_up', False),
-                        ('status', 'PENDING_UPDATE')]
-                with self.member(pool_id=pool1['pool']['id']) as member:
-                    req = self.new_show_request('pools',
-                                                pool1['pool']['id'],
-                                                fmt=self.fmt)
-                    pool1_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertEqual(1, len(pool1_update['pool']['members']))
-
-                    req = self.new_show_request('pools',
-                                                pool2['pool']['id'],
-                                                fmt=self.fmt)
-                    pool2_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertEqual(1, len(pool1_update['pool']['members']))
-                    self.assertEqual(0, len(pool2_update['pool']['members']))
-
-                    data = {'member': {'pool_id': pool2['pool']['id'],
-                                       'weight': 10,
-                                       'admin_state_up': False}}
-                    req = self.new_update_request('members',
-                                                  data,
-                                                  member['member']['id'])
-                    res = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    for k, v in keys:
-                        self.assertEqual(v, res['member'][k])
-
-                    req = self.new_show_request('pools',
-                                                pool1['pool']['id'],
-                                                fmt=self.fmt)
-                    pool1_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-
-                    req = self.new_show_request('pools',
-                                                pool2['pool']['id'],
-                                                fmt=self.fmt)
-                    pool2_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-
-                    self.assertEqual(1, len(pool2_update['pool']['members']))
-                    self.assertEqual(0, len(pool1_update['pool']['members']))
-
-    def test_delete_member(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            with self.member(pool_id=pool_id,
-                             do_delete=False) as member:
-                req = self.new_delete_request('members',
-                                              member['member']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPNoContent.code, res.status_int)
-
-                req = self.new_show_request('pools',
-                                            pool_id,
-                                            fmt=self.fmt)
-                pool_update = self.deserialize(
-                    self.fmt,
-                    req.get_response(self.ext_api)
-                )
-                self.assertEqual(0, len(pool_update['pool']['members']))
-
-    def test_show_member(self):
-        with self.pool() as pool:
-            keys = [('address', "192.168.1.100"),
-                    ('tenant_id', self._tenant_id),
-                    ('protocol_port', 80),
-                    ('weight', 1),
-                    ('pool_id', pool['pool']['id']),
-                    ('admin_state_up', True),
-                    ('status', 'PENDING_CREATE')]
-            with self.member(pool_id=pool['pool']['id']) as member:
-                req = self.new_show_request('members',
-                                            member['member']['id'],
-                                            fmt=self.fmt)
-                res = self.deserialize(
-                    self.fmt,
-                    req.get_response(self.ext_api)
-                )
-                for k, v in keys:
-                    self.assertEqual(v, res['member'][k])
-
-    def test_list_members_with_sort_emulated(self):
-        with self.pool() as pool:
-            with contextlib.nested(self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=81),
-                                   self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=82),
-                                   self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=83)
-                                   ) as (m1, m2, m3):
-                self._test_list_with_sort('member', (m3, m2, m1),
-                                          [('protocol_port', 'desc')])
-
-    def test_list_members_with_pagination_emulated(self):
-        with self.pool() as pool:
-            with contextlib.nested(self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=81),
-                                   self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=82),
-                                   self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=83)
-                                   ) as (m1, m2, m3):
-                self._test_list_with_pagination(
-                    'member', (m1, m2, m3), ('protocol_port', 'asc'), 2, 2
-                )
-
-    def test_list_members_with_pagination_reverse_emulated(self):
-        with self.pool() as pool:
-            with contextlib.nested(self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=81),
-                                   self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=82),
-                                   self.member(pool_id=pool['pool']['id'],
-                                               protocol_port=83)
-                                   ) as (m1, m2, m3):
-                self._test_list_with_pagination_reverse(
-                    'member', (m1, m2, m3), ('protocol_port', 'asc'), 2, 2
-                )
-
-    def test_create_healthmonitor(self):
-        keys = [('type', "TCP"),
-                ('tenant_id', self._tenant_id),
-                ('delay', 30),
-                ('timeout', 10),
-                ('max_retries', 3),
-                ('admin_state_up', True)]
-        with self.health_monitor() as monitor:
-            for k, v in keys:
-                self.assertEqual(v, monitor['health_monitor'][k])
-
-    def test_create_health_monitor_with_timeout_delay_invalid(self):
-        data = {'health_monitor': {'type': type,
-                                   'delay': 3,
-                                   'timeout': 6,
-                                   'max_retries': 2,
-                                   'admin_state_up': True,
-                                   'tenant_id': self._tenant_id}}
-        req = self.new_create_request('health_monitors', data, self.fmt)
-        res = req.get_response(self.ext_api)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, res.status_int)
-
-    def test_update_health_monitor_with_timeout_delay_invalid(self):
-        with self.health_monitor() as monitor:
-            data = {'health_monitor': {'delay': 10,
-                                       'timeout': 20,
-                                       'max_retries': 2,
-                                       'admin_state_up': False}}
-            req = self.new_update_request("health_monitors",
-                                          data,
-                                          monitor['health_monitor']['id'])
-            res = req.get_response(self.ext_api)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, res.status_int)
-
-    def test_update_healthmonitor(self):
-        keys = [('type', "TCP"),
-                ('tenant_id', self._tenant_id),
-                ('delay', 20),
-                ('timeout', 20),
-                ('max_retries', 2),
-                ('admin_state_up', False)]
-        with self.health_monitor() as monitor:
-            data = {'health_monitor': {'delay': 20,
-                                       'timeout': 20,
-                                       'max_retries': 2,
-                                       'admin_state_up': False}}
-            req = self.new_update_request("health_monitors",
-                                          data,
-                                          monitor['health_monitor']['id'])
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            for k, v in keys:
-                self.assertEqual(v, res['health_monitor'][k])
-
-    def test_delete_healthmonitor(self):
-        with self.health_monitor(do_delete=False) as monitor:
-            ctx = context.get_admin_context()
-            qry = ctx.session.query(ldb.HealthMonitor)
-            qry = qry.filter_by(id=monitor['health_monitor']['id'])
-            self.assertIsNotNone(qry.first())
-
-            req = self.new_delete_request('health_monitors',
-                                          monitor['health_monitor']['id'])
-            res = req.get_response(self.ext_api)
-            self.assertEqual(webob.exc.HTTPNoContent.code, res.status_int)
-            qry = ctx.session.query(ldb.HealthMonitor)
-            qry = qry.filter_by(id=monitor['health_monitor']['id'])
-            self.assertIsNone(qry.first())
-
-    def test_delete_healthmonitor_with_associations_raises(self):
-        with self.health_monitor(type='HTTP') as monitor:
-            with self.pool() as pool:
-                data = {
-                    'health_monitor': {
-                        'id': monitor['health_monitor']['id'],
-                        'tenant_id': self._tenant_id
-                    }
-                }
-                req = self.new_create_request(
-                    'pools',
-                    data,
-                    fmt=self.fmt,
-                    id=pool['pool']['id'],
-                    subresource='health_monitors')
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPCreated.code, res.status_int)
-
-                ctx = context.get_admin_context()
-
-                # check if we actually have corresponding Pool associations
-                qry = ctx.session.query(ldb.PoolMonitorAssociation)
-                qry = qry.filter_by(monitor_id=monitor['health_monitor']['id'])
-                self.assertTrue(qry.all())
-                # try to delete the HealthMonitor instance
-                req = self.new_delete_request(
-                    'health_monitors',
-                    monitor['health_monitor']['id']
-                )
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPConflict.code, res.status_int)
-
-                qry = ctx.session.query(ldb.HealthMonitor)
-                qry = qry.filter_by(id=monitor['health_monitor']['id'])
-                self.assertIsNotNone(qry.first())
-                # check if all corresponding Pool associations are not deleted
-                qry = ctx.session.query(ldb.PoolMonitorAssociation)
-                qry = qry.filter_by(monitor_id=monitor['health_monitor']['id'])
-                self.assertTrue(qry.all())
-
-    def test_show_healthmonitor(self):
-        with self.health_monitor() as monitor:
-            keys = [('type', "TCP"),
-                    ('tenant_id', self._tenant_id),
-                    ('delay', 30),
-                    ('timeout', 10),
-                    ('max_retries', 3),
-                    ('admin_state_up', True)]
-            req = self.new_show_request('health_monitors',
-                                        monitor['health_monitor']['id'],
-                                        fmt=self.fmt)
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            for k, v in keys:
-                self.assertEqual(v, res['health_monitor'][k])
-
-    def test_list_healthmonitors_with_sort_emulated(self):
-        with contextlib.nested(self.health_monitor(delay=30),
-                               self.health_monitor(delay=31),
-                               self.health_monitor(delay=32)
-                               ) as (m1, m2, m3):
-            self._test_list_with_sort('health_monitor', (m3, m2, m1),
-                                      [('delay', 'desc')])
-
-    def test_list_healthmonitors_with_pagination_emulated(self):
-        with contextlib.nested(self.health_monitor(delay=30),
-                               self.health_monitor(delay=31),
-                               self.health_monitor(delay=32)
-                               ) as (m1, m2, m3):
-            self._test_list_with_pagination('health_monitor',
-                                            (m1, m2, m3),
-                                            ('delay', 'asc'), 2, 2)
-
-    def test_list_healthmonitors_with_pagination_reverse_emulated(self):
-        with contextlib.nested(self.health_monitor(delay=30),
-                               self.health_monitor(delay=31),
-                               self.health_monitor(delay=32)
-                               ) as (m1, m2, m3):
-            self._test_list_with_pagination_reverse('health_monitor',
-                                                    (m1, m2, m3),
-                                                    ('delay', 'asc'), 2, 2)
-
-    def test_update_pool_invalid_lb_method(self):
-        with self.pool() as pool:
-            update_data = {'pool': {'lb_method': 'dummy'}}
-            req = self.new_update_request('pools', update_data,
-                                          pool['pool']['id'], fmt=self.fmt)
-            res = req.get_response(self.ext_api)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, res.status_int)
-
-    def test_update_pool_stats_with_no_stats(self):
-        keys = ["bytes_in", "bytes_out",
-                "active_connections",
-                "total_connections"]
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            self.plugin.update_pool_stats(ctx, pool_id)
-            pool_obj = ctx.session.query(ldb.Pool).filter_by(id=pool_id).one()
-            for key in keys:
-                self.assertEqual(0, pool_obj.stats.__dict__[key])
-
-    def test_update_pool_stats_with_negative_values(self):
-        stats_data = {"bytes_in": -1,
-                      "bytes_out": -2,
-                      "active_connections": -3,
-                      "total_connections": -4}
-        for k, v in stats_data.items():
-            self._test_update_pool_stats_with_negative_value(k, v)
-
-    def _test_update_pool_stats_with_negative_value(self, k, v):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            self.assertRaises(ValueError, self.plugin.update_pool_stats,
-                              ctx, pool_id, {k: v})
-
-    def test_update_pool_stats(self):
-        stats_data = {"bytes_in": 1,
-                      "bytes_out": 2,
-                      "active_connections": 3,
-                      "total_connections": 4}
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            self.plugin.update_pool_stats(ctx, pool_id, stats_data)
-            pool_obj = ctx.session.query(ldb.Pool).filter_by(id=pool_id).one()
-            for k, v in stats_data.items():
-                self.assertEqual(v, pool_obj.stats.__dict__[k])
-
-    def test_update_pool_stats_members_statuses(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            with self.member(pool_id=pool_id) as member:
-                member_id = member['member']['id']
-                stats_data = {'members': {
-                    member_id: {
-                        'status': 'INACTIVE'
-                    }
-                }}
-                ctx = context.get_admin_context()
-                member = self.plugin.get_member(ctx, member_id)
-                self.assertEqual('PENDING_CREATE', member['status'])
-                self.plugin.update_pool_stats(ctx, pool_id, stats_data)
-                member = self.plugin.get_member(ctx, member_id)
-                self.assertEqual('INACTIVE', member['status'])
-
-    def test_get_pool_stats(self):
-        keys = [("bytes_in", 0),
-                ("bytes_out", 0),
-                ("active_connections", 0),
-                ("total_connections", 0)]
-        with self.pool() as pool:
-            req = self.new_show_request("pools",
-                                        pool['pool']['id'],
-                                        subresource="stats",
-                                        fmt=self.fmt)
-            res = self.deserialize(self.fmt, req.get_response(self.ext_api))
-            for k, v in keys:
-                self.assertEqual(v, res['stats'][k])
-
-    def test_create_healthmonitor_of_pool(self):
-        with self.health_monitor(type="TCP") as monitor1:
-            with self.health_monitor(type="HTTP") as monitor2:
-                with self.pool() as pool:
-                    data = {"health_monitor": {
-                            "id": monitor1['health_monitor']['id'],
-                            'tenant_id': self._tenant_id}}
-                    req = self.new_create_request(
-                        "pools",
-                        data,
-                        fmt=self.fmt,
-                        id=pool['pool']['id'],
-                        subresource="health_monitors")
-                    res = req.get_response(self.ext_api)
-                    self.assertEqual(webob.exc.HTTPCreated.code,
-                                     res.status_int)
-
-                    data = {"health_monitor": {
-                            "id": monitor2['health_monitor']['id'],
-                            'tenant_id': self._tenant_id}}
-                    req = self.new_create_request(
-                        "pools",
-                        data,
-                        fmt=self.fmt,
-                        id=pool['pool']['id'],
-                        subresource="health_monitors")
-                    res = req.get_response(self.ext_api)
-                    self.assertEqual(webob.exc.HTTPCreated.code,
-                                     res.status_int)
-
-                    req = self.new_show_request(
-                        'pools',
-                        pool['pool']['id'],
-                        fmt=self.fmt)
-                    res = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertIn(monitor1['health_monitor']['id'],
-                                  res['pool']['health_monitors'])
-                    self.assertIn(monitor2['health_monitor']['id'],
-                                  res['pool']['health_monitors'])
-                    expected = [
-                        {'monitor_id': monitor1['health_monitor']['id'],
-                         'status': 'PENDING_CREATE',
-                         'status_description': None},
-                        {'monitor_id': monitor2['health_monitor']['id'],
-                         'status': 'PENDING_CREATE',
-                         'status_description': None}]
-                    self.assertEqual(
-                        sorted(expected),
-                        sorted(res['pool']['health_monitors_status']))
-
-    def test_delete_healthmonitor_of_pool(self):
-        with self.health_monitor(type="TCP") as monitor1:
-            with self.health_monitor(type="HTTP") as monitor2:
-                with self.pool() as pool:
-                    # add the monitors to the pool
-                    data = {"health_monitor": {
-                            "id": monitor1['health_monitor']['id'],
-                            'tenant_id': self._tenant_id}}
-                    req = self.new_create_request(
-                        "pools",
-                        data,
-                        fmt=self.fmt,
-                        id=pool['pool']['id'],
-                        subresource="health_monitors")
-                    res = req.get_response(self.ext_api)
-                    self.assertEqual(webob.exc.HTTPCreated.code,
-                                     res.status_int)
-
-                    data = {"health_monitor": {
-                            "id": monitor2['health_monitor']['id'],
-                            'tenant_id': self._tenant_id}}
-                    req = self.new_create_request(
-                        "pools",
-                        data,
-                        fmt=self.fmt,
-                        id=pool['pool']['id'],
-                        subresource="health_monitors")
-                    res = req.get_response(self.ext_api)
-                    self.assertEqual(webob.exc.HTTPCreated.code,
-                                     res.status_int)
-
-                    # remove one of healthmonitor from the pool
-                    req = self.new_delete_request(
-                        "pools",
-                        fmt=self.fmt,
-                        id=pool['pool']['id'],
-                        sub_id=monitor1['health_monitor']['id'],
-                        subresource="health_monitors")
-                    res = req.get_response(self.ext_api)
-                    self.assertEqual(webob.exc.HTTPNoContent.code,
-                                     res.status_int)
-
-                    req = self.new_show_request(
-                        'pools',
-                        pool['pool']['id'],
-                        fmt=self.fmt)
-                    res = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertNotIn(monitor1['health_monitor']['id'],
-                                     res['pool']['health_monitors'])
-                    self.assertIn(monitor2['health_monitor']['id'],
-                                  res['pool']['health_monitors'])
-                    expected = [
-                        {'monitor_id': monitor2['health_monitor']['id'],
-                         'status': 'PENDING_CREATE',
-                         'status_description': None}
-                    ]
-                    self.assertEqual(expected,
-                                     res['pool']['health_monitors_status'])
-
-    def test_create_loadbalancer(self):
-        vip_name = "vip3"
-        pool_name = "pool3"
-
-        with self.pool(name=pool_name) as pool:
-            with self.vip(name=vip_name, pool=pool) as vip:
-                pool_id = pool['pool']['id']
-                vip_id = vip['vip']['id']
-                # Add two members
-                res1 = self._create_member(self.fmt,
-                                           '192.168.1.100',
-                                           '80',
-                                           True,
-                                           pool_id=pool_id,
-                                           weight=1)
-                res2 = self._create_member(self.fmt,
-                                           '192.168.1.101',
-                                           '80',
-                                           True,
-                                           pool_id=pool_id,
-                                           weight=2)
-                # Add a health_monitor
-                req = self._create_health_monitor(self.fmt,
-                                                  'HTTP',
-                                                  '10',
-                                                  '10',
-                                                  '3',
-                                                  True)
-                health_monitor = self.deserialize(self.fmt, req)
-                self.assertEqual(webob.exc.HTTPCreated.code, req.status_int)
-
-                # Associate the health_monitor to the pool
-                data = {"health_monitor": {
-                        "id": health_monitor['health_monitor']['id'],
-                        'tenant_id': self._tenant_id}}
-                req = self.new_create_request("pools",
-                                              data,
-                                              fmt=self.fmt,
-                                              id=pool['pool']['id'],
-                                              subresource="health_monitors")
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPCreated.code, res.status_int)
-
-                # Get pool and vip
-                req = self.new_show_request('pools',
-                                            pool_id,
-                                            fmt=self.fmt)
-                pool_updated = self.deserialize(
-                    self.fmt,
-                    req.get_response(self.ext_api)
-                )
-                member1 = self.deserialize(self.fmt, res1)
-                member2 = self.deserialize(self.fmt, res2)
-                self.assertIn(member1['member']['id'],
-                              pool_updated['pool']['members'])
-                self.assertIn(member2['member']['id'],
-                              pool_updated['pool']['members'])
-                self.assertIn(health_monitor['health_monitor']['id'],
-                              pool_updated['pool']['health_monitors'])
-                expected = [
-                    {'monitor_id': health_monitor['health_monitor']['id'],
-                     'status': 'PENDING_CREATE',
-                     'status_description': None}
-                ]
-                self.assertEqual(
-                    expected, pool_updated['pool']['health_monitors_status'])
-
-                req = self.new_show_request('vips',
-                                            vip_id,
-                                            fmt=self.fmt)
-                vip_updated = self.deserialize(
-                    self.fmt,
-                    req.get_response(self.ext_api)
-                )
-                self.assertEqual(pool_updated['pool']['id'],
-                                 vip_updated['vip']['pool_id'])
-
-                # clean up
-                # disassociate the health_monitor from the pool first
-                req = self.new_delete_request(
-                    "pools",
-                    fmt=self.fmt,
-                    id=pool['pool']['id'],
-                    subresource="health_monitors",
-                    sub_id=health_monitor['health_monitor']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(webob.exc.HTTPNoContent.code, res.status_int)
-                self._delete('health_monitors',
-                             health_monitor['health_monitor']['id'])
-                self._delete('members', member1['member']['id'])
-                self._delete('members', member2['member']['id'])
-
-    def test_create_pool_health_monitor(self):
-        with contextlib.nested(
-            self.health_monitor(),
-            self.health_monitor(),
-            self.pool(name="pool")
-        ) as (health_mon1, health_mon2, pool):
-                res = self.plugin.create_pool_health_monitor(
-                    context.get_admin_context(),
-                    health_mon1, pool['pool']['id']
-                )
-                self.assertEqual({'health_monitor':
-                                  [health_mon1['health_monitor']['id']]},
-                                 res)
-
-                res = self.plugin.create_pool_health_monitor(
-                    context.get_admin_context(),
-                    health_mon2, pool['pool']['id']
-                )
-                self.assertEqual({'health_monitor':
-                                  [health_mon1['health_monitor']['id'],
-                                   health_mon2['health_monitor']['id']]},
-                                 res)
-
-                res = self.plugin.get_pool_health_monitor(
-                    context.get_admin_context(),
-                    health_mon2['health_monitor']['id'], pool['pool']['id'])
-                self.assertEqual(health_mon1['health_monitor']['tenant_id'],
-                                 res['tenant_id'])
-
-    def test_driver_call_create_pool_health_monitor(self):
-        with mock.patch.object(self.plugin.drivers['lbaas'],
-                               'create_pool_health_monitor') as driver_call:
-            with contextlib.nested(
-                self.health_monitor(),
-                self.pool()
-            ) as (hm, pool):
-                data = {'health_monitor': {
-                        'id': hm['health_monitor']['id'],
-                        'tenant_id': self._tenant_id}}
-                self.plugin.create_pool_health_monitor(
-                    context.get_admin_context(),
-                    data, pool['pool']['id']
-                )
-                hm['health_monitor']['pools'] = [
-                    {'pool_id': pool['pool']['id'],
-                     'status': 'PENDING_CREATE',
-                     'status_description': None}]
-                driver_call.assert_called_once_with(
-                    mock.ANY, hm['health_monitor'], pool['pool']['id'])
-
-    def test_pool_monitor_list_of_pools(self):
-        with contextlib.nested(
-            self.health_monitor(),
-            self.pool(),
-            self.pool()
-        ) as (hm, p1, p2):
-            ctx = context.get_admin_context()
-            data = {'health_monitor': {
-                    'id': hm['health_monitor']['id'],
-                    'tenant_id': self._tenant_id}}
-            self.plugin.create_pool_health_monitor(
-                ctx, data, p1['pool']['id'])
-            self.plugin.create_pool_health_monitor(
-                ctx, data, p2['pool']['id'])
-            healthmon = self.plugin.get_health_monitor(
-                ctx, hm['health_monitor']['id'])
-            pool_data = [{'pool_id': p1['pool']['id'],
-                          'status': 'PENDING_CREATE',
-                          'status_description': None},
-                         {'pool_id': p2['pool']['id'],
-                          'status': 'PENDING_CREATE',
-                          'status_description': None}]
-            self.assertEqual(sorted(pool_data),
-                             sorted(healthmon['pools']))
-            req = self.new_show_request(
-                'health_monitors',
-                hm['health_monitor']['id'],
-                fmt=self.fmt)
-            hm = self.deserialize(
-                self.fmt,
-                req.get_response(self.ext_api)
-            )
-            self.assertEqual(sorted(pool_data),
-                             sorted(hm['health_monitor']['pools']))
-
-    def test_create_pool_health_monitor_already_associated(self):
-        with contextlib.nested(
-            self.health_monitor(),
-            self.pool(name="pool")
-        ) as (hm, pool):
-            res = self.plugin.create_pool_health_monitor(
-                context.get_admin_context(),
-                hm, pool['pool']['id']
-            )
-            self.assertEqual({'health_monitor':
-                              [hm['health_monitor']['id']]},
-                             res)
-            self.assertRaises(loadbalancer.PoolMonitorAssociationExists,
-                              self.plugin.create_pool_health_monitor,
-                              context.get_admin_context(),
-                              hm,
-                              pool['pool']['id'])
-
-    def test_create_pool_healthmon_invalid_pool_id(self):
-        with self.health_monitor() as healthmon:
-            self.assertRaises(loadbalancer.PoolNotFound,
-                              self.plugin.create_pool_health_monitor,
-                              context.get_admin_context(),
-                              healthmon,
-                              "123-456-789"
-                              )
-
-    def test_create_pool_healthmon_invalid_health_monitor_id(self):
-        with self.pool() as pool:
-            healthmon = {'health_monitor': {'id': '123-456-789'}}
-            self.assertRaises(loadbalancer.HealthMonitorNotFound,
-                              self.plugin.create_pool_health_monitor,
-                              context.get_admin_context(),
-                              healthmon,
-                              pool['pool']['id']
-                              )
-
-    def test_update_status(self):
-        with self.pool() as pool:
-            self.assertEqual('PENDING_CREATE', pool['pool']['status'])
-            self.assertFalse(pool['pool']['status_description'])
-
-            self.plugin.update_status(context.get_admin_context(), ldb.Pool,
-                                      pool['pool']['id'], 'ERROR', 'unknown')
-            updated_pool = self.plugin.get_pool(context.get_admin_context(),
-                                                pool['pool']['id'])
-            self.assertEqual('ERROR', updated_pool['status'])
-            self.assertEqual('unknown', updated_pool['status_description'])
-
-            # update status to ACTIVE, status_description should be cleared
-            self.plugin.update_status(context.get_admin_context(), ldb.Pool,
-                                      pool['pool']['id'], 'ACTIVE')
-            updated_pool = self.plugin.get_pool(context.get_admin_context(),
-                                                pool['pool']['id'])
-            self.assertEqual('ACTIVE', updated_pool['status'])
-            self.assertFalse(updated_pool['status_description'])
-
-    def test_update_pool_health_monitor(self):
-        with contextlib.nested(
-            self.health_monitor(),
-            self.pool(name="pool")
-        ) as (hm, pool):
-            res = self.plugin.create_pool_health_monitor(
-                context.get_admin_context(),
-                hm, pool['pool']['id'])
-            self.assertEqual({'health_monitor':
-                              [hm['health_monitor']['id']]},
-                             res)
-
-            assoc = self.plugin.get_pool_health_monitor(
-                context.get_admin_context(),
-                hm['health_monitor']['id'],
-                pool['pool']['id'])
-            self.assertEqual('PENDING_CREATE', assoc['status'])
-            self.assertIsNone(assoc['status_description'])
-
-            self.plugin.update_pool_health_monitor(
-                context.get_admin_context(),
-                hm['health_monitor']['id'],
-                pool['pool']['id'],
-                'ACTIVE', 'ok')
-            assoc = self.plugin.get_pool_health_monitor(
-                context.get_admin_context(),
-                hm['health_monitor']['id'],
-                pool['pool']['id'])
-            self.assertEqual('ACTIVE', assoc['status'])
-            self.assertEqual('ok', assoc['status_description'])
-
-    def test_check_orphan_pool_associations(self):
-        with contextlib.nested(
-            #creating pools with default noop driver
-            self.pool(),
-            self.pool()
-        ) as (p1, p2):
-            #checking that 3 associations exist
-            ctx = context.get_admin_context()
-            qry = ctx.session.query(sdb.ProviderResourceAssociation)
-            self.assertEqual(2, qry.count())
-            #removing driver
-            self.set_override([
-                constants.LOADBALANCER +
-                ':lbaas1:' + NOOP_DRIVER_KLASS +
-                ':default'
-            ])
-            # calling _remove_orphan... in constructor
-            self.assertRaises(
-                SystemExit,
-                loadbalancer_plugin.LoadBalancerPlugin
-            )
-
-    def test_port_delete_via_port_api(self):
-        port = {
-            'id': 'my_port_id',
-            'device_owner': n_constants.DEVICE_OWNER_LOADBALANCER
-        }
-        ctx = context.get_admin_context()
-        port['device_owner'] = n_constants.DEVICE_OWNER_LOADBALANCER
-        myvips = [{'name': 'vip1'}]
-        with mock.patch.object(manager.NeutronManager, 'get_plugin') as gp:
-            self.plugin.get_vips = mock.Mock(return_value=myvips)
-            plugin = mock.Mock()
-            gp.return_value = plugin
-            plugin._get_port.return_value = port
-            self.assertRaises(n_exc.ServicePortInUse,
-                              self.plugin.prevent_lbaas_port_deletion,
-                              ctx,
-                              port['id'])
diff --git a/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py b/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py
deleted file mode 100644
index e7cb942..0000000
--- a/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py
+++ /dev/null
@@ -1,3831 +0,0 @@
-# Copyright (c) 2014 OpenStack Foundation.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-# implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-import contextlib
-import copy
-import exceptions as ex
-import mock
-import six
-
-from neutron.api import extensions
-from neutron.api.v2 import attributes
-from neutron.common import config
-from neutron import context
-import neutron.db.l3_db  # noqa
-from neutron.plugins.common import constants
-from neutron.tests.unit.db import test_db_base_plugin_v2
-from neutron_lib import constants as n_constants
-from neutron_lib import exceptions as n_exc
-from oslo_config import cfg
-from oslo_utils import uuidutils
-import testtools
-import webob.exc
-
-from neutron import manager
-from neutron_lbaas._i18n import _
-from neutron_lbaas.common.cert_manager import cert_manager
-from neutron_lbaas.common import exceptions
-from neutron_lbaas.db.loadbalancer import loadbalancer_dbv2
-from neutron_lbaas.db.loadbalancer import models
-from neutron_lbaas.drivers.logging_noop import driver as noop_driver
-import neutron_lbaas.extensions
-from neutron_lbaas.extensions import l7
-from neutron_lbaas.extensions import loadbalancerv2
-from neutron_lbaas.extensions import sharedpools
-from neutron_lbaas.services.loadbalancer import constants as lb_const
-from neutron_lbaas.services.loadbalancer import plugin as loadbalancer_plugin
-from neutron_lbaas.tests import base
-
-
-DB_CORE_PLUGIN_CLASS = 'neutron.db.db_base_plugin_v2.NeutronDbPluginV2'
-DB_LB_PLUGIN_CLASS = (
-    "neutron_lbaas.services.loadbalancer."
-    "plugin.LoadBalancerPluginv2"
-)
-NOOP_DRIVER_CLASS = ('neutron_lbaas.drivers.logging_noop.driver.'
-                     'LoggingNoopLoadBalancerDriver')
-
-extensions_path = ':'.join(neutron_lbaas.extensions.__path__)
-
-_subnet_id = "0c798ed8-33ba-11e2-8b28-000c291c4d14"
-
-
-class LbaasTestMixin(object):
-    resource_keys = loadbalancerv2.RESOURCE_ATTRIBUTE_MAP.keys()
-    resource_keys.extend(l7.RESOURCE_ATTRIBUTE_MAP.keys())
-    resource_prefix_map = dict(
-        (k, loadbalancerv2.LOADBALANCERV2_PREFIX)
-        for k in resource_keys)
-
-    def _get_loadbalancer_optional_args(self):
-        return 'description', 'vip_address', 'admin_state_up', 'name'
-
-    def _create_loadbalancer(self, fmt, subnet_id,
-                             expected_res_status=None, **kwargs):
-        data = {'loadbalancer': {'vip_subnet_id': subnet_id,
-                                 'tenant_id': self._tenant_id}}
-        args = self._get_loadbalancer_optional_args()
-        for arg in args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data['loadbalancer'][arg] = kwargs[arg]
-
-        lb_req = self.new_create_request('loadbalancers', data, fmt)
-        lb_res = lb_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, lb_res.status_int)
-
-        return lb_res
-
-    def _get_listener_optional_args(self):
-        return ('name', 'description', 'default_pool_id', 'loadbalancer_id',
-                'connection_limit', 'admin_state_up',
-                'default_tls_container_ref', 'sni_container_refs')
-
-    def _create_listener(self, fmt, protocol, protocol_port,
-                         loadbalancer_id=None, default_pool_id=None,
-                         expected_res_status=None, **kwargs):
-        data = {'listener': {'protocol': protocol,
-                             'protocol_port': protocol_port,
-                             'tenant_id': self._tenant_id}}
-        if loadbalancer_id:
-            data['listener']['loadbalancer_id'] = loadbalancer_id
-        if default_pool_id:
-            data['listener']['default_pool_id'] = default_pool_id
-
-        args = self._get_listener_optional_args()
-        for arg in args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data['listener'][arg] = kwargs[arg]
-
-        listener_req = self.new_create_request('listeners', data, fmt)
-        listener_res = listener_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, listener_res.status_int)
-
-        return listener_res
-
-    def _get_pool_optional_args(self):
-        return 'name', 'description', 'admin_state_up', 'session_persistence'
-
-    def _create_pool(self, fmt, protocol, lb_algorithm, listener_id=None,
-                     loadbalancer_id=None, expected_res_status=None, **kwargs):
-        data = {'pool': {'protocol': protocol,
-                         'lb_algorithm': lb_algorithm,
-                         'tenant_id': self._tenant_id}}
-        if listener_id:
-            data['pool']['listener_id'] = listener_id
-        if loadbalancer_id:
-            data['pool']['loadbalancer_id'] = loadbalancer_id
-
-        args = self._get_pool_optional_args()
-        for arg in args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data['pool'][arg] = kwargs[arg]
-
-        pool_req = self.new_create_request('pools', data, fmt)
-        pool_res = pool_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, pool_res.status_int)
-
-        return pool_res
-
-    def _get_member_optional_args(self):
-        return 'weight', 'admin_state_up', 'name'
-
-    def _create_member(self, fmt, pool_id, address, protocol_port, subnet_id,
-                       expected_res_status=None, **kwargs):
-        data = {'member': {'address': address,
-                           'protocol_port': protocol_port,
-                           'subnet_id': subnet_id,
-                           'tenant_id': self._tenant_id}}
-
-        args = self._get_member_optional_args()
-        for arg in args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data['member'][arg] = kwargs[arg]
-        member_req = self.new_create_request('pools',
-                                             data,
-                                             fmt=fmt,
-                                             id=pool_id,
-                                             subresource='members')
-        member_res = member_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, member_res.status_int)
-
-        return member_res
-
-    def _get_healthmonitor_optional_args(self):
-        return ('weight', 'admin_state_up', 'expected_codes', 'url_path',
-                'http_method', 'name')
-
-    def _create_healthmonitor(self, fmt, pool_id, type, delay, timeout,
-                              max_retries, expected_res_status=None, **kwargs):
-        data = {'healthmonitor': {'type': type,
-                                  'delay': delay,
-                                  'timeout': timeout,
-                                  'max_retries': max_retries,
-                                  'pool_id': pool_id,
-                                  'tenant_id': self._tenant_id}}
-
-        args = self._get_healthmonitor_optional_args()
-        for arg in args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data['healthmonitor'][arg] = kwargs[arg]
-
-        hm_req = self.new_create_request('healthmonitors', data, fmt=fmt)
-        hm_res = hm_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(expected_res_status, hm_res.status_int)
-
-        return hm_res
-
-    def _add_optional_args(self, optional_args, data, **kwargs):
-        for arg in optional_args:
-            if arg in kwargs and kwargs[arg] is not None:
-                data[arg] = kwargs[arg]
-
-    def _get_l7policy_optional_args(self):
-        return ('name', 'description', 'redirect_pool_id',
-                'redirect_url', 'admin_state_up', 'position')
-
-    def _create_l7policy(self, fmt, listener_id, action,
-                         expected_res_status=None, **kwargs):
-        data = {'l7policy': {'listener_id': listener_id,
-                             'action': action,
-                             'tenant_id': self._tenant_id}}
-
-        optional_args = self._get_l7policy_optional_args()
-        self._add_optional_args(optional_args, data['l7policy'], **kwargs)
-
-        l7policy_req = self.new_create_request('l7policies', data, fmt)
-        l7policy_res = l7policy_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(l7policy_res.status_int, expected_res_status)
-
-        return l7policy_res
-
-    def _get_l7rule_optional_args(self):
-        return ('invert', 'key', 'admin_state_up')
-
-    def _create_l7policy_rule(self, fmt, l7policy_id, type, compare_type,
-                              value, expected_res_status=None, **kwargs):
-        data = {'rule': {'type': type,
-                         'compare_type': compare_type,
-                         'value': value,
-                         'tenant_id': self._tenant_id}}
-
-        optional_args = self._get_l7rule_optional_args()
-        self._add_optional_args(optional_args, data['rule'], **kwargs)
-
-        rule_req = self.new_create_request('l7policies', data, fmt,
-                                           id=l7policy_id,
-                                           subresource='rules')
-        rule_res = rule_req.get_response(self.ext_api)
-        if expected_res_status:
-            self.assertEqual(rule_res.status_int, expected_res_status)
-
-        return rule_res
-
-    @contextlib.contextmanager
-    def loadbalancer(self, fmt=None, subnet=None, no_delete=False, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-
-        with test_db_base_plugin_v2.optional_ctx(
-            subnet, self.subnet) as tmp_subnet:
-
-            res = self._create_loadbalancer(fmt,
-                                            tmp_subnet['subnet']['id'],
-                                            **kwargs)
-            if res.status_int >= webob.exc.HTTPClientError.code:
-                raise webob.exc.HTTPClientError(
-                    explanation=_("Unexpected error code: %s") %
-                    res.status_int
-                )
-            lb = self.deserialize(fmt or self.fmt, res)
-            yield lb
-            if not no_delete:
-                self._delete('loadbalancers', lb['loadbalancer']['id'])
-
-    @contextlib.contextmanager
-    def listener(self, fmt=None, protocol='HTTP', loadbalancer_id=None,
-                 protocol_port=80, default_pool_id=None, no_delete=False,
-                 **kwargs):
-        if not fmt:
-            fmt = self.fmt
-
-        if loadbalancer_id and default_pool_id:
-            res = self._create_listener(fmt, protocol, protocol_port,
-                                        loadbalancer_id=loadbalancer_id,
-                                        default_pool_id=default_pool_id,
-                                        **kwargs)
-        elif loadbalancer_id:
-            res = self._create_listener(fmt, protocol, protocol_port,
-                                        loadbalancer_id=loadbalancer_id,
-                                        **kwargs)
-        else:
-            res = self._create_listener(fmt, protocol, protocol_port,
-                                        default_pool_id=default_pool_id,
-                                        **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-
-        listener = self.deserialize(fmt or self.fmt, res)
-        yield listener
-        if not no_delete:
-            self._delete('listeners', listener['listener']['id'])
-
-    @contextlib.contextmanager
-    def pool(self, fmt=None, protocol='HTTP', lb_algorithm='ROUND_ROBIN',
-             no_delete=False, listener_id=None,
-             loadbalancer_id=None, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-
-        if listener_id and loadbalancer_id:
-            res = self._create_pool(fmt,
-                                    protocol=protocol,
-                                    lb_algorithm=lb_algorithm,
-                                    listener_id=listener_id,
-                                    loadbalancer_id=loadbalancer_id,
-                                    **kwargs)
-        elif listener_id:
-            res = self._create_pool(fmt,
-                                    protocol=protocol,
-                                    lb_algorithm=lb_algorithm,
-                                    listener_id=listener_id,
-                                    **kwargs)
-        else:
-            res = self._create_pool(fmt,
-                                    protocol=protocol,
-                                    lb_algorithm=lb_algorithm,
-                                    loadbalancer_id=loadbalancer_id,
-                                    **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-
-        pool = self.deserialize(fmt or self.fmt, res)
-        yield pool
-        if not no_delete:
-            self._delete('pools', pool['pool']['id'])
-
-    @contextlib.contextmanager
-    def member(self, fmt=None, pool_id='pool1id', address='127.0.0.1',
-               protocol_port=80, subnet=None, no_delete=False,
-               **kwargs):
-        if not fmt:
-            fmt = self.fmt
-        subnet = subnet or self.test_subnet
-        with test_db_base_plugin_v2.optional_ctx(
-            subnet, self.subnet) as tmp_subnet:
-
-            res = self._create_member(fmt,
-                                      pool_id=pool_id,
-                                      address=address,
-                                      protocol_port=protocol_port,
-                                      subnet_id=tmp_subnet['subnet']['id'],
-                                      **kwargs)
-            if res.status_int >= webob.exc.HTTPClientError.code:
-                raise webob.exc.HTTPClientError(
-                    explanation=_("Unexpected error code: %s") % res.status_int
-                )
-
-            member = self.deserialize(fmt or self.fmt, res)
-        yield member
-        if not no_delete:
-            del_req = self.new_delete_request(
-                'pools',
-                fmt=fmt,
-                id=pool_id,
-                subresource='members',
-                sub_id=member['member']['id'])
-            del_res = del_req.get_response(self.ext_api)
-            self.assertEqual(webob.exc.HTTPNoContent.code, del_res.status_int)
-
-    @contextlib.contextmanager
-    def healthmonitor(self, fmt=None, pool_id='pool1id', type='TCP', delay=1,
-                      timeout=1, max_retries=1, no_delete=False, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-
-        res = self._create_healthmonitor(fmt,
-                                         pool_id=pool_id,
-                                         type=type,
-                                         delay=delay,
-                                         timeout=timeout,
-                                         max_retries=max_retries,
-                                         **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-
-        healthmonitor = self.deserialize(fmt or self.fmt, res)
-        yield healthmonitor
-        if not no_delete:
-            del_req = self.new_delete_request(
-                'healthmonitors', fmt=fmt,
-                id=healthmonitor['healthmonitor']['id'])
-            del_res = del_req.get_response(self.ext_api)
-            self.assertEqual(webob.exc.HTTPNoContent.code, del_res.status_int)
-
-    @contextlib.contextmanager
-    def l7policy(self, listener_id, fmt=None,
-                 action=lb_const.L7_POLICY_ACTION_REJECT,
-                 no_delete=False, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-
-        res = self._create_l7policy(fmt,
-                                    listener_id=listener_id,
-                                    action=action,
-                                    **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-
-        l7policy = self.deserialize(fmt or self.fmt, res)
-        yield l7policy
-        if not no_delete:
-            self.plugin.db.update_status(context.get_admin_context(),
-                                         models.L7Policy,
-                                         l7policy['l7policy']['id'],
-                                         constants.ACTIVE)
-            del_req = self.new_delete_request(
-                'l7policies',
-                fmt=fmt,
-                id=l7policy['l7policy']['id'])
-            del_res = del_req.get_response(self.ext_api)
-            self.assertEqual(del_res.status_int,
-                             webob.exc.HTTPNoContent.code)
-
-    @contextlib.contextmanager
-    def l7policy_rule(self, l7policy_id, fmt=None, value='value1',
-                      type=lb_const.L7_RULE_TYPE_HOST_NAME,
-                      compare_type=lb_const.L7_RULE_COMPARE_TYPE_EQUAL_TO,
-                      no_delete=False, **kwargs):
-        if not fmt:
-            fmt = self.fmt
-        res = self._create_l7policy_rule(fmt,
-                                         l7policy_id=l7policy_id,
-                                         type=type,
-                                         compare_type=compare_type,
-                                         value=value,
-                                         **kwargs)
-        if res.status_int >= webob.exc.HTTPClientError.code:
-            raise webob.exc.HTTPClientError(
-                explanation=_("Unexpected error code: %s") % res.status_int
-            )
-
-        rule = self.deserialize(fmt or self.fmt, res)
-        yield rule
-        if not no_delete:
-            self.plugin.db.update_status(context.get_admin_context(),
-                                         models.L7Rule,
-                                         rule['rule']['id'],
-                                         constants.ACTIVE)
-            del_req = self.new_delete_request(
-                'l7policies',
-                fmt=fmt,
-                id=l7policy_id,
-                subresource='rules',
-                sub_id=rule['rule']['id'])
-            del_res = del_req.get_response(self.ext_api)
-            self.assertEqual(del_res.status_int,
-                             webob.exc.HTTPNoContent.code)
-
-
-class ExtendedPluginAwareExtensionManager(object):
-    def __init__(self, extension_aliases):
-        self.extension_aliases = extension_aliases
-
-    def get_resources(self):
-        extensions_list = []
-        if 'shared_pools' in self.extension_aliases:
-            extensions_list.append(sharedpools)
-        if 'l7' in self.extension_aliases:
-            extensions_list.append(l7)
-        for extension in extensions_list:
-            if 'RESOURCE_ATTRIBUTE_MAP' in extension.__dict__:
-                loadbalancerv2.RESOURCE_ATTRIBUTE_MAP.update(
-                    extension.RESOURCE_ATTRIBUTE_MAP)
-            if 'SUB_RESOURCE_ATTRIBUTE_MAP' in extension.__dict__:
-                loadbalancerv2.SUB_RESOURCE_ATTRIBUTE_MAP.update(
-                    extension.SUB_RESOURCE_ATTRIBUTE_MAP)
-            if 'EXTENDED_ATTRIBUTES_2_0' in extension.__dict__:
-                for key in loadbalancerv2.RESOURCE_ATTRIBUTE_MAP.keys():
-                    loadbalancerv2.RESOURCE_ATTRIBUTE_MAP[key].update(
-                        extension.EXTENDED_ATTRIBUTES_2_0.get(key, {}))
-        return loadbalancerv2.Loadbalancerv2.get_resources()
-
-    def get_actions(self):
-        return []
-
-    def get_request_extensions(self):
-        return []
-
-
-class LbaasPluginDbTestCase(LbaasTestMixin, base.NeutronDbPluginV2TestCase):
-    def setUp(self, core_plugin=None, lb_plugin=None, lbaas_provider=None,
-              ext_mgr=None):
-        service_plugins = {'lb_plugin_name': DB_LB_PLUGIN_CLASS}
-        if not lbaas_provider:
-            lbaas_provider = (
-                constants.LOADBALANCERV2 +
-                ':lbaas:' + NOOP_DRIVER_CLASS + ':default')
-        # override the default service provider
-        self.set_override([lbaas_provider])
-
-        # removing service-type because it resides in neutron and tests
-        # dont care
-        LBPlugin = loadbalancer_plugin.LoadBalancerPluginv2
-        sea_index = None
-        for index, sea in enumerate(LBPlugin.supported_extension_aliases):
-            if sea == 'service-type':
-                sea_index = index
-        if sea_index:
-            del LBPlugin.supported_extension_aliases[sea_index]
-
-        super(LbaasPluginDbTestCase, self).setUp(
-            ext_mgr=ext_mgr,
-            service_plugins=service_plugins
-        )
-
-        if not ext_mgr:
-            self.plugin = loadbalancer_plugin.LoadBalancerPluginv2()
-            # This is necessary because the automatic extension manager
-            # finding algorithm below will find the loadbalancerv2
-            # extension and fail to initizlize the main API router with
-            # extensions' resources
-            ext_mgr = ExtendedPluginAwareExtensionManager(
-                LBPlugin.supported_extension_aliases)
-
-            app = config.load_paste_app('extensions_test_app')
-            self.ext_api = extensions.ExtensionMiddleware(app, ext_mgr=ext_mgr)
-
-        get_lbaas_agent_patcher = mock.patch(
-            'neutron_lbaas.agent_scheduler'
-            '.LbaasAgentSchedulerDbMixin.get_agent_hosting_loadbalancer')
-        mock_lbaas_agent = mock.MagicMock()
-        get_lbaas_agent_patcher.start().return_value = mock_lbaas_agent
-        mock_lbaas_agent.__getitem__.return_value = {'host': 'host'}
-
-        self._subnet_id = _subnet_id
-
-    def _update_loadbalancer_api(self, lb_id, data):
-        req = self.new_update_request('loadbalancers', data, lb_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, req.get_response(self.ext_api))
-        return resp, body
-
-    def _delete_loadbalancer_api(self, lb_id):
-        req = self.new_delete_request('loadbalancers', lb_id)
-        resp = req.get_response(self.ext_api)
-        return resp
-
-    def _get_loadbalancer_api(self, lb_id):
-        req = self.new_show_request('loadbalancers', lb_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _list_loadbalancers_api(self):
-        req = self.new_list_request('loadbalancers')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _get_loadbalancer_stats_api(self, lb_id):
-        req = self.new_show_request('loadbalancers', lb_id,
-                                    subresource='stats')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _get_loadbalancer_statuses_api(self, lb_id):
-        req = self.new_show_request('loadbalancers', lb_id,
-                                    subresource='statuses')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _validate_statuses(self, lb_id, listener_id=None,
-                           l7policy_id=None, l7rule_id=None,
-                           pool_id=None, member_id=None, hm_id=None,
-                           member_disabled=False, listener_disabled=False,
-                           l7policy_disabled=False, l7rule_disabled=False,
-                           loadbalancer_disabled=False):
-        resp, body = self._get_loadbalancer_statuses_api(lb_id)
-        lb_statuses = body['statuses']['loadbalancer']
-        self.assertEqual(constants.ACTIVE,
-                         lb_statuses['provisioning_status'])
-        if loadbalancer_disabled:
-            self.assertEqual(lb_const.DISABLED,
-                            lb_statuses['operating_status'])
-        else:
-            self.assertEqual(lb_const.ONLINE,
-                         lb_statuses['operating_status'])
-        if listener_id:
-            listener_statuses = None
-            for listener in lb_statuses['listeners']:
-                if listener['id'] == listener_id:
-                    listener_statuses = listener
-            self.assertIsNotNone(listener_statuses)
-            self.assertEqual(constants.ACTIVE,
-                             listener_statuses['provisioning_status'])
-            if listener_disabled:
-                self.assertEqual(lb_const.DISABLED,
-                                 listener_statuses['operating_status'])
-            else:
-                self.assertEqual(lb_const.ONLINE,
-                                 listener_statuses['operating_status'])
-            if l7policy_id:
-                policy_statuses = None
-                for policy in listener_statuses['l7policies']:
-                    if policy['id'] == l7policy_id:
-                        policy_statuses = policy
-                self.assertIsNotNone(policy_statuses)
-                self.assertEqual(constants.ACTIVE,
-                                 policy_statuses['provisioning_status'])
-                if l7rule_id:
-                    rule_statuses = None
-                    for rule in policy_statuses['rules']:
-                        if rule['id'] == l7rule_id:
-                            rule_statuses = rule
-                    self.assertIsNotNone(rule_statuses)
-                    self.assertEqual(constants.ACTIVE,
-                                     rule_statuses['provisioning_status'])
-
-        if pool_id:
-            pool_statuses = None
-            for pool in lb_statuses['pools']:
-                if pool['id'] == pool_id:
-                    pool_statuses = pool
-            self.assertIsNotNone(pool_statuses)
-            self.assertEqual(constants.ACTIVE,
-                             pool_statuses['provisioning_status'])
-            self.assertEqual(lb_const.ONLINE,
-                             pool_statuses['operating_status'])
-            if member_id:
-                member_statuses = None
-                for member in pool_statuses['members']:
-                    if member['id'] == member_id:
-                        member_statuses = member
-                self.assertIsNotNone(member_statuses)
-                self.assertEqual(constants.ACTIVE,
-                                 member_statuses['provisioning_status'])
-                if member_disabled:
-                    self.assertEqual(lb_const.DISABLED,
-                                     member_statuses["operating_status"])
-                else:
-                    self.assertEqual(lb_const.ONLINE,
-                                     member_statuses['operating_status'])
-            if hm_id:
-                hm_status = pool_statuses['healthmonitor']
-                self.assertEqual(constants.ACTIVE,
-                                 hm_status['provisioning_status'])
-
-    def test_assert_modification_allowed(self):
-        mock_lb = mock.MagicMock()
-        mock_lb.provisioning_status = constants.PENDING_UPDATE
-        mock_lb.id = uuidutils.generate_uuid()
-        LBPluginDBv2 = loadbalancer_dbv2.LoadBalancerPluginDbv2()
-
-        self.assertRaises(
-            loadbalancerv2.StateInvalid,
-            LBPluginDBv2.assert_modification_allowed, mock_lb)
-        # Check that this is a sub-exception of conflict to return 409
-        self.assertRaises(
-            n_exc.Conflict,
-            LBPluginDBv2.assert_modification_allowed, mock_lb)
-
-
-class LbaasLoadBalancerTests(LbaasPluginDbTestCase):
-
-    def test_create_loadbalancer(self, **extras):
-        expected = {
-            'name': 'vip1',
-            'description': '',
-            'admin_state_up': True,
-            'provisioning_status': constants.ACTIVE,
-            'operating_status': lb_const.ONLINE,
-            'tenant_id': self._tenant_id,
-            'listeners': [],
-            'pools': [],
-            'provider': 'lbaas'
-        }
-
-        expected.update(extras)
-
-        with self.subnet() as subnet:
-            expected['vip_subnet_id'] = subnet['subnet']['id']
-            name = expected['name']
-
-            with self.loadbalancer(name=name, subnet=subnet, **extras) as lb:
-                lb_id = lb['loadbalancer']['id']
-                for k in ('id', 'vip_address', 'vip_subnet_id'):
-                    self.assertTrue(lb['loadbalancer'].get(k, None))
-
-                expected['vip_port_id'] = lb['loadbalancer']['vip_port_id']
-                actual = dict((k, v)
-                              for k, v in lb['loadbalancer'].items()
-                              if k in expected)
-                self.assertEqual(expected, actual)
-                self._validate_statuses(lb_id)
-            return lb
-
-    def test_create_loadbalancer_with_vip_address(self):
-        self.test_create_loadbalancer(vip_address='10.0.0.7')
-
-    def test_create_loadbalancer_with_vip_address_outside_subnet(self):
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_loadbalancer(vip_address='9.9.9.9')
-
-    def test_update_loadbalancer(self):
-        name = 'new_loadbalancer'
-        description = 'a crazy loadbalancer'
-        expected_values = {'name': name,
-                           'description': description,
-                           'admin_state_up': False,
-                           'provisioning_status': constants.ACTIVE,
-                           'operating_status': lb_const.ONLINE,
-                           'listeners': [],
-                           'provider': 'lbaas'}
-        with self.subnet() as subnet:
-            expected_values['vip_subnet_id'] = subnet['subnet']['id']
-            with self.loadbalancer(subnet=subnet) as loadbalancer:
-                expected_values['vip_port_id'] = (
-                    loadbalancer['loadbalancer']['vip_port_id'])
-                loadbalancer_id = loadbalancer['loadbalancer']['id']
-                data = {'loadbalancer': {'name': name,
-                                         'description': description,
-                                         'admin_state_up': False}}
-                resp, res = self._update_loadbalancer_api(loadbalancer_id,
-                                                          data)
-                for k in expected_values:
-                    self.assertEqual(expected_values[k],
-                                     res['loadbalancer'][k])
-                self._validate_statuses(loadbalancer_id,
-                                        loadbalancer_disabled=True)
-
-    def test_delete_loadbalancer(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet,
-                                   no_delete=True) as loadbalancer:
-                loadbalancer_id = loadbalancer['loadbalancer']['id']
-                resp = self._delete_loadbalancer_api(loadbalancer_id)
-                self.assertEqual(webob.exc.HTTPNoContent.code, resp.status_int)
-
-    def test_delete_loadbalancer_when_loadbalancer_in_use(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet) as loadbalancer:
-                lb_id = loadbalancer['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id):
-                    ctx = context.get_admin_context()
-                    self.assertRaises(loadbalancerv2.EntityInUse,
-                                      self.plugin.delete_loadbalancer,
-                                      ctx, lb_id)
-                    self._validate_statuses(lb_id)
-
-    def test_show_loadbalancer(self):
-        name = 'lb_show'
-        description = 'lb_show description'
-        vip_address = '10.0.0.10'
-        expected_values = {'name': name,
-                           'description': description,
-                           'vip_address': '10.0.0.10',
-                           'admin_state_up': True,
-                           'provisioning_status': constants.ACTIVE,
-                           'operating_status': lb_const.ONLINE,
-                           'listeners': [],
-                           'provider': 'lbaas'}
-        with self.subnet() as subnet:
-            vip_subnet_id = subnet['subnet']['id']
-            expected_values['vip_subnet_id'] = vip_subnet_id
-            with self.loadbalancer(subnet=subnet, name=name,
-                                   description=description,
-                                   vip_address=vip_address) as lb:
-                lb_id = lb['loadbalancer']['id']
-                expected_values['id'] = lb_id
-                expected_values['vip_port_id'] = (
-                    lb['loadbalancer']['vip_port_id'])
-                resp, body = self._get_loadbalancer_api(lb_id)
-                for k in expected_values:
-                    self.assertEqual(expected_values[k],
-                                     body['loadbalancer'][k])
-
-    def test_list_loadbalancers(self):
-        name = 'lb_show'
-        description = 'lb_show description'
-        vip_address = '10.0.0.10'
-        expected_values = {'name': name,
-                           'description': description,
-                           'vip_address': '10.0.0.10',
-                           'admin_state_up': True,
-                           'provisioning_status': constants.ACTIVE,
-                           'operating_status': lb_const.ONLINE,
-                           'listeners': [],
-                           'provider': 'lbaas'}
-        with self.subnet() as subnet:
-            vip_subnet_id = subnet['subnet']['id']
-            expected_values['vip_subnet_id'] = vip_subnet_id
-            with self.loadbalancer(subnet=subnet, name=name,
-                                   description=description,
-                                   vip_address=vip_address) as lb:
-                lb_id = lb['loadbalancer']['id']
-                expected_values['id'] = lb_id
-                expected_values['vip_port_id'] = (
-                    lb['loadbalancer']['vip_port_id'])
-                resp, body = self._list_loadbalancers_api()
-                self.assertEqual(1, len(body['loadbalancers']))
-                for k in expected_values:
-                    self.assertEqual(expected_values[k],
-                                     body['loadbalancers'][0][k])
-
-    def test_list_loadbalancers_with_sort_emulated(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet, name='lb1') as lb1:
-                with self.loadbalancer(subnet=subnet, name='lb2') as lb2:
-                    with self.loadbalancer(subnet=subnet, name='lb3') as lb3:
-                        self._test_list_with_sort(
-                            'loadbalancer',
-                            (lb1, lb2, lb3),
-                            [('name', 'asc')]
-                        )
-
-    def test_list_loadbalancers_with_pagination_emulated(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet, name='lb1') as lb1:
-                with self.loadbalancer(subnet=subnet, name='lb2') as lb2:
-                    with self.loadbalancer(subnet=subnet, name='lb3') as lb3:
-                        self._test_list_with_pagination(
-                            'loadbalancer',
-                            (lb1, lb2, lb3),
-                            ('name', 'asc'), 2, 2
-                        )
-
-    def test_list_loadbalancers_with_pagination_reverse_emulated(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet, name='lb1') as lb1:
-                with self.loadbalancer(subnet=subnet, name='lb2') as lb2:
-                    with self.loadbalancer(subnet=subnet, name='lb3') as lb3:
-                        self._test_list_with_pagination_reverse(
-                            'loadbalancer',
-                            (lb1, lb2, lb3),
-                            ('name', 'asc'), 2, 2
-                        )
-
-    def test_get_loadbalancer_stats(self):
-        expected_values = {'stats': {lb_const.STATS_TOTAL_CONNECTIONS: 0,
-                                     lb_const.STATS_ACTIVE_CONNECTIONS: 0,
-                                     lb_const.STATS_OUT_BYTES: 0,
-                                     lb_const.STATS_IN_BYTES: 0}}
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet) as lb:
-                lb_id = lb['loadbalancer']['id']
-                resp, body = self._get_loadbalancer_stats_api(lb_id)
-                self.assertEqual(expected_values, body)
-
-    def test_show_loadbalancer_with_listeners(self):
-        name = 'lb_show'
-        description = 'lb_show description'
-        vip_address = '10.0.0.10'
-        expected_values = {'name': name,
-                           'description': description,
-                           'vip_address': '10.0.0.10',
-                           'admin_state_up': True,
-                           'provisioning_status': constants.ACTIVE,
-                           'operating_status': lb_const.ONLINE,
-                           'listeners': []}
-        with self.subnet() as subnet:
-            vip_subnet_id = subnet['subnet']['id']
-            expected_values['vip_subnet_id'] = vip_subnet_id
-            with self.loadbalancer(subnet=subnet, name=name,
-                                   description=description,
-                                   vip_address=vip_address) as lb:
-                lb_id = lb['loadbalancer']['id']
-                expected_values['id'] = lb_id
-                with self.listener(loadbalancer_id=lb_id,
-                                   protocol_port=80) as listener1:
-                    listener1_id = listener1['listener']['id']
-                    expected_values['listeners'].append({'id': listener1_id})
-                    with self.listener(loadbalancer_id=lb_id,
-                                       protocol_port=81) as listener2:
-                        listener2_id = listener2['listener']['id']
-                        expected_values['listeners'].append(
-                            {'id': listener2_id})
-                        resp, body = self._get_loadbalancer_api(lb_id)
-                        for k in expected_values:
-                            self.assertEqual(expected_values[k],
-                                             body['loadbalancer'][k])
-
-    def test_port_delete_via_port_api(self):
-        port = {
-            'id': 'my_port_id',
-            'device_owner': n_constants.DEVICE_OWNER_LOADBALANCERV2
-        }
-        ctx = context.get_admin_context()
-        port['device_owner'] = n_constants.DEVICE_OWNER_LOADBALANCERV2
-        myloadbalancers = [{'name': 'lb1'}]
-        with mock.patch.object(manager.NeutronManager, 'get_plugin') as gp:
-            self.plugin.db.get_loadbalancers = mock.Mock(
-                                               return_value=myloadbalancers)
-            plugin = mock.Mock()
-            gp.return_value = plugin
-            plugin._get_port.return_value = port
-            self.assertRaises(n_exc.ServicePortInUse,
-                              self.plugin.db.prevent_lbaasv2_port_deletion,
-                              ctx,
-                              port['id'])
-
-
-class LoadBalancerDelegateVIPCreation(LbaasPluginDbTestCase):
-
-    def setUp(self):
-        driver_patcher = mock.patch.object(
-            noop_driver.LoggingNoopLoadBalancerManager,
-            'allocates_vip', new_callable=mock.PropertyMock)
-        driver_patcher.start().return_value = True
-        super(LoadBalancerDelegateVIPCreation, self).setUp()
-
-    def test_create_loadbalancer(self):
-        expected = {
-            'name': 'vip1',
-            'description': '',
-            'admin_state_up': True,
-            'provisioning_status': constants.ACTIVE,
-            'operating_status': lb_const.ONLINE,
-            'tenant_id': self._tenant_id,
-            'listeners': [],
-            'pools': [],
-            'provider': 'lbaas'
-        }
-
-        with self.subnet() as subnet:
-            expected['vip_subnet_id'] = subnet['subnet']['id']
-            name = expected['name']
-
-            with self.loadbalancer(name=name, subnet=subnet) as lb:
-                lb_id = lb['loadbalancer']['id']
-                for k in ('id', 'vip_subnet_id'):
-                    self.assertTrue(lb['loadbalancer'].get(k, None))
-
-                self.assertIsNone(lb['loadbalancer'].get('vip_address'))
-                expected['vip_port_id'] = lb['loadbalancer']['vip_port_id']
-                actual = dict((k, v)
-                              for k, v in lb['loadbalancer'].items()
-                              if k in expected)
-                self.assertEqual(expected, actual)
-                self._validate_statuses(lb_id)
-            return lb
-
-    def test_delete_loadbalancer(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet, no_delete=True) as lb:
-                lb_id = lb['loadbalancer']['id']
-                acontext = context.get_admin_context()
-                db_port = self.plugin.db._core_plugin.create_port(
-                    acontext,
-                    {'port': {'network_id': subnet['subnet']['network_id'],
-                              'name': '', 'admin_state_up': True,
-                              'device_id': lb_id, 'device_owner': '',
-                              'mac_address': '', 'fixed_ips': [],
-                              'tenant_id': acontext.tenant_id}})
-                port_id = db_port['id']
-                self.addCleanup(self.plugin.db._core_plugin.delete_port,
-                                acontext, port_id)
-                self.plugin.db.update_loadbalancer(
-                    acontext, lb_id,
-                    {'loadbalancer': {'vip_port_id': port_id}})
-                self.plugin.db.delete_loadbalancer(
-                    acontext, lb_id, delete_vip_port=True)
-                port = self.plugin.db._core_plugin.get_port(acontext, port_id)
-                self.assertIsNotNone(port)
-
-
-class ListenerTestBase(LbaasPluginDbTestCase):
-    def setUp(self):
-        super(ListenerTestBase, self).setUp()
-        network = self._make_network(self.fmt, 'test-net', True)
-        self.test_subnet = self._make_subnet(
-            self.fmt, network, gateway=attributes.ATTR_NOT_SPECIFIED,
-            cidr='10.0.0.0/24')
-        self.test_subnet_id = self.test_subnet['subnet']['id']
-        lb_res = self._create_loadbalancer(
-            self.fmt, subnet_id=self.test_subnet_id)
-        lb_res2 = self._create_loadbalancer(
-            self.fmt, subnet_id=self.test_subnet_id)
-        self.lb = self.deserialize(self.fmt, lb_res)
-        self.lb2 = self.deserialize(self.fmt, lb_res2)
-        self.lb_id = self.lb['loadbalancer']['id']
-        self.lb_id2 = self.lb2['loadbalancer']['id']
-
-    def tearDown(self):
-        self._delete_loadbalancer_api(self.lb_id)
-        super(ListenerTestBase, self).tearDown()
-
-    def _create_listener_api(self, data):
-        req = self.new_create_request("listeners", data, self.fmt)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _update_listener_api(self, listener_id, data):
-        req = self.new_update_request('listeners', data, listener_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, req.get_response(self.ext_api))
-        return resp, body
-
-    def _delete_listener_api(self, listener_id):
-        req = self.new_delete_request('listeners', listener_id)
-        resp = req.get_response(self.ext_api)
-        return resp
-
-    def _get_listener_api(self, listener_id):
-        req = self.new_show_request('listeners', listener_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _list_listeners_api(self):
-        req = self.new_list_request('listeners')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-
-class CertMock(cert_manager.Cert):
-    def __init__(self, cert_container):
-        pass
-
-    def get_certificate(self):
-        return "mock"
-
-    def get_intermediates(self):
-        return "mock"
-
-    def get_private_key(self):
-        return "mock"
-
-    def get_private_key_passphrase(self):
-        return "mock"
-
-
-class Exceptions(object):
-    def __iter__(self):
-        return self
-    pass
-
-
-class LbaasListenerTests(ListenerTestBase):
-
-    def test_create_listener(self, **extras):
-        expected = {
-            'protocol': 'HTTP',
-            'protocol_port': 80,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'default_pool_id': None,
-            'loadbalancers': [{'id': self.lb_id}]
-        }
-
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener'].get('id')
-            self.assertTrue(listener_id)
-            actual = {}
-            for k, v in listener['listener'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, listener_id)
-        return listener
-
-    def test_create_listener_with_default_pool_no_lb(self, **extras):
-        listener_pool_res = self._create_pool(
-            self.fmt, lb_const.PROTOCOL_HTTP,
-            lb_const.LB_METHOD_ROUND_ROBIN,
-            loadbalancer_id=self.lb_id)
-        listener_pool = self.deserialize(self.fmt, listener_pool_res)
-        listener_pool_id = listener_pool['pool']['id']
-        expected = {
-            'protocol': 'HTTP',
-            'protocol_port': 80,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'default_pool_id': listener_pool_id
-        }
-
-        expected.update(extras)
-
-        with self.listener(default_pool_id=listener_pool_id) as listener:
-            listener_id = listener['listener'].get('id')
-            self.assertTrue(listener_id)
-            actual = {}
-            for k, v in listener['listener'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(actual, expected)
-            self._validate_statuses(self.lb_id, listener_id)
-        return listener
-
-    def test_create_listener_same_port_same_load_balancer(self):
-        with self.listener(loadbalancer_id=self.lb_id,
-                           protocol_port=80):
-            self._create_listener(self.fmt, 'HTTP', 80,
-                                  loadbalancer_id=self.lb_id,
-                                  expected_res_status=409)
-
-    def test_create_listener_with_tls_no_default_container(self, **extras):
-        listener_data = {
-            'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS,
-            'default_tls_container_ref': None,
-            'protocol_port': 443,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'loadbalancer_id': self.lb_id,
-        }
-
-        listener_data.update(extras)
-        self.assertRaises(
-                        loadbalancerv2.TLSDefaultContainerNotSpecified,
-                        self.plugin.create_listener,
-                        context.get_admin_context(),
-                        {'listener': listener_data})
-
-    def test_create_listener_with_tls_missing_container(self, **extras):
-        default_tls_container_ref = uuidutils.generate_uuid()
-
-        class ReplaceClass(ex.Exception):
-            def __init__(self, status_code, message):
-                self.status_code = status_code
-                self.message = message
-                pass
-
-        cfg.CONF.set_override('service_name',
-                              'lbaas',
-                              'service_auth')
-        cfg.CONF.set_override('region',
-                              'RegionOne',
-                              'service_auth')
-        listener_data = {
-            'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS,
-            'default_tls_container_ref': default_tls_container_ref,
-            'sni_container_refs': [],
-            'protocol_port': 443,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'loadbalancer_id': self.lb_id
-        }
-        listener_data.update(extras)
-
-        with contextlib.nested(
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.get_cert'),
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.delete_cert')
-        ) as (get_cert_mock, rm_consumer_mock):
-            ex.Exception = ReplaceClass(status_code=404,
-                                        message='Cert Not Found')
-            get_cert_mock.side_effect = ex.Exception
-
-            self.assertRaises(loadbalancerv2.TLSContainerNotFound,
-                              self.plugin.create_listener,
-                              context.get_admin_context(),
-                              {'listener': listener_data})
-
-    def test_create_listener_with_tls_invalid_service_acct(self, **extras):
-        default_tls_container_ref = uuidutils.generate_uuid()
-        listener_data = {
-            'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS,
-            'default_tls_container_ref': default_tls_container_ref,
-            'sni_container_refs': [],
-            'protocol_port': 443,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'loadbalancer_id': self.lb_id
-        }
-        listener_data.update(extras)
-
-        with contextlib.nested(
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.get_cert'),
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.delete_cert')
-        ) as (get_cert_mock, rm_consumer_mock):
-            get_cert_mock.side_effect = Exception('RandomFailure')
-
-            self.assertRaises(loadbalancerv2.CertManagerError,
-                              self.plugin.create_listener,
-                              context.get_admin_context(),
-                              {'listener': listener_data})
-
-    def test_create_listener_with_tls_invalid_container(self, **extras):
-        default_tls_container_ref = uuidutils.generate_uuid()
-        cfg.CONF.set_override('service_name',
-                              'lbaas',
-                              'service_auth')
-        cfg.CONF.set_override('region',
-                              'RegionOne',
-                              'service_auth')
-        listener_data = {
-            'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS,
-            'default_tls_container_ref': default_tls_container_ref,
-            'sni_container_refs': [],
-            'protocol_port': 443,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'loadbalancer_id': self.lb_id
-        }
-        listener_data.update(extras)
-
-        with contextlib.nested(
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'cert_parser.validate_cert'),
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.get_cert'),
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.delete_cert')
-        ) as (validate_cert_mock, get_cert_mock, rm_consumer_mock):
-            get_cert_mock.start().return_value = CertMock(
-                'mock_cert')
-            validate_cert_mock.side_effect = exceptions.MisMatchedKey
-
-            self.assertRaises(loadbalancerv2.TLSContainerInvalid,
-                              self.plugin.create_listener,
-                              context.get_admin_context(),
-                              {'listener': listener_data})
-            rm_consumer_mock.assert_called_once_with(
-                cert_ref=listener_data['default_tls_container_ref'],
-                project_id=self._tenant_id,
-                resource_ref=cert_manager.CertManager.get_service_url(
-                    self.lb_id))
-
-    def test_create_listener_with_tls(self, **extras):
-        default_tls_container_ref = uuidutils.generate_uuid()
-        sni_tls_container_ref_1 = uuidutils.generate_uuid()
-        sni_tls_container_ref_2 = uuidutils.generate_uuid()
-
-        expected = {
-            'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS,
-            'default_tls_container_ref': default_tls_container_ref,
-            'sni_container_refs': [sni_tls_container_ref_1,
-                                   sni_tls_container_ref_2]}
-
-        extras['default_tls_container_ref'] = default_tls_container_ref
-        extras['sni_container_refs'] = [sni_tls_container_ref_1,
-                                        sni_tls_container_ref_2]
-
-        with contextlib.nested(
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'cert_parser.validate_cert'),
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.get_cert')
-        ) as (validate_cert_mock, get_cert_mock):
-            get_cert_mock.start().return_value = CertMock(
-                'mock_cert')
-            validate_cert_mock.start().return_value = True
-
-            with self.listener(protocol=lb_const.PROTOCOL_TERMINATED_HTTPS,
-                               loadbalancer_id=self.lb_id, protocol_port=443,
-                               **extras) as listener:
-                self.assertEqual(
-                    expected,
-                    dict((k, v)
-                         for k, v in listener['listener'].items()
-                         if k in expected)
-                )
-
-    def test_create_listener_loadbalancer_id_does_not_exist(self):
-        self._create_listener(self.fmt, 'HTTP', 80,
-                              loadbalancer_id=uuidutils.generate_uuid(),
-                              expected_res_status=404)
-
-    def test_can_create_listener_with_pool_loadbalancer_match(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet) as loadbalancer:
-                lb_id = loadbalancer['loadbalancer']['id']
-                with self.pool(loadbalancer_id=lb_id) as p1:
-                    p_id = p1['pool']['id']
-                    with self.listener(default_pool_id=p_id,
-                                       loadbalancer_id=lb_id):
-                        pass
-
-    def test_cannot_create_listener_with_pool_loadbalancer_mismatch(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(self.loadbalancer(subnet=subnet),
-                                   self.loadbalancer(subnet=subnet)
-                                   ) as (lb1, lb2):
-                lb_id1 = lb1['loadbalancer']['id']
-                lb_id2 = lb2['loadbalancer']['id']
-                with self.pool(loadbalancer_id=lb_id1) as p1:
-                    p_id = p1['pool']['id']
-                    data = {'listener': {'name': '',
-                                         'protocol_port': 80,
-                                         'protocol': 'HTTP',
-                                         'connection_limit': 100,
-                                         'admin_state_up': True,
-                                         'tenant_id': self._tenant_id,
-                                         'default_pool_id': p_id,
-                                         'loadbalancer_id': lb_id2}}
-                    resp, body = self._create_listener_api(data)
-                    self.assertEqual(resp.status_int,
-                                     webob.exc.HTTPBadRequest.code)
-
-    def test_update_listener(self):
-        name = 'new_listener'
-        expected_values = {'name': name,
-                           'protocol_port': 80,
-                           'protocol': 'HTTP',
-                           'connection_limit': 100,
-                           'admin_state_up': False,
-                           'tenant_id': self._tenant_id,
-                           'loadbalancers': [{'id': self.lb_id}]}
-
-        with self.listener(name=name, loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            data = {'listener': {'name': name,
-                                 'connection_limit': 100,
-                                 'admin_state_up': False}}
-            resp, body = self._update_listener_api(listener_id, data)
-            for k in expected_values:
-                self.assertEqual(expected_values[k], body['listener'][k])
-            self._validate_statuses(self.lb_id, listener_id,
-                                    listener_disabled=True)
-
-    def test_update_listener_with_tls(self):
-        default_tls_container_ref = uuidutils.generate_uuid()
-        sni_tls_container_ref_1 = uuidutils.generate_uuid()
-        sni_tls_container_ref_2 = uuidutils.generate_uuid()
-        sni_tls_container_ref_3 = uuidutils.generate_uuid()
-        sni_tls_container_ref_4 = uuidutils.generate_uuid()
-        sni_tls_container_ref_5 = uuidutils.generate_uuid()
-
-        listener_data = {
-            'protocol': lb_const.PROTOCOL_TERMINATED_HTTPS,
-            'default_tls_container_ref': default_tls_container_ref,
-            'sni_container_refs': [sni_tls_container_ref_1,
-                                   sni_tls_container_ref_2],
-            'protocol_port': 443,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'loadbalancer_id': self.lb_id
-        }
-
-        with contextlib.nested(
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'cert_parser.validate_cert'),
-            mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                       'CERT_MANAGER_PLUGIN.CertManager.get_cert')
-        ) as (validate_cert_mock, get_cert_mock):
-            get_cert_mock.start().return_value = CertMock(
-                'mock_cert')
-            validate_cert_mock.start().return_value = True
-
-            # Default container and two SNI containers
-            # Test order and validation behavior.
-            listener = self.plugin.create_listener(context.get_admin_context(),
-                                                   {'listener': listener_data})
-            self.assertEqual([sni_tls_container_ref_1,
-                              sni_tls_container_ref_2],
-                             listener['sni_container_refs'])
-
-            # Default container and two other SNI containers
-            # Test order and validation behavior.
-            listener_data.pop('loadbalancer_id')
-            listener_data.pop('protocol')
-            listener_data.pop('provisioning_status')
-            listener_data.pop('operating_status')
-            listener_data['sni_container_refs'] = [sni_tls_container_ref_3,
-                                                   sni_tls_container_ref_4]
-            listener = self.plugin.update_listener(
-                context.get_admin_context(),
-                listener['id'],
-                {'listener': listener_data}
-            )
-            self.assertEqual([sni_tls_container_ref_3,
-                              sni_tls_container_ref_4],
-                             listener['sni_container_refs'])
-
-            # Default container, two old SNI containers ordered differently
-            # and one new SNI container.
-            # Test order and validation behavior.
-            listener_data.pop('protocol')
-            listener_data['sni_container_refs'] = [sni_tls_container_ref_4,
-                                                   sni_tls_container_ref_3,
-                                                   sni_tls_container_ref_5]
-            listener = self.plugin.update_listener(context.get_admin_context(),
-                                                   listener['id'],
-                                                   {'listener': listener_data})
-            self.assertEqual([sni_tls_container_ref_4,
-                              sni_tls_container_ref_3,
-                              sni_tls_container_ref_5],
-                             listener['sni_container_refs'])
-
-    def test_delete_listener(self):
-        with self.listener(no_delete=True,
-                           loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            resp = self._delete_listener_api(listener_id)
-            self.assertEqual(webob.exc.HTTPNoContent.code, resp.status_int)
-            resp, body = self._get_loadbalancer_api(self.lb_id)
-            self.assertEqual(0, len(body['loadbalancer']['listeners']))
-
-    def test_delete_listener_with_l7policy(self):
-        with self.listener(loadbalancer_id=self.lb_id,
-                           no_delete=True) as listener:
-            with self.l7policy(listener['listener']['id'], no_delete=True):
-                ctx = context.get_admin_context()
-                self.assertRaises(
-                    loadbalancerv2.EntityInUse,
-                    self.plugin.delete_listener,
-                    ctx, listener['listener']['id'])
-
-    def test_show_listener(self):
-        name = 'show_listener'
-        expected_values = {'name': name,
-                           'protocol_port': 80,
-                           'protocol': 'HTTP',
-                           'connection_limit': -1,
-                           'admin_state_up': True,
-                           'tenant_id': self._tenant_id,
-                           'default_pool_id': None,
-                           'loadbalancers': [{'id': self.lb_id}]}
-
-        with self.listener(name=name, loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            resp, body = self._get_listener_api(listener_id)
-            for k in expected_values:
-                self.assertEqual(expected_values[k], body['listener'][k])
-
-    def test_list_listeners(self):
-        name = 'list_listeners'
-        expected_values = {'name': name,
-                           'protocol_port': 80,
-                           'protocol': 'HTTP',
-                           'connection_limit': -1,
-                           'admin_state_up': True,
-                           'tenant_id': self._tenant_id,
-                           'loadbalancers': [{'id': self.lb_id}]}
-
-        with self.listener(name=name, loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            expected_values['id'] = listener_id
-            resp, body = self._list_listeners_api()
-            listener_list = body['listeners']
-            self.assertEqual(1, len(listener_list))
-            for k in expected_values:
-                self.assertEqual(expected_values[k], listener_list[0][k])
-
-    def test_list_listeners_with_sort_emulated(self):
-        with self.listener(name='listener1', protocol_port=81,
-                           loadbalancer_id=self.lb_id) as listener1:
-            with self.listener(name='listener2',
-                               protocol_port=82,
-                               loadbalancer_id=self.lb_id) as listener2:
-                with self.listener(name='listener3',
-                                   protocol_port=83,
-                                   loadbalancer_id=self.lb_id) as listener3:
-                    self._test_list_with_sort(
-                        'listener',
-                        (listener1, listener2, listener3),
-                        [('protocol_port', 'asc'), ('name', 'desc')]
-                    )
-
-    def test_list_listeners_with_pagination_emulated(self):
-        with self.listener(name='listener1', protocol_port=80,
-                           loadbalancer_id=self.lb_id) as listener1:
-            with self.listener(name='listener2', protocol_port=81,
-                               loadbalancer_id=self.lb_id) as listener2:
-                with self.listener(name='listener3', protocol_port=82,
-                                   loadbalancer_id=self.lb_id) as listener3:
-                    self._test_list_with_pagination(
-                        'listener',
-                        (listener1, listener2, listener3),
-                        ('name', 'asc'), 2, 2
-                    )
-
-    def test_list_listeners_with_pagination_reverse_emulated(self):
-        with self.listener(name='listener1', protocol_port=80,
-                           loadbalancer_id=self.lb_id) as listener1:
-            with self.listener(name='listener2', protocol_port=81,
-                               loadbalancer_id=self.lb_id) as listener2:
-                with self.listener(name='listener3', protocol_port=82,
-                                   loadbalancer_id=self.lb_id) as listener3:
-                    self._test_list_with_pagination(
-                        'listener',
-                        (listener3, listener2, listener1),
-                        ('name', 'desc'), 2, 2
-                    )
-
-
-class LbaasL7Tests(ListenerTestBase):
-    def test_create_l7policy_invalid_listener_id(self, **extras):
-        self._create_l7policy(self.fmt, uuidutils.generate_uuid(),
-                              lb_const.L7_POLICY_ACTION_REJECT,
-                              expected_res_status=webob.exc.HTTPNotFound.code)
-
-    def test_create_l7policy_redirect_no_pool(self, **extras):
-        l7policy_data = {
-            'name': '',
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-            'description': '',
-            'position': 1,
-            'redirect_pool_id': None,
-            'redirect_url': 'http://radware.com',
-            'tenant_id': self._tenant_id,
-            'admin_state_up': True,
-        }
-        l7policy_data.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            ctx = context.get_admin_context()
-            l7policy_data['listener_id'] = listener['listener']['id']
-
-            l7policy_data['action'] = (
-                lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL)
-            self.assertRaises(
-                l7.L7PolicyRedirectPoolIdMissing,
-                self.plugin.create_l7policy,
-                ctx, {'l7policy': l7policy_data})
-
-    def test_create_l7policy_redirect_invalid_pool(self, **extras):
-        l7policy_data = {
-            'name': '',
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-            'description': '',
-            'position': 1,
-            'redirect_pool_id': None,
-            'tenant_id': self._tenant_id,
-            'admin_state_up': True,
-        }
-        l7policy_data.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            ctx = context.get_admin_context()
-            l7policy_data['listener_id'] = listener['listener']['id']
-
-            # Test pool redirect action with invalid pool id specified
-            l7policy_data['redirect_pool_id'] = uuidutils.generate_uuid()
-            self.assertRaises(
-                loadbalancerv2.EntityNotFound,
-                self.plugin.create_l7policy,
-                ctx, {'l7policy': l7policy_data})
-
-    def test_create_l7policy_redirect_foreign_pool(self, **extras):
-        l7policy_data = {
-            'name': '',
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-            'description': '',
-            'position': 1,
-            'redirect_pool_id': None,
-            'tenant_id': self._tenant_id,
-            'admin_state_up': True,
-        }
-        l7policy_data.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            ctx = context.get_admin_context()
-            l7policy_data['listener_id'] = listener['listener']['id']
-
-            # Test pool redirect action with another loadbalancer pool id
-            with self.pool(loadbalancer_id=self.lb_id2) as p:
-                l7policy_data['redirect_pool_id'] = p['pool']['id']
-                self.assertRaises(
-                    sharedpools.ListenerAndPoolMustBeOnSameLoadbalancer,
-                    self.plugin.create_l7policy,
-                    ctx, {'l7policy': l7policy_data})
-
-    def test_create_l7policy_redirect_no_url(self, **extras):
-        l7policy_data = {
-            'name': '',
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL,
-            'description': '',
-            'position': 1,
-            'redirect_pool_id': None,
-            'redirect_url': 'http://radware.com',
-            'tenant_id': self._tenant_id,
-            'admin_state_up': True,
-        }
-        l7policy_data.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            ctx = context.get_admin_context()
-            l7policy_data['listener_id'] = listener['listener']['id']
-
-            # Test url redirect action without url specified
-            del l7policy_data['redirect_url']
-            l7policy_data['action'] = lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL
-            self.assertRaises(
-                l7.L7PolicyRedirectUrlMissing,
-                self.plugin.create_l7policy,
-                ctx, {'l7policy': l7policy_data})
-
-    def test_create_l7policy_redirect_invalid_url(self, **extras):
-        l7policy_data = {
-            'name': '',
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL,
-            'description': '',
-            'position': 1,
-            'redirect_pool_id': None,
-            'redirect_url': 'http://radware.com',
-            'tenant_id': self._tenant_id,
-            'admin_state_up': True,
-        }
-        l7policy_data.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            l7policy_data['listener_id'] = listener['listener']['id']
-
-            # Test url redirect action with invalid url specified
-            try:
-                with contextlib.nested(
-                    self.l7policy(listener['listener']['id'],
-                    action=lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL,
-                    redirect_url='https:/acme.com')):
-                    self.assertTrue(False)
-            except webob.exc.HTTPClientError:
-                pass
-
-    def test_create_l7policy_invalid_position(self, **extras):
-        l7policy_data = {
-            'name': '',
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL,
-            'description': '',
-            'position': 1,
-            'redirect_pool_id': None,
-            'redirect_url': 'http://radware.com',
-            'tenant_id': self._tenant_id,
-            'admin_state_up': True,
-        }
-        l7policy_data.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            l7policy_data['listener_id'] = listener['listener']['id']
-
-            # Test invalid zero position for policy
-            try:
-                with contextlib.nested(
-                    self.l7policy(listener['listener']['id'],
-                    position=0)):
-                    self.assertTrue(False)
-            except webob.exc.HTTPClientError:
-                pass
-
-    def test_create_l7policy(self, **extras):
-        expected = {
-            'action': lb_const.L7_POLICY_ACTION_REJECT,
-            'redirect_pool_id': None,
-            'redirect_url': None,
-            'tenant_id': self._tenant_id,
-        }
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.l7policy(listener_id) as p:
-                expected['listener_id'] = listener_id
-                actual = {}
-                for k, v in p['l7policy'].items():
-                    if k in expected:
-                        actual[k] = v
-                self.assertEqual(actual, expected)
-                self._validate_statuses(self.lb_id, listener_id,
-                                        p['l7policy']['id'])
-
-    def test_create_l7policy_pool_redirect(self, **extras):
-        expected = {
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-            'redirect_pool_id': None,
-            'redirect_url': None,
-            'tenant_id': self._tenant_id,
-        }
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.pool(loadbalancer_id=self.lb_id) as pool:
-                pool_id = pool['pool']['id']
-                with self.l7policy(
-                    listener_id,
-                    action=lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-                    redirect_pool_id=pool_id) as p:
-                    expected['listener_id'] = listener_id
-                    expected['redirect_pool_id'] = pool_id
-                    actual = {}
-                    for k, v in p['l7policy'].items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-    def test_l7policy_pool_deletion(self, **extras):
-        expected = {
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-            'redirect_pool_id': None,
-            'redirect_url': None,
-            'tenant_id': self._tenant_id,
-        }
-        expected.update(extras)
-
-        with contextlib.nested(
-            self.listener(loadbalancer_id=self.lb_id),
-            self.listener(loadbalancer_id=self.lb_id,
-                protocol_port=8080)) as (listener1, listener2):
-            with contextlib.nested(
-                self.pool(loadbalancer_id=self.lb_id,
-                          no_delete=True),
-                self.pool(loadbalancer_id=self.lb_id)) as (pool1, pool2):
-                with contextlib.nested(
-                    self.l7policy(
-                        listener1['listener']['id'],
-                        action=lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-                        redirect_pool_id=pool1['pool']['id']),
-                    self.l7policy(
-                        listener1['listener']['id'],
-                        action=lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-                        redirect_pool_id=pool2['pool']['id']),
-                    self.l7policy(
-                        listener2['listener']['id'],
-                        action=lb_const.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-                        redirect_pool_id=pool1['pool']['id'])) as (
-                        policy1, policy2, policy3):
-
-                    ctx = context.get_admin_context()
-                    self.plugin.delete_pool(ctx, pool1['pool']['id'])
-
-                    l7policy1 = self.plugin.get_l7policy(
-                        ctx, policy1['l7policy']['id'])
-                    self.assertEqual(l7policy1['action'],
-                        lb_const.L7_POLICY_ACTION_REJECT)
-                    self.assertEqual(l7policy1['redirect_pool_id'], None)
-
-                    l7policy3 = self.plugin.get_l7policy(
-                        ctx, policy3['l7policy']['id'])
-                    self.assertEqual(l7policy3['action'],
-                        lb_const.L7_POLICY_ACTION_REJECT)
-                    self.assertEqual(l7policy3['redirect_pool_id'], None)
-
-    def test_create_l7policies_ordering(self, **extras):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with contextlib.nested(
-                self.l7policy(listener_id, name="1"),
-                self.l7policy(listener_id, name="2"),
-                self.l7policy(listener_id, name="3"),
-                self.l7policy(listener_id, position=1, name="4"),
-                self.l7policy(listener_id, position=2, name="5"),
-                self.l7policy(listener_id, position=4, name="6"),
-                self.l7policy(listener_id, name="7"),
-                self.l7policy(listener_id, position=8, name="8"),
-                self.l7policy(listener_id, position=1, name="9"),
-                self.l7policy(listener_id, position=1, name="10")
-            ):
-                listener_db = self.plugin.db._get_resource(
-                    context.get_admin_context(),
-                    models.Listener, listener['listener']['id'])
-                names = ['10', '9', '4', '5', '1', '6', '2', '3', '7', '8']
-                for pos in range(0, 10):
-                    self.assertEqual(
-                        listener_db.l7_policies[pos]['position'], pos + 1)
-                    self.assertEqual(
-                        listener_db.l7_policies[pos]['name'], names[pos])
-
-    def test_update_l7policy(self, **extras):
-        expected = {
-            'admin_state_up': False,
-            'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL,
-            'redirect_pool_id': None,
-            'redirect_url': 'redirect_url',
-            'tenant_id': self._tenant_id,
-            'position': 1,
-        }
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.l7policy(listener_id) as p:
-                l7policy_id = p['l7policy']['id']
-
-                data = {
-                    'l7policy': {
-                        'action': lb_const.L7_POLICY_ACTION_REDIRECT_TO_URL,
-                        'redirect_url': 'redirect_url',
-                        'admin_state_up': False}}
-
-                ctx = context.get_admin_context()
-                self.plugin.update_l7policy(ctx, l7policy_id, data)
-                l7policy = self.plugin.get_l7policy(ctx, l7policy_id)
-                actual = {}
-                for k, v in l7policy.items():
-                    if k in expected:
-                        actual[k] = v
-                self.assertEqual(actual, expected)
-                self._validate_statuses(self.lb_id, listener_id,
-                                        p['l7policy']['id'],
-                                        l7policy_disabled=True)
-
-    def test_update_l7policies_ordering(self, **extras):
-        expected = {
-            'action': lb_const.L7_POLICY_ACTION_REJECT,
-            'redirect_pool_id': None,
-            'redirect_url': '',
-            'tenant_id': self._tenant_id,
-        }
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with contextlib.nested(
-                self.l7policy(listener_id, name="1"),
-                self.l7policy(listener_id, name="2"),
-                self.l7policy(listener_id, name="3"),
-                self.l7policy(listener_id, name="4"),
-                self.l7policy(listener_id, name="5"),
-                self.l7policy(listener_id, name="6"),
-                self.l7policy(listener_id, name="7"),
-                self.l7policy(listener_id, name="8"),
-                self.l7policy(listener_id, name="9"),
-                self.l7policy(listener_id, name="10"),
-            ) as (p1, p2, p3, p4, p5, p6, p7, p8, p9, p10):
-                c = context.get_admin_context()
-
-                listener_db = self.plugin.db._get_resource(
-                    context.get_admin_context(),
-                    models.Listener, listener['listener']['id'])
-
-                expected['position'] = 1
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p2['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p2['l7policy']['id'],
-                                            {'l7policy': expected})
-                expected['position'] = 3
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p1['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p1['l7policy']['id'],
-                                            {'l7policy': expected})
-                expected['position'] = 4
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p6['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p6['l7policy']['id'],
-                                            {'l7policy': expected})
-                expected['position'] = 11
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p2['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p2['l7policy']['id'],
-                                            {'l7policy': expected})
-                expected['position'] = 1
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p1['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p1['l7policy']['id'],
-                                            {'l7policy': expected})
-                expected['position'] = 8
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p5['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p5['l7policy']['id'],
-                                            {'l7policy': expected})
-                expected['position'] = 3
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p10['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.update_l7policy(c, p10['l7policy']['id'],
-                                            {'l7policy': expected})
-                listener_db = self.plugin.db._get_resource(
-                    context.get_admin_context(),
-                    models.Listener, listener['listener']['id'])
-                names = ['1', '3', '10', '6', '4', '7', '8', '9', '5', '2']
-                for pos in range(0, 10):
-                    self.assertEqual(
-                        listener_db.l7_policies[pos]['position'], pos + 1)
-                    self.assertEqual(
-                        listener_db.l7_policies[pos]['name'], names[pos])
-
-    def test_delete_l7policy(self, **extras):
-        expected = {
-            'position': 1,
-            'action': lb_const.L7_POLICY_ACTION_REJECT,
-            'redirect_pool_id': None,
-            'redirect_url': '',
-            'tenant_id': self._tenant_id,
-        }
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with contextlib.nested(
-                self.l7policy(listener_id, name="0"),
-                self.l7policy(listener_id, name="1"),
-                self.l7policy(listener_id, name="2"),
-                self.l7policy(listener_id, name="3", no_delete=True),
-                self.l7policy(listener_id, name="4"),
-                self.l7policy(listener_id, name="5", no_delete=True),
-                self.l7policy(listener_id, name="6")
-            ) as (p0, p1, p2, p3, p4, p5, p6):
-                c = context.get_admin_context()
-
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p3['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.delete_l7policy(c, p3['l7policy']['id'])
-                self.plugin.db.update_status(
-                    c, models.L7Policy, p5['l7policy']['id'],
-                    lb_const.OFFLINE)
-                self.plugin.delete_l7policy(c, p5['l7policy']['id'])
-
-                listener_db = self.plugin.db._get_resource(
-                    context.get_admin_context(),
-                    models.Listener, listener['listener']['id'])
-                names = ['0', '1', '2', '4', '6']
-                for pos in range(0, 4):
-                    self.assertEqual(
-                        listener_db.l7_policies[pos]['position'], pos + 1)
-                    self.assertEqual(
-                        listener_db.l7_policies[pos]['name'], names[pos])
-
-                self.assertRaises(
-                    loadbalancerv2.EntityNotFound,
-                    self.plugin.get_l7policy,
-                    c, p3['l7policy']['id'])
-                self.assertRaises(
-                    loadbalancerv2.EntityNotFound,
-                    self.plugin.get_l7policy,
-                    c, p5['l7policy']['id'])
-
-    def test_show_l7policy(self, **extras):
-        expected = {
-            'position': 1,
-            'action': lb_const.L7_POLICY_ACTION_REJECT,
-            'redirect_pool_id': None,
-            'redirect_url': None,
-            'tenant_id': self._tenant_id,
-        }
-        expected.update(extras)
-
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.l7policy(listener_id, name="0") as p:
-                req = self.new_show_request('l7policies',
-                                            p['l7policy']['id'],
-                                            fmt=self.fmt)
-                res = self.deserialize(self.fmt,
-                                       req.get_response(self.ext_api))
-                actual = {}
-                for k, v in res['l7policy'].items():
-                    if k in expected:
-                        actual[k] = v
-                self.assertEqual(expected, actual)
-            return p
-
-    def test_list_l7policies_with_sort_emulated(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with contextlib.nested(self.l7policy(listener_id, name="b"),
-                                   self.l7policy(listener_id, name="c"),
-                                   self.l7policy(listener_id, name="a")
-                                   ) as (p1, p2, p3):
-                self._test_list_with_sort('l7policy', (p3, p1, p2),
-                                          [('name', 'asc')],
-                                          resources='l7policies')
-
-    def test_list_l7policies_with_pagination_emulated(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with contextlib.nested(self.l7policy(listener_id, name="b"),
-                                   self.l7policy(listener_id, name="c"),
-                                   self.l7policy(listener_id, name="e"),
-                                   self.l7policy(listener_id, name="d"),
-                                   self.l7policy(listener_id, name="f"),
-                                   self.l7policy(listener_id, name="g"),
-                                   self.l7policy(listener_id, name="a")
-                                   ) as (p1, p2, p3, p4, p5, p6, p7):
-                self._test_list_with_pagination(
-                    'l7policy', (p6, p5, p3, p4, p2, p1, p7),
-                    ('name', 'desc'), 2, 4, resources='l7policies')
-
-    def test_list_l7policies_with_pagination_reverse_emulated(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with contextlib.nested(self.l7policy(listener_id, name="b"),
-                                   self.l7policy(listener_id, name="c"),
-                                   self.l7policy(listener_id, name="e"),
-                                   self.l7policy(listener_id, name="d"),
-                                   self.l7policy(listener_id, name="f"),
-                                   self.l7policy(listener_id, name="g"),
-                                   self.l7policy(listener_id, name="a")
-                                   ) as (p1, p2, p3, p4, p5, p6, p7):
-                self._test_list_with_pagination_reverse(
-                    'l7policy', (p6, p5, p3, p4, p2, p1, p7),
-                    ('name', 'desc'), 2, 4, resources='l7policies')
-
-    def test_create_l7rule_invalid_policy_id(self, **extras):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            with self.l7policy(listener['listener']['id']):
-                self._create_l7policy_rule(
-                    self.fmt, uuidutils.generate_uuid(),
-                    lb_const.L7_RULE_TYPE_HOST_NAME,
-                    lb_const.L7_RULE_COMPARE_TYPE_REGEX,
-                    'value',
-                    expected_res_status=webob.exc.HTTPNotFound.code)
-
-    def test_create_invalid_l7rule(self, **extras):
-        rule = {
-            'type': lb_const.L7_RULE_TYPE_HEADER,
-            'compare_type': lb_const.L7_RULE_COMPARE_TYPE_REGEX,
-            'value': '*'
-        }
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            with self.l7policy(listener['listener']['id']) as policy:
-                policy_id = policy['l7policy']['id']
-                ctx = context.get_admin_context()
-
-                # test invalid regex
-                self.assertRaises(
-                    l7.L7RuleInvalidRegex,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test missing key for HEADER type
-                rule['value'] = '/*/'
-                self.assertRaises(
-                    l7.L7RuleKeyMissing,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test missing key for COOKIE type
-                rule['type'] = lb_const.L7_RULE_TYPE_COOKIE
-                self.assertRaises(
-                    l7.L7RuleKeyMissing,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test invalid key for HEADER type
-                rule['type'] = lb_const.L7_RULE_TYPE_HEADER
-                rule['key'] = '/'
-                self.assertRaises(
-                    l7.L7RuleInvalidKey,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test invalid value for COOKIE type
-                rule['compare_type'] =\
-                    lb_const.L7_RULE_COMPARE_TYPE_CONTAINS
-                rule['type'] = lb_const.L7_RULE_TYPE_COOKIE
-                rule['key'] = 'a'
-                rule['value'] = ';'
-                self.assertRaises(
-                    l7.L7RuleInvalidCookieValue,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test invalid value for !COOKIE type
-                rule['type'] = lb_const.L7_RULE_TYPE_PATH
-                rule['value'] = '	'
-                self.assertRaises(
-                    l7.L7RuleInvalidHeaderValue,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test invalid value for !COOKIE type quated
-                rule['value'] = '  '
-                self.assertRaises(
-                    l7.L7RuleInvalidHeaderValue,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-                # test unsupported compare type for FILE type
-                rule['type'] = lb_const.L7_RULE_TYPE_FILE_TYPE
-                self.assertRaises(
-                    l7.L7RuleUnsupportedCompareType,
-                    self.plugin.db.create_l7policy_rule,
-                    ctx, rule, policy_id)
-
-    def test_create_l7rule(self, **extras):
-        expected = {
-            'type': lb_const.L7_RULE_TYPE_HOST_NAME,
-            'compare_type': lb_const.L7_RULE_COMPARE_TYPE_EQUAL_TO,
-            'key': None,
-            'value': 'value1'
-        }
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            with self.l7policy(listener['listener']['id']) as policy:
-                policy_id = policy['l7policy']['id']
-                with contextlib.nested(
-                    self.l7policy_rule(policy_id),
-                    self.l7policy_rule(policy_id, key='key1'),
-                    self.l7policy_rule(policy_id, value='value2'),
-                    self.l7policy_rule(policy_id,
-                                       type=lb_const.L7_RULE_TYPE_PATH),
-                    self.l7policy_rule(
-                        policy_id,
-                        compare_type=lb_const.L7_RULE_COMPARE_TYPE_REGEX),
-                    self.l7policy_rule(
-                        policy_id,
-                        invert=True)
-                ) as (r_def, r_key, r_value, r_type, r_compare_type, r_invert):
-
-                    ctx = context.get_admin_context()
-                    rdb = self.plugin.get_l7policy_rule(
-                        ctx, r_def['rule']['id'], policy_id)
-                    actual = {}
-                    for k, v in rdb.items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-                    rdb = self.plugin.get_l7policy_rule(
-                        ctx, r_key['rule']['id'], policy_id)
-                    expected['key'] = 'key1'
-                    actual = {}
-                    for k, v in rdb.items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-                    rdb = self.plugin.get_l7policy_rule(
-                        ctx, r_value['rule']['id'], policy_id)
-                    expected['key'] = None
-                    expected['value'] = 'value2'
-                    actual = {}
-                    for k, v in rdb.items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-                    rdb = self.plugin.get_l7policy_rule(
-                        ctx, r_type['rule']['id'], policy_id)
-                    expected['value'] = 'value1'
-                    expected['type'] = lb_const.L7_RULE_TYPE_PATH
-                    actual = {}
-                    for k, v in rdb.items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-                    rdb = self.plugin.get_l7policy_rule(
-                        ctx, r_compare_type['rule']['id'], policy_id)
-                    expected['type'] = lb_const.L7_RULE_TYPE_HOST_NAME
-                    expected['compare_type'] =\
-                        lb_const.L7_RULE_COMPARE_TYPE_REGEX
-                    actual = {}
-                    for k, v in rdb.items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-                    rdb = self.plugin.get_l7policy_rule(
-                        ctx, r_invert['rule']['id'], policy_id)
-                    expected['invert'] = True
-                    expected['compare_type'] =\
-                        lb_const.L7_RULE_COMPARE_TYPE_EQUAL_TO
-                    actual = {}
-                    for k, v in rdb.items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-
-    def test_invalid_update_l7rule(self, **extras):
-        rule = {
-            'type': lb_const.L7_RULE_TYPE_HEADER,
-            'compare_type': lb_const.L7_RULE_COMPARE_TYPE_REGEX,
-            'value': '*'
-        }
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            with self.l7policy(listener['listener']['id']) as policy:
-                policy_id = policy['l7policy']['id']
-                with self.l7policy_rule(policy_id) as r:
-                    rule_id = r['rule']['id']
-                    ctx = context.get_admin_context()
-
-                    # test invalid regex
-                    self.assertRaises(
-                        l7.L7RuleInvalidRegex,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test missing key for HEADER type
-                    rule['value'] = '/*/'
-                    self.assertRaises(
-                        l7.L7RuleKeyMissing,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test missing key for COOKIE type
-                    rule['type'] = lb_const.L7_RULE_TYPE_COOKIE
-                    self.assertRaises(
-                        l7.L7RuleKeyMissing,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test invalid key for HEADER type
-                    rule['type'] = lb_const.L7_RULE_TYPE_HEADER
-                    rule['key'] = '/'
-                    self.assertRaises(
-                        l7.L7RuleInvalidKey,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test invalid value for COOKIE type
-                    rule['compare_type'] =\
-                        lb_const.L7_RULE_COMPARE_TYPE_CONTAINS
-                    rule['type'] = lb_const.L7_RULE_TYPE_COOKIE
-                    rule['key'] = 'a'
-                    rule['value'] = ';'
-                    self.assertRaises(
-                        l7.L7RuleInvalidCookieValue,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test invalid value for !COOKIE type
-                    rule['type'] = lb_const.L7_RULE_TYPE_PATH
-                    rule['value'] = '	'
-                    self.assertRaises(
-                        l7.L7RuleInvalidHeaderValue,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test invalid value for !COOKIE type quated
-                    rule['value'] = '  '
-                    self.assertRaises(
-                        l7.L7RuleInvalidHeaderValue,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-                    # test unsupported compare type for FILE type
-                    rule['type'] = lb_const.L7_RULE_TYPE_FILE_TYPE
-                    self.assertRaises(
-                        l7.L7RuleUnsupportedCompareType,
-                        self.plugin.db.update_l7policy_rule,
-                        ctx, rule_id, rule, policy_id)
-
-    def test_update_l7rule(self, **extras):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            with self.l7policy(listener['listener']['id']) as policy:
-                policy_id = policy['l7policy']['id']
-                with self.l7policy_rule(policy_id) as r:
-                    req = self.new_show_request('l7policies',
-                                                policy_id,
-                                                fmt=self.fmt)
-                    policy_show = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertEqual(
-                        len(policy_show['l7policy']['rules']), 1)
-
-                    expected = {}
-                    expected['type'] = lb_const.L7_RULE_TYPE_HEADER
-                    expected['compare_type'] = (
-                        lb_const.L7_RULE_COMPARE_TYPE_REGEX)
-                    expected['value'] = '/.*/'
-                    expected['key'] = 'HEADER1'
-                    expected['invert'] = True
-                    expected['admin_state_up'] = False
-
-                    req = self.new_update_request(
-                        'l7policies', {'rule': expected},
-                        policy_id, subresource='rules',
-                        sub_id=r['rule']['id'])
-                    res = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    actual = {}
-                    for k, v in res['rule'].items():
-                        if k in expected:
-                            actual[k] = v
-                    self.assertEqual(actual, expected)
-                    self._validate_statuses(self.lb_id,
-                                            listener['listener']['id'],
-                                            policy_id, r['rule']['id'],
-                                            l7rule_disabled=True)
-
-    def test_delete_l7rule(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            with self.l7policy(listener['listener']['id']) as policy:
-                policy_id = policy['l7policy']['id']
-                with contextlib.nested(
-                    self.l7policy_rule(policy_id, no_delete=True),
-                    self.l7policy_rule(policy_id, no_delete=True)
-                ) as (r0, r1):
-                    req = self.new_show_request('l7policies',
-                                                policy_id,
-                                                fmt=self.fmt)
-                    policy_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertEqual(
-                        len(policy_update['l7policy']['rules']), 2)
-
-                    req = self.new_delete_request('l7policies',
-                                                  policy_id,
-                                                  subresource='rules',
-                                                  sub_id=r0['rule']['id'])
-                    res = req.get_response(self.ext_api)
-                    self.assertEqual(res.status_int,
-                                     webob.exc.HTTPNoContent.code)
-
-                    req = self.new_show_request('l7policies',
-                                                policy_id,
-                                                fmt=self.fmt)
-                    policy_update = self.deserialize(
-                        self.fmt,
-                        req.get_response(self.ext_api)
-                    )
-                    self.assertEqual(
-                        len(policy_update['l7policy']['rules']), 1)
-
-    def test_list_l7rules_with_sort_emulated(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.l7policy(listener_id) as policy:
-                policy_id = policy['l7policy']['id']
-                with contextlib.nested(
-                    self.l7policy_rule(policy_id, value="b"),
-                    self.l7policy_rule(policy_id, value="c"),
-                    self.l7policy_rule(policy_id, value="a")
-                ) as (r1, r2, r3):
-                    self._test_list_with_sort('l7policy', (r3, r1, r2),
-                                              [('value', 'asc')],
-                                              id=policy_id,
-                                              resources='l7policies',
-                                              subresource='rule',
-                                              subresources='rules')
-
-    def test_list_l7rules_with_pagination_emulated(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.l7policy(listener_id) as policy:
-                policy_id = policy['l7policy']['id']
-                with contextlib.nested(
-                    self.l7policy_rule(policy_id, value="b"),
-                    self.l7policy_rule(policy_id, value="c"),
-                    self.l7policy_rule(policy_id, value="e"),
-                    self.l7policy_rule(policy_id, value="d"),
-                    self.l7policy_rule(policy_id, value="f"),
-                    self.l7policy_rule(policy_id, value="g"),
-                    self.l7policy_rule(policy_id, value="a")
-                ) as (r1, r2, r3, r4, r5, r6, r7):
-                    self._test_list_with_pagination(
-                        'l7policy', (r6, r5, r3, r4, r2, r1, r7),
-                        ('value', 'desc'), 2, 4,
-                        id=policy_id,
-                        resources='l7policies',
-                        subresource='rule',
-                        subresources='rules')
-
-    def test_list_l7rules_with_pagination_reverse_emulated(self):
-        with self.listener(loadbalancer_id=self.lb_id) as listener:
-            listener_id = listener['listener']['id']
-            with self.l7policy(listener_id) as p:
-                policy_id = p['l7policy']['id']
-                with contextlib.nested(
-                    self.l7policy_rule(policy_id, value="b"),
-                    self.l7policy_rule(policy_id, value="c"),
-                    self.l7policy_rule(policy_id, value="e"),
-                    self.l7policy_rule(policy_id, value="d"),
-                    self.l7policy_rule(policy_id, value="f"),
-                    self.l7policy_rule(policy_id, value="g"),
-                    self.l7policy_rule(policy_id, value="a")
-                ) as (r1, r2, r3, r4, r5, r6, r7):
-                    self._test_list_with_pagination_reverse(
-                        'l7policy', (r6, r5, r3, r4, r2, r1, r7),
-                        ('value', 'desc'), 2, 4,
-                        id=policy_id,
-                        resources='l7policies',
-                        subresource='rule',
-                        subresources='rules')
-
-
-class PoolTestBase(ListenerTestBase):
-
-    def setUp(self):
-        super(PoolTestBase, self).setUp()
-        listener_res = self._create_listener(self.fmt, lb_const.PROTOCOL_HTTP,
-                                             80, self.lb_id)
-        listener_res2 = self._create_listener(self.fmt, lb_const.PROTOCOL_HTTP,
-                                              80, self.lb_id2)
-        self.def_listener = self.deserialize(self.fmt, listener_res)
-        self.def_listener2 = self.deserialize(self.fmt, listener_res2)
-        self.listener_id = self.def_listener['listener']['id']
-        self.listener_id2 = self.def_listener2['listener']['id']
-        self.loadbalancer_id = self.lb_id
-        self.loadbalancer_id2 = self.lb_id2
-
-    def tearDown(self):
-        self._delete_listener_api(self.listener_id)
-        super(PoolTestBase, self).tearDown()
-
-    def _create_pool_api(self, data):
-        req = self.new_create_request("pools", data, self.fmt)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _update_pool_api(self, pool_id, data):
-        req = self.new_update_request('pools', data, pool_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _delete_pool_api(self, pool_id):
-        req = self.new_delete_request('pools', pool_id)
-        resp = req.get_response(self.ext_api)
-        return resp
-
-    def _get_pool_api(self, pool_id):
-        req = self.new_show_request('pools', pool_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _list_pools_api(self):
-        req = self.new_list_request('pools')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-
-class LbaasPoolTests(PoolTestBase):
-
-    def test_create_pool(self, **extras):
-        expected = {
-            'name': '',
-            'description': '',
-            'protocol': 'HTTP',
-            'lb_algorithm': 'ROUND_ROBIN',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'healthmonitor_id': None,
-            'members': []
-        }
-
-        expected.update(extras)
-
-        with self.pool(listener_id=self.listener_id, **extras) as pool:
-            pool_id = pool['pool'].get('id')
-            if ('session_persistence' in expected.keys() and
-                    expected['session_persistence'] is not None and
-                    not expected['session_persistence'].get('cookie_name')):
-                expected['session_persistence']['cookie_name'] = None
-            self.assertTrue(pool_id)
-
-            actual = {}
-            for k, v in pool['pool'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=pool_id)
-        return pool
-
-    def test_create_pool_with_loadbalancer_no_listener(self, **extras):
-        expected = {
-            'name': '',
-            'description': '',
-            'protocol': 'HTTP',
-            'lb_algorithm': 'ROUND_ROBIN',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'healthmonitor_id': None,
-            'members': []
-        }
-
-        expected.update(extras)
-
-        with self.pool(loadbalancer_id=self.loadbalancer_id, **extras) as pool:
-            pool_id = pool['pool'].get('id')
-            if 'session_persistence' in expected:
-                if not expected['session_persistence'].get('cookie_name'):
-                    expected['session_persistence']['cookie_name'] = None
-            self.assertTrue(pool_id)
-
-            actual = {}
-            for k, v in pool['pool'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, None, pool_id=pool_id)
-        return pool
-
-    def test_show_pool(self, **extras):
-        expected = {
-            'name': '',
-            'description': '',
-            'protocol': 'HTTP',
-            'lb_algorithm': 'ROUND_ROBIN',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'listeners': [{'id': self.listener_id}],
-            'healthmonitor_id': None,
-            'members': []
-        }
-
-        expected.update(extras)
-
-        with self.pool(listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            resp, body = self._get_pool_api(pool_id)
-            actual = {}
-            for k, v in body['pool'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-        return pool
-
-    def test_update_pool(self, **extras):
-        expected = {
-            'name': '',
-            'description': '',
-            'protocol': 'HTTP',
-            'lb_algorithm': 'LEAST_CONNECTIONS',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'listeners': [{'id': self.listener_id}],
-            'healthmonitor_id': None,
-            'members': []
-        }
-
-        expected.update(extras)
-
-        with self.pool(listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            self.assertTrue(pool_id)
-            data = {'pool': {'lb_algorithm': 'LEAST_CONNECTIONS'}}
-            resp, body = self._update_pool_api(pool_id, data)
-            actual = {}
-            for k, v in body['pool'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=pool_id)
-
-        return pool
-
-    def test_delete_pool(self):
-        with self.pool(no_delete=True, listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            qry = ctx.session.query(models.PoolV2)
-            qry = qry.filter_by(id=pool_id)
-            self.assertIsNotNone(qry.first())
-
-            resp = self._delete_pool_api(pool_id)
-            self.assertEqual(webob.exc.HTTPNoContent.code, resp.status_int)
-            qry = ctx.session.query(models.PoolV2)
-            qry = qry.filter_by(id=pool['pool']['id'])
-            self.assertIsNone(qry.first())
-
-    def test_delete_pool_and_members(self):
-        with self.pool(listener_id=self.listener_id, no_delete=True) as pool:
-            pool_id = pool['pool']['id']
-            with self.member(pool_id=pool_id, no_delete=True) as member:
-                member_id = member['member']['id']
-                ctx = context.get_admin_context()
-                # this will only set status, it requires driver to delete
-                # from db.  Since the LoggingNoopDriver is being used it
-                # should delete from db
-                self.plugin.delete_pool(ctx, pool_id)
-                # verify member got deleted as well
-                self.assertRaises(
-                    loadbalancerv2.EntityNotFound,
-                    self.plugin.db.get_pool_member,
-                    ctx, member_id)
-
-    def test_delete_pool_and_hm(self):
-        with self.pool(listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            with self.healthmonitor(pool_id=pool_id):
-                # verify pool deletion is prevented if HM is associated
-                ctx = context.get_admin_context()
-                self.assertRaises(
-                    loadbalancerv2.EntityInUse,
-                    self.plugin.delete_pool,
-                    ctx, pool_id)
-
-    def test_cannot_add_multiple_pools_to_listener(self):
-        with self.pool(listener_id=self.listener_id):
-            data = {'pool': {'name': '',
-                             'description': '',
-                             'protocol': 'HTTP',
-                             'lb_algorithm': 'ROUND_ROBIN',
-                             'admin_state_up': True,
-                             'tenant_id': self._tenant_id,
-                             'listener_id': self.listener_id}}
-            resp, body = self._create_pool_api(data)
-            self.assertEqual(webob.exc.HTTPConflict.code, resp.status_int)
-
-    def test_create_pool_with_pool_protocol_mismatch(self):
-        with self.listener(protocol=lb_const.PROTOCOL_HTTPS,
-                           loadbalancer_id=self.lb_id,
-                           protocol_port=443) as listener:
-            listener_id = listener['listener']['id']
-            data = {'pool': {'listener_id': listener_id,
-                             'protocol': lb_const.PROTOCOL_HTTP,
-                             'lb_algorithm': lb_const.LB_METHOD_ROUND_ROBIN,
-                             'tenant_id': self._tenant_id}}
-            resp, body = self._create_pool_api(data)
-            self.assertEqual(webob.exc.HTTPConflict.code, resp.status_int)
-
-    def test_create_pool_with_protocol_invalid(self):
-        data = {'pool': {
-            'name': '',
-            'description': '',
-            'protocol': 'BLANK',
-            'lb_algorithm': 'LEAST_CONNECTIONS',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id
-        }}
-        resp, body = self._create_pool_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_can_create_pool_with_listener_loadbalancer_match(self):
-        with self.subnet() as subnet:
-            with self.loadbalancer(subnet=subnet) as loadbalancer:
-                lb_id = loadbalancer['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as l1:
-                    l_id = l1['listener']['id']
-                    with self.pool(listener_id=l_id,
-                                   loadbalancer_id=lb_id):
-                        pass
-
-    def test_cannot_create_pool_with_listener_loadbalancer_mismatch(self):
-        with self.subnet() as subnet:
-            with contextlib.nested(self.loadbalancer(subnet=subnet),
-                                   self.loadbalancer(subnet=subnet)
-                                   ) as (lb1, lb2):
-                lb_id1 = lb1['loadbalancer']['id']
-                lb_id2 = lb2['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id1) as l1:
-                    l_id = l1['listener']['id']
-                    data = {'pool': {'name': '',
-                                     'description': '',
-                                     'protocol': 'HTTP',
-                                     'lb_algorithm': 'ROUND_ROBIN',
-                                     'admin_state_up': True,
-                                     'tenant_id': self._tenant_id,
-                                     'listener_id': l_id,
-                                     'loadbalancer_id': lb_id2}}
-                    resp, body = self._create_pool_api(data)
-                    self.assertEqual(resp.status_int,
-                                     webob.exc.HTTPBadRequest.code)
-
-    def test_create_pool_with_session_persistence(self):
-        self.test_create_pool(session_persistence={'type': 'HTTP_COOKIE'})
-
-    def test_create_pool_with_session_persistence_none(self):
-        self.test_create_pool(session_persistence=None)
-
-    def test_create_pool_with_session_persistence_with_app_cookie(self):
-        sp = {'type': 'APP_COOKIE', 'cookie_name': 'sessionId'}
-        self.test_create_pool(session_persistence=sp)
-
-    def test_create_pool_with_session_persistence_unsupported_type(self):
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_pool(session_persistence={'type': 'UNSUPPORTED'})
-
-    def test_create_pool_with_unnecessary_cookie_name(self):
-        sp = {'type': "SOURCE_IP", 'cookie_name': 'sessionId'}
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_pool(session_persistence=sp)
-
-    def test_create_pool_with_session_persistence_without_cookie_name(self):
-        sp = {'type': "APP_COOKIE"}
-        with testtools.ExpectedException(webob.exc.HTTPClientError):
-            self.test_create_pool(session_persistence=sp)
-
-    def test_validate_session_persistence_valid_with_cookie_name(self):
-        sp = {'type': 'APP_COOKIE', 'cookie_name': 'MyCookie'}
-        self.assertIsNone(
-            self.plugin._validate_session_persistence_info(sp_info=sp))
-
-    def test_validate_session_persistence_invalid_with_cookie_name(self):
-        sp = {'type': 'HTTP', 'cookie_name': 'MyCookie'}
-        with testtools.ExpectedException(
-                loadbalancerv2.SessionPersistenceConfigurationInvalid):
-            self.plugin._validate_session_persistence_info(sp_info=sp)
-
-    def test_validate_session_persistence_invalid_without_cookie_name(self):
-        sp = {'type': 'APP_COOKIE'}
-        with testtools.ExpectedException(
-                loadbalancerv2.SessionPersistenceConfigurationInvalid):
-            self.plugin._validate_session_persistence_info(sp_info=sp)
-
-    def test_reset_session_persistence(self):
-        name = 'pool4'
-        sp = {'type': "HTTP_COOKIE"}
-
-        update_info = {'pool': {'session_persistence': None}}
-
-        with self.pool(name=name, session_persistence=sp,
-                       listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            sp['cookie_name'] = None
-            # Ensure that pool has been created properly
-            self.assertEqual(pool['pool']['session_persistence'],
-                             sp)
-
-            # Try resetting session_persistence
-            resp, body = self._update_pool_api(pool_id, update_info)
-
-            self.assertIsNone(body['pool'].get('session_persistence'))
-
-    def test_update_no_change_session_persistence(self):
-        name = 'pool4'
-        sp = {'type': "HTTP_COOKIE"}
-
-        update_info = {'pool': {'lb_algorithm': 'ROUND_ROBIN'}}
-
-        with self.pool(name=name, session_persistence=sp,
-                       listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            sp['cookie_name'] = None
-            # Ensure that pool has been created properly
-            self.assertEqual(pool['pool']['session_persistence'],
-                             sp)
-
-            # Try updating something other than session_persistence
-            resp, body = self._update_pool_api(pool_id, update_info)
-            # Make sure session_persistence is unchanged
-            self.assertEqual(pool['pool']['session_persistence'],
-                             sp)
-
-    def test_update_pool_with_protocol(self):
-        with self.pool(listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            data = {'pool': {'protocol': 'BLANK'}}
-            resp, body = self._update_pool_api(pool_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_list_pools(self):
-        name = 'list_pools'
-        expected_values = {'name': name,
-                           'protocol': 'HTTP',
-                           'description': 'apool',
-                           'lb_algorithm': 'ROUND_ROBIN',
-                           'admin_state_up': True,
-                           'tenant_id': self._tenant_id,
-                           'session_persistence': {'cookie_name': None,
-                                                   'type': 'HTTP_COOKIE'},
-                           'loadbalancers': [{'id': self.lb_id}],
-                           'members': []}
-
-        with self.pool(name=name, listener_id=self.listener_id,
-                       description='apool',
-                       session_persistence={'type': 'HTTP_COOKIE'},
-                       members=[]) as pool:
-            pool_id = pool['pool']['id']
-            expected_values['id'] = pool_id
-            resp, body = self._list_pools_api()
-            pool_list = body['pools']
-            self.assertEqual(1, len(pool_list))
-            for k in expected_values:
-                self.assertEqual(expected_values[k], pool_list[0][k])
-
-    def test_list_pools_with_sort_emulated(self):
-        with contextlib.nested(self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=81,
-                                             protocol=lb_const.PROTOCOL_HTTPS),
-                               self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=82,
-                                             protocol=lb_const.PROTOCOL_TCP),
-                               self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=83,
-                                             protocol=lb_const.PROTOCOL_HTTP)
-                               ) as (l1, l2, l3):
-            with contextlib.nested(self.pool(listener_id=l1['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_HTTPS),
-                                   self.pool(listener_id=l2['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_TCP),
-                                   self.pool(listener_id=l3['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_HTTP)
-                                   ) as (p1, p2, p3):
-                self._test_list_with_sort('pool', (p2, p1, p3),
-                                          [('protocol', 'desc')])
-
-    def test_list_pools_with_pagination_emulated(self):
-        with contextlib.nested(self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=81,
-                                             protocol=lb_const.PROTOCOL_HTTPS),
-                               self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=82,
-                                             protocol=lb_const.PROTOCOL_TCP),
-                               self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=83,
-                                             protocol=lb_const.PROTOCOL_HTTP)
-                               ) as (l1, l2, l3):
-            with contextlib.nested(self.pool(listener_id=l1['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_HTTPS),
-                                   self.pool(listener_id=l2['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_TCP),
-                                   self.pool(listener_id=l3['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_HTTP)
-                                   ) as (p1, p2, p3):
-                self._test_list_with_pagination('pool',
-                                                (p3, p1, p2),
-                                                ('protocol', 'asc'), 2, 2)
-
-    def test_list_pools_with_pagination_reverse_emulated(self):
-        with contextlib.nested(self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=81,
-                                             protocol=lb_const.PROTOCOL_HTTPS),
-                               self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=82,
-                                             protocol=lb_const.PROTOCOL_TCP),
-                               self.listener(loadbalancer_id=self.lb_id,
-                                             protocol_port=83,
-                                             protocol=lb_const.PROTOCOL_HTTP)
-                               ) as (l1, l2, l3):
-            with contextlib.nested(self.pool(listener_id=l1['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_HTTPS),
-                                   self.pool(listener_id=l2['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_TCP),
-                                   self.pool(listener_id=l3['listener']['id'],
-                                             protocol=lb_const.PROTOCOL_HTTP)
-                                   ) as (p1, p2, p3):
-                self._test_list_with_pagination_reverse('pool',
-                                                        (p3, p1, p2),
-                                                        ('protocol', 'asc'),
-                                                        2, 2)
-
-    def test_get_listener_shows_default_pool(self):
-        with self.pool(listener_id=self.listener_id) as pool:
-            pool_id = pool['pool']['id']
-            resp, body = self._get_listener_api(self.listener_id)
-            self.assertEqual(pool_id, body['listener']['default_pool_id'])
-
-
-class MemberTestBase(PoolTestBase):
-    def setUp(self):
-        super(MemberTestBase, self).setUp()
-        pool_res = self._create_pool(
-            self.fmt, lb_const.PROTOCOL_HTTP,
-            lb_const.LB_METHOD_ROUND_ROBIN,
-            self.listener_id,
-            self.lb_id,
-            session_persistence={'type':
-                                 lb_const.SESSION_PERSISTENCE_HTTP_COOKIE})
-        self.pool = self.deserialize(self.fmt, pool_res)
-        self.pool_id = self.pool['pool']['id']
-        alt_listener_res = self._create_listener(
-            self.fmt, lb_const.PROTOCOL_HTTP,
-            self.def_listener['listener']['protocol_port'] + 1,
-            self.lb_id
-        )
-        self.alt_listener = self.deserialize(self.fmt, alt_listener_res)
-        self.alt_listener_id = self.alt_listener['listener']['id']
-        alt_pool_res = self._create_pool(
-            self.fmt, lb_const.PROTOCOL_HTTP,
-            lb_const.LB_METHOD_ROUND_ROBIN,
-            self.alt_listener_id,
-            session_persistence={'type':
-                                 lb_const.SESSION_PERSISTENCE_HTTP_COOKIE})
-        self.alt_pool = self.deserialize(self.fmt, alt_pool_res)
-        self.alt_pool_id = self.alt_pool['pool']['id']
-
-    def tearDown(self):
-        self._delete('pools', self.alt_pool_id)
-        self._delete('pools', self.pool_id)
-        super(MemberTestBase, self).tearDown()
-
-    def _create_member_api(self, pool_id, data):
-        req = self.new_create_request("pools", data, self.fmt, id=pool_id,
-                                      subresource='members')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _update_member_api(self, pool_id, member_id, data):
-        req = self.new_update_request('pools', data, pool_id,
-                                      subresource='members', sub_id=member_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _delete_member_api(self, pool_id, member_id):
-        req = self.new_delete_request('pools', pool_id, subresource='members',
-                                      sub_id=member_id)
-        resp = req.get_response(self.ext_api)
-        return resp
-
-    def _get_member_api(self, pool_id, member_id):
-        req = self.new_show_request('pools', pool_id, subresource='members',
-                                    sub_id=member_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _list_members_api(self, pool_id):
-        req = self.new_list_request('pools', id=pool_id, subresource='members')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-
-class LbaasMemberTests(MemberTestBase):
-
-    def test_create_member(self, **extras):
-        expected = {
-            'address': '127.0.0.1',
-            'protocol_port': 80,
-            'weight': 1,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'subnet_id': '',
-            'name': 'member1'
-        }
-
-        expected.update(extras)
-
-        expected['subnet_id'] = self.test_subnet_id
-        with self.member(pool_id=self.pool_id, name='member1') as member:
-            member_id = member['member'].get('id')
-            self.assertTrue(member_id)
-
-            actual = {}
-            for k, v in member['member'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=self.pool_id,
-                                    member_id=member_id)
-        return member
-
-    def test_create_member_with_existing_address_port_pool_combination(self):
-        with self.member(pool_id=self.pool_id) as member1:
-            member1 = member1['member']
-            member_data = {
-                'address': member1['address'],
-                'protocol_port': member1['protocol_port'],
-                'weight': 1,
-                'subnet_id': member1['subnet_id'],
-                'admin_state_up': True,
-                'tenant_id': member1['tenant_id']
-            }
-            self.assertRaises(
-                loadbalancerv2.MemberExists,
-                self.plugin.create_pool_member,
-                context.get_admin_context(),
-                self.pool_id,
-                {'member': member_data})
-
-    def test_update_member(self):
-        keys = [('address', "127.0.0.1"),
-                ('tenant_id', self._tenant_id),
-                ('protocol_port', 80),
-                ('weight', 10),
-                ('admin_state_up', False),
-                ('name', 'member2')]
-        with self.member(pool_id=self.pool_id) as member:
-            member_id = member['member']['id']
-            resp, pool1_update = self._get_pool_api(self.pool_id)
-            self.assertEqual(1, len(pool1_update['pool']['members']))
-            data = {'member': {'weight': 10, 'admin_state_up': False,
-                               'name': 'member2'}}
-            resp, body = self._update_member_api(self.pool_id, member_id, data)
-            for k, v in keys:
-                self.assertEqual(v, body['member'][k])
-            resp, pool1_update = self._get_pool_api(self.pool_id)
-            self.assertEqual(1, len(pool1_update['pool']['members']))
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=self.pool_id,
-                                    member_id=member_id, member_disabled=True)
-
-    def test_delete_member(self):
-        with self.member(pool_id=self.pool_id, no_delete=True) as member:
-            member_id = member['member']['id']
-            resp = self._delete_member_api(self.pool_id, member_id)
-            self.assertEqual(webob.exc.HTTPNoContent.code, resp.status_int)
-            resp, pool_update = self._get_pool_api(self.pool_id)
-            self.assertEqual(0, len(pool_update['pool']['members']))
-
-    def test_show_member(self):
-        keys = [('address', "127.0.0.1"),
-                ('tenant_id', self._tenant_id),
-                ('protocol_port', 80),
-                ('weight', 1),
-                ('admin_state_up', True),
-                ('name', 'member1')]
-        with self.member(pool_id=self.pool_id,
-                         name='member1') as member:
-            member_id = member['member']['id']
-            resp, body = self._get_member_api(self.pool_id, member_id)
-            for k, v in keys:
-                self.assertEqual(v, body['member'][k])
-
-    def test_list_members(self):
-        with self.member(pool_id=self.pool_id,
-                         name='member1', protocol_port=81):
-            resp, body = self._list_members_api(self.pool_id)
-            self.assertEqual(1, len(body['members']))
-
-    def test_list_members_only_for_pool(self):
-        with self.member(pool_id=self.alt_pool_id):
-            with self.member(pool_id=self.pool_id,
-                             protocol_port=81) as in_member:
-                resp, body = self._list_members_api(self.pool_id)
-                self.assertEqual(len(body['members']), 1)
-                self.assertIn(in_member['member'], body['members'])
-
-    def test_list_members_with_sort_emulated(self):
-        with self.member(pool_id=self.pool_id, protocol_port=81) as m1:
-            with self.member(pool_id=self.pool_id, protocol_port=82) as m2:
-                with self.member(pool_id=self.pool_id, protocol_port=83) as m3:
-                    self._test_list_with_sort(
-                        'pool', (m3, m2, m1),
-                        [('protocol_port', 'desc')],
-                        id=self.pool_id,
-                        subresource='member')
-
-    def test_list_members_with_pagination_emulated(self):
-        with self.member(pool_id=self.pool_id, protocol_port=81) as m1:
-            with self.member(pool_id=self.pool_id, protocol_port=82) as m2:
-                with self.member(pool_id=self.pool_id, protocol_port=83) as m3:
-                    self._test_list_with_pagination(
-                        'pool', (m1, m2, m3), ('protocol_port', 'asc'),
-                        2, 2,
-                        id=self.pool_id, subresource='member'
-                    )
-
-    def test_list_members_with_pagination_reverse_emulated(self):
-        with self.member(pool_id=self.pool_id, protocol_port=81) as m1:
-            with self.member(pool_id=self.pool_id, protocol_port=82) as m2:
-                with self.member(pool_id=self.pool_id, protocol_port=83) as m3:
-                    self._test_list_with_pagination_reverse(
-                        'pool', (m1, m2, m3), ('protocol_port', 'asc'),
-                        2, 2,
-                        id=self.pool_id, subresource='member'
-                    )
-
-    def test_list_members_invalid_pool_id(self):
-        resp, body = self._list_members_api('WRONG_POOL_ID')
-        self.assertEqual(webob.exc.HTTPNotFound.code, resp.status_int)
-        resp, body = self._list_members_api(self.pool_id)
-        self.assertEqual(webob.exc.HTTPOk.code, resp.status_int)
-
-    def test_get_member_invalid_pool_id(self):
-        with self.member(pool_id=self.pool_id) as member:
-            member_id = member['member']['id']
-            resp, body = self._get_member_api('WRONG_POOL_ID', member_id)
-            self.assertEqual(webob.exc.HTTPNotFound.code, resp.status_int)
-            resp, body = self._get_member_api(self.pool_id, member_id)
-            self.assertEqual(webob.exc.HTTPOk.code, resp.status_int)
-
-    def test_create_member_invalid_pool_id(self):
-        data = {'member': {'address': '127.0.0.1',
-                           'protocol_port': 80,
-                           'weight': 1,
-                           'admin_state_up': True,
-                           'tenant_id': self._tenant_id,
-                           'subnet_id': self.test_subnet_id}}
-        resp, body = self._create_member_api('WRONG_POOL_ID', data)
-        self.assertEqual(webob.exc.HTTPNotFound.code, resp.status_int)
-
-    def test_update_member_invalid_pool_id(self):
-        with self.member(pool_id=self.pool_id) as member:
-            member_id = member['member']['id']
-            data = {'member': {'weight': 1}}
-            resp, body = self._update_member_api(
-                'WRONG_POOL_ID', member_id, data)
-            self.assertEqual(webob.exc.HTTPNotFound.code, resp.status_int)
-
-    def test_create_member_invalid_name(self):
-        data = {'member': {'address': '127.0.0.1',
-                           'protocol_port': 80,
-                           'weight': 1,
-                           'admin_state_up': True,
-                           'tenant_id': self._tenant_id,
-                           'subnet_id': self.test_subnet_id,
-                           'name': 123}}
-        resp, body = self._create_member_api('POOL_ID', data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_delete_member_invalid_pool_id(self):
-        with self.member(pool_id=self.pool_id) as member:
-            member_id = member['member']['id']
-            resp = self._delete_member_api('WRONG_POOL_ID', member_id)
-            self.assertEqual(webob.exc.HTTPNotFound.code, resp.status_int)
-
-    def test_get_pool_shows_members(self):
-        with self.member(pool_id=self.pool_id,
-                         name='member1') as member:
-            expected = {'id': member['member']['id']}
-            resp, body = self._get_pool_api(self.pool_id)
-            self.assertIn(expected, body['pool']['members'])
-
-
-class HealthMonitorTestBase(MemberTestBase):
-
-    def _create_healthmonitor_api(self, data):
-        req = self.new_create_request("healthmonitors", data, self.fmt)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _update_healthmonitor_api(self, hm_id, data):
-        req = self.new_update_request('healthmonitors', data, hm_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _delete_healthmonitor_api(self, hm_id):
-        req = self.new_delete_request('healthmonitors', hm_id)
-        resp = req.get_response(self.ext_api)
-        return resp
-
-    def _get_healthmonitor_api(self, hm_id):
-        req = self.new_show_request('healthmonitors', hm_id)
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-    def _list_healthmonitors_api(self):
-        req = self.new_list_request('healthmonitors')
-        resp = req.get_response(self.ext_api)
-        body = self.deserialize(self.fmt, resp)
-        return resp, body
-
-
-class LbaasHealthMonitorTests(HealthMonitorTestBase):
-
-    def test_create_healthmonitor(self, **extras):
-        expected = {
-            'type': 'HTTP',
-            'delay': 1,
-            'timeout': 1,
-            'max_retries': 1,
-            'http_method': 'GET',
-            'url_path': '/',
-            'expected_codes': '200',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor1'
-        }
-
-        expected.update(extras)
-
-        with self.healthmonitor(pool_id=self.pool_id, type='HTTP',
-                                name='monitor1', **extras) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor'].get('id')
-            self.assertTrue(hm_id)
-
-            actual = {}
-            for k, v in healthmonitor['healthmonitor'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=self.pool_id,
-                                    hm_id=hm_id)
-            _, pool = self._get_pool_api(self.pool_id)
-            self.assertEqual(
-                {'type': lb_const.SESSION_PERSISTENCE_HTTP_COOKIE,
-                 'cookie_name': None},
-                pool['pool'].get('session_persistence'))
-        return healthmonitor
-
-    def test_show_healthmonitor(self, **extras):
-        expected = {
-            'type': 'HTTP',
-            'delay': 1,
-            'timeout': 1,
-            'max_retries': 1,
-            'http_method': 'GET',
-            'url_path': '/',
-            'expected_codes': '200',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor1'
-
-        }
-
-        expected.update(extras)
-
-        with self.healthmonitor(pool_id=self.pool_id, type='HTTP',
-                                name='monitor1') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            resp, body = self._get_healthmonitor_api(hm_id)
-            actual = {}
-            for k, v in body['healthmonitor'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-
-        return healthmonitor
-
-    def test_update_healthmonitor(self, **extras):
-        expected = {
-            'type': 'HTTP',
-            'delay': 30,
-            'timeout': 10,
-            'max_retries': 4,
-            'http_method': 'GET',
-            'url_path': '/index.html',
-            'expected_codes': '200,404',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor2'
-        }
-
-        expected.update(extras)
-
-        with self.healthmonitor(pool_id=self.pool_id, type='HTTP',
-                                name='monitor1') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'delay': 30,
-                                      'timeout': 10,
-                                      'max_retries': 4,
-                                      'expected_codes': '200,404',
-                                      'url_path': '/index.html',
-                                      'name': 'monitor2'}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            actual = {}
-            for k, v in body['healthmonitor'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=self.pool_id,
-                                    hm_id=hm_id)
-
-        return healthmonitor
-
-    def test_delete_healthmonitor(self):
-        with self.healthmonitor(pool_id=self.pool_id,
-                                no_delete=True) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            resp = self._delete_healthmonitor_api(hm_id)
-            self.assertEqual(webob.exc.HTTPNoContent.code, resp.status_int)
-
-    def test_create_healthmonitor_with_type_tcp(self, **extras):
-        expected = {
-            'type': 'TCP',
-            'delay': 1,
-            'timeout': 1,
-            'max_retries': 1,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor1'
-        }
-
-        expected.update(extras)
-
-        with self.healthmonitor(pool_id=self.pool_id,
-                                type='TCP',
-                                name='monitor1') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor'].get('id')
-            self.assertTrue(hm_id)
-
-            actual = {}
-            for k, v in healthmonitor['healthmonitor'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=self.pool_id, hm_id=hm_id)
-        return healthmonitor
-
-    def test_show_healthmonitor_with_type_tcp(self, **extras):
-        expected = {
-            'type': 'TCP',
-            'delay': 1,
-            'timeout': 1,
-            'max_retries': 1,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor1'
-
-        }
-
-        expected.update(extras)
-
-        with self.healthmonitor(pool_id=self.pool_id,
-                                type='TCP',
-                                name='monitor1') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            resp, body = self._get_healthmonitor_api(hm_id)
-            actual = {}
-            for k, v in body['healthmonitor'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-
-        return healthmonitor
-
-    def test_update_healthmonitor_with_type_tcp(self, **extras):
-        expected = {
-            'type': 'TCP',
-            'delay': 30,
-            'timeout': 10,
-            'max_retries': 4,
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor2'
-        }
-
-        expected.update(extras)
-
-        with self.healthmonitor(pool_id=self.pool_id,
-                                type='TCP',
-                                name='monitor1') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'delay': 30,
-                                      'timeout': 10,
-                                      'max_retries': 4,
-                                      'name': 'monitor2'}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            actual = {}
-            for k, v in body['healthmonitor'].items():
-                if k in expected:
-                    actual[k] = v
-            self.assertEqual(expected, actual)
-            self._validate_statuses(self.lb_id, self.listener_id,
-                                    pool_id=self.pool_id, hm_id=hm_id)
-
-        return healthmonitor
-
-    def test_create_health_monitor_with_timeout_invalid(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'delay': 1,
-                                  'timeout': -1,
-                                  'max_retries': 2,
-                                  'admin_state_up': True,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_update_health_monitor_with_timeout_invalid(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'delay': 10,
-                                      'timeout': -1,
-                                      'max_retries': 2,
-                                      'admin_state_up': False}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_create_health_monitor_with_delay_invalid(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'delay': -1,
-                                  'timeout': 1,
-                                  'max_retries': 2,
-                                  'admin_state_up': True,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_update_health_monitor_with_delay_invalid(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'delay': -1,
-                                      'timeout': 1,
-                                      'max_retries': 2,
-                                      'admin_state_up': False}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_create_health_monitor_with_max_retries_invalid(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'delay': 1,
-                                  'timeout': 1,
-                                  'max_retries': 20,
-                                  'admin_state_up': True,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_update_health_monitor_with_max_retries_invalid(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'delay': 1,
-                                      'timeout': 1,
-                                      'max_retries': 20,
-                                      'admin_state_up': False}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_create_health_monitor_with_type_invalid(self):
-        data = {'healthmonitor': {'type': 1,
-                                  'delay': 1,
-                                  'timeout': 1,
-                                  'max_retries': 2,
-                                  'admin_state_up': True,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_update_health_monitor_with_type_invalid(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'type': 1,
-                                      'delay': 1,
-                                      'timeout': 1,
-                                      'max_retries': 2,
-                                      'admin_state_up': False}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_create_health_monitor_with_http_method_non_default(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'http_method': 'POST',
-                                  'delay': 2,
-                                  'timeout': 1,
-                                  'max_retries': 2,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(201, resp.status_int)
-        self._delete('healthmonitors', body['healthmonitor']['id'])
-
-    def test_create_health_monitor_with_http_method_invalid(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'http_method': 'FOO',
-                                  'delay': 1,
-                                  'timeout': 1,
-                                  'max_retries': 2,
-                                  'admin_state_up': True,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_update_health_monitor_with_http_method_invalid(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'type': 'HTTP',
-                                      'http_method': 'FOO',
-                                      'delay': 1,
-                                      'timeout': 1,
-                                      'max_retries': 2,
-                                      'admin_state_up': False}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_create_health_monitor_with_url_path_non_default(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'url_path': '/a/b_c-d/e%20f',
-                                  'delay': 2,
-                                  'timeout': 1,
-                                  'max_retries': 2,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(201, resp.status_int)
-        self._delete('healthmonitors', body['healthmonitor']['id'])
-
-    def test_create_health_monitor_with_url_path_invalid(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'url_path': 1,
-                                  'delay': 1,
-                                  'timeout': 1,
-                                  'max_retries': 2,
-                                  'admin_state_up': True,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_update_health_monitor_with_url_path_invalid(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            data = {'healthmonitor': {'url_path': 1,
-                                      'delay': 1,
-                                      'timeout': 1,
-                                      'max_retries': 2,
-                                      'admin_state_up': False}}
-            resp, body = self._update_healthmonitor_api(hm_id, data)
-            self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_create_healthmonitor_invalid_pool_id(self):
-        data = {'healthmonitor': {'type': lb_const.HEALTH_MONITOR_TCP,
-                                  'delay': 1,
-                                  'timeout': 1,
-                                  'max_retries': 1,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': uuidutils.generate_uuid()}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPNotFound.code, resp.status_int)
-
-    def test_create_healthmonitor_invalid_name(self):
-        data = {'healthmonitor': {'type': lb_const.HEALTH_MONITOR_TCP,
-                                  'delay': 1,
-                                  'timeout': 1,
-                                  'max_retries': 1,
-                                  'tenant_id': self._tenant_id,
-                                  'pool_id': self.pool_id,
-                                  'name': 123}}
-        resp, body = self._create_healthmonitor_api(data)
-        self.assertEqual(webob.exc.HTTPBadRequest.code, resp.status_int)
-
-    def test_only_one_healthmonitor_per_pool(self):
-        with self.healthmonitor(pool_id=self.pool_id):
-            data = {'healthmonitor': {'type': lb_const.HEALTH_MONITOR_TCP,
-                                      'delay': 1,
-                                      'timeout': 1,
-                                      'max_retries': 1,
-                                      'tenant_id': self._tenant_id,
-                                      'pool_id': self.pool_id}}
-            resp, body = self._create_healthmonitor_api(data)
-            self.assertEqual(webob.exc.HTTPConflict.code, resp.status_int)
-
-    def test_get_healthmonitor(self):
-        expected = {
-            'type': 'HTTP',
-            'delay': 1,
-            'timeout': 1,
-            'max_retries': 1,
-            'http_method': 'GET',
-            'url_path': '/',
-            'expected_codes': '200',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': 'monitor1'
-        }
-
-        with self.healthmonitor(pool_id=self.pool_id, type='HTTP',
-                                name='monitor1') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            expected['id'] = hm_id
-            resp, body = self._get_healthmonitor_api(hm_id)
-            self.assertEqual(expected, body['healthmonitor'])
-
-    def test_list_healthmonitors(self):
-        expected = {
-            'type': 'HTTP',
-            'delay': 1,
-            'timeout': 1,
-            'max_retries': 1,
-            'http_method': 'GET',
-            'url_path': '/',
-            'expected_codes': '200',
-            'admin_state_up': True,
-            'tenant_id': self._tenant_id,
-            'pools': [{'id': self.pool_id}],
-            'name': '',
-        }
-
-        with self.healthmonitor(pool_id=self.pool_id,
-                                type='HTTP') as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            expected['id'] = hm_id
-            resp, body = self._list_healthmonitors_api()
-            self.assertEqual([expected], body['healthmonitors'])
-
-    def test_get_pool_shows_healthmonitor_id(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor']['id']
-            resp, body = self._get_pool_api(self.pool_id)
-            self.assertEqual(hm_id, body['pool']['healthmonitor_id'])
-
-    def test_update_healthmonitor_status(self):
-        with self.healthmonitor(pool_id=self.pool_id) as healthmonitor:
-            hm_id = healthmonitor['healthmonitor'].get('id')
-            ctx = context.get_admin_context()
-            self.plugin.db.update_status(ctx,
-                                         models.HealthMonitorV2, hm_id,
-                                         provisioning_status=constants.ACTIVE,
-                                         operating_status=lb_const.DEGRADED)
-            db_hm = self.plugin.db.get_healthmonitor(ctx, hm_id)
-            self.assertEqual(constants.ACTIVE, db_hm.provisioning_status)
-            self.assertFalse(hasattr(db_hm, 'operating_status'))
-
-    def test_create_healthmonitor_admin_state_down(self):
-        self.test_create_healthmonitor(admin_state_up=False)
-
-
-class LbaasStatusesTest(MemberTestBase):
-    def setUp(self):
-        super(LbaasStatusesTest, self).setUp()
-        self.lbs_to_clean = []
-
-    def tearDown(self):
-        for lb_dict in self.lbs_to_clean:
-            self._delete_populated_lb(lb_dict)
-        super(LbaasStatusesTest, self).tearDown()
-
-    def test_disable_lb(self):
-        ctx = context.get_admin_context()
-        lb_dict = self._create_new_populated_loadbalancer()
-        lb_id = lb_dict['id']
-        opt = {'admin_state_up': False}
-        self.plugin.db.update_loadbalancer(ctx, lb_id, opt)
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        n_disabled = self._countDisabledChildren(statuses, 0)
-        self.assertEqual(11, n_disabled)
-
-    def _countDisabledChildren(self, obj, count):
-        if isinstance(obj, dict):
-            for key, value in six.iteritems(obj):
-                if key == "operating_status":
-                    count += 1
-                    continue
-                count = self._countDisabledChildren(value, count)
-        if isinstance(obj, list):
-            for value in obj:
-                count = self._countDisabledChildren(value, count)
-        return count
-
-    def test_disable_trickles_down(self):
-        lb_dict = self._create_new_populated_loadbalancer()
-        lb_id = lb_dict['id']
-        self._update_loadbalancer_api(lb_id,
-                                      {'loadbalancer': {
-                                          'admin_state_up': False}})
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        self._assertDisabled(self._traverse_statuses(statuses))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTP'))
-        self._assertDisabled(self._traverse_statuses(
-            statuses, listener='listener_HTTPS'))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTP',
-                                                     pool='pool_HTTP'))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTPS',
-                                                     pool='pool_HTTPS'))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTP',
-                                                     pool='pool_HTTP',
-                                                     member='127.0.0.1'))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTPS',
-                                                     pool='pool_HTTPS',
-                                                     member='127.0.0.4'))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTP',
-                                                     pool='pool_HTTP',
-                                                     healthmonitor=True))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTPS',
-                                                     pool='pool_HTTPS',
-                                                     healthmonitor=True))
-
-    def test_disable_not_calculated_in_degraded(self):
-        lb_dict = self._create_new_populated_loadbalancer()
-        lb_id = lb_dict['id']
-        listener_id = lb_dict['listeners'][0]['id']
-        listener = 'listener_HTTP'
-        self._update_listener_api(listener_id,
-                                  {'listener': {'admin_state_up': False}})
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        self._assertOnline(self._traverse_statuses(statuses))
-        self._update_listener_api(listener_id,
-                                  {'listener': {'admin_state_up': True}})
-        pool_id = lb_dict['listeners'][0]['pools'][0]['id']
-        pool = 'pool_HTTP'
-        member_id = lb_dict['listeners'][0]['pools'][0]['members'][0]['id']
-        member = '127.0.0.1'
-        self._update_member_api(pool_id, member_id,
-                                {'member': {'admin_state_up': False}})
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        self._assertOnline(self._traverse_statuses(statuses))
-        self._assertOnline(self._traverse_statuses(statuses,
-                                                   listener=listener))
-        self._assertOnline(self._traverse_statuses(statuses,
-                                                   listener=listener,
-                                                   pool=pool))
-        self._assertDisabled(self._traverse_statuses(statuses,
-                                                     listener=listener,
-                                                     pool=pool,
-                                                     member=member))
-
-    def test_that_failures_trickle_up_on_prov_errors(self):
-        ctx = context.get_admin_context()
-        ERROR = constants.ERROR
-        lb_dict = self._create_new_populated_loadbalancer()
-        lb_id = lb_dict['id']
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        stat = self._traverse_statuses(statuses, listener="listener_HTTP",
-                                       pool="pool_HTTP", member='127.0.0.1')
-        member_id = stat['id']
-        self.plugin.db.update_status(ctx, models.MemberV2, member_id,
-                                     provisioning_status=ERROR)
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        #Assert the parents of the member are degraded
-        self._assertDegraded(self._traverse_statuses(statuses,
-                                                     listener='listener_HTTP',
-                                                     pool='pool_HTTP'))
-        self._assertDegraded(self._traverse_statuses(statuses,
-                                                    listener='listener_HTTP'))
-        self._assertDegraded(self._traverse_statuses(statuses))
-        #Verify siblings are not degraded
-        self._assertNotDegraded(self._traverse_statuses(statuses,
-            listener='listener_HTTPS', pool='pool_HTTPS'))
-        self._assertNotDegraded(self._traverse_statuses(statuses,
-            listener='listener_HTTPS'))
-
-    def test_that_failures_trickle_up_on_non_ONLINE_prov_status(self):
-        ctx = context.get_admin_context()
-        lb_dict = self._create_new_populated_loadbalancer()
-        lb_id = lb_dict['id']
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        stat = self._traverse_statuses(statuses, listener="listener_HTTP",
-                                       pool="pool_HTTP", member='127.0.0.1')
-        member_id = stat['id']
-        self.plugin.db.update_status(ctx, models.MemberV2, member_id,
-                                     operating_status=lb_const.OFFLINE)
-        statuses = self._get_loadbalancer_statuses_api(lb_id)[1]
-        #Assert the parents of the member are degraded
-        self._assertDegraded(self._traverse_statuses(statuses,
-                                                    listener='listener_HTTP',
-                                                    pool='pool_HTTP'))
-        self._assertDegraded(self._traverse_statuses(statuses,
-                                                    listener='listener_HTTP'))
-        self._assertDegraded(self._traverse_statuses(statuses))
-        #Verify siblings are not degraded
-        self._assertNotDegraded(self._traverse_statuses(statuses,
-            listener='listener_HTTPS', pool='pool_HTTPS'))
-        self._assertNotDegraded(self._traverse_statuses(statuses,
-            listener='listener_HTTPS'))
-
-    def _assertOnline(self, obj):
-        OS = "operating_status"
-        if OS in obj:
-            self.assertEqual(lb_const.ONLINE, obj[OS])
-
-    def _assertDegraded(self, obj):
-        OS = "operating_status"
-        if OS in obj:
-            self.assertEqual(lb_const.DEGRADED, obj[OS])
-
-    def _assertNotDegraded(self, obj):
-        OS = "operating_status"
-        if OS in obj:
-            self.assertNotEqual(lb_const.DEGRADED, obj[OS])
-
-    def _assertDisabled(self, obj):
-        OS = "operating_status"
-        if OS in obj:
-            self.assertEqual(lb_const.DISABLED, obj[OS])
-
-    def _delete_populated_lb(self, lb_dict):
-        lb_id = lb_dict['id']
-        for pool in lb_dict['pools']:
-            pool_id = pool['id']
-            for member in pool['members']:
-                member_id = member['id']
-                self._delete_member_api(pool_id, member_id)
-            self._delete_pool_api(pool_id)
-        for listener in lb_dict['listeners']:
-            listener_id = listener['id']
-            self._delete_listener_api(listener_id)
-        self._delete_loadbalancer_api(lb_id)
-
-    def _traverse_statuses(self, statuses, listener=None, pool=None,
-                           member=None, healthmonitor=False):
-        lb = statuses['statuses']['loadbalancer']
-        if listener is None:
-            return copy.copy(lb)
-        listener_list = lb['listeners']
-        for listener_obj in listener_list:
-            if listener_obj['name'] == listener:
-                if pool is None:
-                    return copy.copy(listener_obj)
-                pool_list = listener_obj['pools']
-                for pool_obj in pool_list:
-                    if pool_obj['name'] == pool:
-                        if healthmonitor:
-                            return copy.copy(pool_obj['healthmonitor'])
-                        if member is None:
-                            return copy.copy(pool_obj)
-                        member_list = pool_obj['members']
-                        for member_obj in member_list:
-                            if member_obj['address'] == member:
-                                return copy.copy(member_obj)
-        pool_list = lb['pools']
-        for pool_obj in pool_list:
-            if pool_obj['name'] == pool:
-                if healthmonitor:
-                    return copy.copy(pool_obj['healthmonitor'])
-                if member is None:
-                    return copy.copy(pool_obj)
-                member_list = pool_obj['members']
-                for member_obj in member_list:
-                    if member_obj['address'] == member:
-                        return copy.copy(member_obj)
-        raise KeyError
-
-    def _create_new_populated_loadbalancer(self):
-        oct4 = 1
-        subnet_id = self.test_subnet_id
-        HTTP = lb_const.PROTOCOL_HTTP
-        HTTPS = lb_const.PROTOCOL_HTTPS
-        ROUND_ROBIN = lb_const.LB_METHOD_ROUND_ROBIN
-        fmt = self.fmt
-        lb_dict = {}
-        lb_res = self._create_loadbalancer(
-            self.fmt, subnet_id=self.test_subnet_id,
-            name='test_loadbalancer')
-        lb = self.deserialize(fmt, lb_res)
-        lb_id = lb['loadbalancer']['id']
-        lb_dict['id'] = lb_id
-        lb_dict['listeners'] = []
-        lb_dict['pools'] = []
-        for prot, port in [(HTTP, 80), (HTTPS, 443)]:
-            res = self._create_listener(fmt, prot, port, lb_id,
-                                        name="listener_%s" % prot)
-            listener = self.deserialize(fmt, res)
-            listener_id = listener['listener']['id']
-            lb_dict['listeners'].append({'id': listener_id, 'pools': []})
-            res = self._create_pool(fmt, prot, ROUND_ROBIN, listener_id,
-                                    loadbalancer_id=lb_id,
-                                    name="pool_%s" % prot)
-            pool = self.deserialize(fmt, res)
-            pool_id = pool['pool']['id']
-            members = []
-            lb_dict['listeners'][-1]['pools'].append({'id': pool['pool']['id'],
-                                                      'members': members})
-            lb_dict['pools'].append({'id': pool['pool']['id'],
-                                    'members': members})
-            res = self._create_healthmonitor(fmt, pool_id, type=prot, delay=1,
-                                             timeout=1, max_retries=1)
-            health_monitor = self.deserialize(fmt, res)
-            lb_dict['listeners'][-1]['pools'][-1]['health_monitor'] = {
-                'id': health_monitor['healthmonitor']['id']}
-            lb_dict['pools'][-1]['health_monitor'] = {
-                'id': health_monitor['healthmonitor']['id']}
-            for i in six.moves.range(0, 3):
-                address = "127.0.0.%i" % oct4
-                oct4 += 1
-                res = self._create_member(fmt, pool_id, address, port,
-                                          subnet_id)
-                member = self.deserialize(fmt, res)
-                members.append({'id': member['member']['id']})
-        self.lbs_to_clean.append(lb_dict)
-        return lb_dict
diff --git a/tests/unit/db/loadbalancer/test_migrations.py b/tests/unit/db/loadbalancer/test_migrations.py
deleted file mode 100644
index ee28258..0000000
--- a/tests/unit/db/loadbalancer/test_migrations.py
+++ /dev/null
@@ -1,61 +0,0 @@
-# Copyright (c) 2015 Cisco Systems, Inc.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from oslo_config import cfg
-
-from neutron.db.migration.alembic_migrations import external
-from neutron.db.migration import cli as migration
-from neutron.tests.common import base
-from neutron.tests.functional.db import test_migrations
-
-from neutron_lbaas.db.models import head
-
-# EXTERNAL_TABLES should contain all names of tables that are not related to
-# current repo.
-EXTERNAL_TABLES = set(external.TABLES) - set(external.LBAAS_TABLES)
-VERSION_TABLE = 'alembic_version_lbaas'
-
-
-class _TestModelsMigrationsLBAAS(test_migrations._TestModelsMigrations):
-    # TODO(yamamoto): Move this test to functional, once neutron-lbaas
-    # gets a functional job.
-
-    def db_sync(self, engine):
-        cfg.CONF.set_override('connection', engine.url, group='database')
-        for conf in migration.get_alembic_configs():
-            self.alembic_config = conf
-            self.alembic_config.neutron_config = cfg.CONF
-            migration.do_alembic_command(conf, 'upgrade', 'heads')
-
-    def get_metadata(self):
-        return head.get_metadata()
-
-    def include_object(self, object_, name, type_, reflected, compare_to):
-        if type_ == 'table' and (name.startswith('alembic') or
-                                 name == VERSION_TABLE or
-                                 name in EXTERNAL_TABLES):
-            return False
-        if type_ == 'index' and reflected and name.startswith("idx_autoinc_"):
-            return False
-        return True
-
-
-class TestModelsMigrationsMysql(_TestModelsMigrationsLBAAS,
-                                base.MySQLTestCase):
-    pass
-
-
-class TestModelsMigrationsPostgresql(_TestModelsMigrationsLBAAS,
-                                     base.PostgreSQLTestCase):
-    pass
diff --git a/tests/unit/drivers/__init__.py b/tests/unit/drivers/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/a10networks/__init__.py b/tests/unit/drivers/a10networks/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/a10networks/test_driver_v2.py b/tests/unit/drivers/a10networks/test_driver_v2.py
deleted file mode 100644
index c587cff..0000000
--- a/tests/unit/drivers/a10networks/test_driver_v2.py
+++ /dev/null
@@ -1,97 +0,0 @@
-# Copyright 2015, Doug Wiegley (dougwig), A10 Networks
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import sys
-
-import mock
-from neutron import context
-
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-with mock.patch.dict(sys.modules, {'a10_neutron_lbaas': mock.Mock()}):
-    from neutron_lbaas.drivers.a10networks import driver_v2
-
-
-class FakeModel(object):
-    def __init__(self, id):
-        self.id = id
-        self.address = '1.1.1.1'
-        self.tenant_id = "tennant-was-a-great-doctor"
-
-
-class ManagerTest(object):
-    def __init__(self, parent, manager, model, mocked_root):
-        self.parent = parent
-        self.context = parent.context
-        self.driver = parent.driver
-        self.manager = manager
-        self.model = model
-        self.mocked_root = mocked_root
-
-        self.create(model)
-        self.update(model, model)
-        self.delete(model)
-
-    def create(self, model):
-        self.manager.create(self.context, model)
-        self.mocked_root.create.assert_called_with(self.context, model)
-
-    def update(self, old_model, model):
-        self.manager.update(self.context, old_model, model)
-        self.mocked_root.update.assert_called_with(self.context,
-                                                   old_model, model)
-
-    def delete(self, model):
-        self.manager.delete(self.context, model)
-        self.mocked_root.delete.assert_called_with(self.context, model)
-
-    def refresh(self):
-        self.manager.refresh(self.context, self.model)
-        self.mocked_root.refresh.assert_called_with(self.context, self.model)
-
-    def stats(self):
-        self.manager.stats(self.context, self.model)
-        self.mocked_root.stats.assert_called_with(self.context, self.model)
-
-
-class TestA10ThunderDriver(test_db_loadbalancerv2.LbaasPluginDbTestCase):
-
-    def setUp(self):
-        super(TestA10ThunderDriver, self).setUp()
-        self.context = context.get_admin_context()
-        self.plugin = mock.Mock()
-        self.driver = driver_v2.ThunderDriver(self.plugin)
-        self.driver.a10 = mock.Mock()
-
-    def test_load_balancer_ops(self):
-        m = ManagerTest(self, self.driver.load_balancer,
-                        FakeModel("loadbalancer-a10"), self.driver.a10.lb)
-        m.refresh()
-        m.stats()
-
-    def test_listener_ops(self):
-        ManagerTest(self, self.driver.listener, FakeModel("listener-a10"),
-                    self.driver.a10.listener)
-
-    def test_pool_ops(self):
-        ManagerTest(self, self.driver.pool, FakeModel("pool-10"),
-                    self.driver.a10.pool)
-
-    def test_member_ops(self):
-        ManagerTest(self, self.driver.member, FakeModel("member-a10"),
-                    self.driver.a10.member)
-
-    def test_health_monitor_ops(self):
-        ManagerTest(self, self.driver.health_monitor, FakeModel("hm-a10"),
-                    self.driver.a10.hm)
diff --git a/tests/unit/drivers/brocade/__init__.py b/tests/unit/drivers/brocade/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/brocade/test_driver_v2.py b/tests/unit/drivers/brocade/test_driver_v2.py
deleted file mode 100644
index 3b5c2ee..0000000
--- a/tests/unit/drivers/brocade/test_driver_v2.py
+++ /dev/null
@@ -1,144 +0,0 @@
-# Copyright 2014 Brocade Communications Systems, Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-# Pattabi Ayyasami (pattabi), Brocade Communication Systems, Inc.
-#
-import sys
-
-import mock
-from neutron import context
-
-with mock.patch.dict(sys.modules, {'brocade_neutron_lbaas': mock.Mock()}):
-    from neutron_lbaas.drivers.brocade import driver_v2 as driver
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-
-class FakeModel(object):
-    def __init__(self, id):
-        self.id = id
-
-    def attached_to_loadbalancer(self):
-        return True
-
-
-class ManagerTest(object):
-    def __init__(self, parent, manager, model):
-        self.parent = parent
-        self.manager = manager
-        self.model = model
-
-        self.create(model)
-        self.update(model, model)
-        self.delete(model)
-
-    def create(self, model):
-        self.manager.create(self.parent.context, model)
-
-    def update(self, old_model, model):
-        self.manager.update(self.parent.context, old_model, model)
-
-    def delete(self, model):
-        self.manager.delete(self.parent.context, model)
-
-
-class LoadBalancerManagerTest(ManagerTest):
-    def __init__(self, parent, manager, model):
-        super(LoadBalancerManagerTest, self).__init__(parent, manager, model)
-
-        self.refresh(model)
-        self.stats(model)
-
-    def refresh(self, model):
-        self.manager.refresh(self.parent.context, model)
-        self.parent.driver.device_driver.refresh \
-            .assert_called_once_with(model)
-
-    def stats(self, model):
-        self.manager.stats(self.parent.context, model)
-        self.parent.driver.device_driver.stats.assert_called_once_with(model)
-
-
-class TestBrocadeLoadBalancerDriver(
-        test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def _create_fake_models(self):
-        id = 'name-001'
-        lb = data_models.LoadBalancer(id=id)
-        listener = data_models.Listener(id=id, loadbalancer=lb)
-        pool = data_models.Pool(id=id, loadbalancer=lb)
-        member = data_models.Member(id=id, pool=pool)
-        hm = data_models.HealthMonitor(id=id, pool=pool)
-        lb.listeners = [listener]
-        lb.pools = [pool]
-        listener.default_pool = pool
-        pool.members = [member]
-        pool.healthmonitor = hm
-        return lb
-
-    def setUp(self):
-        super(TestBrocadeLoadBalancerDriver, self).setUp()
-        self.context = context.get_admin_context()
-        self.plugin = mock.Mock()
-        self.driver = driver.BrocadeLoadBalancerDriver(self.plugin)
-        self.lb = self._create_fake_models()
-
-    def test_load_balancer_ops(self):
-        LoadBalancerManagerTest(self, self.driver.load_balancer,
-                                self.lb)
-        self.driver.device_driver.create_loadbalancer \
-            .assert_called_once_with(self.lb)
-        self.driver.device_driver.update_loadbalancer \
-            .assert_called_once_with(self.lb, self.lb)
-        self.driver.device_driver.delete_loadbalancer \
-            .assert_called_once_with(self.lb)
-
-    def test_listener_ops(self):
-        ManagerTest(self, self.driver.listener, self.lb.listeners[0])
-        self.driver.device_driver.create_listener \
-            .assert_called_once_with(self.lb.listeners[0])
-        self.driver.device_driver.update_listener \
-            .assert_called_once_with(self.lb.listeners[0],
-                                     self.lb.listeners[0])
-        self.driver.device_driver.delete_listener \
-            .assert_called_once_with(self.lb.listeners[0])
-
-    def test_pool_ops(self):
-        pool_fake_model = self.lb.listeners[0].default_pool
-        ManagerTest(self, self.driver.pool,
-                    pool_fake_model)
-        self.driver.device_driver.update_pool \
-            .assert_called_once_with(pool_fake_model, pool_fake_model)
-        self.driver.device_driver.delete_pool \
-            .assert_called_once_with(pool_fake_model)
-
-    def test_member_ops(self):
-        member_fake_model = self.lb.listeners[0].default_pool.members[0]
-        ManagerTest(self, self.driver.member,
-                    member_fake_model)
-        self.driver.device_driver.create_member \
-            .assert_called_once_with(member_fake_model)
-        self.driver.device_driver.update_member \
-            .assert_called_once_with(member_fake_model, member_fake_model)
-        self.driver.device_driver.delete_member \
-            .assert_called_once_with(member_fake_model)
-
-    def test_health_monitor_ops(self):
-        hm_fake_model = self.lb.listeners[0].default_pool.healthmonitor
-        ManagerTest(self, self.driver.health_monitor, hm_fake_model)
-        self.driver.device_driver.update_healthmonitor \
-            .assert_called_once_with(hm_fake_model, hm_fake_model)
-        self.driver.device_driver.delete_healthmonitor \
-            .assert_called_once_with(hm_fake_model)
diff --git a/tests/unit/drivers/common/__init__.py b/tests/unit/drivers/common/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/common/test_agent_callbacks.py b/tests/unit/drivers/common/test_agent_callbacks.py
deleted file mode 100644
index df119c8..0000000
--- a/tests/unit/drivers/common/test_agent_callbacks.py
+++ /dev/null
@@ -1,291 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-# Copyright 2015 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import mock
-
-from neutron import context
-from neutron.extensions import portbindings
-from neutron.plugins.common import constants
-from neutron.tests.unit import testlib_api
-from oslo_utils import uuidutils
-import six
-from six import moves
-
-from neutron_lbaas.db.loadbalancer import loadbalancer_dbv2 as ldb
-from neutron_lbaas.db.loadbalancer import models as db_models
-from neutron_lbaas.drivers.common import agent_callbacks
-from neutron_lbaas.extensions import loadbalancerv2
-from neutron_lbaas.services.loadbalancer import constants as lb_const
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests.unit.drivers.common import test_agent_driver_base
-
-
-class TestLoadBalancerCallbacks(
-        test_agent_driver_base.TestLoadBalancerPluginBase):
-
-    def setUp(self):
-        super(TestLoadBalancerCallbacks, self).setUp()
-
-        self.callbacks = agent_callbacks.LoadBalancerCallbacks(
-            self.plugin_instance
-        )
-        get_lbaas_agents_patcher = mock.patch(
-            'neutron_lbaas.agent_scheduler.LbaasAgentSchedulerDbMixin.'
-            'get_lbaas_agents')
-        get_lbaas_agents_patcher.start()
-
-    def test_get_ready_devices(self):
-        with self.loadbalancer() as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self.plugin_instance.db.update_loadbalancer_provisioning_status(
-                context.get_admin_context(),
-                loadbalancer['loadbalancer']['id'])
-            with mock.patch(
-                    'neutron_lbaas.agent_scheduler.LbaasAgentSchedulerDbMixin.'
-                    'list_loadbalancers_on_lbaas_agent') as mock_agent_lbs:
-                mock_agent_lbs.return_value = [
-                    data_models.LoadBalancer(id=lb_id)]
-                ready = self.callbacks.get_ready_devices(
-                    context.get_admin_context(),
-                )
-                self.assertEqual([lb_id], ready)
-
-    def test_get_ready_devices_multiple_listeners_and_loadbalancers(self):
-        ctx = context.get_admin_context()
-
-        # add 3 load balancers and 2 listeners directly to DB
-        # to create 2 "ready" devices and one load balancer without listener
-        loadbalancers = []
-        for i in moves.range(3):
-            loadbalancers.append(ldb.models.LoadBalancer(
-                id=uuidutils.generate_uuid(), vip_subnet_id=self._subnet_id,
-                provisioning_status=constants.ACTIVE, admin_state_up=True,
-                operating_status=constants.ACTIVE))
-            ctx.session.add(loadbalancers[i])
-
-        listener0 = ldb.models.Listener(
-            id=uuidutils.generate_uuid(), protocol="HTTP",
-            loadbalancer_id=loadbalancers[0].id,
-            provisioning_status=constants.ACTIVE, admin_state_up=True,
-            connection_limit=3, protocol_port=80,
-            operating_status=constants.ACTIVE)
-        ctx.session.add(listener0)
-        loadbalancers[0].listener_id = listener0.id
-
-        listener1 = ldb.models.Listener(
-            id=uuidutils.generate_uuid(), protocol="HTTP",
-            loadbalancer_id=loadbalancers[1].id,
-            provisioning_status=constants.ACTIVE, admin_state_up=True,
-            connection_limit=3, protocol_port=80,
-            operating_status=constants.ACTIVE)
-        ctx.session.add(listener1)
-        loadbalancers[1].listener_id = listener1.id
-
-        ctx.session.flush()
-
-        self.assertEqual(3, ctx.session.query(ldb.models.LoadBalancer).count())
-        self.assertEqual(2, ctx.session.query(ldb.models.Listener).count())
-        with mock.patch(
-                'neutron_lbaas.agent_scheduler.LbaasAgentSchedulerDbMixin'
-                '.list_loadbalancers_on_lbaas_agent') as mock_agent_lbs:
-            mock_agent_lbs.return_value = loadbalancers
-            ready = self.callbacks.get_ready_devices(ctx)
-            self.assertEqual(3, len(ready))
-            self.assertIn(loadbalancers[0].id, ready)
-            self.assertIn(loadbalancers[1].id, ready)
-            self.assertIn(loadbalancers[2].id, ready)
-        # cleanup
-        ctx.session.query(ldb.models.Listener).delete()
-        ctx.session.query(ldb.models.LoadBalancer).delete()
-
-    def test_get_ready_devices_inactive_loadbalancer(self):
-        with self.loadbalancer() as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self.plugin_instance.db.update_loadbalancer_provisioning_status(
-                context.get_admin_context(),
-                loadbalancer['loadbalancer']['id'])
-            # set the loadbalancer inactive need to use plugin directly since
-            # status is not tenant mutable
-            self.plugin_instance.db.update_loadbalancer(
-                context.get_admin_context(),
-                loadbalancer['loadbalancer']['id'],
-                {'loadbalancer': {'provisioning_status': constants.INACTIVE}}
-            )
-            with mock.patch(
-                    'neutron_lbaas.agent_scheduler.LbaasAgentSchedulerDbMixin.'
-                    'list_loadbalancers_on_lbaas_agent') as mock_agent_lbs:
-                mock_agent_lbs.return_value = [
-                    data_models.LoadBalancer(id=lb_id)]
-                ready = self.callbacks.get_ready_devices(
-                    context.get_admin_context(),
-                )
-                self.assertEqual([loadbalancer['loadbalancer']['id']],
-                                 ready)
-
-    def test_get_loadbalancer_active(self):
-        with self.loadbalancer() as loadbalancer:
-            ctx = context.get_admin_context()
-            # activate objects
-            self.plugin_instance.db.update_status(
-                ctx, db_models.LoadBalancer,
-                loadbalancer['loadbalancer']['id'], 'ACTIVE')
-
-            lb = self.plugin_instance.db.get_loadbalancer(
-                ctx, loadbalancer['loadbalancer']['id']
-            )
-
-            load_balancer = self.callbacks.get_loadbalancer(
-                ctx, loadbalancer['loadbalancer']['id']
-            )
-            expected_lb = lb.to_dict()
-            expected_lb['provider']['device_driver'] = 'dummy'
-            subnet = self.plugin_instance.db._core_plugin.get_subnet(
-                ctx, expected_lb['vip_subnet_id'])
-            subnet = data_models.Subnet.from_dict(subnet).to_dict()
-            expected_lb['vip_port']['fixed_ips'][0]['subnet'] = subnet
-            del expected_lb['stats']
-            self.assertEqual(expected_lb, load_balancer)
-
-    def _update_port_test_helper(self, expected, func, **kwargs):
-        core = self.plugin_instance.db._core_plugin
-
-        with self.loadbalancer() as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            if 'device_id' not in expected:
-                expected['device_id'] = lb_id
-            self.plugin_instance.db.update_loadbalancer_provisioning_status(
-                context.get_admin_context(),
-                loadbalancer['loadbalancer']['id'])
-            ctx = context.get_admin_context()
-            db_lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-            func(ctx, port_id=db_lb.vip_port_id, **kwargs)
-            db_port = core.get_port(ctx, db_lb.vip_port_id)
-            for k, v in six.iteritems(expected):
-                self.assertEqual(v, db_port[k])
-
-    def test_plug_vip_port(self):
-        exp = {
-            'device_owner': 'neutron:' + constants.LOADBALANCERV2,
-            'admin_state_up': True
-        }
-        self._update_port_test_helper(
-            exp,
-            self.callbacks.plug_vip_port,
-            host='host'
-        )
-
-    def test_plug_vip_port_mock_with_host(self):
-        exp = {
-            'device_owner': 'neutron:' + constants.LOADBALANCERV2,
-            'admin_state_up': True,
-            portbindings.HOST_ID: 'host'
-        }
-        with mock.patch.object(
-                self.plugin.db._core_plugin,
-                'update_port') as mock_update_port:
-            with self.loadbalancer() as loadbalancer:
-                lb_id = loadbalancer['loadbalancer']['id']
-                ctx = context.get_admin_context()
-                self.callbacks.update_status(ctx, 'loadbalancer', lb_id,
-                    constants.ACTIVE)
-                (self.plugin_instance.db
-                 .update_loadbalancer_provisioning_status(ctx, lb_id))
-                db_lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                self.callbacks.plug_vip_port(ctx, port_id=db_lb.vip_port_id,
-                                             host='host')
-            mock_update_port.assert_called_once_with(
-                ctx, db_lb.vip_port_id,
-                {'port': testlib_api.SubDictMatch(exp)})
-
-    def test_unplug_vip_port(self):
-        exp = {
-            'device_owner': '',
-            'device_id': '',
-            'admin_state_up': False
-        }
-        self._update_port_test_helper(
-            exp,
-            self.callbacks.unplug_vip_port,
-            host='host'
-        )
-
-    def test_loadbalancer_deployed(self):
-        with self.loadbalancer() as loadbalancer:
-            ctx = context.get_admin_context()
-
-            l = self.plugin_instance.db.get_loadbalancer(
-                ctx, loadbalancer['loadbalancer']['id'])
-            self.assertEqual('PENDING_CREATE', l.provisioning_status)
-
-            self.callbacks.loadbalancer_deployed(
-                ctx, loadbalancer['loadbalancer']['id'])
-
-            l = self.plugin_instance.db.get_loadbalancer(
-                ctx, loadbalancer['loadbalancer']['id'])
-            self.assertEqual('ACTIVE', l.provisioning_status)
-
-    def test_listener_deployed(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            self.plugin_instance.db.update_loadbalancer_provisioning_status(
-                context.get_admin_context(),
-                loadbalancer['loadbalancer']['id'])
-            with self.listener(
-                    loadbalancer_id=loadbalancer[
-                        'loadbalancer']['id']) as listener:
-                ctx = context.get_admin_context()
-
-                l = self.plugin_instance.db.get_loadbalancer(
-                    ctx, loadbalancer['loadbalancer']['id'])
-                self.assertEqual('PENDING_UPDATE', l.provisioning_status)
-
-                ll = self.plugin_instance.db.get_listener(
-                    ctx, listener['listener']['id'])
-                self.assertEqual('PENDING_CREATE', ll.provisioning_status)
-
-                self.callbacks.loadbalancer_deployed(
-                    ctx, loadbalancer['loadbalancer']['id'])
-
-                l = self.plugin_instance.db.get_loadbalancer(
-                    ctx, loadbalancer['loadbalancer']['id'])
-                self.assertEqual('ACTIVE', l.provisioning_status)
-                ll = self.plugin_instance.db.get_listener(
-                    ctx, listener['listener']['id'])
-                self.assertEqual('ACTIVE', ll.provisioning_status)
-
-    def test_update_status_loadbalancer(self):
-        with self.loadbalancer() as loadbalancer:
-            loadbalancer_id = loadbalancer['loadbalancer']['id']
-            ctx = context.get_admin_context()
-            l = self.plugin_instance.db.get_loadbalancer(ctx, loadbalancer_id)
-            self.assertEqual('PENDING_CREATE', l.provisioning_status)
-            self.callbacks.update_status(ctx, 'loadbalancer',
-                                         loadbalancer_id,
-                                         provisioning_status=constants.ACTIVE,
-                                         operating_status=lb_const.ONLINE)
-            l = self.plugin_instance.db.get_loadbalancer(ctx, loadbalancer_id)
-            self.assertEqual(constants.ACTIVE, l.provisioning_status)
-            self.assertEqual(lb_const.ONLINE, l.operating_status)
-
-    def test_update_status_loadbalancer_deleted_already(self):
-        with mock.patch.object(agent_callbacks, 'LOG') as mock_log:
-            loadbalancer_id = 'deleted_lb'
-            ctx = context.get_admin_context()
-            self.assertRaises(loadbalancerv2.EntityNotFound,
-                              self.plugin_instance.get_loadbalancer, ctx,
-                              loadbalancer_id)
-            self.callbacks.update_status(ctx, 'loadbalancer',
-                                         loadbalancer_id,
-                                         provisioning_status=constants.ACTIVE)
-            self.assertTrue(mock_log.warning.called)
diff --git a/tests/unit/drivers/common/test_agent_driver_base.py b/tests/unit/drivers/common/test_agent_driver_base.py
deleted file mode 100644
index c9186df..0000000
--- a/tests/unit/drivers/common/test_agent_driver_base.py
+++ /dev/null
@@ -1,587 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import mock
-
-from neutron import context
-from neutron.db import servicetype_db as st_db
-from neutron import manager
-from neutron.plugins.common import constants
-
-from neutron_lbaas.db.loadbalancer import models
-from neutron_lbaas.drivers.common import agent_driver_base
-from neutron_lbaas.extensions import loadbalancerv2
-from neutron_lbaas.tests import base
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-
-class TestLoadBalancerPluginBase(test_db_loadbalancerv2.LbaasPluginDbTestCase):
-
-    def setUp(self):
-        def reset_device_driver():
-            agent_driver_base.AgentDriverBase.device_driver = None
-        self.addCleanup(reset_device_driver)
-
-        self.mock_importer = mock.patch.object(
-            agent_driver_base, 'importutils').start()
-
-        # needed to reload provider configuration
-        st_db.ServiceTypeManager._instance = None
-        agent_driver_base.AgentDriverBase.device_driver = 'dummy'
-        super(TestLoadBalancerPluginBase, self).setUp(
-            lbaas_provider=('LOADBALANCERV2:lbaas:neutron_lbaas.drivers.'
-                            'common.agent_driver_base.'
-                            'AgentDriverBase:default'))
-
-        # we need access to loaded plugins to modify models
-        loaded_plugins = manager.NeutronManager().get_service_plugins()
-
-        self.plugin_instance = loaded_plugins[constants.LOADBALANCERV2]
-
-
-class TestLoadBalancerAgentApi(base.BaseTestCase):
-    def setUp(self):
-        super(TestLoadBalancerAgentApi, self).setUp()
-
-        self.api = agent_driver_base.LoadBalancerAgentApi('topic')
-
-    def test_init(self):
-        self.assertEqual('topic', self.api.client.target.topic)
-
-    def _call_test_helper(self, method_name, method_args):
-        with contextlib.nested(
-            mock.patch.object(self.api.client, 'cast'),
-            mock.patch.object(self.api.client, 'prepare'),
-        ) as (
-            rpc_mock, prepare_mock
-        ):
-            prepare_mock.return_value = self.api.client
-            getattr(self.api, method_name)(mock.sentinel.context,
-                                           host='host',
-                                           **method_args)
-
-        prepare_args = {'server': 'host'}
-        prepare_mock.assert_called_once_with(**prepare_args)
-
-        if method_name == 'agent_updated':
-            method_args = {'payload': method_args}
-        rpc_mock.assert_called_once_with(mock.sentinel.context, method_name,
-                                         **method_args)
-
-    def test_agent_updated(self):
-        self._call_test_helper('agent_updated', {'admin_state_up': 'test'})
-
-    def test_create_pool(self):
-        self._call_test_helper('create_pool', {'pool': 'test'})
-
-    def test_update_pool(self):
-        self._call_test_helper('update_pool', {'old_pool': 'test',
-                                               'pool': 'test'})
-
-    def test_delete_pool(self):
-        self._call_test_helper('delete_pool', {'pool': 'test'})
-
-    def test_create_loadbalancer(self):
-        self._call_test_helper('create_loadbalancer', {'loadbalancer': 'test',
-                                                       'driver_name': 'dummy'})
-
-    def test_update_loadbalancer(self):
-        self._call_test_helper('update_loadbalancer', {
-            'old_loadbalancer': 'test', 'loadbalancer': 'test'})
-
-    def test_delete_loadbalancer(self):
-        self._call_test_helper('delete_loadbalancer', {'loadbalancer': 'test'})
-
-    def test_create_member(self):
-        self._call_test_helper('create_member', {'member': 'test'})
-
-    def test_update_member(self):
-        self._call_test_helper('update_member', {'old_member': 'test',
-                                                 'member': 'test'})
-
-    def test_delete_member(self):
-        self._call_test_helper('delete_member', {'member': 'test'})
-
-    def test_create_monitor(self):
-        self._call_test_helper('create_healthmonitor',
-                               {'healthmonitor': 'test'})
-
-    def test_update_monitor(self):
-        self._call_test_helper('update_healthmonitor',
-                               {'old_healthmonitor': 'test',
-                                'healthmonitor': 'test'})
-
-    def test_delete_monitor(self):
-        self._call_test_helper('delete_healthmonitor',
-                               {'healthmonitor': 'test'})
-
-
-class TestLoadBalancerPluginNotificationWrapper(TestLoadBalancerPluginBase):
-    def setUp(self):
-        self.log = mock.patch.object(agent_driver_base, 'LOG')
-        api_cls = mock.patch.object(agent_driver_base,
-                                    'LoadBalancerAgentApi').start()
-        super(TestLoadBalancerPluginNotificationWrapper, self).setUp()
-        self.mock_api = api_cls.return_value
-
-        self.mock_get_driver = mock.patch.object(self.plugin_instance,
-                                                 '_get_driver')
-        self.mock_get_driver.return_value = (
-            agent_driver_base.AgentDriverBase(self.plugin_instance))
-
-    def _update_status(self, model, status, id):
-        ctx = context.get_admin_context()
-        self.plugin_instance.db.update_status(
-            ctx,
-            model,
-            id,
-            provisioning_status=status
-        )
-
-    def test_create_loadbalancer(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            calls = self.mock_api.create_loadbalancer.call_args_list
-            self.assertEqual(1, len(calls))
-            _, called_lb, _, device_driver = calls[0][0]
-            self.assertEqual(loadbalancer['loadbalancer']['id'], called_lb.id)
-            self.assertEqual('dummy', device_driver)
-            self.assertEqual(constants.PENDING_CREATE,
-                             called_lb.provisioning_status)
-
-    def test_update_loadbalancer(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            old_lb_name = loadbalancer['loadbalancer']['name']
-            ctx = context.get_admin_context()
-            self.plugin_instance.db.update_loadbalancer_provisioning_status(
-                ctx,
-                loadbalancer['loadbalancer']['id'])
-            new_lb_name = 'new_lb_name'
-            loadbalancer['loadbalancer']['name'] = new_lb_name
-            self._update_loadbalancer_api(
-                lb_id, {'loadbalancer': {'name': new_lb_name}})
-            calls = self.mock_api.update_loadbalancer.call_args_list
-            self.assertEqual(1, len(calls))
-            _, called_old_lb, called_new_lb, called_host = calls[0][0]
-            self.assertEqual(lb_id, called_old_lb.id)
-            self.assertEqual(lb_id, called_new_lb.id)
-            self.assertEqual(old_lb_name, called_old_lb.name)
-            self.assertEqual(new_lb_name, called_new_lb.name)
-            self.assertEqual('host', called_host)
-            self.assertEqual(constants.PENDING_UPDATE,
-                             called_new_lb.provisioning_status)
-
-    def test_delete_loadbalancer(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            ctx = context.get_admin_context()
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            self.plugin_instance.delete_loadbalancer(ctx, lb_id)
-            calls = self.mock_api.delete_loadbalancer.call_args_list
-            self.assertEqual(1, len(calls))
-            _, called_lb, called_host = calls[0][0]
-            self.assertEqual(lb_id, called_lb.id)
-            self.assertEqual('host', called_host)
-            self.assertEqual(constants.PENDING_DELETE,
-                             called_lb.provisioning_status)
-            self.assertRaises(loadbalancerv2.EntityNotFound,
-                              self.plugin_instance.db.get_loadbalancer,
-                              ctx, lb_id)
-
-    def test_create_listener(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                loadbalancer['loadbalancer']['id'])
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                calls = self.mock_api.create_listener.call_args_list
-                _, called_listener, called_host = calls[0][0]
-                self.assertEqual(listener_id, called_listener.id)
-                self.assertEqual('host', called_host)
-                self.assertEqual(constants.PENDING_CREATE,
-                                 called_listener.provisioning_status)
-                ctx = context.get_admin_context()
-                lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                self.assertEqual(constants.PENDING_UPDATE,
-                                 lb.provisioning_status)
-
-    def test_update_listener(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                loadbalancer['loadbalancer']['id'])
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                old_name = listener['listener']['name']
-                ctx = context.get_admin_context()
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                self.plugin_instance.db.get_listener(ctx, listener_id)
-                new_name = 'new_listener_name'
-                listener['listener']['name'] = new_name
-                self.plugin_instance.update_listener(
-                    ctx, listener['listener']['id'], listener)
-                self.plugin_instance.db.get_listener(
-                    ctx, listener['listener']['id'])
-                calls = self.mock_api.update_listener.call_args_list
-                (_, old_called_listener,
-                 new_called_listener, called_host) = calls[0][0]
-                self.assertEqual(listener_id, new_called_listener.id)
-                self.assertEqual(listener_id, old_called_listener.id)
-                self.assertEqual(old_name, old_called_listener.name)
-                self.assertEqual(new_name, new_called_listener.name)
-                self.assertEqual(constants.PENDING_UPDATE,
-                                 new_called_listener.provisioning_status)
-                lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                self.assertEqual(constants.PENDING_UPDATE,
-                                 lb.provisioning_status)
-                self.assertEqual('host', called_host)
-
-    def test_delete_listener(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                ctx = context.get_admin_context()
-                self.plugin_instance.delete_listener(
-                    ctx, listener['listener']['id'])
-                calls = self.mock_api.delete_listener.call_args_list
-                _, called_listener, called_host = calls[0][0]
-                self.assertEqual(listener_id, called_listener.id)
-                self.assertEqual('host', called_host)
-                self.assertEqual(constants.PENDING_DELETE,
-                                 called_listener.provisioning_status)
-                ctx = context.get_admin_context()
-                lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                self.assertEqual(constants.ACTIVE,
-                                 lb.provisioning_status)
-                self.assertRaises(
-                    loadbalancerv2.EntityNotFound,
-                    self.plugin_instance.db.get_listener, ctx, listener_id)
-
-    def test_create_pool(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    calls = self.mock_api.create_pool.call_args_list
-                    _, called_pool, called_host = calls[0][0]
-                    self.assertEqual(pool_id, called_pool.id)
-                    self.assertEqual('host', called_host)
-                    self.assertEqual(constants.PENDING_CREATE,
-                                     called_pool.provisioning_status)
-                    ctx = context.get_admin_context()
-                    lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                    self.assertEqual(constants.PENDING_UPDATE,
-                                     lb.provisioning_status)
-
-    def test_update_pool(self):
-        ctx = context.get_admin_context()
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(loadbalancer_id=lb_id, listener_id=listener_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    old_name = pool['pool']['name']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    new_name = 'new_name'
-                    pool['pool']['name'] = new_name
-                    self.plugin_instance.update_pool(ctx, pool_id, pool)
-                    calls = self.mock_api.update_pool.call_args_list
-                    (_, old_called_pool,
-                     new_called_pool, called_host) = calls[0][0]
-                    self.assertEqual(pool_id, new_called_pool.id)
-                    self.assertEqual(pool_id, old_called_pool.id)
-                    self.assertEqual(old_name, old_called_pool.name)
-                    self.assertEqual(new_name, new_called_pool.name)
-                    self.assertEqual(constants.PENDING_UPDATE,
-                                     new_called_pool.provisioning_status)
-                    lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                    self.assertEqual(constants.PENDING_UPDATE,
-                                     lb.provisioning_status)
-                    self.assertEqual('host', called_host)
-
-    def test_delete_pool(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    ctx = context.get_admin_context()
-                    self.plugin_instance.delete_pool(ctx, pool_id)
-                    calls = self.mock_api.delete_pool.call_args_list
-                    _, called_pool, called_host = calls[0][0]
-                    self.assertEqual(pool_id, called_pool.id)
-                    self.assertEqual('host', called_host)
-                    self.assertEqual(constants.PENDING_DELETE,
-                                     called_pool.provisioning_status)
-                    lb = self.plugin_instance.db.get_loadbalancer(ctx, lb_id)
-                    self.assertEqual(constants.ACTIVE,
-                                     lb.provisioning_status)
-                    self.assertRaises(
-                        loadbalancerv2.EntityNotFound,
-                        self.plugin_instance.db.get_pool, ctx, pool_id)
-
-    def test_create_member(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    with self.subnet(cidr='11.0.0.0/24') as subnet:
-                        with self.member(pool_id=pool_id, subnet=subnet,
-                                         no_delete=True) as member:
-                            member_id = member['member']['id']
-                            calls = self.mock_api.create_member.call_args_list
-                            _, called_member, called_host = calls[0][0]
-                            self.assertEqual(member_id, called_member.id)
-                            self.assertEqual('host', called_host)
-                            self.assertEqual(constants.PENDING_CREATE,
-                                             called_member.provisioning_status)
-                            ctx = context.get_admin_context()
-                            lb = self.plugin_instance.db.get_loadbalancer(
-                                ctx, lb_id)
-                            self.assertEqual(constants.PENDING_UPDATE,
-                                             lb.provisioning_status)
-
-    def test_update_member(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    with self.subnet(cidr='11.0.0.0/24') as subnet:
-                        with self.member(pool_id=pool_id, subnet=subnet,
-                                         no_delete=True) as member:
-                            member_id = member['member']['id']
-                            self._update_status(models.LoadBalancer,
-                                                constants.ACTIVE, lb_id)
-                            old_weight = member['member']['weight']
-                            new_weight = 2
-                            member['member']['weight'] = new_weight
-                            ctx = context.get_admin_context()
-                            self.plugin_instance.update_pool_member(
-                                ctx, member_id, pool_id, member)
-                            calls = self.mock_api.update_member.call_args_list
-                            (_, old_called_member,
-                             new_called_member, called_host) = calls[0][0]
-                            self.assertEqual(member_id, new_called_member.id)
-                            self.assertEqual(member_id, old_called_member.id)
-                            self.assertEqual(old_weight,
-                                             old_called_member.weight)
-                            self.assertEqual(new_weight,
-                                             new_called_member.weight)
-                            self.assertEqual(
-                                constants.PENDING_UPDATE,
-                                new_called_member.provisioning_status)
-                            lb = self.plugin_instance.db.get_loadbalancer(
-                                ctx, lb_id)
-                            self.assertEqual(constants.PENDING_UPDATE,
-                                             lb.provisioning_status)
-                            self.assertEqual('host', called_host)
-
-    def test_delete_member(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    with self.subnet(cidr='11.0.0.0/24') as subnet:
-                        with self.member(pool_id=pool_id, subnet=subnet,
-                                         no_delete=True) as member:
-                            member_id = member['member']['id']
-                            self._update_status(models.LoadBalancer,
-                                                constants.ACTIVE, lb_id)
-                            ctx = context.get_admin_context()
-                            self.plugin_instance.delete_pool_member(
-                                ctx, member_id, pool_id)
-                            calls = self.mock_api.delete_member.call_args_list
-                            _, called_member, called_host = calls[0][0]
-                            self.assertEqual(member_id, called_member.id)
-                            self.assertEqual('host', called_host)
-                            self.assertEqual(constants.PENDING_DELETE,
-                                             called_member.provisioning_status)
-                            lb = self.plugin_instance.db.get_loadbalancer(
-                                ctx, lb_id)
-                            self.assertEqual(constants.ACTIVE,
-                                             lb.provisioning_status)
-                            self.assertRaises(
-                                loadbalancerv2.EntityNotFound,
-                                self.plugin_instance.db.get_pool_member,
-                                ctx, member_id)
-
-    def test_create_health_monitor(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    with self.healthmonitor(pool_id=pool_id,
-                                            no_delete=True) as monitor:
-                        hm_id = monitor['healthmonitor']['id']
-                        calls = (
-                            self.mock_api.create_healthmonitor.call_args_list)
-                        _, called_hm, called_host = calls[0][0]
-                        self.assertEqual(hm_id, called_hm.id)
-                        self.assertEqual('host', called_host)
-                        self.assertEqual(constants.PENDING_CREATE,
-                                         called_hm.provisioning_status)
-                        ctx = context.get_admin_context()
-                        lb = self.plugin_instance.db.get_loadbalancer(
-                            ctx, lb_id)
-                        self.assertEqual(constants.PENDING_UPDATE,
-                                         lb.provisioning_status)
-
-    def test_update_health_monitor(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    with self.healthmonitor(pool_id=pool_id,
-                                            no_delete=True) as monitor:
-                        hm_id = monitor['healthmonitor']['id']
-                        self._update_status(models.LoadBalancer,
-                                            constants.ACTIVE, lb_id)
-                        old_to = monitor['healthmonitor']['timeout']
-                        new_to = 2
-                        monitor['healthmonitor']['timeout'] = new_to
-                        ctx = context.get_admin_context()
-                        self.plugin_instance.update_healthmonitor(ctx, hm_id,
-                                                                  monitor)
-                        calls = (
-                            self.mock_api.update_healthmonitor.call_args_list)
-                        (_, old_called_hm,
-                         new_called_hm, called_host) = calls[0][0]
-                        self.assertEqual(hm_id, new_called_hm.id)
-                        self.assertEqual(hm_id, old_called_hm.id)
-                        self.assertEqual(old_to,
-                                         old_called_hm.timeout)
-                        self.assertEqual(new_to,
-                                         new_called_hm.timeout)
-                        self.assertEqual(
-                            constants.PENDING_UPDATE,
-                            new_called_hm.provisioning_status)
-                        lb = self.plugin_instance.db.get_loadbalancer(
-                            ctx, lb_id)
-                        self.assertEqual(constants.PENDING_UPDATE,
-                                         lb.provisioning_status)
-                        self.assertEqual('host', called_host)
-
-    def test_delete_health_monitor(self):
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            self._update_status(models.LoadBalancer, constants.ACTIVE, lb_id)
-            with self.listener(loadbalancer_id=lb_id,
-                               no_delete=True) as listener:
-                listener_id = listener['listener']['id']
-                self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                    lb_id)
-                with self.pool(listener_id=listener_id, loadbalancer_id=lb_id,
-                               no_delete=True) as pool:
-                    pool_id = pool['pool']['id']
-                    self._update_status(models.LoadBalancer, constants.ACTIVE,
-                                        lb_id)
-                    with self.healthmonitor(pool_id=pool_id,
-                                            no_delete=True) as monitor:
-                        hm_id = monitor['healthmonitor']['id']
-                        self._update_status(models.LoadBalancer,
-                                            constants.ACTIVE, lb_id)
-                        ctx = context.get_admin_context()
-                        self.plugin_instance.delete_healthmonitor(ctx, hm_id)
-                        calls = (
-                            self.mock_api.delete_healthmonitor.call_args_list)
-                        _, called_hm, called_host = calls[0][0]
-                        self.assertEqual(hm_id, called_hm.id)
-                        self.assertEqual('host', called_host)
-                        self.assertEqual(constants.PENDING_DELETE,
-                                         called_hm.provisioning_status)
-                        lb = self.plugin_instance.db.get_loadbalancer(
-                            ctx, lb_id)
-                        self.assertEqual(constants.ACTIVE,
-                                         lb.provisioning_status)
-                        self.assertRaises(
-                            loadbalancerv2.EntityNotFound,
-                            self.plugin_instance.db.get_healthmonitor,
-                            ctx, hm_id)
diff --git a/tests/unit/drivers/haproxy/__init__.py b/tests/unit/drivers/haproxy/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/haproxy/test_namespace_driver.py b/tests/unit/drivers/haproxy/test_namespace_driver.py
deleted file mode 100644
index 1cfec1a..0000000
--- a/tests/unit/drivers/haproxy/test_namespace_driver.py
+++ /dev/null
@@ -1,693 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-# Copyright 2015 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import collections
-import contextlib
-import socket
-
-import mock
-from neutron.plugins.common import constants
-from neutron_lib import exceptions
-
-from neutron_lbaas.drivers.haproxy import namespace_driver
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests import base
-
-
-class TestHaproxyNSDriver(base.BaseTestCase):
-
-    def setUp(self):
-        super(TestHaproxyNSDriver, self).setUp()
-
-        conf = mock.Mock()
-        conf.haproxy.loadbalancer_state_path = '/the/path'
-        conf.interface_driver = 'intdriver'
-        conf.haproxy.user_group = 'test_group'
-        conf.haproxy.send_gratuitous_arp = 3
-        self.conf = conf
-        self.rpc_mock = mock.Mock()
-        with mock.patch(
-                'neutron.common.utils.load_class_by_alias_or_classname'):
-            self.driver = namespace_driver.HaproxyNSDriver(
-                conf,
-                self.rpc_mock
-            )
-        self.vif_driver = mock.Mock()
-        self.driver.vif_driver = self.vif_driver
-        self._build_mock_data_models()
-
-    def _build_mock_data_models(self):
-        host_route = data_models.HostRoute(destination='0.0.0.0/0',
-                                           nexthop='192.0.0.1')
-        subnet = data_models.Subnet(cidr='10.0.0.1/24',
-                                    gateway_ip='10.0.0.2',
-                                    host_routes=[host_route])
-        fixed_ip = data_models.IPAllocation(ip_address='10.0.0.1')
-        setattr(fixed_ip, 'subnet', subnet)
-        port = data_models.Port(id='port1', network_id='network1',
-                                mac_address='12-34-56-78-9A-BC',
-                                fixed_ips=[fixed_ip])
-        self.lb = data_models.LoadBalancer(id='lb1', listeners=[],
-                                           vip_port=port,
-                                           vip_address='10.0.0.1')
-
-    def test_get_name(self):
-        self.assertEqual(namespace_driver.DRIVER_NAME, self.driver.get_name())
-
-    @mock.patch('neutron.agent.linux.ip_lib.IPWrapper')
-    @mock.patch('os.path.dirname')
-    @mock.patch('os.path.isdir')
-    @mock.patch('shutil.rmtree')
-    def test_undeploy_instance(self, mock_shutil, mock_isdir, mock_dirname,
-                               mock_ip_wrap):
-        self.driver._get_state_file_path = mock.Mock(return_value='/path')
-        namespace_driver.kill_pids_in_file = mock.Mock()
-        self.driver._unplug = mock.Mock()
-        mock_dirname.return_value = '/path/' + self.lb.id
-        mock_isdir.return_value = False
-
-        self.driver.undeploy_instance(self.lb.id)
-        namespace_driver.kill_pids_in_file.assert_called_once_with('/path')
-        calls = [mock.call(self.lb.id, 'pid'), mock.call(self.lb.id, '')]
-        self.driver._get_state_file_path.has_calls(calls)
-        self.assertFalse(self.driver._unplug.called)
-        self.assertFalse(mock_ip_wrap.called)
-        mock_isdir.assert_called_once_with('/path/' + self.lb.id)
-        self.assertFalse(mock_shutil.called)
-
-        self.driver.deployed_loadbalancers[self.lb.id] = self.lb
-        mock_isdir.return_value = True
-        namespace_driver.kill_pids_in_file.reset_mock()
-        mock_isdir.reset_mock()
-        mock_ns = mock_ip_wrap.return_value
-        mock_ns.get_devices.return_value = [collections.namedtuple(
-            'Device', ['name'])(name='test_device')]
-        self.driver.undeploy_instance(self.lb.id, cleanup_namespace=True,
-                                      delete_namespace=True)
-        ns = namespace_driver.get_ns_name(self.lb.id)
-        namespace_driver.kill_pids_in_file.assert_called_once_with('/path')
-        calls = [mock.call(self.lb.id, 'pid'), mock.call(self.lb.id, '')]
-        self.driver._get_state_file_path.has_calls(calls)
-        self.driver._unplug.assert_called_once_with(ns, self.lb.vip_port)
-        ip_wrap_calls = [mock.call(namespace=ns), mock.call(namespace=ns)]
-        mock_ip_wrap.has_calls(ip_wrap_calls)
-        mock_ns.get_devices.assert_called_once_with(exclude_loopback=True)
-        self.vif_driver.unplug.assert_called_once_with('test_device',
-                                                       namespace=ns)
-        mock_shutil.assert_called_once_with('/path/' + self.lb.id)
-        mock_ns.garbage_collect_namespace.assert_called_once_with()
-
-    @mock.patch('os.path.exists')
-    @mock.patch('os.listdir')
-    def test_remove_orphans(self, list_dir, exists):
-        lb_ids = [self.lb.id]
-        exists.return_value = False
-        self.driver.remove_orphans(lb_ids)
-        exists.assert_called_once_with(self.driver.state_path)
-        self.assertFalse(list_dir.called)
-
-        exists.reset_mock()
-        exists.return_value = True
-        list_dir.return_value = [self.lb.id, 'lb2']
-        self.driver.exists = mock.Mock()
-        self.driver.undeploy_instance = mock.Mock()
-        self.driver.remove_orphans(lb_ids)
-        exists.assert_called_once_with(self.driver.state_path)
-        list_dir.assert_called_once_with(self.driver.state_path)
-        self.driver.exists.assert_called_once_with('lb2')
-        self.driver.undeploy_instance.assert_called_once_with(
-            'lb2', cleanup_namespace=True)
-
-    def test_get_stats(self):
-        # Shamelessly stolen from v1 namespace driver tests.
-        raw_stats = ('# pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,'
-                     'dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,'
-                     'act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,'
-                     'sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,'
-                     'check_status,check_code,check_duration,hrsp_1xx,'
-                     'hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,'
-                     'req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,\n'
-                     '8e271901-69ed-403e-a59b-f53cf77ef208,BACKEND,1,2,3,4,0,'
-                     '10,7764,2365,0,0,,0,0,0,0,UP,1,1,0,,0,103780,0,,1,2,0,,0'
-                     ',,1,0,,0,,,,0,0,0,0,0,0,,,,,0,0,\n\n'
-                     'a557019b-dc07-4688-9af4-f5cf02bb6d4b,'
-                     '32a6c2a3-420a-44c3-955d-86bd2fc6871e,0,0,0,1,,7,1120,'
-                     '224,,0,,0,0,0,0,UP,1,1,0,0,1,2623,303,,1,2,1,,7,,2,0,,'
-                     '1,L7OK,200,98,0,7,0,0,0,0,0,,,,0,0,\n'
-                     'a557019b-dc07-4688-9af4-f5cf02bb6d4b,'
-                     'd9aea044-8867-4e80-9875-16fb808fa0f9,0,0,0,2,,12,0,0,,'
-                     '0,,0,0,8,4,DOWN,1,1,0,9,2,308,675,,1,2,2,,4,,2,0,,2,'
-                     'L4CON,,2999,0,0,0,0,0,0,0,,,,0,0,\n')
-        raw_stats_empty = ('# pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,'
-                           'bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,'
-                           'status,weight,act,bck,chkfail,chkdown,lastchg,'
-                           'downtime,qlimit,pid,iid,sid,throttle,lbtot,'
-                           'tracked,type,rate,rate_lim,rate_max,check_status,'
-                           'check_code,check_duration,hrsp_1xx,hrsp_2xx,'
-                           'hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,'
-                           'req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,'
-                           '\n')
-        with contextlib.nested(
-                mock.patch.object(self.driver, '_get_state_file_path'),
-                mock.patch('socket.socket'),
-                mock.patch('os.path.exists'),
-        ) as (gsp, mocket, path_exists):
-            gsp.side_effect = lambda x, y, z: '/pool/' + y
-            path_exists.return_value = True
-            mocket.return_value = mocket
-            mocket.recv.return_value = raw_stats
-
-            exp_stats = {'connection_errors': '0',
-                         'active_connections': '3',
-                         'current_sessions': '3',
-                         'bytes_in': '7764',
-                         'max_connections': '4',
-                         'max_sessions': '4',
-                         'bytes_out': '2365',
-                         'response_errors': '0',
-                         'total_sessions': '10',
-                         'total_connections': '10',
-                         'members': {
-                             '32a6c2a3-420a-44c3-955d-86bd2fc6871e': {
-                                 'status': 'ACTIVE',
-                                 'health': 'L7OK',
-                                 'failed_checks': '0'
-                             },
-                             'd9aea044-8867-4e80-9875-16fb808fa0f9': {
-                                 'status': 'INACTIVE',
-                                 'health': 'L4CON',
-                                 'failed_checks': '9'
-                             }
-                         }
-                         }
-            stats = self.driver.get_stats(self.lb.id)
-            self.assertEqual(exp_stats, stats)
-
-            mocket.recv.return_value = raw_stats_empty
-            self.assertEqual({'members': {}},
-                             self.driver.get_stats(self.lb.id))
-
-            path_exists.return_value = False
-            mocket.reset_mock()
-            self.assertEqual({}, self.driver.get_stats(self.lb.id))
-            self.assertFalse(mocket.called)
-
-    def test_deploy_instance(self):
-        self.driver.deployable = mock.Mock(return_value=False)
-        self.driver.exists = mock.Mock(return_value=True)
-        self.driver.update = mock.Mock()
-        self.driver.create = mock.Mock()
-
-        def reset():
-            self.driver.deployable.reset_mock()
-            self.driver.exists.reset_mock()
-            self.driver.update.reset_mock()
-            self.driver.create.reset_mock()
-
-        deployed = self.driver.deploy_instance(self.lb)
-        self.assertFalse(deployed)
-        self.assertFalse(self.driver.exists.called)
-        self.assertFalse(self.driver.create.called)
-        self.assertFalse(self.driver.update.called)
-
-        reset()
-        self.driver.deployable.return_value = True
-        deployed = self.driver.deploy_instance(self.lb)
-        self.assertTrue(deployed)
-        self.driver.exists.assert_called_once_with(self.lb.id)
-        self.driver.update.assert_called_once_with(self.lb)
-        self.assertFalse(self.driver.create.called)
-
-        reset()
-        self.driver.exists.return_value = False
-        deployed = self.driver.deploy_instance(self.lb)
-        self.assertTrue(deployed)
-        self.driver.exists.assert_called_once_with(self.lb.id)
-        self.driver.create.assert_called_once_with(self.lb)
-        self.assertFalse(self.driver.update.called)
-
-    def test_update(self):
-        self.driver._get_state_file_path = mock.Mock(return_value='/path')
-        self.driver._spawn = mock.Mock()
-        with mock.patch('six.moves.builtins.open') as m_open:
-            file_mock = mock.MagicMock()
-            m_open.return_value = file_mock
-            file_mock.__enter__.return_value = file_mock
-            file_mock.__iter__.return_value = iter(['123'])
-            self.driver.update(self.lb)
-            self.driver._spawn.assert_called_once_with(self.lb,
-                                                       ['-sf', '123'])
-
-    @mock.patch('socket.socket')
-    @mock.patch('os.path.exists')
-    @mock.patch('neutron.agent.linux.ip_lib.IPWrapper')
-    def test_exists(self, ip_wrap, exists, mocket):
-        socket_path = '/path/haproxy_stats.sock'
-        mock_ns = ip_wrap.return_value
-        mock_socket = mocket.return_value
-        self.driver._get_state_file_path = mock.Mock(return_value=socket_path)
-        mock_ns.netns.exists.return_value = False
-        exists.return_value = False
-
-        def reset():
-            ip_wrap.reset_mock()
-            self.driver._get_state_file_path.reset_mock()
-            mock_ns.reset_mock()
-            exists.reset_mock()
-            mocket.reset_mock()
-            mock_socket.reset_mock()
-
-        ret_exists = self.driver.exists(self.lb.id)
-        ip_wrap.assert_called_once_with()
-        self.driver._get_state_file_path.assert_called_once_with(
-            self.lb.id, 'haproxy_stats.sock', False)
-        mock_ns.netns.exists.assert_called_once_with(
-            namespace_driver.get_ns_name(self.lb.id))
-        self.assertFalse(exists.called)
-        self.assertFalse(mocket.called)
-        self.assertFalse(mock_socket.connect.called)
-        self.assertFalse(ret_exists)
-
-        reset()
-        mock_ns.netns.exists.return_value = True
-        exists.return_value = False
-        ret_exists = self.driver.exists(self.lb.id)
-        ip_wrap.assert_called_once_with()
-        self.driver._get_state_file_path.assert_called_once_with(
-            self.lb.id, 'haproxy_stats.sock', False)
-        mock_ns.netns.exists.assert_called_once_with(
-            namespace_driver.get_ns_name(self.lb.id))
-        exists.assert_called_once_with(socket_path)
-        self.assertFalse(mocket.called)
-        self.assertFalse(mock_socket.connect.called)
-        self.assertFalse(ret_exists)
-
-        reset()
-        mock_ns.netns.exists.return_value = True
-        exists.return_value = True
-        ret_exists = self.driver.exists(self.lb.id)
-        ip_wrap.assert_called_once_with()
-        self.driver._get_state_file_path.assert_called_once_with(
-            self.lb.id, 'haproxy_stats.sock', False)
-        mock_ns.netns.exists.assert_called_once_with(
-            namespace_driver.get_ns_name(self.lb.id))
-        exists.assert_called_once_with(socket_path)
-        mocket.assert_called_once_with(socket.AF_UNIX, socket.SOCK_STREAM)
-        mock_socket.connect.assert_called_once_with(socket_path)
-        self.assertTrue(ret_exists)
-
-    def test_create(self):
-        self.driver._plug = mock.Mock()
-        self.driver._spawn = mock.Mock()
-        self.driver.create(self.lb)
-        self.driver._plug.assert_called_once_with(
-            namespace_driver.get_ns_name(self.lb.id),
-            self.lb.vip_port, self.lb.vip_address)
-        self.driver._spawn.assert_called_once_with(self.lb)
-
-    def test_deployable(self):
-        # test None
-        ret_val = self.driver.deployable(None)
-        self.assertFalse(ret_val)
-
-        # test no listeners
-        ret_val = self.driver.deployable(self.lb)
-        self.assertFalse(ret_val)
-
-        # test no acceptable listeners
-        listener = data_models.Listener(
-            provisioning_status=constants.PENDING_DELETE,
-            admin_state_up=True)
-        self.lb.listeners.append(listener)
-        ret_val = self.driver.deployable(self.lb)
-        self.assertFalse(ret_val)
-        listener.provisioning_status = constants.PENDING_CREATE
-        listener.admin_state_up = False
-        ret_val = self.driver.deployable(self.lb)
-        self.assertFalse(ret_val)
-
-        # test bad lb status
-        listener.admin_state_up = True
-        self.lb.provisioning_status = constants.PENDING_DELETE
-        self.lb.admin_state_up = True
-        ret_val = self.driver.deployable(self.lb)
-        self.assertFalse(ret_val)
-        self.lb.provisioning_status = constants.PENDING_UPDATE
-        self.lb.admin_state_up = False
-        ret_val = self.driver.deployable(self.lb)
-        self.assertFalse(ret_val)
-
-        # test everything good
-        self.lb.admin_state_up = True
-        ret_val = self.driver.deployable(self.lb)
-        self.assertTrue(ret_val)
-
-    @mock.patch('neutron.common.utils.ensure_dir')
-    def test_get_state_file_path(self, ensure_dir):
-        path = self.driver._get_state_file_path(self.lb.id, 'conf',
-                                                ensure_state_dir=False)
-        self.assertEqual('/the/path/v2/lb1/conf', path)
-        self.assertFalse(ensure_dir.called)
-        path = self.driver._get_state_file_path(self.lb.id, 'conf')
-        self.assertEqual('/the/path/v2/lb1/conf', path)
-        self.assertTrue(ensure_dir.called)
-
-    @mock.patch('neutron.agent.linux.ip_lib.device_exists')
-    @mock.patch('neutron.agent.linux.ip_lib.IPWrapper')
-    def test_plug(self, ip_wrap, device_exists):
-        device_exists.return_value = True
-        interface_name = 'tap-d4nc3'
-        self.vif_driver.get_device_name.return_value = interface_name
-        self.assertRaises(exceptions.PreexistingDeviceFailure,
-                          self.driver._plug, 'ns1', self.lb.vip_port,
-                          self.lb.vip_address, reuse_existing=False)
-        device_exists.assert_called_once_with(interface_name,
-                                              namespace='ns1')
-        self.rpc_mock.plug_vip_port.assert_called_once_with(
-            self.lb.vip_port.id)
-
-        device_exists.reset_mock()
-        self.rpc_mock.plug_vip_port.reset_mock()
-        mock_ns = ip_wrap.return_value
-        self.driver._plug('ns1', self.lb.vip_port, self.lb.vip_address)
-        self.rpc_mock.plug_vip_port.assert_called_once_with(
-            self.lb.vip_port.id)
-        device_exists.assert_called_once_with(interface_name,
-                                              namespace='ns1')
-        self.assertFalse(self.vif_driver.plug.called)
-        expected_cidrs = ['10.0.0.1/24']
-        self.vif_driver.init_l3.assert_called_once_with(
-            interface_name, expected_cidrs, namespace='ns1')
-        calls = [mock.call(['route', 'add', 'default', 'gw', '192.0.0.1'],
-                           check_exit_code=False),
-                 mock.call(['arping', '-U', '-I', interface_name,
-                            '-c', 3, '10.0.0.1'],
-                           check_exit_code=False)]
-        mock_ns.netns.execute.has_calls(calls)
-        self.assertEqual(2, mock_ns.netns.execute.call_count)
-
-    def test_unplug(self):
-        interface_name = 'tap-d4nc3'
-        self.vif_driver.get_device_name.return_value = interface_name
-        self.driver._unplug('ns1', self.lb.vip_port)
-        self.rpc_mock.unplug_vip_port.assert_called_once_with(
-            self.lb.vip_port.id)
-        self.vif_driver.get_device_name.assert_called_once_with(
-            self.lb.vip_port)
-        self.vif_driver.unplug.assert_called_once_with(interface_name,
-                                                       namespace='ns1')
-
-    @mock.patch('neutron.common.utils.ensure_dir')
-    @mock.patch('neutron_lbaas.services.loadbalancer.drivers.haproxy.'
-                'jinja_cfg.save_config')
-    @mock.patch('neutron.agent.linux.ip_lib.IPWrapper')
-    def test_spawn(self, ip_wrap, jinja_save, ensure_dir):
-        mock_ns = ip_wrap.return_value
-        self.driver._spawn(self.lb)
-        conf_dir = self.driver.state_path + '/' + self.lb.id + '/%s'
-        jinja_save.assert_called_once_with(
-            conf_dir % 'haproxy.conf',
-            self.lb,
-            conf_dir % 'haproxy_stats.sock',
-            'test_group',
-            conf_dir % '')
-        ip_wrap.assert_called_once_with(
-            namespace=namespace_driver.get_ns_name(self.lb.id))
-        mock_ns.netns.execute.assert_called_once_with(
-            ['haproxy', '-f', conf_dir % 'haproxy.conf', '-p',
-             conf_dir % 'haproxy.pid'])
-        self.assertIn(self.lb.id, self.driver.deployed_loadbalancers)
-        self.assertEqual(self.lb,
-                         self.driver.deployed_loadbalancers[self.lb.id])
-
-
-class BaseTestManager(base.BaseTestCase):
-
-    def setUp(self):
-        super(BaseTestManager, self).setUp()
-        self.driver = mock.Mock()
-        self.lb_manager = namespace_driver.LoadBalancerManager(self.driver)
-        self.listener_manager = namespace_driver.ListenerManager(self.driver)
-        self.pool_manager = namespace_driver.PoolManager(self.driver)
-        self.member_manager = namespace_driver.MemberManager(self.driver)
-        self.hm_manager = namespace_driver.HealthMonitorManager(self.driver)
-        self.refresh = self.driver.loadbalancer.refresh
-
-
-class BaseTestLoadBalancerManager(BaseTestManager):
-
-    def setUp(self):
-        super(BaseTestLoadBalancerManager, self).setUp()
-        self.in_lb = data_models.LoadBalancer(id='lb1', listeners=[])
-
-
-class TestLoadBalancerManager(BaseTestLoadBalancerManager):
-
-    @mock.patch.object(data_models.LoadBalancer, 'from_dict')
-    def test_refresh(self, lb_from_dict):
-        rpc_return = {'id': self.in_lb.id}
-        self.driver.plugin_rpc.get_loadbalancer.return_value = rpc_return
-        from_dict_return = data_models.LoadBalancer(id=self.in_lb.id)
-        lb_from_dict.return_value = from_dict_return
-        self.driver.deploy_instance.return_value = True
-        self.driver.exists.return_value = True
-        self.lb_manager.refresh(self.in_lb)
-        self.driver.plugin_rpc.get_loadbalancer.assert_called_once_with(
-            self.in_lb.id)
-        lb_from_dict.assert_called_once_with(rpc_return)
-        self.driver.deploy_instance.assert_called_once_with(from_dict_return)
-        self.assertFalse(self.driver.exists.called)
-        self.assertFalse(self.driver.undeploy_instance.called)
-
-        self.driver.reset_mock()
-        lb_from_dict.reset_mock()
-        self.driver.deploy_instance.return_value = False
-        self.driver.exists.return_value = False
-        self.lb_manager.refresh(self.in_lb)
-        self.driver.plugin_rpc.get_loadbalancer.assert_called_once_with(
-            self.in_lb.id)
-        lb_from_dict.assert_called_once_with(rpc_return)
-        self.driver.deploy_instance.assert_called_once_with(from_dict_return)
-        self.driver.exists.assert_called_once_with(self.in_lb.id)
-        self.assertFalse(self.driver.undeploy_instance.called)
-
-        self.driver.reset_mock()
-        lb_from_dict.reset_mock()
-        self.driver.deploy_instance.return_value = False
-        self.driver.exists.return_value = True
-        self.lb_manager.refresh(self.in_lb)
-        self.driver.plugin_rpc.get_loadbalancer.assert_called_once_with(
-            self.in_lb.id)
-        lb_from_dict.assert_called_once_with(rpc_return)
-        self.driver.deploy_instance.assert_called_once_with(from_dict_return)
-        self.driver.exists.assert_called_once_with(from_dict_return.id)
-        self.driver.undeploy_instance.assert_called_once_with(self.in_lb.id)
-
-    def test_delete(self):
-        self.driver.exists.return_value = False
-        self.lb_manager.delete(self.in_lb)
-        self.driver.exists.assert_called_once_with(self.in_lb.id)
-        self.assertFalse(self.driver.undeploy_instance.called)
-
-        self.driver.reset_mock()
-        self.driver.exists.return_value = True
-        self.lb_manager.delete(self.in_lb)
-        self.driver.exists.assert_called_once_with(self.in_lb.id)
-        self.driver.undeploy_instance.assert_called_once_with(
-            self.in_lb.id, delete_namespace=True)
-
-    def test_create(self):
-        self.lb_manager.refresh = mock.Mock()
-        self.lb_manager.create(self.in_lb)
-        self.assertFalse(self.lb_manager.refresh.called)
-
-        self.lb_manager.refresh.reset_mock()
-        self.in_lb.listeners.append(data_models.Listener(id='listener1'))
-        self.lb_manager.create(self.in_lb)
-        self.lb_manager.refresh.assert_called_once_with(self.in_lb)
-
-    def test_get_stats(self):
-        self.lb_manager.get_stats(self.in_lb.id)
-        self.driver.get_stats.assert_called_once_with(self.in_lb.id)
-
-    def test_update(self):
-        old_lb = data_models.LoadBalancer(id='lb0')
-        self.lb_manager.refresh = mock.Mock()
-        self.lb_manager.update(old_lb, self.in_lb)
-        self.lb_manager.refresh.assert_called_once_with(self.in_lb)
-
-
-class BaseTestListenerManager(BaseTestLoadBalancerManager):
-
-    def setUp(self):
-        super(BaseTestListenerManager, self).setUp()
-        self.in_listener = data_models.Listener(id='listener1')
-        self.listener2 = data_models.Listener(id='listener2')
-        self.in_listener.loadbalancer = self.in_lb
-        self.listener2.loadbalancer = self.in_lb
-        self.in_lb.listeners = [self.in_listener, self.listener2]
-        self.refresh = self.driver.loadbalancer.refresh
-
-
-class TestListenerManager(BaseTestListenerManager):
-
-    def setUp(self):
-        super(TestListenerManager, self).setUp()
-        self.in_listener = data_models.Listener(id='listener1')
-        self.listener2 = data_models.Listener(id='listener2')
-        self.in_lb.listeners = [self.in_listener, self.listener2]
-        self.in_listener.loadbalancer = self.in_lb
-        self.listener2.loadbalancer = self.in_lb
-
-    def test_remove_listener(self):
-        self.listener_manager._remove_listener(self.in_lb, self.in_listener.id)
-        self.assertEqual(1, len(self.in_lb.listeners))
-        self.assertEqual(self.listener2.id, self.in_lb.listeners[0].id)
-
-    def test_update(self):
-        old_listener = data_models.Listener(id='listener1', name='bleh')
-        self.listener_manager.update(old_listener, self.in_listener)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_create(self):
-        self.listener_manager.create(self.in_listener)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_delete(self):
-        self.listener_manager.delete(self.in_listener)
-        self.refresh.assert_called_once_with(self.in_lb)
-        self.assertFalse(self.driver.undeploy_instance.called)
-
-        self.refresh.reset_mock()
-        self.driver.reset_mock()
-        self.listener_manager.delete(self.listener2)
-        self.assertFalse(self.refresh.called)
-        self.driver.undeploy_instance.assert_called_once_with(self.in_lb.id)
-
-
-class BaseTestPoolManager(BaseTestListenerManager):
-
-    def setUp(self):
-        super(BaseTestPoolManager, self).setUp()
-        self.in_pool = data_models.Pool(id='pool1')
-        self.in_listener.default_pool = self.in_pool
-        self.in_pool.loadbalancer = self.in_lb
-        self.in_pool.listeners = [self.in_listener]
-        self.in_lb.pools = [self.in_pool]
-
-
-class TestPoolManager(BaseTestPoolManager):
-
-    def test_update(self):
-        old_pool = data_models.Pool(id=self.in_pool.id, name='bleh')
-        self.pool_manager.update(old_pool, self.in_pool)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_create(self):
-        self.pool_manager.create(self.in_pool)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_delete(self):
-        self.pool_manager.delete(self.in_pool)
-        self.assertIsNone(self.in_listener.default_pool)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-
-class BaseTestMemberManager(BaseTestPoolManager):
-
-    def setUp(self):
-        super(BaseTestMemberManager, self).setUp()
-        self.in_member = data_models.Member(id='member1')
-        self.member2 = data_models.Member(id='member2')
-        self.in_pool.members = [self.in_member, self.member2]
-        self.in_member.pool = self.in_pool
-        self.member2.pool = self.in_pool
-
-
-class TestMemberManager(BaseTestMemberManager):
-
-    def test_remove_member(self):
-        self.member_manager._remove_member(self.in_pool, self.in_member.id)
-        self.assertEqual(1, len(self.in_pool.members))
-        self.assertEqual(self.member2.id, self.in_pool.members[0].id)
-
-    def test_update(self):
-        old_member = data_models.Member(id=self.in_member.id,
-                                        address='0.0.0.0')
-        self.member_manager.update(old_member, self.in_member)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_create(self):
-        self.member_manager.create(self.in_member)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_delete(self):
-        self.member_manager.delete(self.in_member)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-
-class BaseTestHealthMonitorManager(BaseTestPoolManager):
-
-    def setUp(self):
-        super(BaseTestHealthMonitorManager, self).setUp()
-        self.in_hm = data_models.HealthMonitor(id='hm1')
-        self.in_pool.healthmonitor = self.in_hm
-        self.in_hm.pool = self.in_pool
-
-
-class TestHealthMonitorManager(BaseTestHealthMonitorManager):
-
-    def test_update(self):
-        old_hm = data_models.HealthMonitor(id=self.in_hm.id, timeout=2)
-        self.hm_manager.update(old_hm, self.in_hm)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_create(self):
-        self.hm_manager.create(self.in_hm)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-    def test_delete(self):
-        self.hm_manager.delete(self.in_hm)
-        self.assertIsNone(self.in_pool.healthmonitor)
-        self.refresh.assert_called_once_with(self.in_lb)
-
-
-class TestNamespaceDriverModule(base.BaseTestCase):
-
-    @mock.patch('os.path.exists')
-    @mock.patch('neutron.agent.linux.utils.execute')
-    def test_kill_pids_in_file(self, execute, exists):
-        pid_path = '/var/lib/data'
-        with mock.patch('six.moves.builtins.open') as m_open:
-            exists.return_value = False
-            file_mock = mock.MagicMock()
-            m_open.return_value = file_mock
-            file_mock.__enter__.return_value = file_mock
-            file_mock.__iter__.return_value = iter(['123'])
-            namespace_driver.kill_pids_in_file(pid_path)
-            # sometimes fails
-            # exists.assert_called_once_with(pid_path)
-            self.assertFalse(m_open.called)
-            self.assertFalse(execute.called)
-
-            exists.return_value = True
-            execute.side_effect = RuntimeError
-            namespace_driver.kill_pids_in_file(pid_path)
-            # sometimes fails
-            # execute.assert_called_once_with(['kill', '-9', '123'])
-
-    def test_get_ns_name(self):
-        ns_name = namespace_driver.get_ns_name('woohoo')
-        self.assertEqual(namespace_driver.NS_PREFIX + 'woohoo', ns_name)
diff --git a/tests/unit/drivers/kemptechnologies/__init__.py b/tests/unit/drivers/kemptechnologies/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/kemptechnologies/test_driver_v2.py b/tests/unit/drivers/kemptechnologies/test_driver_v2.py
deleted file mode 100644
index 9f467b9..0000000
--- a/tests/unit/drivers/kemptechnologies/test_driver_v2.py
+++ /dev/null
@@ -1,98 +0,0 @@
-#  Copyright 2015, Shane McGough, KEMPtechnologies
-#  Licensed under the Apache License, Version 2.0 (the "License"); you may
-#  not use this file except in compliance with the License. You may obtain
-#  a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#  License for the specific language governing permissions and limitations
-#  under the License.
-
-import sys
-
-import mock
-from neutron import context
-
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-with mock.patch.dict(sys.modules, {'kemptech_openstack_lbaas': mock.Mock()}):
-    from neutron_lbaas.drivers.kemptechnologies import driver_v2
-
-
-class FakeModel(object):
-    def __init__(self, id):
-        self.id = id
-        self.address = '1.1.1.1'
-        self.tenant_id = "copying-pre-existing-work-is-easy"
-
-
-class ManagerTest(object):
-    def __init__(self, parent, manager, model, mocked_root):
-        self.parent = parent
-        self.context = parent.context
-        self.driver = parent.driver
-        self.manager = manager
-        self.model = model
-        self.mocked_root = mocked_root
-
-        self.create(model)
-        self.update(model, model)
-        self.delete(model)
-
-    def create(self, model):
-        self.manager.create(self.context, model)
-        self.mocked_root.create.assert_called_with(self.context, model)
-
-    def update(self, old_model, model):
-        self.manager.update(self.context, old_model, model)
-        self.mocked_root.update.assert_called_with(self.context,
-                                                   old_model, model)
-
-    def delete(self, model):
-        self.manager.delete(self.context, model)
-        self.mocked_root.delete.assert_called_with(self.context, model)
-
-    def refresh(self):
-        self.manager.refresh(self.context, self.model)
-        self.mocked_root.refresh.assert_called_with(self.context, self.model)
-
-    def stats(self):
-        self.manager.stats(self.context, self.model)
-        self.mocked_root.stats.assert_called_with(self.context, self.model)
-
-
-class TestKempLoadMasterDriver(test_db_loadbalancerv2.LbaasPluginDbTestCase):
-
-    def setUp(self):
-        super(TestKempLoadMasterDriver, self).setUp()
-        self.context = context.get_admin_context()
-        self.plugin = mock.Mock()
-        self.driver = driver_v2.KempLoadMasterDriver(self.plugin)
-        self.driver.kemptech = mock.Mock()
-
-    def test_load_balancer_ops(self):
-        m = ManagerTest(self, self.driver.load_balancer,
-                        FakeModel("load_balancer-kemptech"),
-                        self.driver.kemptech.load_balancer)
-        m.refresh()
-        m.stats()
-
-    def test_listener_ops(self):
-        ManagerTest(self, self.driver.listener, FakeModel("listener-kemptech"),
-                    self.driver.kemptech.listener)
-
-    def test_pool_ops(self):
-        ManagerTest(self, self.driver.pool, FakeModel("pool-kemptech"),
-                    self.driver.kemptech.pool)
-
-    def test_member_ops(self):
-        ManagerTest(self, self.driver.member, FakeModel("member-kemptech"),
-                    self.driver.kemptech.member)
-
-    def test_health_monitor_ops(self):
-        ManagerTest(self, self.driver.health_monitor,
-                    FakeModel("health_monitor-kemptech"),
-                    self.driver.kemptech.health_monitor)
diff --git a/tests/unit/drivers/logging_noop/__init__.py b/tests/unit/drivers/logging_noop/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/logging_noop/test_logging_noop_driver.py b/tests/unit/drivers/logging_noop/test_logging_noop_driver.py
deleted file mode 100644
index ce5715a..0000000
--- a/tests/unit/drivers/logging_noop/test_logging_noop_driver.py
+++ /dev/null
@@ -1,169 +0,0 @@
-# Copyright 2014, Doug Wiegley (dougwig), A10 Networks
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import mock
-from neutron import context
-
-from neutron_lbaas.drivers.logging_noop import driver
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-log_path = ('neutron_lbaas.drivers.logging_noop.driver.LOG')
-
-
-class FakeModel(object):
-    def __init__(self, id):
-        self.id = id
-
-    def attached_to_loadbalancer(self):
-        return True
-
-
-def patch_manager(func):
-    @mock.patch(log_path)
-    def wrapper(*args):
-        log_mock = args[-1]
-        manager_test = args[0]
-        model = args[1]
-        parent = manager_test.parent
-        driver = parent.driver
-        driver.plugin.reset_mock()
-
-        func(*args[:-1])
-
-        s = str(log_mock.mock_calls[0])
-        parent.assertEqual("call.debug(", s[:11])
-        parent.assertTrue(s.index(model.id) != -1,
-                          msg="Model ID not found in log")
-
-    return wrapper
-
-
-class ManagerTest(object):
-    def __init__(self, parent, manager, model):
-        self.parent = parent
-        self.manager = manager
-
-        self.create(model)
-        self.update(model, model)
-        self.delete(model)
-
-    @patch_manager
-    def create(self, model):
-        self.manager.create(self.parent.context, model)
-
-    @patch_manager
-    def update(self, old_model, model):
-        self.manager.update(self.parent.context, old_model, model)
-
-    @patch_manager
-    def delete(self, model):
-        self.manager.delete(self.parent.context, model)
-
-
-class ManagerTestWithUpdates(ManagerTest):
-    def __init__(self, parent, manager, model):
-        self.parent = parent
-        self.manager = manager
-
-        self.create(model)
-        self.update(model, model)
-        self.delete(model)
-
-    @patch_manager
-    def create(self, model):
-        self.manager.create(self.parent.context, model)
-
-    @patch_manager
-    def update(self, old_model, model):
-        self.manager.update(self.parent.context, old_model, model)
-
-    @patch_manager
-    def delete(self, model):
-        self.manager.delete(self.parent.context, model)
-
-
-class LoadBalancerManagerTest(ManagerTestWithUpdates):
-    def __init__(self, parent, manager, model):
-        super(LoadBalancerManagerTest, self).__init__(parent, manager, model)
-
-        self.create_and_allocate_vip(model)
-        self.refresh(model)
-        self.stats(model)
-
-    @patch_manager
-    def allocates_vip(self):
-        self.manager.allocates_vip()
-
-    @patch_manager
-    def create_and_allocate_vip(self, model):
-        self.manager.create(self.parent.context, model)
-
-    @patch_manager
-    def refresh(self, model):
-        self.manager.refresh(self.parent.context, model)
-
-    @patch_manager
-    def stats(self, model):
-        dummy_stats = {
-            "bytes_in": 0,
-            "bytes_out": 0,
-            "active_connections": 0,
-            "total_connections": 0
-        }
-        h = self.manager.stats(self.parent.context, model)
-        self.parent.assertEqual(dummy_stats, h)
-
-
-class TestLoggingNoopLoadBalancerDriver(
-        test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def _create_fake_models(self):
-        id = 'name-001'
-        lb = data_models.LoadBalancer(id=id)
-        pool = data_models.Pool(id=id, loadbalancer=lb)
-        listener = data_models.Listener(id=id, loadbalancer=lb)
-        member = data_models.Member(id=id, pool=pool)
-        hm = data_models.HealthMonitor(id=id, pool=pool)
-        lb.listeners = [listener]
-        lb.pools = [pool]
-        listener.default_pool = pool
-        pool.members = [member]
-        pool.healthmonitor = hm
-        return lb
-
-    def setUp(self):
-        super(TestLoggingNoopLoadBalancerDriver, self).setUp()
-        self.context = context.get_admin_context()
-        self.plugin = mock.Mock()
-        self.driver = driver.LoggingNoopLoadBalancerDriver(self.plugin)
-        self.lb = self._create_fake_models()
-
-    def test_load_balancer_ops(self):
-        LoadBalancerManagerTest(self, self.driver.load_balancer, self.lb)
-
-    def test_listener_ops(self):
-        ManagerTest(self, self.driver.listener, self.lb.listeners[0])
-
-    def test_pool_ops(self):
-        ManagerTestWithUpdates(self, self.driver.pool,
-                               self.lb.listeners[0].default_pool)
-
-    def test_member_ops(self):
-        ManagerTestWithUpdates(self, self.driver.member,
-                               self.lb.listeners[0].default_pool.members[0])
-
-    def test_health_monitor_ops(self):
-        ManagerTest(self, self.driver.health_monitor,
-                    self.lb.listeners[0].default_pool.healthmonitor)
diff --git a/tests/unit/drivers/netscaler/test_netscaler_driver_v2.py b/tests/unit/drivers/netscaler/test_netscaler_driver_v2.py
deleted file mode 100644
index 04b8639..0000000
--- a/tests/unit/drivers/netscaler/test_netscaler_driver_v2.py
+++ /dev/null
@@ -1,342 +0,0 @@
-# Copyright 2015 Citrix Systems
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import mock
-
-from neutron_lbaas.drivers.netscaler \
-    import netscaler_driver_v2
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.services.loadbalancer.drivers.netscaler import ncc_client
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-
-LBAAS_DRIVER_CLASS = ('neutron_lbaas.services.loadbalancer.drivers'
-                      '.netscaler.netscaler_driver_v2'
-                      '.NetScalerLoadBalancerDriverV2')
-
-NCC_CLIENT_CLASS = ('neutron_lbaas.services.loadbalancer.drivers'
-                    '.netscaler.ncc_client'
-                    '.NSClient')
-
-LBAAS_PROVIDER_NAME = 'NetScaler'
-LBAAS_PROVIDER = ('LOADBALANCERV2:%s:%s:default' %
-                  (LBAAS_PROVIDER_NAME, LBAAS_DRIVER_CLASS))
-
-log_path = ('neutron_lbaas.services.loadbalancer.drivers.'
-            'logging_noop.driver.LOG')
-
-
-class FakeModel(object):
-
-    def __init__(self, id):
-        self.id = id
-
-    def attached_to_loadbalancer(self):
-        return True
-
-
-class ManagerTest(object):
-
-    def __init__(self, parent, manager, model):
-        self.parent = parent
-        self.manager = manager
-        self.model = model
-        self.object_path = None
-        self.async_obj_track_list = (netscaler_driver_v2.
-                                     PROVISIONING_STATUS_TRACKER)
-        self.successful_completion_mock = mock.patch.object(
-            manager, "successful_completion").start()
-        self.failed_completion_mock = mock.patch.object(
-            manager, "failed_completion").start()
-
-    def start_tests(self):
-        model = self.model
-        self.object_path = "%s/%s" % (
-            self.resource_path,
-            model.id)
-        self.create_success(model)
-        self.update_success(model, model)
-        self.delete_success(model)
-
-        self.create_failure(model)
-        self.update_failure(model, model)
-        self.delete_failure(model)
-
-    def _check_success_completion(self):
-        """Check if success_completion is called"""
-        successful_completion_mock = self.successful_completion_mock
-        successful_completion_mock.assert_called_once_with(
-            mock.ANY, self.model)
-        successful_completion_mock.reset_mock()
-
-    def _check_success_completion_with_delete(self):
-        """Check if success_compeletion is called with delete"""
-        successful_completion_mock = self.successful_completion_mock
-        successful_completion_mock.assert_called_once_with(
-            mock.ANY, self.model, delete=True)
-        successful_completion_mock.reset_mock()
-
-    def _check_failure_completion(self):
-        """Check failed_completion is called"""
-        failed_completion_mock = self.failed_completion_mock
-        failed_completion_mock.assert_called_once_with(
-            mock.ANY, self.model)
-        failed_completion_mock.reset_mock()
-
-    def _set_response_error(self, mock_instance):
-        errorcode = ncc_client.NCCException.RESPONSE_ERROR
-        mock_instance.side_effect = (ncc_client
-                                     .NCCException(errorcode))
-
-    def create(self, model):
-        self.manager.create(self.parent.context, model)
-        create_resource_mock = self.parent.create_resource_mock
-        self.parent.assertTrue(create_resource_mock.called)
-        resource_path = self.resource_path
-        object_name = self.object_name
-        create_payload = mock.ANY
-        create_resource_mock.assert_called_once_with(
-            mock.ANY, resource_path, object_name, create_payload)
-
-    def update(self, old_model, model):
-        self.manager.update(self.parent.context, old_model, model)
-        update_resource_mock = self.parent.update_resource_mock
-        self.parent.assertTrue(update_resource_mock.called)
-        object_path = self.object_path
-        object_name = self.object_name
-        update_payload = mock.ANY
-        update_resource_mock.assert_called_once_with(
-            mock.ANY, object_path, object_name, update_payload)
-
-    def delete(self, model):
-        self.manager.delete(self.parent.context, model)
-        remove_resource_mock = self.parent.remove_resource_mock
-        self.parent.assertTrue(remove_resource_mock.called)
-        object_path = self.object_path
-        remove_resource_mock.assert_called_once_with(
-            mock.ANY, object_path)
-
-    def check_op_status(self, model, delete=False):
-        loadbalancer = model.root_loadbalancer
-        if hasattr(self, "async_obj_track_list") and self.async_obj_track_list:
-            self.parent.assertIn(
-                loadbalancer.id, self.async_obj_track_list)
-        else:
-            if delete:
-                self._check_success_completion_with_delete()
-            else:
-                self._check_success_completion()
-
-    def create_success(self, model):
-        self.create(model)
-        self.check_op_status(model)
-        self.parent.create_resource_mock.reset()
-
-    def update_success(self, old_model, model):
-        self.update(old_model, model)
-        self.check_op_status(model)
-        self.parent.update_resource_mock.reset_mock()
-
-    def delete_success(self, model):
-        self.delete(model)
-        self.check_op_status(model, delete=True)
-        self.parent.remove_resource_mock.reset_mock()
-
-    def create_failure(self, model):
-        create_resource_mock = self.parent.create_resource_mock
-        self._set_response_error(create_resource_mock)
-
-        try:
-            self.create(model)
-        except Exception:
-            pass
-
-        self._check_failure_completion()
-        create_resource_mock.reset_mock()
-        create_resource_mock.side_effect = mock_create_resource_func
-
-    def update_failure(self, old_model, model):
-        update_resource_mock = self.parent.update_resource_mock
-        self._set_response_error(update_resource_mock)
-
-        try:
-            self.update(old_model, model)
-        except Exception:
-            pass
-
-        self._check_failure_completion()
-        update_resource_mock.reset_mock()
-        update_resource_mock.side_effect = mock_update_resource_func
-
-    def delete_failure(self, model):
-        remove_resource_mock = self.parent.remove_resource_mock
-        self._set_response_error(remove_resource_mock)
-        try:
-            self.delete(model)
-        except Exception:
-            pass
-
-        self._check_failure_completion()
-        remove_resource_mock.reset_mock()
-        remove_resource_mock.side_effect = mock_remove_resource_func
-
-
-class LoadBalancerManagerTest(ManagerTest):
-
-    def __init__(self, parent, manager, model):
-        super(LoadBalancerManagerTest, self).__init__(parent, manager, model)
-        self.object_name = netscaler_driver_v2.LB_RESOURCE
-        self.resource_path = "%s/%s" % (
-            netscaler_driver_v2.RESOURCE_PREFIX,
-            netscaler_driver_v2.LBS_RESOURCE)
-        self.start_tests()
-
-
-class ListenerManagerTest(ManagerTest):
-
-    def __init__(self, parent, manager, model):
-        super(ListenerManagerTest, self).__init__(parent, manager, model)
-        self.object_name = netscaler_driver_v2.LISTENER_RESOURCE
-        self.resource_path = "%s/%s" % (
-            netscaler_driver_v2.RESOURCE_PREFIX,
-            netscaler_driver_v2.LISTENERS_RESOURCE)
-        self.start_tests()
-
-
-class PoolManagerTest(ManagerTest):
-
-    def __init__(self, parent, manager, model):
-        super(PoolManagerTest, self).__init__(parent, manager, model)
-        self.object_name = netscaler_driver_v2.POOL_RESOURCE
-        self.resource_path = "%s/%s" % (
-            netscaler_driver_v2.RESOURCE_PREFIX,
-            netscaler_driver_v2.POOLS_RESOURCE)
-        self.start_tests()
-
-
-class MemberManagerTest(ManagerTest):
-
-    def __init__(self, parent, manager, model):
-        super(MemberManagerTest, self).__init__(parent, manager, model)
-        self.object_name = netscaler_driver_v2.MEMBER_RESOURCE
-        self.resource_path = "%s/%s/%s/%s" % (
-            netscaler_driver_v2.RESOURCE_PREFIX,
-            netscaler_driver_v2.POOLS_RESOURCE,
-            model.pool.id,
-            netscaler_driver_v2.MEMBERS_RESOURCE)
-        self.start_tests()
-
-
-class MonitorManagerTest(ManagerTest):
-
-    def __init__(self, parent, manager, model):
-        super(MonitorManagerTest, self).__init__(parent, manager, model)
-        self.object_name = netscaler_driver_v2.MONITOR_RESOURCE
-        self.resource_path = "%s/%s" % (
-            netscaler_driver_v2.RESOURCE_PREFIX,
-            netscaler_driver_v2.MONITORS_RESOURCE)
-        self.start_tests()
-
-
-class TestNetScalerLoadBalancerDriverV2(
-        test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def _create_fake_models(self):
-        id = 'name-001'
-        lb = data_models.LoadBalancer(id=id)
-        listener = data_models.Listener(id=id, loadbalancer=lb)
-        pool = data_models.Pool(id=id, listener=listener)
-        member = data_models.Member(id=id, pool=pool)
-        hm = data_models.HealthMonitor(id=id, pool=pool)
-        lb.listeners = [listener]
-        listener.default_pool = pool
-        pool.members = [member]
-        pool.healthmonitor = hm
-        return lb
-
-    def _get_fake_network_info(self):
-        network_info = {}
-        network_info["network_id"] = "network_id_1"
-        network_info["subnet_id"] = "subnet_id_1"
-        return network_info
-
-    def setUp(self):
-        super(TestNetScalerLoadBalancerDriverV2, self).setUp()
-        self.context = mock.Mock()
-
-        self.plugin = mock.Mock()
-        self.lb = self._create_fake_models()
-        mock.patch.object(netscaler_driver_v2, 'LOG').start()
-
-        network_info_mock = mock.patch.object(
-            netscaler_driver_v2.PayloadPreparer, "get_network_info").start()
-        network_info_mock.return_value = self._get_fake_network_info()
-
-        mock.patch.object(
-            netscaler_driver_v2.NetScalerLoadBalancerDriverV2,
-            "_init_status_collection").start()
-
-        """mock the NSClient class (REST client)"""
-        client_mock_cls = mock.patch(NCC_CLIENT_CLASS).start()
-
-        """mock the REST methods of the NSClient class"""
-
-        self.client_mock_instance = client_mock_cls.return_value
-        self.create_resource_mock = self.client_mock_instance.create_resource
-        self.create_resource_mock.side_effect = mock_create_resource_func
-        self.update_resource_mock = self.client_mock_instance.update_resource
-        self.update_resource_mock.side_effect = mock_update_resource_func
-        self.retrieve_resource_mock = (self.client_mock_instance
-                                           .retrieve_resource)
-        self.retrieve_resource_mock.side_effect = mock_retrieve_resource_func
-        self.remove_resource_mock = self.client_mock_instance.remove_resource
-        self.remove_resource_mock.side_effect = mock_remove_resource_func
-
-        self.driver = netscaler_driver_v2.NetScalerLoadBalancerDriverV2(
-            self.plugin)
-        self.assertTrue(client_mock_cls.called)
-
-    def test_load_balancer_ops(self):
-        LoadBalancerManagerTest(self, self.driver.load_balancer, self.lb)
-
-    def test_listener_ops(self):
-        ListenerManagerTest(self, self.driver.listener, self.lb.listeners[0])
-
-    def test_pool_ops(self):
-        PoolManagerTest(self, self.driver.pool,
-                        self.lb.listeners[0].default_pool)
-
-    def test_member_ops(self):
-        MemberManagerTest(self, self.driver.member,
-                          self.lb.listeners[0].default_pool.members[0])
-
-    def test_health_monitor_ops(self):
-        MonitorManagerTest(self, self.driver.health_monitor,
-                           self.lb.listeners[0].default_pool.healthmonitor)
-
-
-def mock_create_resource_func(*args, **kwargs):
-    return 201, {}
-
-
-def mock_update_resource_func(*args, **kwargs):
-    return 202, {}
-
-
-def mock_retrieve_resource_func(*args, **kwargs):
-    return 200, {}
-
-
-def mock_remove_resource_func(*args, **kwargs):
-    return 200, {}
diff --git a/tests/unit/drivers/octavia/__init__.py b/tests/unit/drivers/octavia/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/octavia/test_octavia_driver.py b/tests/unit/drivers/octavia/test_octavia_driver.py
deleted file mode 100644
index 0766ef1..0000000
--- a/tests/unit/drivers/octavia/test_octavia_driver.py
+++ /dev/null
@@ -1,499 +0,0 @@
-# Copyright 2015, Banashankar Veerad, Copyright IBM Corporation
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import copy
-import mock
-from oslo_config import cfg
-
-from neutron import context
-from neutron_lbaas.drivers.octavia import driver
-from neutron_lbaas.services.loadbalancer import constants
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-
-class ManagerTest(object):
-    def __init__(self, parent, manager, mocked_req):
-        self.parent = parent
-        self.context = parent.context
-        self.driver = parent.driver
-        self.manager = manager
-        self.mocked_req = mocked_req
-
-    def create(self, model, url, args):
-        self.manager.create(self.context, model)
-        self.mocked_req.post.assert_called_with(url, args)
-
-    def update(self, old_model, model, url, args):
-        self.manager.update(self.context, old_model, model)
-        self.mocked_req.put.assert_called_with(url, args)
-
-    def delete(self, model, url):
-        self.manager.delete(self.context, model)
-        self.mocked_req.delete.assert_called_with(url)
-
-    def delete_cascade(self, model, url):
-        self.manager.delete_cascade(self.context, model)
-        self.mocked_req.delete.assert_called_with(url)
-
-    # TODO(Banashankar) : Complete refresh function. Need more info.
-    def refresh(self):
-        pass
-
-    # TODO(Banashankar): Complete stats function. Need more info.
-    def stats(self):
-        pass
-
-
-class BaseOctaviaDriverTest(test_db_loadbalancerv2.LbaasPluginDbTestCase):
-
-    # Copied it from Brocade's test code :/
-    def _create_fake_models(self):
-        # This id is used for all the entities.
-        id = 'test_id'
-        lb = data_models.LoadBalancer(id=id)
-        sni_container = data_models.SNI(listener_id=id)
-        listener = data_models.Listener(id=id, loadbalancer=lb,
-                                        sni_containers=[sni_container])
-        pool = data_models.Pool(id=id, loadbalancer=lb)
-        member = data_models.Member(id=id, pool=pool)
-        hm = data_models.HealthMonitor(id=id, pool=pool)
-        l7policy = data_models.L7Policy(
-            id=id, listener=listener, redirect_pool_id=pool.id,
-            action=constants.L7_POLICY_ACTION_REDIRECT_TO_POOL)
-        l7rule = data_models.L7Rule(
-            id=id, policy=l7policy,
-            type=constants.L7_RULE_TYPE_PATH,
-            compare_type=constants.L7_RULE_COMPARE_TYPE_STARTS_WITH,
-            value='/api')
-        lb.listeners = [listener]
-        lb.pools = [pool]
-        listener.default_pool = pool
-        listener.l7policies = [l7policy]
-        l7policy.rules = [l7rule]
-        pool.members = [member]
-        pool.healthmonitor = hm
-        return lb
-
-    def setUp(self):
-        super(BaseOctaviaDriverTest, self).setUp()
-        self.context = context.get_admin_context()
-        self.plugin = mock.Mock()
-        self.driver = driver.OctaviaDriver(self.plugin)
-        # mock of rest call.
-        self.driver.req = mock.Mock()
-        self.lb = self._create_fake_models()
-
-
-class TestOctaviaDriver(BaseOctaviaDriverTest):
-
-    def test_allocates_vip(self):
-        self.addCleanup(cfg.CONF.clear_override,
-                        'allocates_vip', group='octavia')
-        cfg.CONF.set_override('allocates_vip', True, group='octavia')
-        test_driver = driver.OctaviaDriver(self.plugin)
-        self.assertTrue(test_driver.load_balancer.allocates_vip)
-
-    def test_load_balancer_ops(self):
-        m = ManagerTest(self, self.driver.load_balancer,
-                        self.driver.req)
-
-        lb = self.lb
-
-        # urls for assert test.
-        lb_url = '/v1/loadbalancers'
-        lb_url_id = '/v1/loadbalancers/' + lb.id
-
-        # Create LB test
-        # args for create assert.
-        args = {
-            'id': lb.id,
-            'name': lb.name,
-            'description': lb.description,
-            'enabled': lb.admin_state_up,
-            'project_id': lb.tenant_id,
-            'vip': {
-                'subnet_id': lb.vip_subnet_id,
-                'ip_address': lb.vip_address,
-                'port_id': lb.vip_port_id,
-            }
-        }
-        m.create(lb, lb_url, args)
-
-        # Update LB test
-        # args for update assert.
-        args = args = {
-            'name': lb.name,
-            'description': lb.description,
-            'enabled': lb.admin_state_up,
-        }
-        m.update(lb, lb, lb_url_id, args)
-
-        # delete LB test
-        m.delete_cascade(lb, lb_url_id + '/delete_cascade')
-
-        # TODO(Banashankar) : refresh n stats fucntions are not yet done.
-        #m.refresh()
-        #m.stats()
-
-    def test_listener_ops(self):
-        m = ManagerTest(self, self.driver.listener,
-                        self.driver.req)
-
-        listener = self.lb.listeners[0]
-
-        # urls for assert test.
-        list_url = '/v1/loadbalancers/%s/listeners' % listener.loadbalancer.id
-        list_url_id = list_url + '/%s' % (listener.id)
-
-        # Create Listener test.
-        # args for create and update assert.
-        sni_containers = [sni.tls_container_id
-                          for sni in listener.sni_containers]
-        args = {
-            'id': listener.id,
-            'name': listener.name,
-            'description': listener.description,
-            'enabled': listener.admin_state_up,
-            'protocol': listener.protocol,
-            'protocol_port': listener.protocol_port,
-            'connection_limit': listener.connection_limit,
-            'tls_certificate_id': listener.default_tls_container_id,
-            'sni_containers': sni_containers,
-            'default_pool_id': listener.default_pool_id,
-            'project_id': listener.tenant_id
-        }
-        m.create(listener, list_url, args)
-
-        # Update listener test.
-        del args['id']
-        del args['project_id']
-        m.update(listener, listener, list_url_id, args)
-
-        # Delete listener.
-        m.delete(listener, list_url_id)
-
-    def test_pool_ops(self):
-        m = ManagerTest(self, self.driver.pool,
-                        self.driver.req)
-
-        pool = self.lb.listeners[0].default_pool
-
-        # urls for assert test.
-        pool_url = '/v1/loadbalancers/%s/pools' % (
-            pool.loadbalancer.id)
-        pool_url_id = pool_url + "/%s" % pool.id
-
-        # Test create pool.
-        # args for create and update assert.
-        args = {
-            'id': pool.id,
-            'name': pool.name,
-            'description': pool.description,
-            'enabled': pool.admin_state_up,
-            'protocol': pool.protocol,
-            'lb_algorithm': pool.lb_algorithm,
-            'project_id': pool.tenant_id
-        }
-        if pool.session_persistence:
-            args['session_persistence'] = {
-                'type': pool.session_persistence.type,
-                'cookie_name': pool.session_persistence.cookie_name,
-            }
-        else:
-            args['session_persistence'] = None
-        m.create(pool, pool_url, args)
-
-        # Test update pool.
-        del args['id']
-        del args['project_id']
-        m.update(pool, pool, pool_url_id, args)
-
-        # Test pool delete.
-        m.delete(pool, pool_url_id)
-
-    def test_member_ops(self):
-        m = ManagerTest(self, self.driver.member,
-                        self.driver.req)
-
-        member = self.lb.listeners[0].default_pool.members[0]
-
-        # urls for assert.
-        mem_url = '/v1/loadbalancers/%s/pools/%s/members' % (
-            member.pool.loadbalancer.id,
-            member.pool.id)
-        mem_url_id = mem_url + "/%s" % member.id
-
-        # Test Create member.
-        # args for create assert.
-        args = {
-            'id': member.id,
-            'enabled': member.admin_state_up,
-            'ip_address': member.address,
-            'protocol_port': member.protocol_port,
-            'weight': member.weight,
-            'subnet_id': member.subnet_id,
-            'project_id': member.tenant_id
-        }
-        m.create(member, mem_url, args)
-
-        # Test member update.
-        # args for update assert.
-        args = {
-            'enabled': member.admin_state_up,
-            'protocol_port': member.protocol_port,
-            'weight': member.weight,
-        }
-        m.update(member, member, mem_url_id, args)
-
-        # Test member delete.
-        m.delete(member, mem_url_id)
-
-    def test_health_monitor_ops(self):
-        m = ManagerTest(self, self.driver.health_monitor,
-                        self.driver.req)
-
-        hm = self.lb.listeners[0].default_pool.healthmonitor
-
-        # urls for assert.
-        hm_url = '/v1/loadbalancers/%s/pools/%s/healthmonitor' % (
-            hm.pool.loadbalancer.id,
-            hm.pool.id)
-
-        # Test HM create.
-        # args for create and update assert.
-        args = {
-            'type': hm.type,
-            'delay': hm.delay,
-            'timeout': hm.timeout,
-            'rise_threshold': hm.max_retries,
-            'fall_threshold': hm.max_retries,
-            'http_method': hm.http_method,
-            'url_path': hm.url_path,
-            'expected_codes': hm.expected_codes,
-            'enabled': hm.admin_state_up,
-            'project_id': hm.tenant_id
-        }
-        m.create(hm, hm_url, args)
-
-        # Test HM update
-        del args['project_id']
-        m.update(hm, hm, hm_url, args)
-
-        # Test HM delete
-        m.delete(hm, hm_url)
-
-    def test_l7_policy_ops_reject(self):
-        m = ManagerTest(self, self.driver.l7policy,
-                        self.driver.req)
-
-        l7p = copy.deepcopy(self.lb.listeners[0].l7policies[0])
-        l7p.action = constants.L7_POLICY_ACTION_REJECT
-
-        # urls for assert.
-        l7p_url = '/v1/loadbalancers/%s/listeners/%s/l7policies' % (
-            l7p.listener.loadbalancer.id,
-            l7p.listener.id)
-        l7p_url_id = l7p_url + "/%s" % l7p.id
-
-        # Test L7Policy create.
-        # args for create and update assert.
-        args = {
-            'id': l7p.id,
-            'name': l7p.name,
-            'description': l7p.description,
-            'action': constants.L7_POLICY_ACTION_REJECT,
-            'position': l7p.position,
-            'enabled': l7p.admin_state_up
-        }
-        m.create(l7p, l7p_url, args)
-
-        # Test L7Policy update
-        del args['id']
-        m.update(l7p, l7p, l7p_url_id, args)
-
-        # Test L7Policy delete
-        m.delete(l7p, l7p_url_id)
-
-    def test_l7_policy_ops_rdr_pool(self):
-        m = ManagerTest(self, self.driver.l7policy,
-                        self.driver.req)
-
-        l7p = copy.deepcopy(self.lb.listeners[0].l7policies[0])
-        l7p.action = constants.L7_POLICY_ACTION_REDIRECT_TO_POOL
-
-        # urls for assert.
-        l7p_url = '/v1/loadbalancers/%s/listeners/%s/l7policies' % (
-            l7p.listener.loadbalancer.id,
-            l7p.listener.id)
-        l7p_url_id = l7p_url + "/%s" % l7p.id
-
-        # Test L7Policy create.
-        # args for create and update assert.
-        args = {
-            'id': l7p.id,
-            'name': l7p.name,
-            'description': l7p.description,
-            'action': constants.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-            'redirect_pool_id': l7p.redirect_pool_id,
-            'position': l7p.position,
-            'enabled': l7p.admin_state_up
-        }
-        m.create(l7p, l7p_url, args)
-
-        # Test L7Policy update
-        del args['id']
-        m.update(l7p, l7p, l7p_url_id, args)
-
-        # Test L7Policy delete
-        m.delete(l7p, l7p_url_id)
-
-    def test_l7_policy_ops_rdr_url(self):
-        m = ManagerTest(self, self.driver.l7policy,
-                        self.driver.req)
-
-        l7p = copy.deepcopy(self.lb.listeners[0].l7policies[0])
-        l7p.action = constants.L7_POLICY_ACTION_REDIRECT_TO_URL
-
-        # urls for assert.
-        l7p_url = '/v1/loadbalancers/%s/listeners/%s/l7policies' % (
-            l7p.listener.loadbalancer.id,
-            l7p.listener.id)
-        l7p_url_id = l7p_url + "/%s" % l7p.id
-
-        # Test L7Policy create.
-        # args for create and update assert.
-        args = {
-            'id': l7p.id,
-            'name': l7p.name,
-            'description': l7p.description,
-            'action': constants.L7_POLICY_ACTION_REDIRECT_TO_URL,
-            'redirect_url': l7p.redirect_url,
-            'position': l7p.position,
-            'enabled': l7p.admin_state_up
-        }
-        m.create(l7p, l7p_url, args)
-
-        # Test L7Policy update
-        del args['id']
-        m.update(l7p, l7p, l7p_url_id, args)
-
-        # Test L7Policy delete
-        m.delete(l7p, l7p_url_id)
-
-    def test_l7_rule_ops(self):
-        m = ManagerTest(self, self.driver.l7rule,
-                        self.driver.req)
-
-        l7r = self.lb.listeners[0].l7policies[0].rules[0]
-
-        # urls for assert.
-        l7r_url = '/v1/loadbalancers/%s/listeners/%s/l7policies/%s/l7rules' % (
-            l7r.policy.listener.loadbalancer.id,
-            l7r.policy.listener.id,
-            l7r.policy.id)
-        l7r_url_id = l7r_url + "/%s" % l7r.id
-
-        # Test L7Rule create.
-        # args for create and update assert.
-        args = {
-            'id': l7r.id,
-            'type': l7r.type,
-            'compare_type': l7r.compare_type,
-            'key': l7r.key,
-            'value': l7r.value,
-            'invert': l7r.invert
-        }
-        m.create(l7r, l7r_url, args)
-
-        # Test L7rule update
-        del args['id']
-        m.update(l7r, l7r, l7r_url_id, args)
-
-        # Test L7Rule delete
-        m.delete(l7r, l7r_url_id)
-
-
-class TestThreadedDriver(BaseOctaviaDriverTest):
-
-        def setUp(self):
-            super(TestThreadedDriver, self).setUp()
-            cfg.CONF.set_override('request_poll_interval', 1, group='octavia')
-            cfg.CONF.set_override('request_poll_timeout', 5, group='octavia')
-            self.driver.req.get = mock.MagicMock()
-            self.succ_completion = mock.MagicMock()
-            self.fail_completion = mock.MagicMock()
-            self.context = mock.MagicMock()
-            ctx_patcher = mock.patch('neutron.context.get_admin_context',
-                                     return_value=self.context)
-            ctx_patcher.start()
-            self.addCleanup(ctx_patcher.stop)
-            self.driver.load_balancer.successful_completion = (
-                self.succ_completion)
-            self.driver.load_balancer.failed_completion = self.fail_completion
-
-        def test_thread_op_goes_active(self):
-            self.driver.req.get.side_effect = [
-                {'provisioning_status': 'PENDING_CREATE'},
-                {'provisioning_status': 'ACTIVE'}
-            ]
-            driver.thread_op(self.driver.load_balancer, self.lb)
-            self.succ_completion.assert_called_once_with(self.context, self.lb,
-                                                         delete=False)
-            self.assertEqual(0, self.fail_completion.call_count)
-
-        def test_thread_op_goes_deleted(self):
-            self.driver.req.get.side_effect = [
-                {'provisioning_status': 'PENDING_DELETE'},
-                {'provisioning_status': 'DELETED'}
-            ]
-            driver.thread_op(self.driver.load_balancer, self.lb, delete=True)
-            self.succ_completion.assert_called_once_with(self.context, self.lb,
-                                                         delete=True)
-            self.assertEqual(0, self.fail_completion.call_count)
-
-        def test_thread_op_goes_error(self):
-            self.driver.req.get.side_effect = [
-                {'provisioning_status': 'PENDING_CREATE'},
-                {'provisioning_status': 'ERROR'}
-            ]
-            driver.thread_op(self.driver.load_balancer, self.lb)
-            self.fail_completion.assert_called_once_with(self.context, self.lb)
-            self.assertEqual(0, self.succ_completion.call_count)
-
-        def test_thread_op_a_times_out(self):
-            cfg.CONF.set_override('request_poll_timeout', 1, group='octavia')
-            self.driver.req.get.side_effect = [
-                {'provisioning_status': 'PENDING_CREATE'}
-            ]
-            driver.thread_op(self.driver.load_balancer, self.lb)
-            self.fail_completion.assert_called_once_with(self.context, self.lb)
-            self.assertEqual(0, self.succ_completion.call_count)
-
-        def test_thread_op_updates_vip_when_vip_delegated(self):
-            cfg.CONF.set_override('allocates_vip', True, group='octavia')
-            expected_vip = '10.1.1.1'
-            self.driver.req.get.side_effect = [
-                {'provisioning_status': 'PENDING_CREATE',
-                 'vip': {'ip_address': ''}},
-                {'provisioning_status': 'ACTIVE',
-                 'vip': {'ip_address': expected_vip}}
-            ]
-            driver.thread_op(self.driver.load_balancer,
-                             self.lb,
-                             lb_create=True)
-            self.succ_completion.assert_called_once_with(self.context, self.lb,
-                                                         delete=False,
-                                                         lb_create=True)
-            self.assertEqual(expected_vip, self.lb.vip_address)
diff --git a/tests/unit/drivers/octavia/test_octavia_messaging_consumer.py b/tests/unit/drivers/octavia/test_octavia_messaging_consumer.py
deleted file mode 100644
index e693f16..0000000
--- a/tests/unit/drivers/octavia/test_octavia_messaging_consumer.py
+++ /dev/null
@@ -1,177 +0,0 @@
-# Copyright 2016 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import mock
-from oslo_config import cfg
-
-from neutron_lbaas.common import exceptions
-from neutron_lbaas.db.loadbalancer import models
-import neutron_lbaas.drivers.octavia.driver as odriver
-from neutron_lbaas.drivers.octavia.driver import octavia_messaging_consumer
-from neutron_lbaas.services.loadbalancer import constants
-from neutron_lbaas.tests.unit.drivers.octavia import test_octavia_driver
-
-InfoContainer = octavia_messaging_consumer.InfoContainer
-
-
-class TestOctaviaMessagingConsumer(test_octavia_driver.BaseOctaviaDriverTest):
-    def setUp(self):
-        super(test_octavia_driver.BaseOctaviaDriverTest, self).setUp()
-        self.plugin = mock.Mock()
-        self.driver = odriver.OctaviaDriver(self.plugin)
-
-    def assert_handle_streamed_event_called(self, model_class, id_param,
-                                            payload):
-        call_args_list = self.driver.plugin.db.update_status.call_args_list[0]
-        self.assertEqual(len(call_args_list), 2)
-        self.assertEqual(len(call_args_list[0]), 3)
-        self.assertEqual(model_class, call_args_list[0][1])
-        self.assertEqual(call_args_list[0][2], id_param)
-        self.assertEqual(call_args_list[1], payload)
-
-    def test_info_container_constructor(self):
-        ID = 'test_id'
-        PAYLOAD = 'test_payload'
-        TYPE = 'test_type'
-        cnt = InfoContainer(TYPE, ID, PAYLOAD)
-        self.assertEqual(cnt.info_type, TYPE)
-        self.assertEqual(cnt.info_id, ID)
-        self.assertEqual(cnt.info_payload, PAYLOAD)
-        self.assertEqual(cnt.to_dict(), {'info_type': TYPE, 'info_id': ID,
-        'info_payload': PAYLOAD})
-
-    def test_info_container_from_dict(self):
-        ID = 'test_id'
-        PAYLOAD = 'test_payload'
-        TYPE = 'test_type'
-        cnt = InfoContainer.from_dict({'info_type': TYPE, 'info_id': ID,
-        'info_payload': PAYLOAD})
-        self.assertEqual(cnt.info_type, TYPE)
-        self.assertEqual(cnt.info_id, ID)
-        self.assertEqual(cnt.info_payload, PAYLOAD)
-
-    def test_set_consumer_topic(self):
-        TOPIC = 'neutron_lbaas_event'
-        self.addCleanup(cfg.CONF.clear_override, 'event_stream_topic',
-                        group='oslo_messaging')
-        cfg.CONF.set_override('event_stream_topic', TOPIC,
-                              group='oslo_messaging')
-        consumer = octavia_messaging_consumer.OctaviaConsumer(self.driver)
-        self.assertIsNotNone(consumer.transport)
-        self.assertEqual(TOPIC, consumer.target.topic)
-        self.assertEqual(cfg.CONF.host, consumer.target.server)
-
-    @mock.patch.object(octavia_messaging_consumer.messaging, 'get_rpc_server')
-    def test_consumer_start(self, mock_get_rpc_server):
-        mock_server = mock.Mock()
-        mock_get_rpc_server.return_value = mock_server
-        TOPIC = 'neutron_lbaas_event'
-        self.addCleanup(cfg.CONF.clear_override, 'event_stream_topic',
-                        group='oslo_messaging')
-        cfg.CONF.set_override('event_stream_topic', TOPIC,
-                              group='oslo_messaging')
-        consumer = octavia_messaging_consumer.OctaviaConsumer(self.driver)
-        consumer.start()
-        mock_get_rpc_server.assert_called_once_with(
-            consumer.transport, consumer.target, consumer.endpoints,
-            executor='eventlet'
-        )
-        mock_server.start.assert_called_once_with()
-
-    @mock.patch.object(octavia_messaging_consumer.messaging, 'get_rpc_server')
-    def test_consumer_stop(self, mock_get_rpc_server):
-        mock_server = mock.Mock()
-        mock_get_rpc_server.return_value = mock_server
-        consumer = octavia_messaging_consumer.OctaviaConsumer(self.driver)
-        consumer.start()
-        consumer.stop()
-        mock_server.stop.assert_called_once_with()
-        mock_server.wait.assert_not_called()
-
-    @mock.patch.object(octavia_messaging_consumer.messaging, 'get_rpc_server')
-    def test_consumer_graceful_stop(self, mock_get_rpc_server):
-        mock_server = mock.Mock()
-        mock_get_rpc_server.return_value = mock_server
-        consumer = octavia_messaging_consumer.OctaviaConsumer(self.driver)
-        consumer.start()
-        consumer.stop(graceful=True)
-        mock_server.stop.assert_called_once_with()
-        mock_server.wait.assert_called_once_with()
-
-    @mock.patch.object(octavia_messaging_consumer.messaging, 'get_rpc_server')
-    def test_consumer_reset(self, mock_get_rpc_server):
-        mock_server = mock.Mock()
-        mock_get_rpc_server.return_value = mock_server
-        consumer = octavia_messaging_consumer.OctaviaConsumer(self.driver)
-        consumer.start()
-        consumer.reset()
-        mock_server.reset.assert_called_once_with()
-
-    def set_db_mocks(self):
-        TOPIC = 'neutron_lbaas_event'
-        self.addCleanup(cfg.CONF.clear_override, 'event_stream_topic',
-                        group='oslo_messaging')
-        cfg.CONF.set_override('event_stream_topic', TOPIC,
-                              group='oslo_messaging')
-        self.payload = {'operating_status': 'ONLINE'}
-        self.consumer = octavia_messaging_consumer.OctaviaConsumer(
-            self.driver)
-
-    def test_updatedb_with_raises_exception_with_bad_model_name(self):
-        self.set_db_mocks()
-
-        cnt = InfoContainer('listener_statsX', 'id',
-                            self.payload).to_dict()
-        self.assertRaises(exceptions.ModelMapException,
-                          self.consumer.endpoints[0].update_info, {}, cnt)
-
-    def test_updatedb_ignores_listener_stats(self):
-        self.set_db_mocks()
-        cnt = InfoContainer('listener_stats', 'id', self.payload).to_dict()
-        self.consumer.endpoints[0].update_info({}, cnt)
-        call_len = len(self.driver.plugin.db.update_status.call_args_list)
-        self.assertEqual(call_len, 0)   # See didn't do anything
-
-    def test_updatedb_loadbalancer(self):
-        self.set_db_mocks()
-        cnt = InfoContainer(constants.LOADBALANCER_EVENT, 'lb_id',
-                            self.payload).to_dict()
-        self.consumer.endpoints[0].update_info({}, cnt)
-        self.assert_handle_streamed_event_called(models.LoadBalancer, 'lb_id',
-                                                 self.payload)
-
-    def test_updatedb_listener(self):
-        self.set_db_mocks()
-        cnt = InfoContainer(constants.LISTENER_EVENT, 'listener_id',
-                            self.payload).to_dict()
-        self.consumer.endpoints[0].update_info({}, cnt)
-        self.assert_handle_streamed_event_called(models.Listener,
-                                                 'listener_id',
-                                                 self.payload)
-
-    def test_updatedb_pool(self):
-        self.set_db_mocks()
-        cnt = InfoContainer(constants.POOL_EVENT, 'pool_id',
-                            self.payload).to_dict()
-        self.consumer.endpoints[0].update_info({}, cnt)
-        self.assert_handle_streamed_event_called(models.PoolV2, 'pool_id',
-                                                 self.payload)
-
-    def test_updatedb_member(self):
-        self.set_db_mocks()
-        cnt = InfoContainer(constants.MEMBER_EVENT, 'pool_id',
-                            self.payload).to_dict()
-        self.consumer.endpoints[0].update_info({}, cnt)
-        self.assert_handle_streamed_event_called(models.MemberV2, 'pool_id',
-                                                 self.payload)
diff --git a/tests/unit/drivers/radware/__init__.py b/tests/unit/drivers/radware/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/radware/test_v2_plugin_driver.py b/tests/unit/drivers/radware/test_v2_plugin_driver.py
deleted file mode 100644
index aef849e..0000000
--- a/tests/unit/drivers/radware/test_v2_plugin_driver.py
+++ /dev/null
@@ -1,1073 +0,0 @@
-# Copyright 2015 Radware LTD. All rights reserved
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import copy
-import mock
-import re
-
-from neutron import context
-from neutron import manager
-from neutron.plugins.common import constants
-from oslo_config import cfg
-from oslo_serialization import jsonutils
-from six.moves import queue as Queue
-
-from neutron_lbaas.common.cert_manager import cert_manager
-from neutron_lbaas.drivers.radware import exceptions as r_exc
-from neutron_lbaas.drivers.radware import v2_driver
-from neutron_lbaas.extensions import loadbalancerv2
-from neutron_lbaas.services.loadbalancer import constants as lb_con
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-GET_200 = ('/api/workflow/', '/api/workflowTemplate')
-SERVER_DOWN_CODES = (-1, 301, 307)
-
-
-class QueueMock(Queue.Queue):
-    def __init__(self, completion_handler):
-        self.completion_handler = completion_handler
-        super(QueueMock, self).__init__()
-
-    def put_nowait(self, oper):
-        self.completion_handler(oper)
-
-
-def _recover_function_mock(action, resource, data, headers, binary=False):
-    pass
-
-
-def rest_call_function_mock(action, resource, data, headers, binary=False):
-    if rest_call_function_mock.RESPOND_WITH_ERROR:
-        return 400, 'error_status', 'error_description', None
-    if rest_call_function_mock.RESPOND_WITH_SERVER_DOWN in SERVER_DOWN_CODES:
-        val = rest_call_function_mock.RESPOND_WITH_SERVER_DOWN
-        return val, 'error_status', 'error_description', None
-    if action == 'GET':
-        return _get_handler(resource)
-    elif action == 'DELETE':
-        return _delete_handler(resource)
-    elif action == 'POST':
-        return _post_handler(resource, binary)
-    else:
-        return 0, None, None, None
-
-
-def _get_handler(resource):
-    if resource.startswith(GET_200[1]):
-        return 200, '', '', rest_call_function_mock.WF_TEMPLATES_TO_RETURN
-
-    if resource.startswith(GET_200[0]):
-        if rest_call_function_mock.WORKFLOW_MISSING:
-            data = jsonutils.loads('{"complete":"True", "success": "True"}')
-            return 404, '', '', data
-        elif resource.endswith('parameters'):
-            return 200, '', '', {'stats': {'bytes_in': 100,
-                'total_connections': 2, 'active_connections': 1,
-                'bytes_out': 200}}
-        else:
-            return 200, '', '', ''
-
-    if resource.startswith(GET_200):
-        return 200, '', '', ''
-    else:
-        data = jsonutils.loads('{"complete":"True", "success": "True"}')
-        return 202, '', '', data
-
-
-def _delete_handler(resource):
-    return 404, '', '', {'message': 'Not Found'}
-
-
-def _post_handler(resource, binary):
-    if re.search(r'/api/workflow/.+/action/.+', resource):
-        data = jsonutils.loads('{"uri":"some_uri"}')
-        return 202, '', '', data
-    elif re.search(r'/api/service\?name=.+', resource):
-        data = jsonutils.loads('{"links":{"actions":{"provision":"someuri"}}}')
-        return 201, '', '', data
-    elif binary:
-        return 201, '', '', ''
-    else:
-        return 202, '', '', ''
-
-RADWARE_PROVIDER = ('LOADBALANCERV2:radwarev2:neutron_lbaas.'
-                    'drivers.radware.v2_driver.'
-                    'RadwareLBaaSV2Driver:default')
-
-WF_SRV_PARAMS = {
-    "name": "_REPLACE_", "tenantId": "_REPLACE_", "haPair": False,
-    "sessionMirroringEnabled": False, "islVlan": -1,
-    "primary": {
-        "capacity": {
-            "throughput": 1000, "sslThroughput": 100,
-            "compressionThroughput": 100, "cache": 20},
-        "network": {
-            "type": "portgroup", "portgroups": "_REPLACE_"},
-        "adcType": "VA", "acceptableAdc": "Exact"},
-    "resourcePoolIds": []}
-
-WF_CREATE_PARAMS = {'parameters':
-    {"provision_service": True, "configure_l3": True, "configure_l4": True,
-     "twoleg_enabled": False, "ha_network_name": "HA-Network",
-     "ha_ip_pool_name": "default", "allocate_ha_vrrp": True,
-     "allocate_ha_ips": True, "data_port": 1,
-     "data_ip_address": "192.168.200.99", "data_ip_mask": "255.255.255.0",
-     "gateway": "192.168.200.1", "ha_port": 2}}
-WF_APPLY_EMPTY_LB_PARAMS = {'parameters': {
-    'loadbalancer': {'listeners': [], 'pools': [], 'admin_state_up': True,
-    'pip_address': u'10.0.0.2', 'vip_address': u'10.0.0.2'}}}
-
-
-class TestLBaaSDriverBase(
-    test_db_loadbalancerv2.LbaasPluginDbTestCase):
-
-    def setUp(self):
-        super(TestLBaaSDriverBase, self).setUp(
-            lbaas_provider=RADWARE_PROVIDER)
-
-        loaded_plugins = manager.NeutronManager().get_service_plugins()
-        self.plugin_instance = loaded_plugins[constants.LOADBALANCERV2]
-        self.driver = self.plugin_instance.drivers['radwarev2']
-
-
-class TestLBaaSDriverRestClient(TestLBaaSDriverBase):
-    def setUp(self):
-
-        cfg.CONF.set_override('vdirect_address', '1.1.1.1',
-                              group='radwarev2')
-        cfg.CONF.set_override('ha_secondary_address', '1.1.1.2',
-                              group='radwarev2')
-        super(TestLBaaSDriverRestClient, self).setUp()
-
-        self.flip_servers_mock = mock.Mock(
-            return_value=None)
-        self.recover_mock = mock.Mock(
-            side_effect=_recover_function_mock)
-
-        self.orig_recover = self.driver.rest_client._recover
-        self.orig_flip_servers = self.driver.rest_client._flip_servers
-        self.driver.rest_client._flip_servers = self.flip_servers_mock
-        self.driver.rest_client._recover = self.recover_mock
-
-    def test_recover_was_called(self):
-        """Call REST client which fails and verify _recover is called."""
-        self.driver.rest_client.call('GET', '/api/workflowTemplate',
-                                     None, None)
-        self.recover_mock.assert_called_once_with('GET',
-                                                  '/api/workflowTemplate',
-                                                  None, None, False)
-
-    def test_flip_servers(self):
-        server = self.driver.rest_client.server
-        sec_server = self.driver.rest_client.secondary_server
-
-        self.driver.rest_client._recover = self.orig_recover
-        self.driver.rest_client._flip_servers = self.orig_flip_servers
-        self.driver.rest_client.call('GET', '/api/workflowTemplate',
-                                     None, None)
-        self.assertEqual(server, self.driver.rest_client.secondary_server)
-        self.assertEqual(sec_server, self.driver.rest_client.server)
-
-
-class CertMock(cert_manager.Cert):
-    def __init__(self, cert_container):
-        pass
-
-    def get_certificate(self):
-        return "certificate"
-
-    def get_intermediates(self):
-        return "intermediates"
-
-    def get_private_key(self):
-        return "private_key"
-
-    def get_private_key_passphrase(self):
-        return "private_key_passphrase"
-
-
-class TestLBaaSDriver(TestLBaaSDriverBase):
-    def setUp(self):
-        super(TestLBaaSDriver, self).setUp()
-
-        templates_to_return = [{'name': self.driver.workflow_template_name}]
-        for t in self.driver.child_workflow_template_names:
-            templates_to_return.append({'name': t})
-        rest_call_function_mock.__dict__.update(
-            {'RESPOND_WITH_ERROR': False, 'WORKFLOW_MISSING': True,
-             'WORKFLOW_TEMPLATE_MISSING': True,
-             'RESPOND_WITH_SERVER_DOWN': 200,
-             'WF_TEMPLATES_TO_RETURN': templates_to_return})
-
-        self.operation_completer_start_mock = mock.Mock(
-            return_value=None)
-        self.operation_completer_join_mock = mock.Mock(
-            return_value=None)
-        self.driver_rest_call_mock = mock.Mock(
-            side_effect=rest_call_function_mock)
-        self.flip_servers_mock = mock.Mock(
-            return_value=None)
-        self.recover_mock = mock.Mock(
-            side_effect=_recover_function_mock)
-
-        self.driver.completion_handler.start = (
-            self.operation_completer_start_mock)
-        self.driver.completion_handler.join = (
-            self.operation_completer_join_mock)
-        self.driver.rest_client.call = self.driver_rest_call_mock
-        self.driver.rest_client._call = self.driver_rest_call_mock
-        self.driver.completion_handler.rest_client.call = (
-            self.driver_rest_call_mock)
-
-        self.driver.queue = QueueMock(
-            self.driver.completion_handler.handle_operation_completion)
-
-        self.addCleanup(self.driver.completion_handler.join)
-
-    def test_verify_workflow_templates(self):
-        templates_to_return = []
-        for t in self.driver.child_workflow_template_names:
-            templates_to_return.append({'name': t})
-        rest_call_function_mock.__dict__.update(
-            {'WF_TEMPLATES_TO_RETURN': templates_to_return})
-        message = r_exc.WorkflowTemplateMissing.message % \
-            {'workflow_template': self.driver.workflow_template_name}
-        try:
-            self.driver._verify_workflow_templates()
-        except r_exc.WorkflowTemplateMissing as e:
-            self.assertEqual(message, e.msg)
-
-        templates_to_return.append(
-            {'name': self.driver.workflow_template_name})
-        rest_call_function_mock.__dict__.update(
-            {'WF_TEMPLATES_TO_RETURN': templates_to_return})
-        try:
-            self.driver._verify_workflow_templates()
-            self.assertTrue(True)
-        except r_exc.WorkflowTemplateMissing as e:
-            self.assertTrue(False)
-
-    def test_wf_created_on_first_member_creation(self):
-        with self.subnet(cidr='10.0.0.0/24') as vip_sub:
-            with self.loadbalancer(subnet=vip_sub) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(
-                    loadbalancer_id=lb_id) as listener:
-                    with self.pool(
-                        protocol=lb_con.PROTOCOL_HTTP,
-                        listener_id=listener['listener']['id']) as pool:
-                        self.driver_rest_call_mock.assert_has_calls([])
-                        with self.member(pool_id=pool['pool']['id'],
-                                         subnet=vip_sub, address='10.0.1.10'):
-                            calls = [
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    mock.ANY,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-
-    def test_wf_deleted_on_lb_deletion(self):
-        with self.subnet(cidr='10.0.0.0/24') as vip_sub:
-            with self.loadbalancer(subnet=vip_sub) as lb:
-                get_calls = [
-                    mock.call('GET', u'/api/workflow/LB_' +
-                        lb['loadbalancer']['id'], None, None)]
-                with self.listener(
-                    loadbalancer_id=lb['loadbalancer']['id']) as listener:
-                    with self.pool(
-                        protocol=lb_con.PROTOCOL_HTTP,
-                        listener_id=listener['listener']['id']) as pool:
-                        with self.member(pool_id=pool['pool']['id'],
-                                         subnet=vip_sub, address='10.0.1.10'):
-                            self.driver_rest_call_mock.reset_mock()
-                            rest_call_function_mock.__dict__.update(
-                                {'WORKFLOW_MISSING': False})
-
-                        self.driver_rest_call_mock.assert_has_calls(get_calls)
-                        self.driver_rest_call_mock.reset_mock()
-                    self.driver_rest_call_mock.assert_has_calls(get_calls)
-                    self.driver_rest_call_mock.reset_mock()
-                self.driver_rest_call_mock.assert_has_calls(get_calls)
-                self.driver_rest_call_mock.reset_mock()
-            self.driver_rest_call_mock.assert_any_call(
-                'DELETE', u'/api/workflow/LB_' + lb['loadbalancer']['id'],
-                None, None)
-
-    def test_lb_crud(self):
-        with self.subnet(cidr='10.0.0.0/24') as s:
-            with self.loadbalancer(subnet=s, no_delete=True) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as l:
-                    with self.pool(
-                        protocol=lb_con.PROTOCOL_HTTP,
-                        listener_id=l['listener']['id']) as p:
-                        self.driver_rest_call_mock.assert_has_calls([])
-
-                        self.plugin_instance.update_loadbalancer(
-                            context.get_admin_context(),
-                            lb_id, {'loadbalancer': lb})
-                        self.driver_rest_call_mock.assert_has_calls([])
-
-                        lb_db = self.plugin_instance.db.get_loadbalancer(
-                            context.get_admin_context(),
-                            lb_id)
-                        self.driver.load_balancer.refresh(
-                            context.get_admin_context(), lb_db)
-                        self.driver_rest_call_mock.assert_has_calls([])
-
-                        with self.member(
-                            no_delete=True, pool_id=p['pool']['id'],
-                            subnet=s, address='10.0.1.10') as m:
-
-                            m_data = {
-                                "id": m['member']['id'],
-                                "address": "10.0.1.10",
-                                "protocol_port": 80,
-                                "weight": 1, "admin_state_up": True,
-                                "subnet": "255.255.255.255",
-                                "mask": "255.255.255.255",
-                                "gw": "255.255.255.255",
-                                "admin_state_up": True}
-                            pool_data = {
-                                "id": p['pool']['id'],
-                                "protocol": lb_con.PROTOCOL_HTTP,
-                                "lb_algorithm":
-                                    "ROUND_ROBIN",
-                                "admin_state_up": True,
-                                "members": [m_data]}
-                            def_pool_data = {
-                                "id": p['pool']['id']}
-                            wf_apply_params = {'parameters': {
-                                'listeners': [{
-                                    "id": l['listener']['id'],
-                                    "admin_state_up": True,
-                                    "protocol_port": 80,
-                                    "protocol": lb_con.PROTOCOL_HTTP,
-                                    "connection_limit": -1,
-                                    "admin_state_up": True,
-                                    "default_pool": def_pool_data,
-                                    "l7_policies": []}],
-                                "pools": [pool_data],
-                                "admin_state_up": True,
-                                "pip_address": "10.0.0.2",
-                                "vip_address": "10.0.0.2"}}
-                            calls = [
-                                mock.call(
-                                    'POST', '/api/workflowTemplate/' +
-                                    'os_lb_v2?name=LB_' + lb_id, mock.ANY,
-                                    v2_driver.TEMPLATE_HEADER),
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    wf_apply_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-                            self.driver_rest_call_mock.reset_mock()
-                            rest_call_function_mock.__dict__.update(
-                                {'WORKFLOW_MISSING': False})
-
-                            calls = [
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    wf_apply_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-                            self.plugin_instance.update_loadbalancer(
-                                context.get_admin_context(),
-                                lb_id, {'loadbalancer': lb})
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-                            self.driver_rest_call_mock.reset_mock()
-
-                            lb_db = self.plugin_instance.db.get_loadbalancer(
-                                context.get_admin_context(), lb_id)
-                            self.driver.load_balancer.refresh(
-                                context.get_admin_context(), lb_db)
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-                            self.driver_rest_call_mock.reset_mock()
-
-                self.plugin_instance.delete_loadbalancer(
-                    context.get_admin_context(), lb_id)
-                self.driver_rest_call_mock.assert_any_call(
-                    'DELETE', '/api/workflow/LB_' + lb_id,
-                    None, None)
-                self.assertRaises(loadbalancerv2.EntityNotFound,
-                                  self.plugin_instance.get_loadbalancer,
-                                  context.get_admin_context(), lb_id)
-
-    def test_lb_stats(self):
-        with self.subnet(cidr='10.0.0.0/24') as s:
-            with self.loadbalancer(subnet=s) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as l:
-                    with self.pool(
-                        protocol=lb_con.PROTOCOL_HTTP,
-                        listener_id=l['listener']['id']) as p:
-                        with self.member(
-                            no_delete=True, pool_id=p['pool']['id'],
-                            subnet=s, address='10.0.1.10'):
-
-                            rest_call_function_mock.__dict__.update(
-                                {'WORKFLOW_MISSING': False})
-
-                            stats = self.plugin_instance.stats(
-                                context.get_admin_context(), lb_id,)
-                            self.assertEqual({'stats': {'bytes_in': 100,
-                                'total_connections': 2,
-                                'active_connections': 1, 'bytes_out': 200}},
-                                stats)
-
-    def test_member_crud(self):
-        with self.subnet(cidr='10.0.0.0/24') as s:
-            with self.loadbalancer(subnet=s) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as l:
-                    with self.pool(
-                        protocol=lb_con.PROTOCOL_HTTP,
-                        listener_id=l['listener']['id']) as p:
-                        with contextlib.nested(
-                            self.member(
-                                no_delete=True, pool_id=p['pool']['id'],
-                                subnet=s, address='10.0.1.10'),
-                            self.member(
-                                no_delete=True, pool_id=p['pool']['id'],
-                                subnet=s, address='10.0.1.20')) as (m1, m2):
-
-                            m1_data = {
-                                "id": m1['member']['id'],
-                                "address": "10.0.1.10",
-                                "protocol_port": 80,
-                                "weight": 1, "admin_state_up": True,
-                                "subnet": "255.255.255.255",
-                                "mask": "255.255.255.255",
-                                "gw": "255.255.255.255",
-                                "admin_state_up": True}
-                            m2_data = {
-                                "id": m2['member']['id'],
-                                "address": "10.0.1.20",
-                                "protocol_port": 80,
-                                "weight": 1, "admin_state_up": True,
-                                "subnet": "255.255.255.255",
-                                "mask": "255.255.255.255",
-                                "gw": "255.255.255.255",
-                                "admin_state_up": True}
-                            pool_data = {
-                                "id": p['pool']['id'],
-                                "protocol": lb_con.PROTOCOL_HTTP,
-                                "lb_algorithm": "ROUND_ROBIN",
-                                "admin_state_up": True,
-                                "members": [m1_data, m2_data]}
-                            def_pool_data = {
-                                "id": p['pool']['id']}
-                            listener_data = {
-                                    "id": l['listener']['id'],
-                                    "admin_state_up": True,
-                                    "protocol_port": 80,
-                                    "protocol": lb_con.PROTOCOL_HTTP,
-                                    "connection_limit": -1,
-                                    "admin_state_up": True,
-                                    "default_pool": def_pool_data,
-                                    "l7_policies": []}
-                            wf_apply_params = {'parameters': {
-                                'listeners': [listener_data],
-                                'pools': [pool_data],
-                                "admin_state_up": True,
-                                "pip_address": "10.0.0.2",
-                                "vip_address": "10.0.0.2"}}
-                            calls = [
-                                mock.call(
-                                    'POST', '/api/workflowTemplate/' +
-                                    'os_lb_v2?name=LB_' + lb_id, mock.ANY,
-                                    v2_driver.TEMPLATE_HEADER),
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    wf_apply_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-                            self.driver_rest_call_mock.reset_mock()
-                            member = self.plugin_instance.db.get_pool_member(
-                                context.get_admin_context(),
-                                m1['member']['id']).to_dict(pool=False)
-
-                            member['weight'] = 2
-                            m1_data['weight'] = 2
-                            self.plugin_instance.update_pool_member(
-                                context.get_admin_context(),
-                                m1['member']['id'], p['pool']['id'],
-                                {'member': member})
-                            calls = [
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    wf_apply_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-                            self.driver_rest_call_mock.reset_mock()
-
-                            self.plugin_instance.delete_pool_member(
-                                context.get_admin_context(),
-                                m2['member']['id'], p['pool']['id'])
-                            pool_data["members"] = [m1_data]
-                            calls = [
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    wf_apply_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-                            self.driver_rest_call_mock.assert_has_calls(calls)
-                            lb = self.plugin_instance.db.get_loadbalancer(
-                                context.get_admin_context(),
-                                lb_id).to_dict(listener=False)
-                            self.assertEqual('ACTIVE',
-                                             lb['provisioning_status'])
-
-    def test_build_objects_with_tls(self):
-        with self.subnet(cidr='10.0.0.0/24') as vip_sub:
-            with self.loadbalancer(subnet=vip_sub) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with contextlib.nested(
-                    mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                               'cert_parser', autospec=True),
-                    mock.patch('neutron_lbaas.services.loadbalancer.plugin.'
-                               'CERT_MANAGER_PLUGIN.CertManager',
-                               autospec=True)
-                ) as (cert_parser_mock, cert_manager_mock):
-                    cert_mock = mock.Mock(spec=cert_manager.Cert)
-                    cert_mock.get_certificate.return_value = 'certificate'
-                    cert_mock.get_intermediates.return_value = 'intermediates'
-                    cert_mock.get_private_key.return_value = 'private_key'
-                    cert_mock.get_private_key_passphrase.return_value = \
-                        'private_key_passphrase'
-                    cert_manager_mock().get_cert.return_value = cert_mock
-                    cert_parser_mock.validate_cert.return_value = True
-
-                    with self.listener(
-                        protocol=lb_con.PROTOCOL_TERMINATED_HTTPS,
-                        loadbalancer_id=lb_id,
-                        default_tls_container_ref='def1',
-                        sni_container_refs=['sni1', 'sni2']) as listener:
-                        with self.pool(
-                            protocol=lb_con.PROTOCOL_HTTP,
-                            listener_id=listener['listener']['id']) as pool:
-                            with self.member(pool_id=pool['pool']['id'],
-                                             subnet=vip_sub,
-                                             address='10.0.1.10') as m:
-
-                                wf_srv_params = copy.deepcopy(WF_SRV_PARAMS)
-                                wf_params = copy.deepcopy(WF_CREATE_PARAMS)
-
-                                wf_srv_params['name'] = 'srv_' + (
-                                    vip_sub['subnet']['network_id'])
-                                wf_srv_params['tenantId'] = self._tenant_id
-                                wf_srv_params['primary']['network'][
-                                    'portgroups'] = [vip_sub['subnet'][
-                                         'network_id']]
-                                wf_params['parameters']['service_params'] = (
-                                    wf_srv_params)
-
-                                m_data = {
-                                    "id": m['member']['id'],
-                                    "address": "10.0.1.10",
-                                    "protocol_port": 80,
-                                    "weight": 1, "admin_state_up": True,
-                                    "subnet": "255.255.255.255",
-                                    "mask": "255.255.255.255",
-                                    "gw": "255.255.255.255",
-                                    'admin_state_up': True}
-                                default_tls_cert_data = {
-                                    'id': 'def1',
-                                    'certificate': 'certificate',
-                                    'intermediates': 'intermediates',
-                                    'private_key': 'private_key',
-                                    'passphrase': 'private_key_passphrase'}
-                                sni1_tls_cert_data = {
-                                    'id': 'sni1',
-                                    'position': 0,
-                                    'certificate': 'certificate',
-                                    'intermediates': 'intermediates',
-                                    'private_key': 'private_key',
-                                    'passphrase': 'private_key_passphrase'}
-                                sni2_tls_cert_data = {
-                                    'id': 'sni2',
-                                    'position': 1,
-                                    'certificate': 'certificate',
-                                    'intermediates': 'intermediates',
-                                    'private_key': 'private_key',
-                                    'passphrase': 'private_key_passphrase'}
-                                pool_data = {
-                                    "id": pool['pool']['id'],
-                                    "protocol": lb_con.PROTOCOL_HTTP,
-                                    "lb_algorithm": "ROUND_ROBIN",
-                                    "admin_state_up": True,
-                                    "members": [m_data]}
-                                def_pool_data = {
-                                    "id": pool['pool']['id']}
-                                wf_apply_one_leg_params = {'parameters': {
-                                    'listeners': [{
-                                        "id": listener['listener']['id'],
-                                        "admin_state_up": True,
-                                        "protocol_port": 80,
-                                        "protocol":
-                                        lb_con.PROTOCOL_TERMINATED_HTTPS,
-                                        "connection_limit": -1,
-                                        "default_pool": def_pool_data,
-                                        "default_tls_certificate":
-                                        default_tls_cert_data,
-                                        "sni_tls_certificates": [
-                                             sni1_tls_cert_data,
-                                             sni2_tls_cert_data],
-                                        "l7_policies": []}],
-                                    "pools": [pool_data],
-                                    "admin_state_up": True,
-                                    "pip_address": "10.0.0.2",
-                                    "vip_address": "10.0.0.2"}}
-
-                                calls = [
-                                    mock.call('GET',
-                                              '/api/workflow/LB_' + lb_id,
-                                              None, None),
-                                    mock.call(
-                                        'POST',
-                                        '/api/workflowTemplate/' +
-                                        'os_lb_v2?name=LB_' + lb_id,
-                                        wf_params,
-                                        v2_driver.TEMPLATE_HEADER),
-                                    mock.call(
-                                        'POST',
-                                        '/api/workflow/LB_' + lb_id +
-                                        '/action/apply',
-                                        wf_apply_one_leg_params,
-                                        v2_driver.TEMPLATE_HEADER)
-                                ]
-                                self.driver_rest_call_mock.assert_has_calls(
-                                    calls, any_order=True)
-
-    # This test some times fails with same input.
-    # mock calls are not found sometimes, will be back after fix
-    def _test_build_objects_with_l7(self):
-        with self.subnet(cidr='10.0.0.0/24') as vip_sub:
-            with self.loadbalancer(subnet=vip_sub) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(
-                    protocol=lb_con.PROTOCOL_HTTP,
-                    loadbalancer_id=lb_id) as listener:
-                    with contextlib.nested(
-                        self.pool(
-                            protocol=lb_con.PROTOCOL_HTTP,
-                            listener_id=listener['listener']['id']),
-                        self.pool(
-                            protocol=lb_con.PROTOCOL_HTTP,
-                            loadbalancer_id=lb_id)) as (def_pool, pol_pool):
-                        with self.l7policy(
-                            listener['listener']['id'],
-                            action=lb_con.L7_POLICY_ACTION_REDIRECT_TO_POOL,
-                            redirect_pool_id=pol_pool['pool']['id']) as policy:
-
-                            self.driver_rest_call_mock.reset_mock()
-
-                            with contextlib.nested(
-                                self.l7policy_rule(
-                                    l7policy_id=policy['l7policy']['id'],
-                                    key='key1', value='val1'),
-                                self.l7policy_rule(
-                                    l7policy_id=policy['l7policy']['id'],
-                                    key='key2', value='val2'),
-                                self.member(
-                                    pool_id=def_pool['pool']['id'],
-                                    subnet=vip_sub,
-                                    address='10.0.1.10'),
-                                self.member(
-                                    pool_id=pol_pool['pool']['id'],
-                                    subnet=vip_sub,
-                                    address='10.0.1.20')) as (
-                                    rule1, rule2, def_m, pol_m):
-
-                                wf_srv_params = copy.deepcopy(WF_SRV_PARAMS)
-                                wf_params = copy.deepcopy(WF_CREATE_PARAMS)
-
-                                wf_srv_params['name'] = 'srv_' + (
-                                    vip_sub['subnet']['network_id'])
-                                wf_srv_params['tenantId'] = self._tenant_id
-                                wf_srv_params['primary']['network'][
-                                    'portgroups'] = [vip_sub['subnet'][
-                                         'network_id']]
-                                wf_params['parameters']['service_params'] = (
-                                    wf_srv_params)
-                                rule1_data = {
-                                    'id': rule1['rule']['id'],
-                                    'type': lb_con.L7_RULE_TYPE_HOST_NAME,
-                                    'compare_type':
-                                        lb_con.L7_RULE_COMPARE_TYPE_EQUAL_TO,
-                                    'admin_state_up': True,
-                                    'key': 'key1',
-                                    'value': 'val1'}
-                                rule2_data = {
-                                    'id': rule2['rule']['id'],
-                                    'type': lb_con.L7_RULE_TYPE_HOST_NAME,
-                                    'compare_type':
-                                        lb_con.L7_RULE_COMPARE_TYPE_EQUAL_TO,
-                                    'admin_state_up': True,
-                                    'key': 'key2',
-                                    'value': 'val2'}
-                                l7_policy_data = {
-                                    'redirect_pool_id': pol_pool['pool']['id'],
-                                    'rules': [rule1_data, rule2_data],
-                                    'redirect_url': None,
-                                    'action': lb_con.
-                                    L7_POLICY_ACTION_REDIRECT_TO_POOL,
-                                    'position': 1,
-                                    'admin_state_up': True,
-                                    'id': policy['l7policy']['id']}
-                                def_m_data = {
-                                    'id': def_m['member']['id'],
-                                    'address': "10.0.1.10",
-                                    'protocol_port': 80,
-                                    'weight': 1, 'admin_state_up': True,
-                                    'subnet': '255.255.255.255',
-                                    'mask': '255.255.255.255',
-                                    'gw': '255.255.255.255',
-                                    'admin_state_up': True}
-                                pol_m_data = {
-                                    'id': pol_m['member']['id'],
-                                    'address': "10.0.1.20",
-                                    'protocol_port': 80,
-                                    'weight': 1, 'admin_state_up': True,
-                                    'subnet': '255.255.255.255',
-                                    'mask': '255.255.255.255',
-                                    'gw': '255.255.255.255',
-                                    'admin_state_up': True}
-                                def_pool_data = {
-                                    'id': def_pool['pool']['id']}
-                                default_pool_data = {
-                                    'id': def_pool['pool']['id'],
-                                    'protocol': lb_con.PROTOCOL_HTTP,
-                                    'lb_algorithm': 'ROUND_ROBIN',
-                                    'admin_state_up': True,
-                                    'members': [def_m_data]}
-                                pol_pool_data = {
-                                    'id': pol_pool['pool']['id'],
-                                    'protocol': lb_con.PROTOCOL_HTTP,
-                                    'lb_algorithm': 'ROUND_ROBIN',
-                                    'admin_state_up': True,
-                                    'members': [pol_m_data]}
-                                wf_apply_one_leg_params = {'parameters': {
-                                    'listeners': [{
-                                        'id': listener['listener']['id'],
-                                        'admin_state_up': True,
-                                        'protocol_port': 80,
-                                        'protocol': lb_con.PROTOCOL_HTTP,
-                                        'connection_limit': -1,
-                                        'default_pool': def_pool_data,
-                                        'l7_policies': [
-                                            l7_policy_data]}],
-                                    'pools': [default_pool_data,
-                                              pol_pool_data],
-                                    'admin_state_up': True,
-                                    'pip_address': '10.0.0.2',
-                                    'vip_address': '10.0.0.2'}}
-
-                                calls = [
-                                    mock.call(
-                                        'POST',
-                                        '/api/workflow/LB_' + lb_id +
-                                        '/action/apply',
-                                        wf_apply_one_leg_params,
-                                        v2_driver.TEMPLATE_HEADER)
-                                ]
-                                self.driver_rest_call_mock.assert_has_calls(
-                                    calls, any_order=True)
-
-    def test_build_objects_graph_one_leg(self):
-        with self.subnet(cidr='10.0.0.0/24') as vip_sub:
-            with self.loadbalancer(subnet=vip_sub) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as listener:
-                    with self.pool(
-                        protocol='HTTP',
-                        listener_id=listener['listener']['id']) as pool:
-                        with contextlib.nested(
-                            self.member(pool_id=pool['pool']['id'],
-                                        subnet=vip_sub, address='10.0.1.10'),
-                            self.member(pool_id=pool['pool']['id'],
-                                        subnet=vip_sub, address='10.0.1.20')
-                        ) as (member1, member2):
-
-                            wf_srv_params = copy.deepcopy(WF_SRV_PARAMS)
-                            wf_params = copy.deepcopy(WF_CREATE_PARAMS)
-
-                            wf_srv_params['name'] = 'srv_' + (
-                                vip_sub['subnet']['network_id'])
-                            wf_srv_params['tenantId'] = self._tenant_id
-                            wf_srv_params['primary']['network'][
-                                'portgroups'] = [vip_sub['subnet'][
-                                     'network_id']]
-                            wf_params['parameters']['service_params'] = (
-                                wf_srv_params)
-
-                            member1_data = {
-                                "id": member1['member']['id'],
-                                "address": "10.0.1.10", "protocol_port": 80,
-                                "weight": 1, "admin_state_up": True,
-                                "subnet": "255.255.255.255",
-                                "mask": "255.255.255.255",
-                                "gw": "255.255.255.255",
-                                'admin_state_up': True}
-                            member2_data = {
-                                "id": member2['member']['id'],
-                                "address": "10.0.1.20", "protocol_port": 80,
-                                "weight": 1, "admin_state_up": True,
-                                "subnet": "255.255.255.255",
-                                "mask": "255.255.255.255",
-                                "gw": "255.255.255.255",
-                                "admin_state_up": True}
-                            def_pool_data = {
-                                "id": pool['pool']['id']}
-                            pool_data = {
-                                "id": pool['pool']['id'],
-                                "protocol": "HTTP",
-                                "lb_algorithm": "ROUND_ROBIN",
-                                "admin_state_up": True,
-                                "members": [
-                                    member1_data, member2_data]}
-                            wf_apply_one_leg_params = {'parameters': {
-                                'listeners': [{
-                                    "id": listener['listener']['id'],
-                                    "admin_state_up": True,
-                                    "protocol_port": 80,
-                                    "protocol": "HTTP",
-                                    "connection_limit": -1,
-                                    "default_pool": def_pool_data,
-                                    "l7_policies": []}],
-                                "pools": [pool_data],
-                                "admin_state_up": True,
-                                "pip_address": "10.0.0.2",
-                                "vip_address": "10.0.0.2"}}
-
-                            calls = [
-                                mock.call('GET', '/api/workflow/LB_' + lb_id,
-                                          None, None),
-                                mock.call(
-                                    'POST',
-                                    '/api/workflowTemplate/' +
-                                    'os_lb_v2?name=LB_' + lb_id,
-                                    wf_params,
-                                    v2_driver.TEMPLATE_HEADER),
-                                mock.call(
-                                    'POST',
-                                    '/api/workflow/LB_' + lb_id +
-                                    '/action/apply',
-                                    wf_apply_one_leg_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-                            self.driver_rest_call_mock.assert_has_calls(
-                                calls, any_order=True)
-
-    def test_build_objects_graph_two_legs_full(self):
-        with contextlib.nested(
-            self.subnet(cidr='10.0.0.0/24'),
-            self.subnet(cidr='20.0.0.0/24'),
-            self.subnet(cidr='30.0.0.0/24')
-        ) as (vip_sub, member_sub1, member_sub2):
-            with self.loadbalancer(subnet=vip_sub) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as listener:
-                    with self.pool(
-                        protocol='HTTP',
-                        listener_id=listener['listener']['id'],
-                        session_persistence={
-                            'type': "APP_COOKIE",
-                            'cookie_name': 'sessionId'}) as pool:
-                        with self.healthmonitor(
-                            type='HTTP', pool_id=pool['pool']['id']) as hm:
-                            with self.member(
-                                pool_id=pool['pool']['id'],
-                                subnet=member_sub1,
-                                address='20.0.1.10') as member:
-
-                                    wf_params = copy.deepcopy(WF_CREATE_PARAMS)
-                                    wf_srv_params = copy.deepcopy(
-                                        WF_SRV_PARAMS)
-                                    wf_srv_params['name'] = (
-                                        'srv_' + vip_sub['subnet'][
-                                            'network_id'])
-                                    wf_srv_params['tenantId'] = self._tenant_id
-                                    wf_srv_params['primary']['network'][
-                                        'portgroups'] = [
-                                            vip_sub['subnet']['network_id'],
-                                        member_sub1['subnet']['network_id']]
-                                    wf_params['parameters'][
-                                        'twoleg_enabled'] = True
-                                    wf_params['parameters'][
-                                        'service_params'] = (wf_srv_params)
-                                    hm_data = {
-                                        "admin_state_up": True,
-                                        "id": hm['healthmonitor']['id'],
-                                        "type": "HTTP", "delay": 1,
-                                        "timeout": 1,
-                                        "max_retries": 1,
-                                        "admin_state_up": True,
-                                        "url_path": "/", "http_method": "GET",
-                                        "expected_codes": '200'}
-                                    sp_data = {
-                                        "type": "APP_COOKIE",
-                                        "cookie_name": "sessionId"}
-                                    m_data = {
-                                        "id": member['member']['id'],
-                                        "address": "20.0.1.10",
-                                        "protocol_port": 80,
-                                        "weight": 1, "admin_state_up": True,
-                                        "subnet": "20.0.1.10",
-                                        "mask": "255.255.255.255",
-                                        "gw": "20.0.0.1",
-                                        "admin_state_up": True}
-                                    def_pool_data = {
-                                        "id": pool['pool']['id'],
-                                        "sessionpersistence":
-                                            sp_data}
-                                    pool_data = {
-                                        "id": pool['pool']['id'],
-                                        "protocol": "HTTP",
-                                        "lb_algorithm":
-                                            "ROUND_ROBIN",
-                                        "admin_state_up": True,
-                                        "healthmonitor": hm_data,
-                                        "members": [m_data]}
-                                    wf_apply_full_params = {'parameters': {
-                                        'listeners': [{
-                                            "id": listener['listener']['id'],
-                                            "admin_state_up": True,
-                                            "protocol_port": 80,
-                                            "protocol": "HTTP",
-                                            "connection_limit": -1,
-                                            "admin_state_up": True,
-                                            "default_pool": def_pool_data,
-                                            "l7_policies": []}],
-                                        "pools": [pool_data],
-                                        "admin_state_up": True,
-                                        "pip_address": "20.0.0.2",
-                                        "vip_address": "10.0.0.2"}}
-                                    calls = [
-                                        mock.call(
-                                            'GET',
-                                            '/api/workflow/LB_' + lb_id,
-                                            None, None),
-                                        mock.call(
-                                            'POST', '/api/workflowTemplate/' +
-                                            'os_lb_v2?name=LB_' + lb_id,
-                                            wf_params,
-                                            v2_driver.TEMPLATE_HEADER),
-                                        mock.call(
-                                            'POST', '/api/workflow/LB_' +
-                                            lb_id + '/action/apply',
-                                            wf_apply_full_params,
-                                            v2_driver.TEMPLATE_HEADER),
-                                        mock.call('GET', 'some_uri',
-                                                  None, None)]
-                                    self.driver_rest_call_mock.\
-                                        assert_has_calls(
-                                            calls, any_order=True)
-
-
-class TestLBaaSDriverDebugOptions(TestLBaaSDriverBase):
-    def setUp(self):
-        cfg.CONF.set_override('configure_l3', False,
-                              group='radwarev2_debug')
-        cfg.CONF.set_override('configure_l4', False,
-                              group='radwarev2_debug')
-        super(TestLBaaSDriverDebugOptions, self).setUp()
-
-        templates_to_return = [{'name': self.driver.workflow_template_name}]
-        for t in self.driver.child_workflow_template_names:
-            templates_to_return.append({'name': t})
-        rest_call_function_mock.__dict__.update(
-            {'RESPOND_WITH_ERROR': False, 'WORKFLOW_MISSING': True,
-             'WORKFLOW_TEMPLATE_MISSING': True,
-             'RESPOND_WITH_SERVER_DOWN': 200,
-             'WF_TEMPLATES_TO_RETURN': templates_to_return})
-
-        self.operation_completer_start_mock = mock.Mock(
-            return_value=None)
-        self.operation_completer_join_mock = mock.Mock(
-            return_value=None)
-        self.driver_rest_call_mock = mock.Mock(
-            side_effect=rest_call_function_mock)
-        self.flip_servers_mock = mock.Mock(
-            return_value=None)
-        self.recover_mock = mock.Mock(
-            side_effect=_recover_function_mock)
-
-        self.driver.completion_handler.start = (
-            self.operation_completer_start_mock)
-        self.driver.completion_handler.join = (
-            self.operation_completer_join_mock)
-        self.driver.rest_client.call = self.driver_rest_call_mock
-        self.driver.rest_client._call = self.driver_rest_call_mock
-        self.driver.completion_handler.rest_client.call = (
-            self.driver_rest_call_mock)
-
-        self.driver.queue = QueueMock(
-            self.driver.completion_handler.handle_operation_completion)
-
-    def test_debug_options(self):
-        with self.subnet(cidr='10.0.0.0/24') as s:
-            with self.loadbalancer(subnet=s) as lb:
-                lb_id = lb['loadbalancer']['id']
-                with self.listener(loadbalancer_id=lb_id) as l:
-                    with self.pool(
-                        protocol='HTTP',
-                        listener_id=l['listener']['id']) as p:
-                        with self.member(
-                            pool_id=p['pool']['id'],
-                            subnet=s, address='10.0.1.10'):
-                            wf_srv_params = copy.deepcopy(WF_SRV_PARAMS)
-                            wf_params = copy.deepcopy(WF_CREATE_PARAMS)
-
-                            wf_srv_params['name'] = 'srv_' + (
-                                s['subnet']['network_id'])
-                            wf_srv_params['tenantId'] = self._tenant_id
-                            wf_srv_params['primary']['network'][
-                                'portgroups'] = [s['subnet'][
-                                     'network_id']]
-                            wf_params['parameters']['service_params'] = (
-                                wf_srv_params)
-                            wf_params['parameters']['configure_l3'] = False
-                            wf_params['parameters']['configure_l4'] = False
-                            calls = [
-                                mock.call('GET', '/api/workflow/LB_' + lb_id,
-                                          None, None),
-                                mock.call(
-                                    'POST',
-                                    '/api/workflowTemplate/' +
-                                    'os_lb_v2?name=LB_' + lb_id,
-                                    wf_params,
-                                    v2_driver.TEMPLATE_HEADER)
-                            ]
-                            self.driver_rest_call_mock.assert_has_calls(
-                                calls, any_order=True)
diff --git a/tests/unit/drivers/vmware/__init__.py b/tests/unit/drivers/vmware/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/drivers/vmware/test_edge_driver_v2.py b/tests/unit/drivers/vmware/test_edge_driver_v2.py
deleted file mode 100644
index 8e5a902..0000000
--- a/tests/unit/drivers/vmware/test_edge_driver_v2.py
+++ /dev/null
@@ -1,118 +0,0 @@
-# Copyright 2015 VMware, Inc.
-# All Rights Reserved
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import mock
-
-from neutron import context as ncontext
-
-from neutron_lbaas.drivers.vmware import edge_driver_v2
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-DUMMY_CERT = {'id': 'fake_id'}
-
-
-class FakeModel(object):
-    def __init__(self, id):
-        self.id = id
-
-
-class ManagerTest(object):
-    def __init__(self, context, manager, model, mocked_nsxv):
-        self.context = context
-        self.manager = manager
-        self.model = model
-        self.mocked_nsxv = mocked_nsxv
-
-        self.create(model)
-        self.update(model, model)
-        self.delete(model)
-
-    def create(self, model):
-        self.manager.create(self.context, model)
-        if model.id == 'listener':
-            model.default_tls_container_id = 'fake_id'
-            self.mocked_nsxv.create.assert_called_with(
-                self.context, model, certificate=DUMMY_CERT)
-        else:
-            self.mocked_nsxv.create.assert_called_with(self.context, model)
-
-    def update(self, old_model, model):
-        self.manager.update(self.context, old_model, model)
-        if model.id == 'listener':
-            self.mocked_nsxv.update.assert_called_with(
-                self.context, old_model, model, certificate=DUMMY_CERT)
-        else:
-            self.mocked_nsxv.update.assert_called_with(self.context,
-                                                       old_model, model)
-
-    def delete(self, model):
-        self.manager.delete(self.context, model)
-        self.mocked_nsxv.delete.assert_called_with(self.context, model)
-
-    def refresh(self):
-        self.manager.refresh(self.context, self.model)
-        self.mocked_nsxv.refresh.assert_called_with(self.context, self.model)
-
-    def stats(self):
-        self.manager.stats(self.context, self.model)
-        self.mocked_nsxv.stats.assert_called_with(self.context, self.model)
-
-
-class TestVMWareEdgeLoadBalancerDriverV2(
-        test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def setUp(self):
-        super(TestVMWareEdgeLoadBalancerDriverV2, self).setUp()
-        self.context = ncontext.get_admin_context()
-        self.driver = edge_driver_v2.EdgeLoadBalancerDriverV2(self.plugin)
-
-    def _patch_manager(self, mgr):
-        mgr.driver = mock.Mock()
-        mgr.driver.plugin.db = mock.Mock()
-        mgr.driver.plugin.db._core_plugin = mock.Mock()
-        mgr.driver.plugin.db._core_plugin.nsx_v = mock.Mock()
-        return mgr.driver.plugin.db._core_plugin.nsx_v
-
-    def test_load_balancer_ops(self):
-        mock_nsxv_driver = self._patch_manager(self.driver.load_balancer)
-        m = ManagerTest(self, self.driver.load_balancer,
-                        FakeModel("loadbalancer"),
-                        mock_nsxv_driver.loadbalancer)
-        m.refresh()
-        m.stats()
-
-    def test_listener_ops(self):
-        mock_nsxv_driver = self._patch_manager(self.driver.listener)
-        self.driver.listener._get_default_cert = mock.Mock()
-        self.driver.listener._get_default_cert.return_value = DUMMY_CERT
-        listener = FakeModel("listener")
-        listener.default_tls_container_id = None
-        ManagerTest(self, self.driver.listener, listener,
-                    mock_nsxv_driver.listener)
-
-    def test_pool_ops(self):
-        mock_nsxv_driver = self._patch_manager(self.driver.pool)
-        ManagerTest(self, self.driver.pool, FakeModel("pool"),
-                    mock_nsxv_driver.pool)
-
-    def test_member_ops(self):
-        mock_nsxv_driver = self._patch_manager(self.driver.member)
-        ManagerTest(self, self.driver.member, FakeModel("member"),
-                    mock_nsxv_driver.member)
-
-    def test_health_monitor_ops(self):
-        mock_nsxv_driver = self._patch_manager(self.driver.health_monitor)
-        ManagerTest(self, self.driver.health_monitor, FakeModel("hm"),
-                    mock_nsxv_driver.healthmonitor)
diff --git a/tests/unit/services/__init__.py b/tests/unit/services/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/__init__.py b/tests/unit/services/loadbalancer/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/agent/__init__.py b/tests/unit/services/loadbalancer/agent/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/agent/test_agent.py b/tests/unit/services/loadbalancer/agent/test_agent.py
deleted file mode 100644
index ae1e38a..0000000
--- a/tests/unit/services/loadbalancer/agent/test_agent.py
+++ /dev/null
@@ -1,47 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import mock
-from oslo_config import cfg
-
-from neutron_lbaas.services.loadbalancer.agent import agent
-from neutron_lbaas.tests import base
-
-
-class TestLbaasService(base.BaseTestCase):
-    def test_start(self):
-        with mock.patch.object(
-            agent.n_rpc.Service, 'start'
-        ) as mock_start:
-
-            mgr = mock.Mock()
-            cfg.CONF.periodic_interval = mock.Mock(return_value=10)
-            agent_service = agent.LbaasAgentService('host', 'topic', mgr)
-            agent_service.start()
-
-            self.assertTrue(mock_start.called)
-
-    def test_main(self):
-        logging_str = 'neutron.agent.common.config.setup_logging'
-        with contextlib.nested(
-            mock.patch(logging_str),
-            mock.patch.object(agent.service, 'launch'),
-            mock.patch('sys.argv'),
-            mock.patch.object(agent.manager, 'LbaasAgentManager'),
-            mock.patch.object(cfg.CONF, 'register_opts')
-        ) as (mock_logging, mock_launch, sys_argv, mgr_cls, ro):
-            agent.main()
-
-            mock_launch.assert_called_once_with(mock.ANY, mock.ANY)
diff --git a/tests/unit/services/loadbalancer/agent/test_agent_manager.py b/tests/unit/services/loadbalancer/agent/test_agent_manager.py
deleted file mode 100644
index a6ea232..0000000
--- a/tests/unit/services/loadbalancer/agent/test_agent_manager.py
+++ /dev/null
@@ -1,446 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-
-import mock
-from neutron.plugins.common import constants
-
-from neutron_lbaas.services.loadbalancer.agent import agent_manager as manager
-from neutron_lbaas.services.loadbalancer import constants as l_const
-from neutron_lbaas.tests import base
-
-
-class TestManager(base.BaseTestCase):
-    def setUp(self):
-        super(TestManager, self).setUp()
-
-        mock_conf = mock.Mock()
-        mock_conf.device_driver = ['devdriver']
-
-        self.mock_importer = mock.patch.object(manager, 'importutils').start()
-
-        rpc_mock_cls = mock.patch(
-            'neutron_lbaas.services.loadbalancer.agent.agent_api.LbaasAgentApi'
-        ).start()
-
-        # disable setting up periodic state reporting
-        mock_conf.AGENT.report_interval = 0
-
-        self.mgr = manager.LbaasAgentManager(mock_conf)
-        self.rpc_mock = rpc_mock_cls.return_value
-        self.log = mock.patch.object(manager, 'LOG').start()
-        self.driver_mock = mock.Mock()
-        self.mgr.device_drivers = {'devdriver': self.driver_mock}
-        self.mgr.instance_mapping = {'1': 'devdriver', '2': 'devdriver'}
-        self.mgr.needs_resync = False
-
-    def test_initialize_service_hook(self):
-        with mock.patch.object(self.mgr, 'sync_state') as sync:
-            self.mgr.initialize_service_hook(mock.Mock())
-            sync.assert_called_once_with()
-
-    def test_periodic_resync_needs_sync(self):
-        with mock.patch.object(self.mgr, 'sync_state') as sync:
-            self.mgr.needs_resync = True
-            self.mgr.periodic_resync(mock.Mock())
-            sync.assert_called_once_with()
-
-    def test_periodic_resync_no_sync(self):
-        with mock.patch.object(self.mgr, 'sync_state') as sync:
-            self.mgr.needs_resync = False
-            self.mgr.periodic_resync(mock.Mock())
-            self.assertFalse(sync.called)
-
-    def test_collect_stats(self):
-        self.mgr.collect_stats(mock.Mock())
-        self.rpc_mock.update_pool_stats.assert_has_calls([
-            mock.call('1', mock.ANY),
-            mock.call('2', mock.ANY)
-        ], any_order=True)
-
-    def test_collect_stats_exception(self):
-        self.driver_mock.get_stats.side_effect = Exception
-
-        self.mgr.collect_stats(mock.Mock())
-
-        self.assertFalse(self.rpc_mock.called)
-        self.assertTrue(self.mgr.needs_resync)
-        self.assertTrue(self.log.exception.called)
-
-    def _sync_state_helper(self, ready, reloaded, destroyed):
-        with contextlib.nested(
-            mock.patch.object(self.mgr, '_reload_pool'),
-            mock.patch.object(self.mgr, '_destroy_pool')
-        ) as (reload, destroy):
-
-            self.rpc_mock.get_ready_devices.return_value = ready
-
-            self.mgr.sync_state()
-
-            self.assertEqual(len(reloaded), len(reload.mock_calls))
-            self.assertEqual(len(destroyed), len(destroy.mock_calls))
-
-            reload.assert_has_calls([mock.call(i) for i in reloaded],
-                                    any_order=True)
-            destroy.assert_has_calls([mock.call(i) for i in destroyed],
-                                     any_order=True)
-            self.assertFalse(self.mgr.needs_resync)
-
-    def test_sync_state_all_known(self):
-        self._sync_state_helper(['1', '2'], ['1', '2'], [])
-
-    def test_sync_state_all_unknown(self):
-        self.mgr.instance_mapping = {}
-        self._sync_state_helper(['1', '2'], ['1', '2'], [])
-
-    def test_sync_state_destroy_all(self):
-        self._sync_state_helper([], [], ['1', '2'])
-
-    def test_sync_state_both(self):
-        self.mgr.instance_mapping = {'1': 'devdriver'}
-        self._sync_state_helper(['2'], ['2'], ['1'])
-
-    def test_sync_state_exception(self):
-        self.rpc_mock.get_ready_devices.side_effect = Exception
-
-        self.mgr.sync_state()
-
-        self.assertTrue(self.log.exception.called)
-        self.assertTrue(self.mgr.needs_resync)
-
-    def test_reload_pool(self):
-        config = {'driver': 'devdriver'}
-        self.rpc_mock.get_logical_device.return_value = config
-        pool_id = 'new_id'
-        self.assertNotIn(pool_id, self.mgr.instance_mapping)
-
-        self.mgr._reload_pool(pool_id)
-
-        self.driver_mock.deploy_instance.assert_called_once_with(config)
-        self.assertIn(pool_id, self.mgr.instance_mapping)
-        self.rpc_mock.pool_deployed.assert_called_once_with(pool_id)
-
-    def test_reload_pool_driver_not_found(self):
-        config = {'driver': 'unknown_driver'}
-        self.rpc_mock.get_logical_device.return_value = config
-        pool_id = 'new_id'
-        self.assertNotIn(pool_id, self.mgr.instance_mapping)
-
-        self.mgr._reload_pool(pool_id)
-
-        self.assertTrue(self.log.error.called)
-        self.assertFalse(self.driver_mock.deploy_instance.called)
-        self.assertNotIn(pool_id, self.mgr.instance_mapping)
-        self.assertFalse(self.rpc_mock.pool_deployed.called)
-
-    def test_reload_pool_exception_on_driver(self):
-        config = {'driver': 'devdriver'}
-        self.rpc_mock.get_logical_device.return_value = config
-        self.driver_mock.deploy_instance.side_effect = Exception
-        pool_id = 'new_id'
-        self.assertNotIn(pool_id, self.mgr.instance_mapping)
-
-        self.mgr._reload_pool(pool_id)
-
-        self.driver_mock.deploy_instance.assert_called_once_with(config)
-        self.assertNotIn(pool_id, self.mgr.instance_mapping)
-        self.assertFalse(self.rpc_mock.pool_deployed.called)
-        self.assertTrue(self.log.exception.called)
-        self.assertTrue(self.mgr.needs_resync)
-
-    def test_destroy_pool(self):
-        pool_id = '1'
-        self.assertIn(pool_id, self.mgr.instance_mapping)
-
-        self.mgr._destroy_pool(pool_id)
-
-        self.driver_mock.undeploy_instance.assert_called_once_with(
-            pool_id, delete_namespace=True)
-        self.assertNotIn(pool_id, self.mgr.instance_mapping)
-        self.rpc_mock.pool_destroyed.assert_called_once_with(pool_id)
-        self.assertFalse(self.mgr.needs_resync)
-
-    def test_destroy_pool_exception_on_driver(self):
-        pool_id = '1'
-        self.assertIn(pool_id, self.mgr.instance_mapping)
-        self.driver_mock.undeploy_instance.side_effect = Exception
-
-        self.mgr._destroy_pool(pool_id)
-
-        self.driver_mock.undeploy_instance.assert_called_once_with(
-            pool_id, delete_namespace=True)
-        self.assertIn(pool_id, self.mgr.instance_mapping)
-        self.assertFalse(self.rpc_mock.pool_destroyed.called)
-        self.assertTrue(self.log.exception.called)
-        self.assertTrue(self.mgr.needs_resync)
-
-    def test_get_driver_unknown_device(self):
-        self.assertRaises(manager.DeviceNotFoundOnAgent,
-                          self.mgr._get_driver, 'unknown')
-
-    def test_remove_orphans(self):
-        self.mgr.remove_orphans()
-        orphans = {'1': "Fake", '2': "Fake"}
-        self.driver_mock.remove_orphans.assert_called_once_with(orphans.keys())
-
-    def test_create_vip(self):
-        vip = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.mgr.create_vip(mock.Mock(), vip)
-        self.driver_mock.create_vip.assert_called_once_with(vip)
-        self.rpc_mock.update_status.assert_called_once_with('vip', vip['id'],
-                                                            constants.ACTIVE)
-
-    def test_create_vip_with_admin_down(self):
-        vip = {'id': 'id1', 'pool_id': '1', 'admin_state_up': False}
-        self.mgr.create_vip(mock.Mock(), vip)
-        self.driver_mock.create_vip.assert_called_once_with(vip)
-        self.rpc_mock.update_status.assert_called_once_with('vip', vip['id'],
-                                                            l_const.DISABLED)
-
-    def test_create_vip_failed(self):
-        vip = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.driver_mock.create_vip.side_effect = Exception
-        self.mgr.create_vip(mock.Mock(), vip)
-        self.driver_mock.create_vip.assert_called_once_with(vip)
-        self.rpc_mock.update_status.assert_called_once_with('vip', vip['id'],
-                                                            constants.ERROR)
-
-    def test_update_vip(self):
-        old_vip = {'id': 'id1', 'admin_state_up': True}
-        vip = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.mgr.update_vip(mock.Mock(), old_vip, vip)
-        self.driver_mock.update_vip.assert_called_once_with(old_vip, vip)
-        self.rpc_mock.update_status.assert_called_once_with('vip', vip['id'],
-                                                            constants.ACTIVE)
-
-    def test_update_vip_with_admin_down(self):
-        old_vip = {'id': 'id1', 'admin_state_up': True}
-        vip = {'id': 'id1', 'pool_id': '1', 'admin_state_up': False}
-        self.mgr.update_vip(mock.Mock(), old_vip, vip)
-        self.driver_mock.update_vip.assert_called_once_with(old_vip, vip)
-        self.rpc_mock.update_status.assert_called_once_with('vip', vip['id'],
-                                                            l_const.DISABLED)
-
-    def test_update_vip_failed(self):
-        old_vip = {'id': 'id1', 'admin_state_up': True}
-        vip = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.driver_mock.update_vip.side_effect = Exception
-        self.mgr.update_vip(mock.Mock(), old_vip, vip)
-        self.driver_mock.update_vip.assert_called_once_with(old_vip, vip)
-        self.rpc_mock.update_status.assert_called_once_with('vip', vip['id'],
-                                                            constants.ERROR)
-
-    def test_delete_vip(self):
-        vip = {'id': 'id1', 'pool_id': '1'}
-        self.mgr.delete_vip(mock.Mock(), vip)
-        self.driver_mock.delete_vip.assert_called_once_with(vip)
-
-    def test_create_pool(self):
-        pool = {'id': 'id1', 'admin_state_up': True}
-        self.assertNotIn(pool['id'], self.mgr.instance_mapping)
-        self.mgr.create_pool(mock.Mock(), pool, 'devdriver')
-        self.driver_mock.create_pool.assert_called_once_with(pool)
-        self.rpc_mock.update_status.assert_called_once_with('pool', pool['id'],
-                                                            constants.ACTIVE)
-        self.assertIn(pool['id'], self.mgr.instance_mapping)
-
-    def test_create_pool_with_admin_down(self):
-        pool = {'id': 'id1', 'admin_state_up': False}
-        self.assertNotIn(pool['id'], self.mgr.instance_mapping)
-        self.mgr.create_pool(mock.Mock(), pool, 'devdriver')
-        self.driver_mock.create_pool.assert_called_once_with(pool)
-        self.rpc_mock.update_status.assert_called_once_with('pool', pool['id'],
-                                                            l_const.DISABLED)
-        self.assertIn(pool['id'], self.mgr.instance_mapping)
-
-    def test_create_pool_failed(self):
-        pool = {'id': 'id1', 'admin_state_up': True}
-        self.assertNotIn(pool['id'], self.mgr.instance_mapping)
-        self.driver_mock.create_pool.side_effect = Exception
-        self.mgr.create_pool(mock.Mock(), pool, 'devdriver')
-        self.driver_mock.create_pool.assert_called_once_with(pool)
-        self.rpc_mock.update_status.assert_called_once_with('pool', pool['id'],
-                                                            constants.ERROR)
-        self.assertNotIn(pool['id'], self.mgr.instance_mapping)
-
-    def test_update_pool(self):
-        old_pool = {'id': '1', 'admin_state_up': True}
-        pool = {'id': '1', 'admin_state_up': True}
-        self.mgr.update_pool(mock.Mock(), old_pool, pool)
-        self.driver_mock.update_pool.assert_called_once_with(old_pool, pool)
-        self.rpc_mock.update_status.assert_called_once_with('pool', pool['id'],
-                                                            constants.ACTIVE)
-
-    def test_update_pool_with_admin_down(self):
-        old_pool = {'id': '1', 'admin_state_up': True}
-        pool = {'id': '1', 'admin_state_up': False}
-        self.mgr.update_pool(mock.Mock(), old_pool, pool)
-        self.driver_mock.update_pool.assert_called_once_with(old_pool, pool)
-        self.rpc_mock.update_status.assert_called_once_with('pool', pool['id'],
-                                                            l_const.DISABLED)
-
-    def test_update_pool_failed(self):
-        old_pool = {'id': '1', 'admin_state_up': True}
-        pool = {'id': '1', 'admin_state_up': True}
-        self.driver_mock.update_pool.side_effect = Exception
-        self.mgr.update_pool(mock.Mock(), old_pool, pool)
-        self.driver_mock.update_pool.assert_called_once_with(old_pool, pool)
-        self.rpc_mock.update_status.assert_called_once_with('pool', pool['id'],
-                                                            constants.ERROR)
-
-    def test_delete_pool(self):
-        pool = {'id': '1'}
-        self.assertIn(pool['id'], self.mgr.instance_mapping)
-        self.mgr.delete_pool(mock.Mock(), pool)
-        self.driver_mock.delete_pool.assert_called_once_with(pool)
-        self.assertNotIn(pool['id'], self.mgr.instance_mapping)
-
-    def test_create_member(self):
-        member = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.mgr.create_member(mock.Mock(), member)
-        self.driver_mock.create_member.assert_called_once_with(member)
-        self.rpc_mock.update_status.assert_called_once_with('member',
-                                                            member['id'],
-                                                            constants.ACTIVE)
-
-    def test_create_member_with_admin_down(self):
-        member = {'id': 'id1', 'pool_id': '1', 'admin_state_up': False}
-        self.mgr.create_member(mock.Mock(), member)
-        self.driver_mock.create_member.assert_called_once_with(member)
-        self.rpc_mock.update_status.assert_called_once_with('member',
-                                                            member['id'],
-                                                            l_const.DISABLED)
-
-    def test_create_member_failed(self):
-        member = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.driver_mock.create_member.side_effect = Exception
-        self.mgr.create_member(mock.Mock(), member)
-        self.driver_mock.create_member.assert_called_once_with(member)
-        self.rpc_mock.update_status.assert_called_once_with('member',
-                                                            member['id'],
-                                                            constants.ERROR)
-
-    def test_update_member(self):
-        old_member = {'id': 'id1', 'admin_state_up': True}
-        member = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.mgr.update_member(mock.Mock(), old_member, member)
-        self.driver_mock.update_member.assert_called_once_with(old_member,
-                                                               member)
-        self.rpc_mock.update_status.assert_called_once_with('member',
-                                                            member['id'],
-                                                            constants.ACTIVE)
-
-    def test_update_member_with_admin_down(self):
-        old_member = {'id': 'id1', 'admin_state_up': True}
-        member = {'id': 'id1', 'pool_id': '1', 'admin_state_up': False}
-        self.mgr.update_member(mock.Mock(), old_member, member)
-        self.driver_mock.update_member.assert_called_once_with(old_member,
-                                                               member)
-        self.rpc_mock.update_status.assert_called_once_with('member',
-                                                            member['id'],
-                                                            l_const.DISABLED)
-
-    def test_update_member_failed(self):
-        old_member = {'id': 'id1', 'admin_state_up': True}
-        member = {'id': 'id1', 'pool_id': '1', 'admin_state_up': True}
-        self.driver_mock.update_member.side_effect = Exception
-        self.mgr.update_member(mock.Mock(), old_member, member)
-        self.driver_mock.update_member.assert_called_once_with(old_member,
-                                                               member)
-        self.rpc_mock.update_status.assert_called_once_with('member',
-                                                            member['id'],
-                                                            constants.ERROR)
-
-    def test_delete_member(self):
-        member = {'id': 'id1', 'pool_id': '1'}
-        self.mgr.delete_member(mock.Mock(), member)
-        self.driver_mock.delete_member.assert_called_once_with(member)
-
-    def test_create_monitor(self):
-        monitor = {'id': 'id1', 'admin_state_up': True}
-        assoc_id = {'monitor_id': monitor['id'], 'pool_id': '1'}
-        self.mgr.create_pool_health_monitor(mock.Mock(), monitor, '1')
-        self.driver_mock.create_pool_health_monitor.assert_called_once_with(
-            monitor, '1')
-        self.rpc_mock.update_status.assert_called_once_with('health_monitor',
-                                                            assoc_id,
-                                                            constants.ACTIVE)
-
-    def test_create_monitor_with_admin_down(self):
-        monitor = {'id': 'id1', 'admin_state_up': False}
-        assoc_id = {'monitor_id': monitor['id'], 'pool_id': '1'}
-        self.mgr.create_pool_health_monitor(mock.Mock(), monitor, '1')
-        self.driver_mock.create_pool_health_monitor.assert_called_once_with(
-            monitor, '1')
-        self.rpc_mock.update_status.assert_called_once_with('health_monitor',
-                                                            assoc_id,
-                                                            l_const.DISABLED)
-
-    def test_create_monitor_failed(self):
-        monitor = {'id': 'id1', 'admin_state_up': True}
-        assoc_id = {'monitor_id': monitor['id'], 'pool_id': '1'}
-        self.driver_mock.create_pool_health_monitor.side_effect = Exception
-        self.mgr.create_pool_health_monitor(mock.Mock(), monitor, '1')
-        self.driver_mock.create_pool_health_monitor.assert_called_once_with(
-            monitor, '1')
-        self.rpc_mock.update_status.assert_called_once_with('health_monitor',
-                                                            assoc_id,
-                                                            constants.ERROR)
-
-    def test_update_monitor(self):
-        monitor = {'id': 'id1', 'admin_state_up': True}
-        assoc_id = {'monitor_id': monitor['id'], 'pool_id': '1'}
-        self.mgr.update_pool_health_monitor(mock.Mock(), monitor, monitor, '1')
-        self.driver_mock.update_pool_health_monitor.assert_called_once_with(
-            monitor, monitor, '1')
-        self.rpc_mock.update_status.assert_called_once_with('health_monitor',
-                                                            assoc_id,
-                                                            constants.ACTIVE)
-
-    def test_update_monitor_with_admin_down(self):
-        monitor = {'id': 'id1', 'admin_state_up': False}
-        assoc_id = {'monitor_id': monitor['id'], 'pool_id': '1'}
-        self.mgr.update_pool_health_monitor(mock.Mock(), monitor, monitor, '1')
-        self.driver_mock.update_pool_health_monitor.assert_called_once_with(
-            monitor, monitor, '1')
-        self.rpc_mock.update_status.assert_called_once_with('health_monitor',
-                                                            assoc_id,
-                                                            l_const.DISABLED)
-
-    def test_update_monitor_failed(self):
-        monitor = {'id': 'id1', 'admin_state_up': True}
-        assoc_id = {'monitor_id': monitor['id'], 'pool_id': '1'}
-        self.driver_mock.update_pool_health_monitor.side_effect = Exception
-        self.mgr.update_pool_health_monitor(mock.Mock(), monitor, monitor, '1')
-        self.driver_mock.update_pool_health_monitor.assert_called_once_with(
-            monitor, monitor, '1')
-        self.rpc_mock.update_status.assert_called_once_with('health_monitor',
-                                                            assoc_id,
-                                                            constants.ERROR)
-
-    def test_delete_monitor(self):
-        monitor = {'id': 'id1'}
-        self.mgr.delete_pool_health_monitor(mock.Mock(), monitor, '1')
-        self.driver_mock.delete_pool_health_monitor.assert_called_once_with(
-            monitor, '1')
-
-    def test_agent_disabled(self):
-        payload = {'admin_state_up': False}
-        self.mgr.agent_updated(mock.Mock(), payload)
-        self.driver_mock.undeploy_instance.assert_has_calls(
-            [mock.call('1', delete_namespace=True),
-             mock.call('2', delete_namespace=True)],
-            any_order=True
-        )
diff --git a/tests/unit/services/loadbalancer/agent/test_api.py b/tests/unit/services/loadbalancer/agent/test_api.py
deleted file mode 100644
index aa356c1..0000000
--- a/tests/unit/services/loadbalancer/agent/test_api.py
+++ /dev/null
@@ -1,81 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import copy
-import mock
-
-from neutron_lbaas.services.loadbalancer.agent import agent_api as api
-from neutron_lbaas.tests import base
-
-
-class TestApiCache(base.BaseTestCase):
-    def setUp(self):
-        super(TestApiCache, self).setUp()
-
-        self.api = api.LbaasAgentApi('topic', mock.sentinel.context, 'host')
-
-    def test_init(self):
-        self.assertEqual('host', self.api.host)
-        self.assertEqual(mock.sentinel.context, self.api.context)
-
-    def _test_method(self, method, **kwargs):
-        add_host = ('get_ready_devices', 'plug_vip_port', 'unplug_vip_port',
-                    'update_pool_stats')
-        expected_kwargs = copy.copy(kwargs)
-        if method in add_host:
-            expected_kwargs['host'] = self.api.host
-
-        with contextlib.nested(
-            mock.patch.object(self.api.client, 'call'),
-            mock.patch.object(self.api.client, 'prepare'),
-        ) as (
-            rpc_mock, prepare_mock
-        ):
-            prepare_mock.return_value = self.api.client
-            rpc_mock.return_value = 'foo'
-            rv = getattr(self.api, method)(**kwargs)
-
-        self.assertEqual('foo', rv)
-
-        prepare_args = {}
-        prepare_mock.assert_called_once_with(**prepare_args)
-
-        rpc_mock.assert_called_once_with(mock.sentinel.context, method,
-                                         **expected_kwargs)
-
-    def test_get_ready_devices(self):
-        self._test_method('get_ready_devices')
-
-    def test_get_logical_device(self):
-        self._test_method('get_logical_device', pool_id='pool_id')
-
-    def test_pool_destroyed(self):
-        self._test_method('pool_destroyed', pool_id='pool_id')
-
-    def test_pool_deployed(self):
-        self._test_method('pool_deployed', pool_id='pool_id')
-
-    def test_update_status(self):
-        self._test_method('update_status', obj_type='type', obj_id='id',
-                          status='status')
-
-    def test_plug_vip_port(self):
-        self._test_method('plug_vip_port', port_id='port_id')
-
-    def test_unplug_vip_port(self):
-        self._test_method('unplug_vip_port', port_id='port_id')
-
-    def test_update_pool_stats(self):
-        self._test_method('update_pool_stats', pool_id='id', stats='stats')
diff --git a/tests/unit/services/loadbalancer/drivers/__init__.py b/tests/unit/services/loadbalancer/drivers/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/a10networks/__init__.py b/tests/unit/services/loadbalancer/drivers/a10networks/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py b/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py
deleted file mode 100644
index 1bcb888..0000000
--- a/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py
+++ /dev/null
@@ -1,180 +0,0 @@
-# Copyright 2014, Doug Wiegley (dougwig), A10 Networks
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import sys
-
-import mock
-from neutron import context
-
-from neutron_lbaas.db.loadbalancer import loadbalancer_db as lb_db
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-with mock.patch.dict(sys.modules, {'a10_neutron_lbaas': mock.Mock()}):
-    from neutron_lbaas.services.loadbalancer.drivers.a10networks \
-        import driver_v1
-
-
-def fake_model(id):
-    return {
-        'id': id,
-        'tenant_id': "tennant-was-a-great-doctor"
-    }
-
-
-def fake_member(id):
-    return {
-        'id': id,
-        'tenant_id': "vippyvip",
-        'address': '1.1.1.1'
-    }
-
-
-class TestA10ThunderDriver(test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def setUp(self):
-        super(TestA10ThunderDriver, self).setUp()
-        self.context = context.get_admin_context()
-        self.plugin = mock.Mock()
-        self.driver = driver_v1.ThunderDriver(self.plugin)
-        self.driver.a10 = mock.Mock()
-        self.m = fake_model('p1')
-
-    def test__hm_binding_count(self):
-        n = self.driver._hm_binding_count(self.context, 'hm01')
-        self.assertEqual(0, n)
-
-    def test__member_count(self):
-        self.m = fake_member('mem1')
-        n = self.driver._member_count(self.context, self.m)
-        self.assertEqual(0, n)
-
-    def test__member_get_ip(self):
-        self.m = fake_member('mem1')
-        z = self.driver._member_get_ip(self.context, self.m, False)
-        self.assertEqual('1.1.1.1', z)
-        z = self.driver._member_get_ip(self.context, self.m, True)
-        self.assertEqual('1.1.1.1', z)
-
-    def test__pool_get_hm(self):
-        self.driver._pool_get_hm(self.context, 'hm01')
-        self.plugin.get_health_monitor.assert_called_once_with(
-            self.context, 'hm01')
-
-    def test__pool_get_tenant_id(self):
-        z = self.driver._pool_get_tenant_id(self.context, 'pool1')
-        self.assertEqual('', z)
-
-    def test__pool_get_vip_id(self):
-        z = self.driver._pool_get_vip_id(self.context, 'pool1')
-        self.assertEqual('', z)
-
-    def test__pool_total(self):
-        n = self.driver._pool_total(self.context,
-                                    tenant_id='whatareyoudoingdave')
-        self.assertEqual(0, n)
-
-    def test__active(self):
-        self.driver._active(self.context, 'vip', 'vip1')
-        self.plugin.update_status.assert_called_once_with(
-            self.context, lb_db.Vip, 'vip1', 'ACTIVE')
-
-    def test__failed(self):
-        self.driver._failed(self.context, 'vip', 'vip2-1-2')
-        self.plugin.update_status.assert_called_once_with(
-            self.context, lb_db.Vip, 'vip2-1-2', 'ERROR')
-
-    def test__db_delete(self):
-        self.driver._db_delete(self.context, 'pool', 'myid0101')
-        self.plugin._delete_db_pool.assert_called_once_with(
-            self.context, 'myid0101')
-
-    def test__hm_active(self):
-        self.driver._hm_active(self.context, 'hm01', 'pool1')
-        self.plugin.update_pool_health_monitor.assert_called_once_with(
-            self.context, 'hm01', 'pool1', 'ACTIVE')
-
-    def test__hm_failed(self):
-        self.driver._hm_failed(self.context, 'hm01', 'pool1')
-        self.plugin.update_pool_health_monitor.assert_called_once_with(
-            self.context, 'hm01', 'pool1', 'ERROR')
-
-    def test__hm_db_delete(self):
-        self.driver._hm_db_delete(self.context, 'hm01', 'pool2')
-        self.plugin._delete_db_pool_health_monitor.assert_called_once_with(
-            self.context, 'hm01', 'pool2')
-
-    def test_create_vip(self):
-        self.driver.create_vip(self.context, self.m)
-        self.driver.a10.vip.create.assert_called_once_with(
-            self.context, self.m)
-
-    def test_update_vip(self):
-        self.driver.update_vip(self.context, self.m, self.m)
-        self.driver.a10.vip.update.assert_called_once_with(
-            self.context, self.m, self.m)
-
-    def test_delete_vip(self):
-        self.driver.delete_vip(self.context, self.m)
-        self.driver.a10.vip.delete.assert_called_once_with(
-            self.context, self.m)
-
-    def test_create_pool(self):
-        self.driver.create_pool(self.context, self.m)
-        self.driver.a10.pool.create.assert_called_once_with(
-            self.context, self.m)
-
-    def test_update_pool(self):
-        self.driver.update_pool(self.context, self.m, self.m)
-        self.driver.a10.pool.update.assert_called_once_with(
-            self.context, self.m, self.m)
-
-    def test_delete_pool(self):
-        self.driver.delete_pool(self.context, self.m)
-        self.driver.a10.pool.delete.assert_called_once_with(
-            self.context, self.m)
-
-    def test_stats(self):
-        self.driver.stats(self.context, self.m['id'])
-        self.driver.a10.pool.stats.assert_called_once_with(
-            self.context, self.m['id'])
-
-    def test_create_member(self):
-        self.driver.create_member(self.context, self.m)
-        self.driver.a10.member.create.assert_called_once_with(
-            self.context, self.m)
-
-    def test_update_member(self):
-        self.driver.update_member(self.context, self.m, self.m)
-        self.driver.a10.member.update.assert_called_once_with(
-            self.context, self.m, self.m)
-
-    def test_delete_member(self):
-        self.driver.delete_member(self.context, self.m)
-        self.driver.a10.member.delete.assert_called_once_with(
-            self.context, self.m)
-
-    def test_update_pool_health_monitor(self):
-        self.driver.update_pool_health_monitor(self.context, self.m, self.m,
-                                               'pool1')
-        self.driver.a10.hm.update.assert_called_once_with(
-            self.context, self.m, self.m, 'pool1')
-
-    def test_create_pool_health_monitor(self):
-        self.driver.create_pool_health_monitor(self.context, self.m, 'pool1')
-        self.driver.a10.hm.create.assert_called_once_with(
-            self.context, self.m, 'pool1')
-
-    def test_delete_pool_health_monitor(self):
-        self.driver.delete_pool_health_monitor(self.context, self.m, 'pool1')
-        self.driver.a10.hm.delete.assert_called_once_with(
-            self.context, self.m, 'pool1')
diff --git a/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py b/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/__init__.py b/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py b/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py
deleted file mode 100644
index c23176b..0000000
--- a/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py
+++ /dev/null
@@ -1,294 +0,0 @@
-# Copyright 2014 OpenStack Foundation
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-
-import collections
-
-RET_PERSISTENCE = {
-    'type': 'HTTP_COOKIE',
-    'cookie_name': 'HTTP_COOKIE'}
-
-HASHSEED_ORDERED_CODES = list({'404', '405', '500'})
-PIPED_CODES = '|'.join(HASHSEED_ORDERED_CODES)
-
-RET_MONITOR = {
-    'id': 'sample_monitor_id_1',
-    'type': 'HTTP',
-    'delay': 30,
-    'timeout': 31,
-    'max_retries': 3,
-    'http_method': 'GET',
-    'url_path': '/index.html',
-    'expected_codes': PIPED_CODES,
-    'admin_state_up': True}
-
-RET_MEMBER_1 = {
-    'id': 'sample_member_id_1',
-    'address': '10.0.0.99',
-    'protocol_port': 82,
-    'weight': 13,
-    'subnet_id': '10.0.0.1/24',
-    'admin_state_up': True,
-    'provisioning_status': 'ACTIVE'}
-
-RET_MEMBER_2 = {
-    'id': 'sample_member_id_2',
-    'address': '10.0.0.98',
-    'protocol_port': 82,
-    'weight': 13,
-    'subnet_id': '10.0.0.1/24',
-    'admin_state_up': True,
-    'provisioning_status': 'ACTIVE'}
-
-RET_POOL = {
-    'id': 'sample_pool_id_1',
-    'protocol': 'http',
-    'lb_algorithm': 'roundrobin',
-    'members': [RET_MEMBER_1, RET_MEMBER_2],
-    'health_monitor': RET_MONITOR,
-    'session_persistence': RET_PERSISTENCE,
-    'admin_state_up': True,
-    'provisioning_status': 'ACTIVE'}
-
-RET_DEF_TLS_CONT = {'id': 'cont_id_1', 'allencompassingpem': 'imapem'}
-RET_SNI_CONT_1 = {'id': 'cont_id_2', 'allencompassingpem': 'imapem2'}
-RET_SNI_CONT_2 = {'id': 'cont_id_3', 'allencompassingpem': 'imapem3'}
-
-RET_LISTENER = {
-    'id': 'sample_listener_id_1',
-    'protocol_port': '80',
-    'protocol': 'HTTP',
-    'protocol_mode': 'http',
-    'default_pool': RET_POOL,
-    'connection_limit': 98}
-
-RET_LISTENER_TLS = {
-    'id': 'sample_listener_id_1',
-    'protocol_port': '443',
-    'protocol_mode': 'HTTP',
-    'protocol': 'TERMINATED_HTTPS',
-    'default_pool': RET_POOL,
-    'connection_limit': 98,
-    'default_tls_container_id': 'cont_id_1',
-    'default_tls_path': '/v2/sample_loadbalancer_id_1/cont_id_1.pem',
-    'default_tls_container': RET_DEF_TLS_CONT}
-
-RET_LISTENER_TLS_SNI = {
-    'id': 'sample_listener_id_1',
-    'protocol_port': '443',
-    'protocol_mode': 'http',
-    'protocol': 'TERMINATED_HTTPS',
-    'default_pool': RET_POOL,
-    'connection_limit': 98,
-    'default_tls_container_id': 'cont_id_1',
-    'default_tls_path': '/v2/sample_loadbalancer_id_1/cont_id_1.pem',
-    'default_tls_container': RET_DEF_TLS_CONT,
-    'crt_dir': '/v2/sample_loadbalancer_id_1',
-    'sni_container_ids': ['cont_id_2', 'cont_id_3'],
-    'sni_containers': [RET_SNI_CONT_1, RET_SNI_CONT_2]}
-
-RET_LB = {
-    'name': 'test-lb',
-    'vip_address': '10.0.0.2',
-    'listeners': [RET_LISTENER],
-    'pools': [RET_POOL]}
-
-RET_LB_TLS = {
-    'name': 'test-lb',
-    'vip_address': '10.0.0.2',
-    'listeners': [RET_LISTENER_TLS],
-    'pools': [RET_POOL]}
-
-RET_LB_TLS_SNI = {
-    'name': 'test-lb',
-    'vip_address': '10.0.0.2',
-    'listeners': [RET_LISTENER_TLS_SNI],
-    'pools': [RET_POOL]}
-
-
-def sample_loadbalancer_tuple(proto=None, monitor=True, persistence=True,
-                              persistence_type=None, tls=False, sni=False):
-    proto = 'HTTP' if proto is None else proto
-    in_lb = collections.namedtuple(
-        'loadbalancer', 'id, name, vip_address, protocol, vip_port, '
-                        'listeners, pools')
-    return in_lb(
-        id='sample_loadbalancer_id_1',
-        name='test-lb',
-        vip_address='10.0.0.2',
-        protocol=proto,
-        vip_port=sample_vip_port_tuple(),
-        listeners=[sample_listener_tuple(proto=proto, monitor=monitor,
-                                         persistence=persistence,
-                                         persistence_type=persistence_type,
-                                         tls=tls,
-                                         sni=sni)],
-        pools=[sample_pool_tuple(proto=proto, monitor=monitor,
-                                 persistence=persistence,
-                                 persistence_type=persistence_type)]
-    )
-
-
-def sample_vip_port_tuple():
-    vip_port = collections.namedtuple('vip_port', 'fixed_ips')
-    ip_address = collections.namedtuple('ip_address', 'ip_address')
-    in_address = ip_address(ip_address='10.0.0.2')
-    return vip_port(fixed_ips=[in_address])
-
-
-def sample_listener_tuple(proto=None, monitor=True, persistence=True,
-                          persistence_type=None, tls=False, sni=False):
-    proto = 'HTTP' if proto is None else proto
-    port = '443' if proto is 'HTTPS' or proto is 'TERMINATED_HTTPS' else '80'
-    in_listener = collections.namedtuple(
-        'listener', 'id, tenant_id, protocol_port, protocol, default_pool, '
-        'connection_limit, admin_state_up, default_tls_container_id, '
-                    'sni_container_ids, default_tls_container, '
-                    'sni_containers, loadbalancer_id')
-    return in_listener(
-        id='sample_listener_id_1',
-        tenant_id='sample_tenant_id',
-        protocol_port=port,
-        protocol=proto,
-        default_pool=sample_pool_tuple(
-            proto=proto, monitor=monitor, persistence=persistence,
-            persistence_type=persistence_type),
-        connection_limit=98,
-        admin_state_up=True,
-        default_tls_container_id='cont_id_1' if tls else '',
-        sni_container_ids=['cont_id_2', 'cont_id_3'] if sni else [],
-        default_tls_container=sample_tls_container_tuple(
-            id='cont_id_1', certificate='--imapem1--\n',
-            private_key='--imakey1--\n', intermediates=[
-                '--imainter1--\n', '--imainter1too--\n'],
-            primary_cn='fakeCNM'
-        ) if tls else '',
-        sni_containers=[
-            sample_tls_sni_container_tuple(
-                tls_container_id='cont_id_2',
-                tls_container=sample_tls_container_tuple(
-                    id='cont_id_2', certificate='--imapem2--\n',
-                    private_key='--imakey2--\n', intermediates=[
-                        '--imainter2--\n', '--imainter2too--\n'],
-                    primary_cn='fakeCN')),
-            sample_tls_sni_container_tuple(
-                tls_container_id='cont_id_3',
-                tls_container=sample_tls_container_tuple(
-                    id='cont_id_3', certificate='--imapem3--\n',
-                    private_key='--imakey3--\n', intermediates=[
-                        '--imainter3--\n', '--imainter3too--\n'],
-                    primary_cn='fakeCN2'))]
-        if sni else [],
-        loadbalancer_id='sample_loadbalancer_id_1'
-    )
-
-
-def sample_tls_sni_container_tuple(tls_container=None, tls_container_id=None):
-    sc = collections.namedtuple('sni_container', 'tls_container,'
-                                                 'tls_container_id')
-    return sc(tls_container=tls_container, tls_container_id=tls_container_id)
-
-
-def sample_tls_container_tuple(id='cont_id_1', certificate=None,
-                               private_key=None, intermediates=None,
-                               primary_cn=None):
-    intermediates = intermediates or []
-    sc = collections.namedtuple(
-        'tls_cert',
-        'id, certificate, private_key, intermediates, primary_cn')
-    return sc(id=id, certificate=certificate, private_key=private_key,
-              intermediates=intermediates or [], primary_cn=primary_cn)
-
-
-def sample_pool_tuple(proto=None, monitor=True, persistence=True,
-                      persistence_type=None, hm_admin_state=True):
-    proto = 'HTTP' if proto is None else proto
-    in_pool = collections.namedtuple(
-        'pool', 'id, protocol, lb_algorithm, members, healthmonitor,'
-                'session_persistence, admin_state_up, provisioning_status')
-    mon = (sample_health_monitor_tuple(proto=proto, admin_state=hm_admin_state)
-           if monitor is True else None)
-    persis = sample_session_persistence_tuple(
-        persistence_type=persistence_type) if persistence is True else None
-    return in_pool(
-        id='sample_pool_id_1',
-        protocol=proto,
-        lb_algorithm='ROUND_ROBIN',
-        members=[sample_member_tuple('sample_member_id_1', '10.0.0.99'),
-                 sample_member_tuple('sample_member_id_2', '10.0.0.98')],
-        healthmonitor=mon,
-        session_persistence=persis,
-        admin_state_up=True,
-        provisioning_status='ACTIVE')
-
-
-def sample_member_tuple(id, ip, admin_state_up=True, status='ACTIVE'):
-    in_member = collections.namedtuple('member',
-                                       'id, address, protocol_port, '
-                                       'weight, subnet_id, '
-                                       'admin_state_up, provisioning_status')
-    return in_member(
-        id=id,
-        address=ip,
-        protocol_port=82,
-        weight=13,
-        subnet_id='10.0.0.1/24',
-        admin_state_up=admin_state_up,
-        provisioning_status=status)
-
-
-def sample_session_persistence_tuple(persistence_type=None):
-    spersistence = collections.namedtuple('SessionPersistence',
-                                          'type, cookie_name')
-    pt = 'HTTP_COOKIE' if persistence_type is None else persistence_type
-    return spersistence(type=pt,
-                        cookie_name=pt)
-
-
-def sample_health_monitor_tuple(proto='HTTP', admin_state=True):
-    proto = 'HTTP' if proto is 'TERMINATED_HTTPS' else proto
-    monitor = collections.namedtuple(
-        'monitor', 'id, type, delay, timeout, max_retries, http_method, '
-                   'url_path, expected_codes, admin_state_up')
-
-    return monitor(id='sample_monitor_id_1', type=proto, delay=30,
-                   timeout=31, max_retries=3, http_method='GET',
-                   url_path='/index.html', expected_codes='500, 405, 404',
-                   admin_state_up=admin_state)
-
-
-def sample_base_expected_config(backend, frontend=None):
-    if frontend is None:
-        frontend = ("frontend sample_listener_id_1\n"
-                    "    option tcplog\n"
-                    "    maxconn 98\n"
-                    "    option forwardfor\n"
-                    "    bind 10.0.0.2:80\n"
-                    "    mode http\n"
-                    "    default_backend sample_pool_id_1\n\n")
-    return ("# Configuration for test-lb\n"
-            "global\n"
-            "    daemon\n"
-            "    user nobody\n"
-            "    group nogroup\n"
-            "    log /dev/log local0\n"
-            "    log /dev/log local1 notice\n"
-            "    stats socket /sock_path mode 0666 level user\n\n"
-            "defaults\n"
-            "    log global\n"
-            "    retries 3\n"
-            "    option redispatch\n"
-            "    timeout connect 5000\n"
-            "    timeout client 50000\n"
-            "    timeout server 50000\n\n" + frontend + backend)
diff --git a/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py b/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py
deleted file mode 100644
index 9428b57..0000000
--- a/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py
+++ /dev/null
@@ -1,236 +0,0 @@
-# Copyright 2013 Mirantis, Inc.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-
-import mock
-
-from neutron_lbaas.services.loadbalancer.drivers.haproxy import cfg
-from neutron_lbaas.tests import base
-
-
-class TestHaproxyCfg(base.BaseTestCase):
-    def test_save_config(self):
-        with contextlib.nested(
-                mock.patch('neutron_lbaas.services.loadbalancer.'
-                           'drivers.haproxy.cfg._build_global'),
-                mock.patch('neutron_lbaas.services.loadbalancer.'
-                           'drivers.haproxy.cfg._build_defaults'),
-                mock.patch('neutron_lbaas.services.loadbalancer.'
-                           'drivers.haproxy.cfg._build_frontend'),
-                mock.patch('neutron_lbaas.services.loadbalancer.'
-                           'drivers.haproxy.cfg._build_backend'),
-                mock.patch('neutron.common.utils.replace_file')
-        ) as (b_g, b_d, b_f, b_b, replace):
-            test_config = ['globals', 'defaults', 'frontend', 'backend']
-            b_g.return_value = [test_config[0]]
-            b_d.return_value = [test_config[1]]
-            b_f.return_value = [test_config[2]]
-            b_b.return_value = [test_config[3]]
-
-            cfg.save_config('test_path', mock.Mock())
-            replace.assert_called_once_with('test_path',
-                                            '\n'.join(test_config))
-
-    def test_build_global(self):
-        expected_opts = ['global',
-                         '\tdaemon',
-                         '\tuser nobody',
-                         '\tgroup test_group',
-                         '\tlog /dev/log local0',
-                         '\tlog /dev/log local1 notice',
-                         '\tstats socket test_path mode 0666 level user']
-        opts = cfg._build_global(mock.Mock(), 'test_path', 'test_group')
-        self.assertEqual(expected_opts, list(opts))
-
-    def test_build_defaults(self):
-        expected_opts = ['defaults',
-                         '\tlog global',
-                         '\tretries 3',
-                         '\toption redispatch',
-                         '\ttimeout connect 5000',
-                         '\ttimeout client 50000',
-                         '\ttimeout server 50000']
-        opts = cfg._build_defaults(mock.Mock())
-        self.assertEqual(expected_opts, list(opts))
-
-    def test_build_frontend(self):
-        test_config = {'vip': {'id': 'vip_id',
-                               'protocol': 'HTTP',
-                               'port': {'fixed_ips': [
-                                   {'ip_address': '10.0.0.2'}]
-                               },
-                               'protocol_port': 80,
-                               'connection_limit': 2000,
-                               'admin_state_up': True,
-                               },
-                       'pool': {'id': 'pool_id'}}
-        expected_opts = ['frontend vip_id',
-                         '\toption tcplog',
-                         '\tbind 10.0.0.2:80',
-                         '\tmode http',
-                         '\tdefault_backend pool_id',
-                         '\tmaxconn 2000',
-                         '\toption forwardfor']
-        opts = cfg._build_frontend(test_config)
-        self.assertEqual(expected_opts, list(opts))
-
-        test_config['vip']['connection_limit'] = -1
-        expected_opts.remove('\tmaxconn 2000')
-        opts = cfg._build_frontend(test_config)
-        self.assertEqual(expected_opts, list(opts))
-
-        test_config['vip']['admin_state_up'] = False
-        expected_opts.append('\tdisabled')
-        opts = cfg._build_frontend(test_config)
-        self.assertEqual(expected_opts, list(opts))
-
-    def test_build_backend(self):
-        test_config = {'pool': {'id': 'pool_id',
-                                'protocol': 'HTTP',
-                                'lb_method': 'ROUND_ROBIN',
-                                'admin_state_up': True},
-                       'members': [{'status': 'ACTIVE',
-                                    'admin_state_up': True,
-                                    'id': 'member1_id',
-                                    'address': '10.0.0.3',
-                                    'protocol_port': 80,
-                                    'weight': 1},
-                                   {'status': 'INACTIVE',
-                                    'admin_state_up': True,
-                                    'id': 'member2_id',
-                                    'address': '10.0.0.4',
-                                    'protocol_port': 80,
-                                    'weight': 1},
-                                   {'status': 'PENDING_CREATE',
-                                    'admin_state_up': True,
-                                    'id': 'member3_id',
-                                    'address': '10.0.0.5',
-                                    'protocol_port': 80,
-                                    'weight': 1}],
-                       'healthmonitors': [{'admin_state_up': True,
-                                           'delay': 3,
-                                           'max_retries': 4,
-                                           'timeout': 2,
-                                           'type': 'TCP'}],
-                       'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}}
-        expected_opts = ['backend pool_id',
-                         '\tmode http',
-                         '\tbalance roundrobin',
-                         '\toption forwardfor',
-                         '\ttimeout check 2s',
-                         '\tcookie SRV insert indirect nocache',
-                         '\tserver member1_id 10.0.0.3:80 weight 1 '
-                         'check inter 3s fall 4 cookie member1_id',
-                         '\tserver member2_id 10.0.0.4:80 weight 1 '
-                         'check inter 3s fall 4 cookie member2_id',
-                         '\tserver member3_id 10.0.0.5:80 weight 1 '
-                         'check inter 3s fall 4 cookie member3_id']
-        opts = cfg._build_backend(test_config)
-        self.assertEqual(expected_opts, list(opts))
-
-        test_config['pool']['admin_state_up'] = False
-        expected_opts.append('\tdisabled')
-        opts = cfg._build_backend(test_config)
-        self.assertEqual(expected_opts, list(opts))
-
-    def test_get_server_health_option(self):
-        test_config = {'healthmonitors': [{'admin_state_up': False,
-                                           'delay': 3,
-                                           'max_retries': 4,
-                                           'timeout': 2,
-                                           'type': 'TCP',
-                                           'http_method': 'GET',
-                                           'url_path': '/',
-                                           'expected_codes': '200'}]}
-        self.assertEqual(('', []), cfg._get_server_health_option(test_config))
-
-        self.assertEqual(('', []), cfg._get_server_health_option(test_config))
-
-        test_config['healthmonitors'][0]['admin_state_up'] = True
-        expected = (' check inter 3s fall 4', ['timeout check 2s'])
-        self.assertEqual(expected, cfg._get_server_health_option(test_config))
-
-        test_config['healthmonitors'][0]['type'] = 'HTTPS'
-        expected = (' check inter 3s fall 4',
-                    ['timeout check 2s',
-                     'option httpchk GET /',
-                     'http-check expect rstatus 200',
-                     'option ssl-hello-chk'])
-        self.assertEqual(expected, cfg._get_server_health_option(test_config))
-
-    def test_has_http_cookie_persistence(self):
-        config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}}
-        self.assertTrue(cfg._has_http_cookie_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'SOURCE_IP'}}}
-        self.assertFalse(cfg._has_http_cookie_persistence(config))
-
-        config = {'vip': {'session_persistence': {}}}
-        self.assertFalse(cfg._has_http_cookie_persistence(config))
-
-    def test_get_session_persistence(self):
-        config = {'vip': {'session_persistence': {'type': 'SOURCE_IP'}}}
-        self.assertEqual(['stick-table type ip size 10k', 'stick on src'],
-                         cfg._get_session_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}},
-                  'members': []}
-        self.assertEqual([], cfg._get_session_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}}}
-        self.assertEqual([], cfg._get_session_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'HTTP_COOKIE'}},
-                  'members': [{'id': 'member1_id'}]}
-        self.assertEqual(['cookie SRV insert indirect nocache'],
-                         cfg._get_session_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'APP_COOKIE',
-                                                  'cookie_name': 'test'}}}
-        self.assertEqual(['appsession test len 56 timeout 3h'],
-                         cfg._get_session_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'APP_COOKIE'}}}
-        self.assertEqual([], cfg._get_session_persistence(config))
-
-        config = {'vip': {'session_persistence': {'type': 'UNSUPPORTED'}}}
-        self.assertEqual([], cfg._get_session_persistence(config))
-
-    def test_expand_expected_codes(self):
-        exp_codes = ''
-        self.assertEqual(set([]), cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200'
-        self.assertEqual(set(['200']), cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201'
-        self.assertEqual(set(['200', '201']),
-                         cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201,202'
-        self.assertEqual(set(['200', '201', '202']),
-                         cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200-202'
-        self.assertEqual(set(['200', '201', '202']),
-                         cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200-202, 205'
-        self.assertEqual(set(['200', '201', '202', '205']),
-                         cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201-203'
-        self.assertEqual(set(['200', '201', '202', '203']),
-                         cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201-203, 205'
-        self.assertEqual(set(['200', '201', '202', '203', '205']),
-                         cfg._expand_expected_codes(exp_codes))
-        exp_codes = '201-200, 205'
-        self.assertEqual(set(['205']), cfg._expand_expected_codes(exp_codes))
diff --git a/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py b/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py
deleted file mode 100644
index cf8e706..0000000
--- a/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py
+++ /dev/null
@@ -1,497 +0,0 @@
-# Copyright 2014 OpenStack Foundation
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import mock
-
-from neutron.tests import base
-
-from neutron_lbaas.common.cert_manager import cert_manager
-from neutron_lbaas.common.tls_utils import cert_parser
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.services.loadbalancer.drivers.haproxy import jinja_cfg
-from neutron_lbaas.tests.unit.services.loadbalancer.drivers.haproxy.\
-    sample_configs import sample_configs
-
-
-class TestHaproxyCfg(base.BaseTestCase):
-    def test_save_config(self):
-        with contextlib.nested(
-            mock.patch('neutron_lbaas.services.loadbalancer.'
-                       'drivers.haproxy.jinja_cfg.render_loadbalancer_obj'),
-            mock.patch('neutron.common.utils.replace_file')
-        ) as (r_t, replace):
-            r_t.return_value = 'fake_rendered_template'
-            lb = mock.Mock()
-            jinja_cfg.save_config('test_conf_path', lb, 'test_sock_path',
-                                  'nogroup',
-                                  'fake_state_path')
-            r_t.assert_called_once_with(lb,
-                                        'nogroup',
-                                        'test_sock_path',
-                                        'fake_state_path')
-            replace.assert_called_once_with('test_conf_path',
-                                            'fake_rendered_template')
-
-    def test_get_template(self):
-        template = jinja_cfg._get_template()
-        self.assertEqual('haproxy.loadbalancer.j2', template.name)
-
-    def test_render_template_tls_termination(self):
-        lb = sample_configs.sample_loadbalancer_tuple(
-            proto='TERMINATED_HTTPS', tls=True, sni=True)
-
-        fe = ("frontend sample_listener_id_1\n"
-              "    option tcplog\n"
-              "    redirect scheme https if !{ ssl_fc }\n"
-              "    maxconn 98\n"
-              "    option forwardfor\n"
-              "    bind 10.0.0.2:443"
-              " ssl crt /v2/sample_listener_id_1/fakeCNM.pem"
-              " crt /v2/sample_listener_id_1\n"
-              "    mode http\n"
-              "    default_backend sample_pool_id_1\n\n")
-        be = ("backend sample_pool_id_1\n"
-              "    mode http\n"
-              "    balance roundrobin\n"
-              "    cookie SRV insert indirect nocache\n"
-              "    timeout check 31\n"
-              "    option httpchk GET /index.html\n"
-              "    http-check expect rstatus %s\n"
-              "    server sample_member_id_1 10.0.0.99:82"
-              " weight 13 check inter 30s fall 3 cookie sample_member_id_1\n"
-              "    server sample_member_id_2 10.0.0.98:82"
-              " weight 13 check inter 30s fall 3 cookie "
-              "sample_member_id_2\n\n"
-              % sample_configs.PIPED_CODES)
-        with mock.patch('os.makedirs'):
-            with mock.patch('os.listdir'):
-                with mock.patch.object(jinja_cfg, 'n_utils'):
-                    with mock.patch.object(
-                            jinja_cfg, '_process_tls_certificates') as crt:
-                        crt.return_value = {
-                            'tls_cert': lb.listeners[0]
-                            .default_tls_container,
-                            'sni_certs': [lb.listeners[0]
-                                          .sni_containers[0].tls_container]}
-                        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-                            lb, 'nogroup',
-                            '/sock_path',
-                            '/v2')
-                        self.assertEqual(
-                            sample_configs.sample_base_expected_config(
-                                frontend=fe, backend=be),
-                            rendered_obj)
-
-    def test_render_template_tls_termination_no_sni(self):
-        lb = sample_configs.sample_loadbalancer_tuple(
-            proto='TERMINATED_HTTPS', tls=True)
-
-        fe = ("frontend sample_listener_id_1\n"
-              "    option tcplog\n"
-              "    redirect scheme https if !{ ssl_fc }\n"
-              "    maxconn 98\n"
-              "    option forwardfor\n"
-              "    bind 10.0.0.2:443"
-              " ssl crt /v2/sample_listener_id_1/fakeCNM.pem\n"
-              "    mode http\n"
-              "    default_backend sample_pool_id_1\n\n")
-        be = ("backend sample_pool_id_1\n"
-              "    mode http\n"
-              "    balance roundrobin\n"
-              "    cookie SRV insert indirect nocache\n"
-              "    timeout check 31\n"
-              "    option httpchk GET /index.html\n"
-              "    http-check expect rstatus %s\n"
-              "    server sample_member_id_1 10.0.0.99:82 "
-              "weight 13 check inter 30s fall 3 cookie sample_member_id_1\n"
-              "    server sample_member_id_2 10.0.0.98:82 "
-              "weight 13 check inter 30s fall 3 cookie sample_member_id_2\n\n"
-              % sample_configs.PIPED_CODES)
-        with mock.patch('os.makedirs'):
-            with mock.patch('neutron.common.utils.replace_file'):
-                with mock.patch('os.listdir'):
-                    with mock.patch.object(jinja_cfg, 'n_utils'):
-                        with mock.patch.object(
-                                jinja_cfg, '_process_tls_certificates') as crt:
-                            crt.return_value = {
-                                'tls_cert': lb.listeners[0]
-                                .default_tls_container,
-                                'sni_certs': []}
-                            rendered_obj = jinja_cfg.render_loadbalancer_obj(
-                                lb, 'nogroup',
-                                '/sock_path',
-                                '/v2')
-                            self.assertEqual(
-                                sample_configs.sample_base_expected_config(
-                                    frontend=fe, backend=be),
-                                rendered_obj)
-
-    def test_render_template_http(self):
-        be = ("backend sample_pool_id_1\n"
-              "    mode http\n"
-              "    balance roundrobin\n"
-              "    cookie SRV insert indirect nocache\n"
-              "    timeout check 31\n"
-              "    option httpchk GET /index.html\n"
-              "    http-check expect rstatus %s\n"
-              "    server sample_member_id_1 10.0.0.99:82 "
-              "weight 13 check inter 30s fall 3 cookie sample_member_id_1\n"
-              "    server sample_member_id_2 10.0.0.98:82 "
-              "weight 13 check inter 30s fall 3 cookie sample_member_id_2\n\n"
-              % sample_configs.PIPED_CODES)
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(
-            sample_configs.sample_base_expected_config(backend=be),
-            rendered_obj)
-
-    def test_render_template_https(self):
-        fe = ("frontend sample_listener_id_1\n"
-              "    option tcplog\n"
-              "    maxconn 98\n"
-              "    bind 10.0.0.2:443\n"
-              "    mode tcp\n"
-              "    default_backend sample_pool_id_1\n\n")
-        be = ("backend sample_pool_id_1\n"
-              "    mode tcp\n"
-              "    balance roundrobin\n"
-              "    cookie SRV insert indirect nocache\n"
-              "    timeout check 31\n"
-              "    option httpchk GET /index.html\n"
-              "    http-check expect rstatus %s\n"
-              "    option ssl-hello-chk\n"
-              "    server sample_member_id_1 10.0.0.99:82 "
-              "weight 13 check inter 30s fall 3 cookie sample_member_id_1\n"
-              "    server sample_member_id_2 10.0.0.98:82 "
-              "weight 13 check inter 30s fall 3 cookie sample_member_id_2\n\n"
-              % sample_configs.PIPED_CODES)
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(proto='HTTPS'),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(sample_configs.sample_base_expected_config(
-            frontend=fe, backend=be), rendered_obj)
-
-    def test_render_template_no_monitor_http(self):
-        be = ("backend sample_pool_id_1\n"
-              "    mode http\n"
-              "    balance roundrobin\n"
-              "    cookie SRV insert indirect nocache\n"
-              "    server sample_member_id_1 10.0.0.99:82 weight 13 "
-              "cookie sample_member_id_1\n"
-              "    server sample_member_id_2 10.0.0.98:82 weight 13 "
-              "cookie sample_member_id_2\n\n")
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(
-                proto='HTTP', monitor=False),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(sample_configs.sample_base_expected_config(
-            backend=be), rendered_obj)
-
-    def test_render_template_no_monitor_https(self):
-        fe = ("frontend sample_listener_id_1\n"
-              "    option tcplog\n"
-              "    maxconn 98\n"
-              "    bind 10.0.0.2:443\n"
-              "    mode tcp\n"
-              "    default_backend sample_pool_id_1\n\n")
-        be = ("backend sample_pool_id_1\n"
-              "    mode tcp\n"
-              "    balance roundrobin\n"
-              "    cookie SRV insert indirect nocache\n"
-              "    server sample_member_id_1 10.0.0.99:82 weight 13 "
-              "cookie sample_member_id_1\n"
-              "    server sample_member_id_2 10.0.0.98:82 weight 13 "
-              "cookie sample_member_id_2\n\n")
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(
-                proto='HTTPS', monitor=False),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(sample_configs.sample_base_expected_config(
-            frontend=fe, backend=be), rendered_obj)
-
-    def test_render_template_no_persistence_https(self):
-        fe = ("frontend sample_listener_id_1\n"
-              "    option tcplog\n"
-              "    maxconn 98\n"
-              "    bind 10.0.0.2:443\n"
-              "    mode tcp\n"
-              "    default_backend sample_pool_id_1\n\n")
-        be = ("backend sample_pool_id_1\n"
-              "    mode tcp\n"
-              "    balance roundrobin\n"
-              "    server sample_member_id_1 10.0.0.99:82 weight 13\n"
-              "    server sample_member_id_2 10.0.0.98:82 weight 13\n\n")
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(
-                proto='HTTPS', monitor=False, persistence=False),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(sample_configs.sample_base_expected_config(
-            frontend=fe, backend=be), rendered_obj)
-
-    def test_render_template_no_persistence_http(self):
-        be = ("backend sample_pool_id_1\n"
-              "    mode http\n"
-              "    balance roundrobin\n"
-              "    server sample_member_id_1 10.0.0.99:82 weight 13\n"
-              "    server sample_member_id_2 10.0.0.98:82 weight 13\n\n")
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(
-                proto='HTTP', monitor=False, persistence=False),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(sample_configs.sample_base_expected_config(
-            backend=be), rendered_obj)
-
-    def test_render_template_sourceip_persistence(self):
-        be = ("backend sample_pool_id_1\n"
-              "    mode http\n"
-              "    balance roundrobin\n"
-              "    stick-table type ip size 10k\n"
-              "    stick on src\n"
-              "    timeout check 31\n"
-              "    option httpchk GET /index.html\n"
-              "    http-check expect rstatus %s\n"
-              "    server sample_member_id_1 10.0.0.99:82 "
-              "weight 13 check inter 30s fall 3\n"
-              "    server sample_member_id_2 10.0.0.98:82 "
-              "weight 13 check inter 30s fall 3\n\n"
-              % sample_configs.PIPED_CODES)
-        rendered_obj = jinja_cfg.render_loadbalancer_obj(
-            sample_configs.sample_loadbalancer_tuple(
-                persistence_type='SOURCE_IP'),
-            'nogroup', '/sock_path', '/v2')
-        self.assertEqual(
-            sample_configs.sample_base_expected_config(backend=be),
-            rendered_obj)
-
-    def test_render_template_appsession_persistence(self):
-        with mock.patch('os.makedirs') as md:
-            with mock.patch.object(jinja_cfg, 'n_utils'):
-                md.return_value = '/data/dirs/'
-                be = ("backend sample_pool_id_1\n"
-                      "    mode http\n"
-                      "    balance roundrobin\n"
-                      "    appsession APP_COOKIE len 56 timeout 3h\n"
-                      "    timeout check 31\n"
-                      "    option httpchk GET /index.html\n"
-                      "    http-check expect rstatus %s\n"
-                      "    server sample_member_id_1 10.0.0.99:82 "
-                      "weight 13 check inter 30s fall 3\n"
-                      "    server sample_member_id_2 10.0.0.98:82 "
-                      "weight 13 check inter 30s fall 3\n\n"
-                      % sample_configs.PIPED_CODES)
-                rendered_obj = jinja_cfg.render_loadbalancer_obj(
-                    sample_configs.sample_loadbalancer_tuple(
-                        persistence_type='APP_COOKIE'),
-                    'nogroup', '/sock_path',
-                    '/v2')
-                self.assertEqual(
-                    sample_configs.sample_base_expected_config(backend=be),
-                    rendered_obj)
-
-    def test_retrieve_crt_path(self):
-        with mock.patch('os.makedirs'):
-            with mock.patch('os.path.isdir') as isdir:
-                with mock.patch.object(jinja_cfg, '_retrieve_crt_path') as rcp:
-                    isdir.return_value = True
-                    rcp.return_value = '/v2/loadbalancers/lb_id_1/' \
-                                       'cont_id_1.pem'
-                    ret = jinja_cfg._retrieve_crt_path(
-                        '/v2/loadbalancers', 'lb_id_1', 'cont_id_1')
-                    self.assertEqual(
-                        '/v2/loadbalancers/lb_id_1/cont_id_1.pem', ret)
-
-    def test_store_listener_crt(self):
-        l = sample_configs.sample_listener_tuple(tls=True, sni=True)
-        with mock.patch('os.makedirs'):
-            with mock.patch('neutron.common.utils.replace_file'):
-                    ret = jinja_cfg._store_listener_crt(
-                        '/v2/loadbalancers', l, l.default_tls_container)
-                    self.assertEqual(
-                        '/v2/loadbalancers/sample_listener_id_1/fakeCNM.pem',
-                        ret)
-
-    def test_process_tls_certificates(self):
-        sl = sample_configs.sample_listener_tuple(tls=True, sni=True)
-        tls = data_models.TLSContainer(primary_cn='fakeCN',
-                                       certificate='imaCert',
-                                       private_key='imaPrivateKey',
-                                       intermediates=['imainter1',
-                                                      'imainter2'])
-        cert = mock.Mock(spec=cert_manager.Cert)
-        cert.get_private_key.return_value = tls.private_key
-        cert.get_certificate.return_value = tls.certificate
-        cert.get_intermediates.return_value = tls.intermediates
-
-        with contextlib.nested(
-            mock.patch.object(jinja_cfg, '_map_cert_tls_container'),
-            mock.patch.object(jinja_cfg, '_store_listener_crt'),
-            mock.patch.object(cert_parser, 'get_host_names'),
-            mock.patch.object(jinja_cfg, 'CERT_MANAGER_PLUGIN')
-        ) as (map, store_cert, get_host_names, cert_mgr):
-            map.return_value = tls
-            cert_mgr_mock = mock.Mock(spec=cert_manager.CertManager)
-            cert_mgr_mock.get_cert.return_value = cert
-            cert_mgr.CertManager.return_value = cert_mgr_mock
-            get_host_names.return_value = {'cn': 'fakeCN'}
-            jinja_cfg._process_tls_certificates(sl)
-
-            # Ensure get_cert is called three times
-            calls_certs = [
-                mock.call(sl.default_tls_container.id),
-                mock.call('cont_id_2'),
-                mock.call('cont_id_3')]
-            cert_mgr_mock.get_cert.call_args_list == calls_certs
-
-            # Ensure store_cert is called three times
-            calls_ac = [mock.call('/v2/',
-                                  'sample_listener_id_1',
-                                  tls),
-                        mock.call('/v2/',
-                                  'sample_listener_id_1',
-                                  tls),
-                        mock.call('/v2/',
-                                  'sample_listener_id_1',
-                                  tls)]
-            store_cert.call_args_list == calls_ac
-
-    def test_get_primary_cn(self):
-        cert = mock.MagicMock()
-
-        with mock.patch.object(cert_parser, 'get_host_names') as cp:
-            cp.return_value = {'cn': 'fakeCN'}
-            cn = jinja_cfg._get_primary_cn(cert.get_certificate())
-            self.assertEqual('fakeCN', cn)
-
-    def test_map_cert_tls_container(self):
-        tls = data_models.TLSContainer(primary_cn='fakeCN',
-                                       certificate='imaCert',
-                                       private_key='imaPrivateKey',
-                                       intermediates=['imainter1',
-                                                      'imainter2'])
-        cert = mock.MagicMock()
-        cert.get_private_key.return_value = tls.private_key
-        cert.get_certificate.return_value = tls.certificate
-        cert.get_intermediates.return_value = tls.intermediates
-        cert.get_private_key_passphrase.return_value = 'passphrase'
-        with mock.patch.object(cert_parser, 'get_host_names') as cp:
-            with mock.patch.object(cert_parser, 'dump_private_key') as dp:
-                cp.return_value = {'cn': 'fakeCN'}
-                dp.return_value = 'imaPrivateKey'
-                self.assertEqual(tls.primary_cn,
-                                 jinja_cfg._map_cert_tls_container(
-                                     cert).primary_cn)
-                self.assertEqual(tls.certificate,
-                                 jinja_cfg._map_cert_tls_container(
-                                     cert).certificate)
-                self.assertEqual(tls.private_key,
-                                 jinja_cfg._map_cert_tls_container(
-                                     cert).private_key)
-                self.assertEqual(tls.intermediates,
-                                 jinja_cfg._map_cert_tls_container(
-                                     cert).intermediates)
-
-    def test_build_pem(self):
-        expected = 'imainter\nimainter2\nimacert\nimakey'
-        tls_tupe = sample_configs.sample_tls_container_tuple(
-            certificate='imacert', private_key='imakey',
-            intermediates=['imainter', 'imainter2'])
-        self.assertEqual(expected, jinja_cfg._build_pem(tls_tupe))
-
-    def test_transform_session_persistence(self):
-        in_persistence = sample_configs.sample_session_persistence_tuple()
-        ret = jinja_cfg._transform_session_persistence(in_persistence)
-        self.assertEqual(sample_configs.RET_PERSISTENCE, ret)
-
-    def test_transform_health_monitor(self):
-        in_persistence = sample_configs.sample_health_monitor_tuple()
-        ret = jinja_cfg._transform_health_monitor(in_persistence)
-        self.assertEqual(sample_configs.RET_MONITOR, ret)
-
-    def test_transform_member(self):
-        in_member = sample_configs.sample_member_tuple('sample_member_id_1',
-                                                       '10.0.0.99')
-        ret = jinja_cfg._transform_member(in_member)
-        self.assertEqual(sample_configs.RET_MEMBER_1, ret)
-
-    def test_transform_pool(self):
-        in_pool = sample_configs.sample_pool_tuple()
-        ret = jinja_cfg._transform_pool(in_pool)
-        self.assertEqual(sample_configs.RET_POOL, ret)
-
-    def test_transform_pool_admin_state_down(self):
-        in_pool = sample_configs.sample_pool_tuple(hm_admin_state=False)
-        ret = jinja_cfg._transform_pool(in_pool)
-        result = sample_configs.RET_POOL
-        result['health_monitor'] = ''
-        self.assertEqual(result, ret)
-
-    def test_transform_listener(self):
-        in_listener = sample_configs.sample_listener_tuple()
-        ret = jinja_cfg._transform_listener(in_listener, '/v2')
-        self.assertEqual(sample_configs.RET_LISTENER, ret)
-
-    def test_transform_loadbalancer(self):
-        in_lb = sample_configs.sample_loadbalancer_tuple()
-        ret = jinja_cfg._transform_loadbalancer(in_lb, '/v2')
-        self.assertEqual(sample_configs.RET_LB, ret)
-
-    def test_include_member(self):
-        ret = jinja_cfg._include_member(
-            sample_configs.sample_member_tuple('sample_member_id_1',
-                                               '10.0.0.99'))
-        self.assertTrue(ret)
-
-    def test_include_member_invalid_status(self):
-        ret = jinja_cfg._include_member(
-            sample_configs.sample_member_tuple('sample_member_id_1',
-                                               '10.0.0.99', status='PENDING'))
-        self.assertFalse(ret)
-
-    def test_include_member_invalid_admin_state(self):
-        ret = jinja_cfg._include_member(
-            sample_configs.sample_member_tuple('sample_member_id_1',
-                                               '10.0.0.99',
-                                               admin_state_up=False))
-        self.assertFalse(ret)
-
-    def test_expand_expected_codes(self):
-        exp_codes = ''
-        self.assertEqual(set([]), jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200'
-        self.assertEqual(set(['200']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201'
-        self.assertEqual(set(['200', '201']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201,202'
-        self.assertEqual(set(['200', '201', '202']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200-202'
-        self.assertEqual(set(['200', '201', '202']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200-202, 205'
-        self.assertEqual(set(['200', '201', '202', '205']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201-203'
-        self.assertEqual(set(['200', '201', '202', '203']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '200, 201-203, 205'
-        self.assertEqual(set(['200', '201', '202', '203', '205']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
-        exp_codes = '201-200, 205'
-        self.assertEqual(set(['205']),
-                         jinja_cfg._expand_expected_codes(exp_codes))
diff --git a/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py b/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py
deleted file mode 100644
index 7ede761..0000000
--- a/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py
+++ /dev/null
@@ -1,596 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-
-import mock
-from neutron_lib import exceptions
-import six
-
-from neutron_lbaas.services.loadbalancer.drivers.haproxy \
-    import namespace_driver
-from neutron_lbaas.tests import base
-
-
-class TestHaproxyNSDriver(base.BaseTestCase):
-    def setUp(self):
-        super(TestHaproxyNSDriver, self).setUp()
-
-        conf = mock.Mock()
-        conf.haproxy.loadbalancer_state_path = '/the/path'
-        conf.interface_driver = 'intdriver'
-        conf.haproxy.user_group = 'test_group'
-        conf.haproxy.send_gratuitous_arp = 3
-        self.conf = conf
-        self.rpc_mock = mock.Mock()
-        with mock.patch(
-                'neutron.common.utils.load_class_by_alias_or_classname'):
-            self.driver = namespace_driver.HaproxyNSDriver(
-                conf,
-                self.rpc_mock
-            )
-        self.vif_driver = mock.Mock()
-        self.driver.vif_driver = self.vif_driver
-
-        self.fake_config = {
-            'pool': {'id': 'pool_id', 'status': 'ACTIVE',
-                     'admin_state_up': True},
-            'vip': {'id': 'vip_id', 'port': {'id': 'port_id'},
-                    'address': '10.0.0.2',
-                    'status': 'ACTIVE', 'admin_state_up': True}
-        }
-
-    def _ip_mock_call(self, ns=None):
-        kwargs = {}
-        if ns:
-            kwargs['namespace'] = ns
-        return mock.call(**kwargs)
-
-    def test_get_name(self):
-        self.assertEqual(namespace_driver.DRIVER_NAME, self.driver.get_name())
-
-    def test_create(self):
-        with mock.patch.object(self.driver, '_plug') as plug:
-            with mock.patch.object(self.driver, '_spawn') as spawn:
-                self.driver.create(self.fake_config)
-
-                plug.assert_called_once_with(
-                    'qlbaas-pool_id', {'id': 'port_id'}, '10.0.0.2'
-                )
-                spawn.assert_called_once_with(self.fake_config)
-
-    def test_update(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, '_get_state_file_path'),
-            mock.patch.object(self.driver, '_spawn'),
-            mock.patch.object(six.moves.builtins, 'open')
-        ) as (gsp, spawn, mock_open):
-            mock_open.return_value = ['5']
-
-            self.driver.update(self.fake_config)
-
-            mock_open.assert_called_once_with(gsp.return_value, 'r')
-            spawn.assert_called_once_with(self.fake_config, ['-sf', '5'])
-
-    def test_spawn(self):
-        with contextlib.nested(
-            mock.patch.object(namespace_driver.hacfg, 'save_config'),
-            mock.patch.object(self.driver, '_get_state_file_path'),
-            mock.patch('neutron.agent.linux.ip_lib.IPWrapper')
-        ) as (mock_save, gsp, ip_wrap):
-            gsp.side_effect = lambda x, y: y
-
-            self.driver._spawn(self.fake_config)
-
-            mock_save.assert_called_once_with('conf', self.fake_config,
-                                              'sock', 'test_group')
-            cmd = ['haproxy', '-f', 'conf', '-p', 'pid']
-            ip_wrap.assert_has_calls([
-                self._ip_mock_call('qlbaas-pool_id'),
-                mock.call().netns.execute(cmd)
-            ])
-
-    def test_undeploy_instance(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, '_get_state_file_path'),
-            mock.patch.object(namespace_driver, 'kill_pids_in_file'),
-            mock.patch.object(self.driver, '_unplug'),
-            mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-            mock.patch('os.path.isdir'),
-            mock.patch('shutil.rmtree')
-        ) as (gsp, kill, unplug, ip_wrap, isdir, rmtree):
-            gsp.side_effect = lambda x, y: '/pool/' + y
-
-            self.driver.pool_to_port_id['pool_id'] = 'port_id'
-            isdir.return_value = True
-
-            self.driver.undeploy_instance('pool_id', delete_namespace=True)
-
-            kill.assert_called_once_with('/pool/pid')
-            unplug.assert_called_once_with('qlbaas-pool_id', 'port_id')
-            isdir.assert_called_once_with('/pool')
-            rmtree.assert_called_once_with('/pool')
-            ip_wrap.assert_has_calls([
-                self._ip_mock_call('qlbaas-pool_id'),
-                mock.call().garbage_collect_namespace()
-            ])
-
-    def test_undeploy_instance_with_ns_cleanup(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, '_get_state_file_path'),
-            mock.patch.object(self.driver, 'vif_driver'),
-            mock.patch.object(namespace_driver, 'kill_pids_in_file'),
-            mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-            mock.patch('os.path.isdir'),
-            mock.patch('shutil.rmtree')
-        ) as (gsp, vif, kill, ip_wrap, isdir, rmtree):
-            device = mock.Mock()
-            device_name = 'port_device'
-            device.name = device_name
-            ip_wrap.return_value.get_devices.return_value = [device]
-
-            self.driver.undeploy_instance('pool_id', cleanup_namespace=True)
-            vif.unplug.assert_called_once_with(device_name,
-                                               namespace='qlbaas-pool_id')
-
-    def test_remove_orphans(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, 'exists'),
-            mock.patch.object(self.driver, 'undeploy_instance'),
-            mock.patch('os.listdir'),
-            mock.patch('os.path.exists')
-        ) as (exists, undeploy, listdir, path_exists):
-            known = ['known1', 'known2']
-            unknown = ['unknown1', 'unknown2']
-            listdir.return_value = known + unknown
-            exists.side_effect = lambda x: x == 'unknown2'
-
-            self.driver.remove_orphans(known)
-
-            undeploy.assert_called_once_with('unknown2',
-                                             cleanup_namespace=True)
-
-    def test_exists(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, '_get_state_file_path'),
-            mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-            mock.patch('socket.socket'),
-            mock.patch('os.path.exists'),
-        ) as (gsp, ip_wrap, socket, path_exists):
-            gsp.side_effect = lambda x, y, z: '/pool/' + y
-
-            ip_wrap.return_value.netns.exists.return_value = True
-            path_exists.return_value = True
-
-            self.driver.exists('pool_id')
-
-            ip_wrap.assert_has_calls([
-                self._ip_mock_call(),
-                mock.call().netns.exists('qlbaas-pool_id')
-            ])
-
-            self.assertTrue(self.driver.exists('pool_id'))
-
-    def test_get_stats(self):
-        raw_stats = ('# pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,bout,'
-                     'dreq,dresp,ereq,econ,eresp,wretr,wredis,status,weight,'
-                     'act,bck,chkfail,chkdown,lastchg,downtime,qlimit,pid,iid,'
-                     'sid,throttle,lbtot,tracked,type,rate,rate_lim,rate_max,'
-                     'check_status,check_code,check_duration,hrsp_1xx,'
-                     'hrsp_2xx,hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,'
-                     'req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,\n'
-                     '8e271901-69ed-403e-a59b-f53cf77ef208,BACKEND,1,2,3,4,0,'
-                     '10,7764,2365,0,0,,0,0,0,0,UP,1,1,0,,0,103780,0,,1,2,0,,0'
-                     ',,1,0,,0,,,,0,0,0,0,0,0,,,,,0,0,\n\n'
-                     'a557019b-dc07-4688-9af4-f5cf02bb6d4b,'
-                     '32a6c2a3-420a-44c3-955d-86bd2fc6871e,0,0,0,1,,7,1120,'
-                     '224,,0,,0,0,0,0,UP,1,1,0,0,1,2623,303,,1,2,1,,7,,2,0,,'
-                     '1,L7OK,200,98,0,7,0,0,0,0,0,,,,0,0,\n'
-                     'a557019b-dc07-4688-9af4-f5cf02bb6d4b,'
-                     'd9aea044-8867-4e80-9875-16fb808fa0f9,0,0,0,2,,12,0,0,,'
-                     '0,,0,0,8,4,DOWN,1,1,0,9,2,308,675,,1,2,2,,4,,2,0,,2,'
-                     'L4CON,,2999,0,0,0,0,0,0,0,,,,0,0,\n')
-        raw_stats_empty = ('# pxname,svname,qcur,qmax,scur,smax,slim,stot,bin,'
-                           'bout,dreq,dresp,ereq,econ,eresp,wretr,wredis,'
-                           'status,weight,act,bck,chkfail,chkdown,lastchg,'
-                           'downtime,qlimit,pid,iid,sid,throttle,lbtot,'
-                           'tracked,type,rate,rate_lim,rate_max,check_status,'
-                           'check_code,check_duration,hrsp_1xx,hrsp_2xx,'
-                           'hrsp_3xx,hrsp_4xx,hrsp_5xx,hrsp_other,hanafail,'
-                           'req_rate,req_rate_max,req_tot,cli_abrt,srv_abrt,'
-                           '\n')
-        with contextlib.nested(
-                mock.patch.object(self.driver, '_get_state_file_path'),
-                mock.patch('socket.socket'),
-                mock.patch('os.path.exists'),
-        ) as (gsp, socket, path_exists):
-            gsp.side_effect = lambda x, y, z: '/pool/' + y
-            path_exists.return_value = True
-            socket.return_value = socket
-            socket.recv.return_value = raw_stats
-
-            exp_stats = {'connection_errors': '0',
-                         'active_connections': '3',
-                         'current_sessions': '3',
-                         'bytes_in': '7764',
-                         'max_connections': '4',
-                         'max_sessions': '4',
-                         'bytes_out': '2365',
-                         'response_errors': '0',
-                         'total_sessions': '10',
-                         'total_connections': '10',
-                         'members': {
-                             '32a6c2a3-420a-44c3-955d-86bd2fc6871e': {
-                                 'status': 'ACTIVE',
-                                 'health': 'L7OK',
-                                 'failed_checks': '0'
-                             },
-                             'd9aea044-8867-4e80-9875-16fb808fa0f9': {
-                                 'status': 'INACTIVE',
-                                 'health': 'L4CON',
-                                 'failed_checks': '9'
-                             }
-                         }
-                         }
-            stats = self.driver.get_stats('pool_id')
-            self.assertEqual(exp_stats, stats)
-
-            socket.recv.return_value = raw_stats_empty
-            self.assertEqual({'members': {}}, self.driver.get_stats('pool_id'))
-
-            path_exists.return_value = False
-            socket.reset_mock()
-            self.assertEqual({}, self.driver.get_stats('pool_id'))
-            self.assertFalse(socket.called)
-
-    def test_plug(self):
-        test_port = {'id': 'port_id',
-                     'network_id': 'net_id',
-                     'mac_address': 'mac_addr',
-                     'fixed_ips': [{'ip_address': '10.0.0.2',
-                                    'subnet': {'cidr': '10.0.0.0/24',
-                                               'gateway_ip': '10.0.0.1'}}]}
-        test_address = '10.0.0.2'
-        with contextlib.nested(
-                mock.patch('neutron.agent.linux.ip_lib.device_exists'),
-                mock.patch('netaddr.IPNetwork'),
-                mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-        ) as (dev_exists, ip_net, ip_wrap):
-            self.vif_driver.get_device_name.return_value = 'test_interface'
-            dev_exists.return_value = False
-            ip_net.return_value = ip_net
-            ip_net.prefixlen = 24
-
-            self.driver._plug('test_ns', test_port, test_address)
-            self.rpc_mock.plug_vip_port.assert_called_once_with(
-                test_port['id'])
-            self.assertTrue(dev_exists.called)
-            self.vif_driver.plug.assert_called_once_with('net_id', 'port_id',
-                                                         'test_interface',
-                                                         'mac_addr',
-                                                         namespace='test_ns')
-            self.vif_driver.init_l3.assert_called_once_with(
-                'test_interface',
-                ['10.0.0.2/24'],
-                namespace='test_ns'
-            )
-            cmd = ['route', 'add', 'default', 'gw', '10.0.0.1']
-            cmd_arping = ['arping', '-U', '-I',
-                          'test_interface', '-c',
-                          self.conf.haproxy.send_gratuitous_arp, '10.0.0.2']
-            ip_wrap.assert_has_calls([
-                self._ip_mock_call('test_ns'),
-                mock.call().netns.execute(cmd, check_exit_code=False),
-                mock.call().netns.execute(cmd_arping, check_exit_code=False),
-            ])
-
-            dev_exists.return_value = True
-            self.assertRaises(exceptions.PreexistingDeviceFailure,
-                              self.driver._plug, 'test_ns', test_port,
-                              test_address, False)
-
-    def test_plug_not_send_gratuitous_arp(self):
-        self.conf.haproxy.send_gratuitous_arp = 0
-        test_port = {'id': 'port_id',
-                     'network_id': 'net_id',
-                     'mac_address': 'mac_addr',
-                     'fixed_ips': [{'ip_address': '10.0.0.2',
-                                    'subnet': {'cidr': '10.0.0.0/24',
-                                               'gateway_ip': '10.0.0.1'}}]}
-        test_address = '10.0.0.2'
-        with contextlib.nested(
-                mock.patch('neutron.agent.linux.ip_lib.device_exists'),
-                mock.patch('netaddr.IPNetwork'),
-                mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-        ) as (dev_exists, ip_net, ip_wrap):
-            self.vif_driver.get_device_name.return_value = 'test_interface'
-            dev_exists.return_value = False
-            ip_net.return_value = ip_net
-            ip_net.prefixlen = 24
-
-            self.driver._plug('test_ns', test_port, test_address)
-            cmd = ['route', 'add', 'default', 'gw', '10.0.0.1']
-            expected = [
-                self._ip_mock_call('test_ns'),
-                mock.call().netns.execute(cmd, check_exit_code=False)]
-            self.assertEqual(expected, ip_wrap.mock_calls)
-
-    def test_plug_no_gw(self):
-        test_port = {'id': 'port_id',
-                     'network_id': 'net_id',
-                     'mac_address': 'mac_addr',
-                     'fixed_ips': [{'ip_address': '10.0.0.2',
-                                    'subnet': {'cidr': '10.0.0.0/24'}}]}
-        test_address = '10.0.0.2'
-        with contextlib.nested(
-                mock.patch('neutron.agent.linux.ip_lib.device_exists'),
-                mock.patch('netaddr.IPNetwork'),
-                mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-        ) as (dev_exists, ip_net, ip_wrap):
-            self.vif_driver.get_device_name.return_value = 'test_interface'
-            dev_exists.return_value = False
-            ip_net.return_value = ip_net
-            ip_net.prefixlen = 24
-
-            self.driver._plug('test_ns', test_port, test_address)
-            self.rpc_mock.plug_vip_port.assert_called_once_with(
-                test_port['id'])
-            self.assertTrue(dev_exists.called)
-            self.vif_driver.plug.assert_called_once_with('net_id', 'port_id',
-                                                         'test_interface',
-                                                         'mac_addr',
-                                                         namespace='test_ns')
-            self.vif_driver.init_l3.assert_called_once_with(
-                'test_interface',
-                ['10.0.0.2/24'],
-                namespace='test_ns'
-            )
-            self.assertFalse(ip_wrap.called)
-            dev_exists.return_value = True
-            self.assertRaises(exceptions.PreexistingDeviceFailure,
-                              self.driver._plug, 'test_ns', test_port,
-                              test_address, False)
-
-    def test_plug_gw_in_host_routes(self):
-        test_port = {'id': 'port_id',
-                     'network_id': 'net_id',
-                     'mac_address': 'mac_addr',
-                     'fixed_ips': [{'ip_address': '10.0.0.2',
-                                    'subnet': {'cidr': '10.0.0.0/24',
-                                               'host_routes':
-                                               [{'destination': '0.0.0.0/0',
-                                                 'nexthop': '10.0.0.1'}]}}]}
-        test_address = '10.0.0.2'
-        with contextlib.nested(
-                mock.patch('neutron.agent.linux.ip_lib.device_exists'),
-                mock.patch('netaddr.IPNetwork'),
-                mock.patch('neutron.agent.linux.ip_lib.IPWrapper'),
-        ) as (dev_exists, ip_net, ip_wrap):
-            self.vif_driver.get_device_name.return_value = 'test_interface'
-            dev_exists.return_value = False
-            ip_net.return_value = ip_net
-            ip_net.prefixlen = 24
-
-            self.driver._plug('test_ns', test_port, test_address)
-            self.rpc_mock.plug_vip_port.assert_called_once_with(
-                test_port['id'])
-            self.assertTrue(dev_exists.called)
-            self.vif_driver.plug.assert_called_once_with('net_id', 'port_id',
-                                                         'test_interface',
-                                                         'mac_addr',
-                                                         namespace='test_ns')
-            self.vif_driver.init_l3.assert_called_once_with(
-                'test_interface',
-                ['10.0.0.2/24'],
-                namespace='test_ns'
-            )
-            cmd = ['route', 'add', 'default', 'gw', '10.0.0.1']
-            ip_wrap.assert_has_calls([
-                self._ip_mock_call('test_ns'),
-                mock.call().netns.execute(cmd, check_exit_code=False),
-            ])
-
-    def test_unplug(self):
-        self.vif_driver.get_device_name.return_value = 'test_interface'
-
-        self.driver._unplug('test_ns', 'port_id')
-        self.rpc_mock.unplug_vip_port.assert_called_once_with('port_id')
-        self.vif_driver.unplug('test_interface', namespace='test_ns')
-
-    def test_kill_pids_in_file(self):
-        with contextlib.nested(
-            mock.patch('os.path.exists'),
-            mock.patch.object(six.moves.builtins, 'open'),
-            mock.patch('neutron.agent.linux.utils.execute'),
-            mock.patch.object(namespace_driver.LOG, 'exception'),
-        ) as (path_exists, mock_open, mock_execute, mock_log):
-            file_mock = mock.MagicMock()
-            mock_open.return_value = file_mock
-            file_mock.__enter__.return_value = file_mock
-            file_mock.__iter__.return_value = iter(['123'])
-
-            path_exists.return_value = False
-            namespace_driver.kill_pids_in_file('test_path')
-            path_exists.assert_called_once_with('test_path')
-            self.assertFalse(mock_open.called)
-            self.assertFalse(mock_execute.called)
-
-            path_exists.return_value = True
-            mock_execute.side_effect = RuntimeError
-            namespace_driver.kill_pids_in_file('test_path')
-            self.assertTrue(mock_log.called)
-            mock_execute.assert_called_once_with(
-                ['kill', '-9', '123'], run_as_root=True)
-
-    def test_get_state_file_path(self):
-        with mock.patch('os.makedirs') as mkdir:
-            path = self.driver._get_state_file_path('pool_id', 'conf')
-            self.assertEqual('/the/path/pool_id/conf', path)
-            mkdir.assert_called_once_with('/the/path/pool_id', 0o755)
-
-    def test_deploy_instance(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            with mock.patch.object(self.driver, 'update') as update:
-                self.driver.deploy_instance(self.fake_config)
-                exists.assert_called_once_with(self.fake_config['pool']['id'])
-                update.assert_called_once_with(self.fake_config)
-
-    def test_deploy_instance_non_existing(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            with mock.patch.object(self.driver, 'create') as create:
-                exists.return_value = False
-                self.driver.deploy_instance(self.fake_config)
-                exists.assert_called_once_with(self.fake_config['pool']['id'])
-                create.assert_called_once_with(self.fake_config)
-
-    def test_deploy_instance_vip_status_non_active(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            self.fake_config['vip']['status'] = 'NON_ACTIVE'
-            self.driver.deploy_instance(self.fake_config)
-            self.assertFalse(exists.called)
-
-    def test_deploy_instance_vip_admin_state_down(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            self.fake_config['vip']['admin_state_up'] = False
-            self.driver.deploy_instance(self.fake_config)
-            self.assertFalse(exists.called)
-
-    def test_deploy_instance_no_vip(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            del self.fake_config['vip']
-            self.driver.deploy_instance(self.fake_config)
-            self.assertFalse(exists.called)
-
-    def test_deploy_instance_pool_status_non_active(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            self.fake_config['pool']['status'] = 'NON_ACTIVE'
-            self.driver.deploy_instance(self.fake_config)
-            self.assertFalse(exists.called)
-
-    def test_deploy_instance_pool_admin_state_down(self):
-        with mock.patch.object(self.driver, 'exists') as exists:
-            with mock.patch.object(self.driver, 'update') as update:
-                self.fake_config['pool']['admin_state_up'] = False
-                self.driver.deploy_instance(self.fake_config)
-                exists.assert_called_once_with(self.fake_config['pool']['id'])
-                update.assert_called_once_with(self.fake_config)
-
-    def test_refresh_device(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, 'deploy_instance'),
-            mock.patch.object(self.driver, 'undeploy_instance')
-        ) as (deploy, undeploy):
-            pool_id = 'pool_id1'
-            self.driver._refresh_device(pool_id)
-            self.rpc_mock.get_logical_device.assert_called_once_with(pool_id)
-            deploy.assert_called_once_with(
-                self.rpc_mock.get_logical_device.return_value)
-            self.assertFalse(undeploy.called)
-
-    def test_refresh_device_not_deployed(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, 'deploy_instance'),
-            mock.patch.object(self.driver, 'exists'),
-            mock.patch.object(self.driver, 'undeploy_instance')
-        ) as (deploy, exists, undeploy):
-            pool_id = 'pool_id1'
-            deploy.return_value = False
-            exists.return_value = True
-            self.driver._refresh_device(pool_id)
-            undeploy.assert_called_once_with(pool_id)
-
-    def test_refresh_device_non_existing(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, 'deploy_instance'),
-            mock.patch.object(self.driver, 'exists'),
-            mock.patch.object(self.driver, 'undeploy_instance')
-        ) as (deploy, exists, undeploy):
-            pool_id = 'pool_id1'
-            deploy.return_value = False
-            exists.return_value = False
-            self.driver._refresh_device(pool_id)
-            self.assertFalse(undeploy.called)
-
-    def test_create_vip(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.create_vip({'pool_id': '1'})
-            refresh.assert_called_once_with('1')
-
-    def test_update_vip(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.update_vip({}, {'pool_id': '1'})
-            refresh.assert_called_once_with('1')
-
-    def test_delete_vip(self):
-        with mock.patch.object(self.driver, 'undeploy_instance') as undeploy:
-            self.driver.delete_vip({'pool_id': '1'})
-            undeploy.assert_called_once_with('1')
-
-    def test_create_pool(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.create_pool({'id': '1'})
-            self.assertFalse(refresh.called)
-
-    def test_update_pool(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.update_pool({}, {'id': '1'})
-            refresh.assert_called_once_with('1')
-
-    def test_delete_pool_existing(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, 'undeploy_instance'),
-            mock.patch.object(self.driver, 'exists'),
-        ) as (undeploy, exists):
-            exists.return_value = True
-            self.driver.delete_pool({'id': '1'})
-            undeploy.assert_called_once_with('1', delete_namespace=True)
-
-    def test_delete_pool_non_existing(self):
-        with contextlib.nested(
-            mock.patch.object(self.driver, 'undeploy_instance'),
-            mock.patch.object(self.driver, 'exists'),
-        ) as (undeploy, exists):
-            exists.return_value = False
-            self.driver.delete_pool({'id': '1'})
-            self.assertFalse(undeploy.called)
-
-    def test_create_member(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.create_member({'pool_id': '1'})
-            refresh.assert_called_once_with('1')
-
-    def test_update_member(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.update_member({}, {'pool_id': '1'})
-            refresh.assert_called_once_with('1')
-
-    def test_delete_member(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.delete_member({'pool_id': '1'})
-            refresh.assert_called_once_with('1')
-
-    def test_create_pool_health_monitor(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.create_pool_health_monitor('', '1')
-            refresh.assert_called_once_with('1')
-
-    def test_update_pool_health_monitor(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.update_pool_health_monitor('', '', '1')
-            refresh.assert_called_once_with('1')
-
-    def test_delete_pool_health_monitor(self):
-        with mock.patch.object(self.driver, '_refresh_device') as refresh:
-            self.driver.delete_pool_health_monitor('', '1')
-            refresh.assert_called_once_with('1')
diff --git a/tests/unit/services/loadbalancer/drivers/netscaler/__init__.py b/tests/unit/services/loadbalancer/drivers/netscaler/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py b/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py
deleted file mode 100644
index 3f29dfd..0000000
--- a/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py
+++ /dev/null
@@ -1,215 +0,0 @@
-# Copyright 2014 Citrix Systems
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import mock
-from neutron.tests.unit import testlib_api
-import requests
-
-from neutron_lbaas.services.loadbalancer.drivers.netscaler import ncc_client
-from neutron_lbaas.services.loadbalancer.drivers.netscaler \
-    import netscaler_driver
-
-NCC_CLIENT_CLASS = ('neutron_lbaas.services.loadbalancer.drivers'
-                    '.netscaler.ncc_client.NSClient')
-
-TESTURI_SCHEME = 'http'
-TESTURI_HOSTNAME = '1.1.1.1'
-TESTURI_PORT = 4433
-TESTURI_PATH = '/ncc_service/1.0'
-TESTURI = '%s://%s:%s%s' % (TESTURI_SCHEME, TESTURI_HOSTNAME,
-                            TESTURI_PORT, TESTURI_PATH)
-TEST_USERNAME = 'user211'
-TEST_PASSWORD = '@30xHl5cT'
-TEST_TENANT_ID = '9c5245a2-0432-9d4c-4829-9bd7028603a1'
-TESTVIP_ID = '52ab5d71-6bb2-457f-8414-22a4ba55efec'
-
-
-class TestNSClient(testlib_api.WebTestCase):
-
-    """A Unit test for the NetScaler NCC client module."""
-
-    def setUp(self):
-        self.log = mock.patch.object(ncc_client, 'LOG').start()
-        super(TestNSClient, self).setUp()
-        # mock the requests.request function call
-        self.request_method_mock = mock.Mock()
-        requests.request = self.request_method_mock
-        self.testclient = self._get_nsclient()
-        self.testclient.login = mock.Mock()
-        self.testclient.login.side_effect = self.mock_auth_func(
-            self.testclient)
-        nfe_mock = mock.patch.object(
-            ncc_client.NCCException, "is_not_found_exception").start()
-        nfe_mock.return_value = True
-
-    def mock_auth_func(self, ncc_test_client):
-        ncc_test_client.auth = "SessId=123456789"
-
-    def test_instantiate_nsclient_with_empty_uri(self):
-        """Asserts that a call with empty URI will raise an exception."""
-        self.assertRaises(ncc_client.NCCException, ncc_client.NSClient,
-                          '', TEST_USERNAME, TEST_PASSWORD)
-
-    def test_create_resource_with_no_connection(self):
-        """Asserts that a call with no connection will raise an exception."""
-        # mock a connection object that fails to establish a connection
-        self.request_method_mock.side_effect = (
-            requests.exceptions.ConnectionError())
-        resource_path = netscaler_driver.VIPS_RESOURCE
-        resource_name = netscaler_driver.VIP_RESOURCE
-        resource_body = self._get_testvip_httpbody_for_create()
-        # call method under test: create_resource() and assert that
-        # it raises an exception
-        self.assertRaises(ncc_client.NCCException,
-                          self.testclient.create_resource,
-                          TEST_TENANT_ID, resource_path,
-                          resource_name, resource_body)
-
-    def test_create_resource_with_error(self):
-        """Asserts that a failed create call raises an exception."""
-        # create a mock object to represent a valid http response
-        # with a failure status code.
-        fake_response = requests.Response()
-        fake_response.status_code = requests.codes.unavailable
-        fake_response.headers = []
-        requests.request.return_value = fake_response
-        resource_path = netscaler_driver.VIPS_RESOURCE
-        resource_name = netscaler_driver.VIP_RESOURCE
-        resource_body = self._get_testvip_httpbody_for_create()
-        # call method under test: create_resource
-        # and assert that it raises the expected exception.
-        self.assertRaises(ncc_client.NCCException,
-                          self.testclient.create_resource,
-                          TEST_TENANT_ID, resource_path,
-                          resource_name, resource_body)
-
-    def test_create_resource(self):
-        """Asserts that a correct call will succeed."""
-        # obtain the mock object that corresponds to the call of request()
-        fake_response = requests.Response()
-        fake_response.status_code = requests.codes.created
-        fake_response.headers = []
-        self.request_method_mock.return_value = fake_response
-        resource_path = netscaler_driver.VIPS_RESOURCE
-        resource_name = netscaler_driver.VIP_RESOURCE
-        resource_body = self._get_testvip_httpbody_for_create()
-        # call method under test: create_resource()
-        self.testclient.create_resource(TEST_TENANT_ID, resource_path,
-                                        resource_name, resource_body)
-        # assert that request() was called
-        # with the expected params.
-        resource_url = "%s/%s" % (self.testclient.service_uri, resource_path)
-        self.request_method_mock.assert_called_once_with(
-            'POST',
-            url=resource_url,
-            headers=mock.ANY,
-            data=mock.ANY)
-
-    def test_update_resource_with_error(self):
-        """Asserts that a failed update call raises an exception."""
-        # create a valid http response with a failure status code.
-        fake_response = requests.Response()
-        fake_response.status_code = requests.codes.unavailable
-        fake_response.headers = []
-        # obtain the mock object that corresponds to the call of request()
-        self.request_method_mock.return_value = fake_response
-        resource_path = "%s/%s" % (netscaler_driver.VIPS_RESOURCE,
-                                   TESTVIP_ID)
-        resource_name = netscaler_driver.VIP_RESOURCE
-        resource_body = self._get_testvip_httpbody_for_update()
-        # call method under test: update_resource() and
-        # assert that it raises the expected exception.
-        self.assertRaises(ncc_client.NCCException,
-                          self.testclient.update_resource,
-                          TEST_TENANT_ID, resource_path,
-                          resource_name, resource_body)
-
-    def test_update_resource(self):
-        """Asserts that a correct update call will succeed."""
-        # create a valid http response with a successful status code.
-        fake_response = requests.Response()
-        fake_response.status_code = requests.codes.ok
-        fake_response.headers = []
-        # obtain the mock object that corresponds to the call of request()
-        self.request_method_mock.return_value = fake_response
-        resource_path = "%s/%s" % (netscaler_driver.VIPS_RESOURCE,
-                                   TESTVIP_ID)
-        resource_name = netscaler_driver.VIP_RESOURCE
-        resource_body = self._get_testvip_httpbody_for_update()
-        # call method under test: update_resource.
-        self.testclient.update_resource(TEST_TENANT_ID, resource_path,
-                                        resource_name, resource_body)
-        resource_url = "%s/%s" % (self.testclient.service_uri, resource_path)
-        # assert that requests.request() was called with the
-        # expected params.
-        self.request_method_mock.assert_called_once_with(
-            'PUT',
-            url=resource_url,
-            headers=mock.ANY,
-            data=mock.ANY)
-
-    def test_delete_resource_with_error(self):
-        """Asserts that a failed delete call raises an exception."""
-        # create a valid http response with a failure status code.
-        fake_response = requests.Response()
-        fake_response.status_code = requests.codes.unavailable
-        fake_response.headers = []
-        self.request_method_mock.return_value = fake_response
-        resource_path = "%s/%s" % (netscaler_driver.VIPS_RESOURCE,
-                                   TESTVIP_ID)
-        # call method under test: create_resource
-        self.assertRaises(ncc_client.NCCException,
-                          self.testclient.remove_resource,
-                          TEST_TENANT_ID, resource_path)
-
-    def test_delete_resource(self):
-        """Asserts that a correct delete call will succeed."""
-        # create a valid http response with a failure status code.
-        fake_response = requests.Response()
-        fake_response.status_code = requests.codes.ok
-        fake_response.headers = []
-        # obtain the mock object that corresponds to the call of request()
-        self.request_method_mock.return_value = fake_response
-        resource_path = "%s/%s" % (netscaler_driver.VIPS_RESOURCE,
-                                   TESTVIP_ID)
-        resource_url = "%s/%s" % (self.testclient.service_uri, resource_path)
-        # call method under test: create_resource
-        self.testclient.remove_resource(TEST_TENANT_ID, resource_path)
-        # assert that httplib.HTTPConnection request() was called with the
-        # expected params
-        self.request_method_mock.assert_called_once_with(
-            'DELETE',
-            url=resource_url,
-            headers=mock.ANY,
-            data=mock.ANY)
-
-    def _get_nsclient(self):
-        return ncc_client.NSClient(TESTURI, TEST_USERNAME, TEST_PASSWORD)
-
-    def _get_testvip_httpbody_for_create(self):
-        body = {
-            'name': 'vip1',
-            'address': '10.0.0.3',
-            'pool_id': 'da477c13-24cd-4c9f-8c19-757a61ef3b9d',
-            'protocol': 'HTTP',
-            'protocol_port': 80,
-            'admin_state_up': True,
-        }
-        return body
-
-    def _get_testvip_httpbody_for_update(self):
-        body = {}
-        body['name'] = 'updated vip1'
-        body['admin_state_up'] = False
-        return body
diff --git a/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py b/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py
deleted file mode 100644
index c47d3f8..0000000
--- a/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py
+++ /dev/null
@@ -1,803 +0,0 @@
-# Copyright 2014 Citrix Systems
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-
-import mock
-from neutron import context
-from neutron import manager
-from neutron.plugins.common import constants
-from neutron_lib import exceptions
-
-from neutron_lbaas.db.loadbalancer import loadbalancer_db
-from neutron_lbaas.services.loadbalancer.drivers.netscaler import ncc_client
-from neutron_lbaas.services.loadbalancer.drivers.netscaler \
-    import netscaler_driver
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-
-LBAAS_DRIVER_CLASS = ('neutron_lbaas.services.loadbalancer.drivers'
-                      '.netscaler.netscaler_driver'
-                      '.NetScalerPluginDriver')
-
-NCC_CLIENT_CLASS = ('neutron_lbaas.services.loadbalancer.drivers'
-                    '.netscaler.ncc_client'
-                    '.NSClient')
-
-LBAAS_PROVIDER_NAME = 'netscaler'
-LBAAS_PROVIDER = ('LOADBALANCER:%s:%s:default' %
-                  (LBAAS_PROVIDER_NAME, LBAAS_DRIVER_CLASS))
-
-#Test data
-TESTVIP_ID = '52ab5d71-6bb2-457f-8414-22a4ba55efec'
-TESTPOOL_ID = 'da477c13-24cd-4c9f-8c19-757a61ef3b9d'
-TESTMEMBER_ID = '84dea8bc-3416-4fb0-83f9-2ca6e7173bee'
-TESTMONITOR_ID = '9b9245a2-0413-4f15-87ef-9a41ef66048c'
-
-TESTVIP_PORT_ID = '327d9662-ade9-4c74-aaf6-c76f145c1180'
-TESTPOOL_PORT_ID = '132c1dbb-d3d8-45aa-96e3-71f2ea51651e'
-TESTPOOL_SNATIP_ADDRESS = '10.0.0.50'
-TESTPOOL_SNAT_PORT = {
-    'id': TESTPOOL_PORT_ID,
-    'fixed_ips': [{'ip_address': TESTPOOL_SNATIP_ADDRESS}]
-}
-TESTVIP_IP = '10.0.1.100'
-TESTMEMBER_IP = '10.0.0.5'
-
-
-class TestLoadBalancerPluginBase(test_db_loadbalancer
-                                 .LoadBalancerPluginDbTestCase):
-
-    def setUp(self):
-        # mock the NSClient class (REST client)
-        client_mock_cls = mock.patch(NCC_CLIENT_CLASS).start()
-
-        #mock the REST methods of the NSClient class
-        self.client_mock_instance = client_mock_cls.return_value
-        self.create_resource_mock = self.client_mock_instance.create_resource
-        self.create_resource_mock.side_effect = mock_create_resource_func
-        self.update_resource_mock = self.client_mock_instance.update_resource
-        self.update_resource_mock.side_effect = mock_update_resource_func
-        self.retrieve_resource_mock = (self.client_mock_instance
-                                           .retrieve_resource)
-        self.retrieve_resource_mock.side_effect = mock_retrieve_resource_func
-        self.remove_resource_mock = self.client_mock_instance.remove_resource
-        self.remove_resource_mock.side_effect = mock_remove_resource_func
-        super(TestLoadBalancerPluginBase, self).setUp(
-            lbaas_provider=LBAAS_PROVIDER)
-        loaded_plugins = manager.NeutronManager().get_service_plugins()
-        self.plugin_instance = loaded_plugins[constants.LOADBALANCER]
-
-
-class TestNetScalerPluginDriver(TestLoadBalancerPluginBase):
-
-    """Unit tests for the NetScaler LBaaS driver module."""
-
-    def setUp(self):
-        mock.patch.object(netscaler_driver, 'LOG').start()
-
-        super(TestNetScalerPluginDriver, self).setUp()
-        self.plugin_instance.drivers[LBAAS_PROVIDER_NAME] = (
-            netscaler_driver.NetScalerPluginDriver(self.plugin_instance))
-        self.driver = self.plugin_instance.drivers[LBAAS_PROVIDER_NAME]
-        self.context = context.get_admin_context()
-
-    def test_create_vip(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                testvip = self._build_testvip_contents(subnet['subnet'],
-                                                       pool['pool'])
-                expectedvip = self._build_expectedvip_contents(
-                    testvip,
-                    subnet['subnet'])
-                # mock the LBaaS plugin update_status().
-                self._mock_update_status()
-                # reset the create_resource() mock
-                self.create_resource_mock.reset_mock()
-                # execute the method under test
-                self.driver.create_vip(self.context, testvip)
-                # First, assert that create_resource was called once
-                # with expected params.
-                self.create_resource_mock.assert_called_once_with(
-                    None,
-                    netscaler_driver.VIPS_RESOURCE,
-                    netscaler_driver.VIP_RESOURCE,
-                    expectedvip)
-                #Finally, assert that the vip object is now ACTIVE
-                self.mock_update_status_obj.assert_called_once_with(
-                    mock.ANY,
-                    loadbalancer_db.Vip,
-                    expectedvip['id'],
-                    constants.ACTIVE)
-
-    def test_create_vip_without_connection(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                testvip = self._build_testvip_contents(subnet['subnet'],
-                                                       pool['pool'])
-                expectedvip = self._build_expectedvip_contents(
-                    testvip,
-                    subnet['subnet'])
-                errorcode = ncc_client.NCCException.CONNECTION_ERROR
-                self.create_resource_mock.side_effect = (
-                    ncc_client.NCCException(errorcode))
-                # mock the plugin's update_status()
-                self._mock_update_status()
-                # reset the create_resource() mock
-                self.create_resource_mock.reset_mock()
-                # execute the method under test.
-                self.driver.create_vip(self.context, testvip)
-                # First, assert that update_resource was called once
-                # with expected params.
-                self.create_resource_mock.assert_called_once_with(
-                    None,
-                    netscaler_driver.VIPS_RESOURCE,
-                    netscaler_driver.VIP_RESOURCE,
-                    expectedvip)
-                #Finally, assert that the vip object is in ERROR state
-                self.mock_update_status_obj.assert_called_once_with(
-                    mock.ANY,
-                    loadbalancer_db.Vip,
-                    testvip['id'],
-                    constants.ERROR)
-
-    def test_update_vip(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                with self.vip(pool=pool, subnet=subnet) as vip:
-                    updated_vip = self._build_updated_testvip_contents(
-                        vip['vip'],
-                        subnet['subnet'],
-                        pool['pool'])
-                    expectedvip = self._build_updated_expectedvip_contents(
-                        updated_vip,
-                        subnet['subnet'],
-                        pool['pool'])
-                    # mock the plugin's update_status()
-                    self._mock_update_status()
-                    # reset the update_resource() mock
-                    self.update_resource_mock.reset_mock()
-                    # execute the method under test
-                    self.driver.update_vip(self.context, updated_vip,
-                                           updated_vip)
-                    vip_resource_path = "%s/%s" % (
-                        (netscaler_driver.VIPS_RESOURCE,
-                         vip['vip']['id']))
-                    # First, assert that update_resource was called once
-                    # with expected params.
-                    (self.update_resource_mock
-                         .assert_called_once_with(
-                             None,
-                             vip_resource_path,
-                             netscaler_driver.VIP_RESOURCE,
-                             expectedvip))
-                    #Finally, assert that the vip object is now ACTIVE
-                    self.mock_update_status_obj.assert_called_once_with(
-                        mock.ANY,
-                        loadbalancer_db.Vip,
-                        vip['vip']['id'],
-                        constants.ACTIVE)
-
-    def test_delete_vip(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                with contextlib.nested(
-                    self.vip(pool=pool, subnet=subnet),
-                    mock.patch.object(self.driver.plugin, '_delete_db_vip')
-                ) as (vip, mock_delete_db_vip):
-                    mock_delete_db_vip.return_value = None
-                    #reset the remove_resource() mock
-                    self.remove_resource_mock.reset_mock()
-                    # execute the method under test
-                    self.driver.delete_vip(self.context, vip['vip'])
-                    vip_resource_path = "%s/%s" % (
-                                        (netscaler_driver.VIPS_RESOURCE,
-                                         vip['vip']['id']))
-                    # Assert that remove_resource() was called once
-                    # with expected params.
-                    (self.remove_resource_mock
-                         .assert_called_once_with(None, vip_resource_path))
-
-    def test_create_pool(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet'),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_ports'),
-            mock.patch.object(self.driver.plugin._core_plugin, 'create_port')
-        ) as (subnet, mock_get_subnet, mock_get_ports, mock_create_port):
-            mock_get_subnet.return_value = subnet['subnet']
-            mock_get_ports.return_value = None
-            mock_create_port.return_value = TESTPOOL_SNAT_PORT
-            testpool = self._build_testpool_contents(subnet['subnet'])
-            expectedpool = self._build_expectedpool_contents(testpool,
-                                                             subnet['subnet'])
-            #reset the create_resource() mock
-            self.create_resource_mock.reset_mock()
-            # mock the plugin's update_status()
-            self._mock_update_status()
-            # execute the method under test
-            self.driver.create_pool(self.context, testpool)
-            # First, assert that create_resource was called once
-            # with expected params.
-            (self.create_resource_mock
-                 .assert_called_once_with(None,
-                                          netscaler_driver.POOLS_RESOURCE,
-                                          netscaler_driver.POOL_RESOURCE,
-                                          expectedpool))
-            #Finally, assert that the pool object is now ACTIVE
-            self.mock_update_status_obj.assert_called_once_with(
-                mock.ANY,
-                loadbalancer_db.Pool,
-                expectedpool['id'],
-                constants.ACTIVE)
-
-    def test_create_pool_with_error(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet'),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_ports'),
-            mock.patch.object(self.driver.plugin._core_plugin, 'create_port')
-        ) as (subnet, mock_get_subnet, mock_get_ports, mock_create_port):
-            mock_get_subnet.return_value = subnet['subnet']
-            mock_get_ports.return_value = None
-            mock_create_port.return_value = TESTPOOL_SNAT_PORT
-            errorcode = ncc_client.NCCException.CONNECTION_ERROR
-            self.create_resource_mock.side_effect = (ncc_client
-                                                     .NCCException(errorcode))
-            testpool = self._build_testpool_contents(subnet['subnet'])
-            expectedpool = self._build_expectedpool_contents(testpool,
-                                                             subnet['subnet'])
-            # mock the plugin's update_status()
-            self._mock_update_status()
-            #reset the create_resource() mock
-            self.create_resource_mock.reset_mock()
-            # execute the method under test.
-            self.driver.create_pool(self.context, testpool)
-            # Also assert that create_resource was called once
-            # with expected params.
-            (self.create_resource_mock
-                 .assert_called_once_with(None,
-                                          netscaler_driver.POOLS_RESOURCE,
-                                          netscaler_driver.POOL_RESOURCE,
-                                          expectedpool))
-            #Finally, assert that the pool object is in ERROR state
-            self.mock_update_status_obj.assert_called_once_with(
-                mock.ANY,
-                loadbalancer_db.Pool,
-                expectedpool['id'],
-                constants.ERROR)
-
-    def test_create_pool_with_snatportcreate_failure(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet'),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_ports'),
-            mock.patch.object(self.driver.plugin._core_plugin, 'create_port')
-        ) as (subnet, mock_get_subnet, mock_get_ports, mock_create_port):
-            mock_get_subnet.return_value = subnet['subnet']
-            mock_get_ports.return_value = None
-            mock_create_port.side_effect = exceptions.NeutronException()
-            testpool = self._build_testpool_contents(subnet['subnet'])
-            #reset the create_resource() mock
-            self.create_resource_mock.reset_mock()
-            # execute the method under test.
-            self.assertRaises(exceptions.NeutronException,
-                              self.driver.create_pool,
-                              self.context, testpool)
-
-    def test_update_pool(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                updated_pool = self._build_updated_testpool_contents(
-                    pool['pool'],
-                    subnet['subnet'])
-                expectedpool = self._build_updated_expectedpool_contents(
-                    updated_pool,
-                    subnet['subnet'])
-                # mock the plugin's update_status()
-                self._mock_update_status()
-                # reset the update_resource() mock
-                self.update_resource_mock.reset_mock()
-                # execute the method under test.
-                self.driver.update_pool(self.context, pool['pool'],
-                                        updated_pool)
-                pool_resource_path = "%s/%s" % (
-                    (netscaler_driver.POOLS_RESOURCE,
-                     pool['pool']['id']))
-                # First, assert that update_resource was called once
-                # with expected params.
-                (self.update_resource_mock
-                     .assert_called_once_with(None,
-                                              pool_resource_path,
-                                              netscaler_driver.POOL_RESOURCE,
-                                              expectedpool))
-                #Finally, assert that the pool object is now ACTIVE
-                self.mock_update_status_obj.assert_called_once_with(
-                    mock.ANY,
-                    loadbalancer_db.Pool,
-                    pool['pool']['id'],
-                    constants.ACTIVE)
-
-    def test_delete_pool(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with contextlib.nested(
-                self.pool(provider=LBAAS_PROVIDER_NAME),
-                mock.patch.object(self.driver.plugin._core_plugin,
-                                  'delete_port'),
-                mock.patch.object(self.driver.plugin._core_plugin,
-                                  'get_ports'),
-                mock.patch.object(self.driver.plugin,
-                                  'get_pools'),
-                mock.patch.object(self.driver.plugin,
-                                  '_delete_db_pool')
-            ) as (pool, mock_delete_port, mock_get_ports, mock_get_pools,
-                  mock_delete_db_pool):
-                mock_delete_port.return_value = None
-                mock_get_ports.return_value = [{'id': TESTPOOL_PORT_ID}]
-                mock_get_pools.return_value = []
-                mock_delete_db_pool.return_value = None
-                #reset the remove_resource() mock
-                self.remove_resource_mock.reset_mock()
-                # execute the method under test.
-                self.driver.delete_pool(self.context, pool['pool'])
-                pool_resource_path = "%s/%s" % (
-                    (netscaler_driver.POOLS_RESOURCE,
-                     pool['pool']['id']))
-                # Assert that delete_resource was called
-                # once with expected params.
-                (self.remove_resource_mock
-                     .assert_called_once_with(None, pool_resource_path))
-
-    def test_create_member(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin,
-                              'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                testmember = self._build_testmember_contents(pool['pool'])
-                expectedmember = self._build_expectedmember_contents(
-                    testmember)
-                # mock the plugin's update_status()
-                self._mock_update_status()
-                #reset the create_resource() mock
-                self.create_resource_mock.reset_mock()
-                # execute the method under test.
-                self.driver.create_member(self.context, testmember)
-                # First, assert that create_resource was called once
-                # with expected params.
-                (self.create_resource_mock
-                     .assert_called_once_with(
-                         None,
-                         netscaler_driver.POOLMEMBERS_RESOURCE,
-                         netscaler_driver.POOLMEMBER_RESOURCE,
-                         expectedmember))
-                #Finally, assert that the member object is now ACTIVE
-                self.mock_update_status_obj.assert_called_once_with(
-                    mock.ANY,
-                    loadbalancer_db.Member,
-                    expectedmember['id'],
-                    constants.ACTIVE)
-
-    def test_update_member(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                with self.member(pool_id=pool['pool']['id']) as member:
-                    updatedmember = (self._build_updated_testmember_contents(
-                        member['member']))
-                    expectedmember = (self
-                                      ._build_updated_expectedmember_contents(
-                                          updatedmember))
-                    # mock the plugin's update_status()
-                    self._mock_update_status()
-                    # reset the update_resource() mock
-                    self.update_resource_mock.reset_mock()
-                    # execute the method under test
-                    self.driver.update_member(self.context,
-                                              member['member'],
-                                              updatedmember)
-                    member_resource_path = "%s/%s" % (
-                        (netscaler_driver.POOLMEMBERS_RESOURCE,
-                         member['member']['id']))
-                    # First, assert that update_resource was called once
-                    # with expected params.
-                    (self.update_resource_mock
-                         .assert_called_once_with(
-                             None,
-                             member_resource_path,
-                             netscaler_driver.POOLMEMBER_RESOURCE,
-                             expectedmember))
-                    #Finally, assert that the member object is now ACTIVE
-                    self.mock_update_status_obj.assert_called_once_with(
-                        mock.ANY,
-                        loadbalancer_db.Member,
-                        member['member']['id'],
-                        constants.ACTIVE)
-
-    def test_delete_member(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                with contextlib.nested(
-                    self.member(pool_id=pool['pool']['id']),
-                    mock.patch.object(self.driver.plugin, '_delete_db_member')
-                ) as (member, mock_delete_db_member):
-                    mock_delete_db_member.return_value = None
-                    # reset the remove_resource() mock
-                    self.remove_resource_mock.reset_mock()
-                    # execute the method under test
-                    self.driver.delete_member(self.context,
-                                              member['member'])
-                    member_resource_path = "%s/%s" % (
-                        (netscaler_driver.POOLMEMBERS_RESOURCE,
-                         member['member']['id']))
-                    # Assert that delete_resource was called once
-                    # with expected params.
-                    (self.remove_resource_mock
-                         .assert_called_once_with(None, member_resource_path))
-
-    def test_create_pool_health_monitor(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                testhealthmonitor = self._build_testhealthmonitor_contents(
-                    pool['pool'])
-                expectedhealthmonitor = (
-                    self._build_expectedhealthmonitor_contents(
-                        testhealthmonitor))
-                with mock.patch.object(self.driver.plugin,
-                                       'update_pool_health_monitor') as mhm:
-                    # reset the create_resource() mock
-                    self.create_resource_mock.reset_mock()
-                    # execute the method under test.
-                    self.driver.create_pool_health_monitor(self.context,
-                                                           testhealthmonitor,
-                                                           pool['pool']['id'])
-                    # First, assert that create_resource was called once
-                    # with expected params.
-                    resource_path = "%s/%s/%s" % (
-                        netscaler_driver.POOLS_RESOURCE,
-                        pool['pool']['id'],
-                        netscaler_driver.MONITORS_RESOURCE)
-                    (self.create_resource_mock
-                         .assert_called_once_with(
-                             None,
-                             resource_path,
-                             netscaler_driver.MONITOR_RESOURCE,
-                             expectedhealthmonitor))
-                    # Finally, assert that the healthmonitor object is
-                    # now ACTIVE.
-                    (mhm.assert_called_once_with(
-                        mock.ANY,
-                        expectedhealthmonitor['id'],
-                        pool['pool']['id'],
-                        constants.ACTIVE, ""))
-
-    def test_update_pool_health_monitor(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                with self.health_monitor(
-                    pool_id=pool['pool']['id']
-                ) as (health_monitor):
-                    updatedhealthmonitor = (
-                        self._build_updated_testhealthmonitor_contents(
-                            health_monitor['health_monitor']))
-                    expectedhealthmonitor = (
-                        self._build_updated_expectedhealthmonitor_contents(
-                            updatedhealthmonitor))
-                    with mock.patch.object(self.driver.plugin,
-                                           'update_pool_health_monitor')as mhm:
-                        # reset the update_resource() mock
-                        self.update_resource_mock.reset_mock()
-                        # execute the method under test.
-                        self.driver.update_pool_health_monitor(
-                            self.context,
-                            health_monitor['health_monitor'],
-                            updatedhealthmonitor,
-                            pool['pool']['id'])
-                        monitor_resource_path = "%s/%s" % (
-                            (netscaler_driver.MONITORS_RESOURCE,
-                             health_monitor['health_monitor']['id']))
-                        # First, assert that update_resource was called once
-                        # with expected params.
-                        self.update_resource_mock.assert_called_once_with(
-                            None,
-                            monitor_resource_path,
-                            netscaler_driver.MONITOR_RESOURCE,
-                            expectedhealthmonitor)
-                        #Finally, assert that the member object is now ACTIVE
-                        (mhm.assert_called_once_with(
-                            mock.ANY,
-                            health_monitor['health_monitor']['id'],
-                            pool['pool']['id'],
-                            constants.ACTIVE, ""))
-
-    def test_delete_pool_health_monitor(self):
-        with contextlib.nested(
-            self.subnet(),
-            mock.patch.object(self.driver.plugin._core_plugin, 'get_subnet')
-        ) as (subnet, mock_get_subnet):
-            mock_get_subnet.return_value = subnet['subnet']
-            with self.pool(provider=LBAAS_PROVIDER_NAME) as pool:
-                with contextlib.nested(
-                    self.health_monitor(pool_id=pool['pool']['id']),
-                    mock.patch.object(self.driver.plugin,
-                                      '_delete_db_pool_health_monitor')
-                ) as (health_monitor, mock_delete_db_monitor):
-                    mock_delete_db_monitor.return_value = None
-                    # reset the remove_resource() mock
-                    self.remove_resource_mock.reset_mock()
-                    # execute the method under test.
-                    self.driver.delete_pool_health_monitor(
-                        self.context,
-                        health_monitor['health_monitor'],
-                        pool['pool']['id'])
-                    monitor_resource_path = "%s/%s/%s/%s" % (
-                        netscaler_driver.POOLS_RESOURCE,
-                        pool['pool']['id'],
-                        netscaler_driver.MONITORS_RESOURCE,
-                        health_monitor['health_monitor']['id'])
-                    # Assert that delete_resource was called once
-                    # with expected params.
-                    self.remove_resource_mock.assert_called_once_with(
-                        None,
-                        monitor_resource_path)
-
-    def _build_testvip_contents(self, subnet, pool):
-        vip_obj = dict(id=TESTVIP_ID,
-                       name='testvip',
-                       description='a test vip',
-                       tenant_id=self._tenant_id,
-                       subnet_id=subnet['id'],
-                       address=TESTVIP_IP,
-                       port_id=TESTVIP_PORT_ID,
-                       pool_id=pool['id'],
-                       protocol='HTTP',
-                       protocol_port=80,
-                       connection_limit=1000,
-                       admin_state_up=True,
-                       status='PENDING_CREATE',
-                       status_description='')
-        return vip_obj
-
-    def _build_expectedvip_contents(self, testvip, subnet):
-        expectedvip = dict(id=testvip['id'],
-                           name=testvip['name'],
-                           description=testvip['description'],
-                           tenant_id=testvip['tenant_id'],
-                           subnet_id=testvip['subnet_id'],
-                           address=testvip['address'],
-                           network_id=subnet['network_id'],
-                           port_id=testvip['port_id'],
-                           pool_id=testvip['pool_id'],
-                           protocol=testvip['protocol'],
-                           protocol_port=testvip['protocol_port'],
-                           connection_limit=testvip['connection_limit'],
-                           admin_state_up=testvip['admin_state_up'])
-        return expectedvip
-
-    def _build_updated_testvip_contents(self, testvip, subnet, pool):
-        #update some updateable fields of the vip
-        testvip['name'] = 'udpated testvip'
-        testvip['description'] = 'An updated version of test vip'
-        testvip['connection_limit'] = 2000
-        return testvip
-
-    def _build_updated_expectedvip_contents(self, testvip, subnet, pool):
-        expectedvip = dict(name=testvip['name'],
-                           description=testvip['description'],
-                           connection_limit=testvip['connection_limit'],
-                           admin_state_up=testvip['admin_state_up'],
-                           pool_id=testvip['pool_id'])
-        return expectedvip
-
-    def _build_testpool_contents(self, subnet):
-        pool_obj = dict(id=TESTPOOL_ID,
-                        name='testpool',
-                        description='a test pool',
-                        tenant_id=self._tenant_id,
-                        subnet_id=subnet['id'],
-                        protocol='HTTP',
-                        vip_id=None,
-                        admin_state_up=True,
-                        lb_method='ROUND_ROBIN',
-                        status='PENDING_CREATE',
-                        status_description='',
-                        members=[],
-                        health_monitors=[],
-                        health_monitors_status=None,
-                        provider=LBAAS_PROVIDER_NAME)
-        return pool_obj
-
-    def _build_expectedpool_contents(self, testpool, subnet):
-        expectedpool = dict(id=testpool['id'],
-                            name=testpool['name'],
-                            description=testpool['description'],
-                            tenant_id=testpool['tenant_id'],
-                            subnet_id=testpool['subnet_id'],
-                            network_id=subnet['network_id'],
-                            protocol=testpool['protocol'],
-                            vip_id=testpool['vip_id'],
-                            lb_method=testpool['lb_method'],
-                            snat_ip=TESTPOOL_SNATIP_ADDRESS,
-                            port_id=TESTPOOL_PORT_ID,
-                            admin_state_up=testpool['admin_state_up'])
-        return expectedpool
-
-    def _build_updated_testpool_contents(self, testpool, subnet):
-        updated_pool = dict(testpool.items())
-        updated_pool['name'] = 'udpated testpool'
-        updated_pool['description'] = 'An updated version of test pool'
-        updated_pool['lb_method'] = 'LEAST_CONNECTIONS'
-        updated_pool['admin_state_up'] = True
-        updated_pool['provider'] = LBAAS_PROVIDER_NAME
-        updated_pool['status'] = 'PENDING_UPDATE'
-        updated_pool['status_description'] = ''
-        updated_pool['members'] = []
-        updated_pool["health_monitors"] = []
-        updated_pool["health_monitors_status"] = None
-        return updated_pool
-
-    def _build_updated_expectedpool_contents(self, testpool, subnet):
-        expectedpool = dict(name=testpool['name'],
-                            description=testpool['description'],
-                            lb_method=testpool['lb_method'],
-                            admin_state_up=testpool['admin_state_up'])
-        return expectedpool
-
-    def _build_testmember_contents(self, pool):
-        member_obj = dict(
-            id=TESTMEMBER_ID,
-            tenant_id=self._tenant_id,
-            pool_id=pool['id'],
-            address=TESTMEMBER_IP,
-            protocol_port=8080,
-            weight=2,
-            admin_state_up=True,
-            status='PENDING_CREATE',
-            status_description='')
-        return member_obj
-
-    def _build_expectedmember_contents(self, testmember):
-        expectedmember = dict(
-            id=testmember['id'],
-            tenant_id=testmember['tenant_id'],
-            pool_id=testmember['pool_id'],
-            address=testmember['address'],
-            protocol_port=testmember['protocol_port'],
-            weight=testmember['weight'],
-            admin_state_up=testmember['admin_state_up'])
-        return expectedmember
-
-    def _build_updated_testmember_contents(self, testmember):
-        updated_member = dict(testmember.items())
-        updated_member.update(
-            weight=3,
-            admin_state_up=True,
-            status='PENDING_CREATE',
-            status_description=''
-        )
-        return updated_member
-
-    def _build_updated_expectedmember_contents(self, testmember):
-        expectedmember = dict(weight=testmember['weight'],
-                              pool_id=testmember['pool_id'],
-                              admin_state_up=testmember['admin_state_up'])
-        return expectedmember
-
-    def _build_testhealthmonitor_contents(self, pool):
-        monitor_obj = dict(
-            id=TESTMONITOR_ID,
-            tenant_id=self._tenant_id,
-            type='TCP',
-            delay=10,
-            timeout=5,
-            max_retries=3,
-            admin_state_up=True,
-            pools=[])
-        pool_obj = dict(status='PENDING_CREATE',
-                        status_description=None,
-                        pool_id=pool['id'])
-        monitor_obj['pools'].append(pool_obj)
-        return monitor_obj
-
-    def _build_expectedhealthmonitor_contents(self, testhealthmonitor):
-        expectedmonitor = dict(id=testhealthmonitor['id'],
-                               tenant_id=testhealthmonitor['tenant_id'],
-                               type=testhealthmonitor['type'],
-                               delay=testhealthmonitor['delay'],
-                               timeout=testhealthmonitor['timeout'],
-                               max_retries=testhealthmonitor['max_retries'],
-                               admin_state_up=(
-                                   testhealthmonitor['admin_state_up']))
-        return expectedmonitor
-
-    def _build_updated_testhealthmonitor_contents(self, testmonitor):
-        updated_monitor = dict(testmonitor.items())
-        updated_monitor.update(
-            delay=30,
-            timeout=3,
-            max_retries=5,
-            admin_state_up=True
-        )
-        return updated_monitor
-
-    def _build_updated_expectedhealthmonitor_contents(self, testmonitor):
-        expectedmonitor = dict(delay=testmonitor['delay'],
-                               timeout=testmonitor['timeout'],
-                               max_retries=testmonitor['max_retries'],
-                               admin_state_up=testmonitor['admin_state_up'])
-        return expectedmonitor
-
-    def _mock_update_status(self):
-        #patch the plugin's update_status() method with a mock object
-        self.mock_update_status_patcher = mock.patch.object(
-            self.driver.plugin,
-            'update_status')
-        self.mock_update_status_obj = self.mock_update_status_patcher.start()
-
-
-def mock_create_resource_func(*args, **kwargs):
-    return 201, {}
-
-
-def mock_update_resource_func(*args, **kwargs):
-    return 202, {}
-
-
-def mock_retrieve_resource_func(*args, **kwargs):
-    return 200, {}
-
-
-def mock_remove_resource_func(*args, **kwargs):
-    return 200, {}
diff --git a/tests/unit/services/loadbalancer/drivers/radware/__init__.py b/tests/unit/services/loadbalancer/drivers/radware/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py b/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py
deleted file mode 100644
index 4dddb7e..0000000
--- a/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py
+++ /dev/null
@@ -1,998 +0,0 @@
-# Copyright 2013 Radware LTD.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import re
-
-import contextlib
-import mock
-from neutron.api.v2 import attributes
-from neutron import context
-from neutron import manager
-from neutron.plugins.common import constants
-from oslo_config import cfg
-from oslo_serialization import jsonutils
-from six.moves import queue as Queue
-
-from neutron_lbaas.extensions import loadbalancer
-from neutron_lbaas.services.loadbalancer.drivers.radware import driver
-from neutron_lbaas.services.loadbalancer.drivers.radware \
-    import exceptions as r_exc
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-GET_200 = ('/api/workflow/', '/api/service/', '/api/workflowTemplate')
-SERVER_DOWN_CODES = (-1, 301, 307)
-
-
-class QueueMock(Queue.Queue):
-    def __init__(self, completion_handler):
-        self.completion_handler = completion_handler
-        super(QueueMock, self).__init__()
-
-    def put_nowait(self, oper):
-        self.completion_handler(oper)
-
-
-def _recover_function_mock(action, resource, data, headers, binary=False):
-    pass
-
-
-def rest_call_function_mock(action, resource, data, headers, binary=False):
-    if rest_call_function_mock.RESPOND_WITH_ERROR:
-        return 400, 'error_status', 'error_description', None
-    if rest_call_function_mock.RESPOND_WITH_SERVER_DOWN in SERVER_DOWN_CODES:
-        val = rest_call_function_mock.RESPOND_WITH_SERVER_DOWN
-        return val, 'error_status', 'error_description', None
-    if action == 'GET':
-        return _get_handler(resource)
-    elif action == 'DELETE':
-        return _delete_handler(resource)
-    elif action == 'POST':
-        return _post_handler(resource, binary)
-    else:
-        return 0, None, None, None
-
-
-def _get_handler(resource):
-    if resource == GET_200[2]:
-        if rest_call_function_mock.TEMPLATES_MISSING:
-            data = jsonutils.loads('[]')
-        else:
-            data = jsonutils.loads(
-                '[{"name":"openstack_l2_l3"},{"name":"openstack_l4"}]'
-            )
-        return 200, '', '', data
-
-    if resource in GET_200:
-        return 200, '', '', ''
-    else:
-        data = jsonutils.loads('{"complete":"True", "success": "True"}')
-        return 202, '', '', data
-
-
-def _delete_handler(resource):
-    return 404, '', '', {'message': 'Not Found'}
-
-
-def _post_handler(resource, binary):
-    if re.search(r'/api/workflow/.+/action/.+', resource):
-        data = jsonutils.loads('{"uri":"some_uri"}')
-        return 202, '', '', data
-    elif re.search(r'/api/service\?name=.+', resource):
-        data = jsonutils.loads('{"links":{"actions":{"provision":"someuri"}}}')
-        return 201, '', '', data
-    elif binary:
-        return 201, '', '', ''
-    else:
-        return 202, '', '', ''
-
-RADWARE_PROVIDER = ('LOADBALANCER:radware:neutron_lbaas.services.'
-                    'loadbalancer.drivers.radware.driver.'
-                    'LoadBalancerDriver:default')
-
-
-class TestLoadBalancerPluginBase(
-    test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def setUp(self):
-        super(TestLoadBalancerPluginBase, self).setUp(
-            lbaas_provider=RADWARE_PROVIDER)
-
-        loaded_plugins = manager.NeutronManager().get_service_plugins()
-        self.plugin_instance = loaded_plugins[constants.LOADBALANCER]
-
-
-class TestLoadBalancerPlugin(TestLoadBalancerPluginBase):
-    def setUp(self):
-        super(TestLoadBalancerPlugin, self).setUp()
-
-        rest_call_function_mock.__dict__.update(
-            {'RESPOND_WITH_ERROR': False})
-        rest_call_function_mock.__dict__.update(
-            {'TEMPLATES_MISSING': False})
-        rest_call_function_mock.__dict__.update(
-            {'RESPOND_WITH_SERVER_DOWN': 200})
-
-        self.operation_completer_start_mock = mock.Mock(
-            return_value=None)
-        self.operation_completer_join_mock = mock.Mock(
-            return_value=None)
-        self.driver_rest_call_mock = mock.Mock(
-            side_effect=rest_call_function_mock)
-        self.flip_servers_mock = mock.Mock(
-            return_value=None)
-        self.recover_mock = mock.Mock(
-            side_effect=_recover_function_mock)
-
-        radware_driver = self.plugin_instance.drivers['radware']
-        radware_driver.completion_handler.start = (
-            self.operation_completer_start_mock)
-        radware_driver.completion_handler.join = (
-            self.operation_completer_join_mock)
-        self.orig_call = radware_driver.rest_client.call
-        self.orig__call = radware_driver.rest_client._call
-        radware_driver.rest_client.call = self.driver_rest_call_mock
-        radware_driver.rest_client._call = self.driver_rest_call_mock
-        radware_driver.rest_client._flip_servers = self.flip_servers_mock
-        radware_driver.rest_client._recover = self.recover_mock
-        radware_driver.completion_handler.rest_client.call = (
-            self.driver_rest_call_mock)
-
-        radware_driver.queue = QueueMock(
-            radware_driver.completion_handler.handle_operation_completion)
-
-        self.addCleanup(radware_driver.completion_handler.join)
-
-    def test_get_pip(self):
-        """Call _get_pip twice and verify that a Port is created once."""
-        port_dict = {'fixed_ips': [{'subnet_id': '10.10.10.10',
-                                    'ip_address': '11.11.11.11'}]}
-        port_data = {
-            'tenant_id': 'tenant_id',
-            'name': 'port_name',
-            'network_id': 'network_id',
-            'mac_address': attributes.ATTR_NOT_SPECIFIED,
-            'admin_state_up': False,
-            'device_id': '',
-            'device_owner': 'neutron:' + constants.LOADBALANCER,
-            'fixed_ips': [{'subnet_id': '10.10.10.10'}]
-        }
-        self.plugin_instance._core_plugin.get_ports = mock.Mock(
-            return_value=[])
-        self.plugin_instance._core_plugin.create_port = mock.Mock(
-            return_value=port_dict)
-        radware_driver = self.plugin_instance.drivers['radware']
-        radware_driver._get_pip(context.get_admin_context(),
-                                'tenant_id', 'port_name',
-                                'network_id', '10.10.10.10')
-        self.plugin_instance._core_plugin.get_ports.assert_called_once_with(
-                mock.ANY, filters={'name': ['port_name']})
-        self.plugin_instance._core_plugin.create_port.assert_called_once_with(
-                mock.ANY, {'port': port_data})
-        self.plugin_instance._core_plugin.create_port.reset_mock()
-        self.plugin_instance._core_plugin.get_ports.reset_mock()
-        self.plugin_instance._core_plugin.get_ports.return_value = [port_dict]
-        radware_driver._get_pip(context.get_admin_context(),
-                                'tenant_id', 'port_name',
-                                'network_id', '10.10.10.10')
-        self.plugin_instance._core_plugin.get_ports.assert_called_once_with(
-                mock.ANY, filters={'name': ['port_name']})
-        self.assertFalse(self.plugin_instance._core_plugin.create_port.called)
-
-    def test_rest_client_recover_was_called(self):
-        """Call the real REST client and verify _recover is called."""
-        radware_driver = self.plugin_instance.drivers['radware']
-        radware_driver.rest_client.call = self.orig_call
-        radware_driver.rest_client._call = self.orig__call
-        self.assertRaises(r_exc.RESTRequestFailure,
-                          radware_driver._verify_workflow_templates)
-        self.recover_mock.assert_called_once_with('GET',
-                                                  '/api/workflowTemplate',
-                                                  None, None, False)
-
-    def test_rest_client_flip_servers(self):
-        radware_driver = self.plugin_instance.drivers['radware']
-        server = radware_driver.rest_client.server
-        sec_server = radware_driver.rest_client.secondary_server
-        radware_driver.rest_client._flip_servers()
-        self.assertEqual(server,
-                         radware_driver.rest_client.secondary_server)
-        self.assertEqual(sec_server,
-                         radware_driver.rest_client.server)
-
-    def test_verify_workflow_templates_server_down(self):
-        """Test the rest call failure when backend is down."""
-        for value in SERVER_DOWN_CODES:
-            rest_call_function_mock.__dict__.update(
-                {'RESPOND_WITH_SERVER_DOWN': value})
-            self.assertRaises(r_exc.RESTRequestFailure,
-                              self.plugin_instance.drivers['radware'].
-                              _verify_workflow_templates)
-
-    def test_verify_workflow_templates(self):
-        """Test the rest call failure handling by Exception raising."""
-        rest_call_function_mock.__dict__.update(
-            {'TEMPLATES_MISSING': True})
-
-        self.assertRaises(r_exc.WorkflowMissing,
-                          self.plugin_instance.drivers['radware'].
-                          _verify_workflow_templates)
-
-    def test_create_vip_failure(self):
-        """Test the rest call failure handling by Exception raising."""
-        with self.network() as network:
-            with self.subnet(network=network) as subnet:
-                with self.pool(do_delete=False,
-                               provider='radware',
-                               subnet_id=subnet['subnet']['id']) as pool:
-                    vip_data = {
-                        'name': 'vip1',
-                        'subnet_id': subnet['subnet']['id'],
-                        'pool_id': pool['pool']['id'],
-                        'description': '',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'connection_limit': -1,
-                        'admin_state_up': True,
-                        'status': constants.PENDING_CREATE,
-                        'tenant_id': self._tenant_id,
-                        'session_persistence': ''
-                    }
-
-                    rest_call_function_mock.__dict__.update(
-                        {'RESPOND_WITH_ERROR': True})
-
-                    self.assertRaises(r_exc.RESTRequestFailure,
-                                      self.plugin_instance.create_vip,
-                                      context.get_admin_context(),
-                                      {'vip': vip_data})
-
-    def test_create_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           subnet_id=subnet['subnet']['id']) as pool:
-                vip_data = {
-                    'name': 'vip1',
-                    'subnet_id': subnet['subnet']['id'],
-                    'pool_id': pool['pool']['id'],
-                    'description': '',
-                    'protocol_port': 80,
-                    'protocol': 'HTTP',
-                    'connection_limit': -1,
-                    'admin_state_up': True,
-                    'status': constants.PENDING_CREATE,
-                    'tenant_id': self._tenant_id,
-                    'session_persistence': ''
-                }
-
-                vip = self.plugin_instance.create_vip(
-                    context.get_admin_context(), {'vip': vip_data})
-
-                # Test creation REST calls
-                calls = [
-                    mock.call('GET', u'/api/service/srv_' +
-                              subnet['subnet']['network_id'], None, None),
-                    mock.call('POST', u'/api/service?name=srv_' +
-                              subnet['subnet']['network_id'] + '&tenant=' +
-                              vip['tenant_id'], mock.ANY,
-                              driver.CREATE_SERVICE_HEADER),
-                    mock.call('GET', u'/api/workflow/l2_l3_' +
-                              subnet['subnet']['network_id'], None, None),
-                    mock.call('POST', '/api/workflow/l2_l3_' +
-                              subnet['subnet']['network_id'] +
-                              '/action/setup_l2_l3',
-                              mock.ANY, driver.TEMPLATE_HEADER),
-                    mock.call('POST', 'someuri',
-                              None, driver.PROVISION_HEADER),
-
-
-                    mock.call('POST', '/api/workflowTemplate/' +
-                              'openstack_l4' +
-                              '?name=' + pool['pool']['id'],
-                              mock.ANY,
-                              driver.TEMPLATE_HEADER),
-                    mock.call('POST', '/api/workflowTemplate/' +
-                              'openstack_l2_l3' +
-                              '?name=l2_l3_' + subnet['subnet']['network_id'],
-                              mock.ANY,
-                              driver.TEMPLATE_HEADER),
-
-                    mock.call('POST', '/api/workflow/' + pool['pool']['id'] +
-                              '/action/BaseCreate',
-                              mock.ANY, driver.TEMPLATE_HEADER),
-                    mock.call('GET', '/api/workflow/' +
-                              pool['pool']['id'], None, None)
-                ]
-                self.driver_rest_call_mock.assert_has_calls(calls,
-                                                            any_order=True)
-
-                #Test DB
-                new_vip = self.plugin_instance.get_vip(
-                    context.get_admin_context(),
-                    vip['id']
-                )
-                self.assertEqual(constants.ACTIVE, new_vip['status'])
-
-                # Delete VIP
-                self.plugin_instance.delete_vip(
-                    context.get_admin_context(), vip['id'])
-
-                # Test deletion REST calls
-                calls = [
-                    mock.call('DELETE', u'/api/workflow/' + pool['pool']['id'],
-                              None, None)
-                ]
-                self.driver_rest_call_mock.assert_has_calls(
-                    calls, any_order=True)
-
-    def test_create_vip_2_leg(self):
-        """Test creation of a VIP where Alteon VIP and PIP are different."""
-
-        with self.subnet(cidr='10.0.0.0/24') as subnet:
-            with self.subnet(cidr='10.0.1.0/24') as pool_sub:
-                with self.pool(provider='radware',
-                               subnet_id=pool_sub['subnet']['id']) as pool:
-                    vip_data = {
-                        'name': 'vip1',
-                        'subnet_id': subnet['subnet']['id'],
-                        'pool_id': pool['pool']['id'],
-                        'description': '',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'connection_limit': -1,
-                        'admin_state_up': True,
-                        'status': constants.PENDING_CREATE,
-                        'tenant_id': self._tenant_id,
-                        'session_persistence': ''
-                    }
-
-                    vip = self.plugin_instance.create_vip(
-                        context.get_admin_context(), {'vip': vip_data})
-                    name_suffix = '%s_%s' % (subnet['subnet']['network_id'],
-                                             pool_sub['subnet']['network_id'])
-                    # Test creation REST calls
-                    calls = [
-                        mock.call('GET', '/api/workflowTemplate', None, None),
-                        mock.call('GET', '/api/service/srv_' + name_suffix,
-                                  None, None),
-                        mock.call('POST', '/api/service?name=srv_' +
-                                  name_suffix + '&tenant=' + vip['tenant_id'],
-                                  mock.ANY, driver.CREATE_SERVICE_HEADER),
-                        mock.call('POST', 'someuri',
-                                  None, driver.PROVISION_HEADER),
-                        mock.call('GET', '/api/workflow/l2_l3_' + name_suffix,
-                                  None, None),
-                        mock.call('POST', '/api/workflowTemplate/' +
-                                  'openstack_l2_l3' +
-                                  '?name=l2_l3_' + name_suffix,
-                                  mock.ANY,
-                                  driver.TEMPLATE_HEADER),
-                        mock.call('POST', '/api/workflow/l2_l3_' +
-                                  name_suffix + '/action/setup_l2_l3',
-                                  mock.ANY, driver.TEMPLATE_HEADER),
-                        mock.call('GET', '/api/workflow/' +
-                                  pool['pool']['id'], None, None),
-                        mock.call('POST', '/api/workflowTemplate/' +
-                                  'openstack_l4' +
-                                  '?name=' + pool['pool']['id'],
-                                  mock.ANY,
-                                  driver.TEMPLATE_HEADER),
-                        mock.call('POST', '/api/workflow/' +
-                                  pool['pool']['id'] + '/action/BaseCreate',
-                                  mock.ANY, driver.TEMPLATE_HEADER)
-                    ]
-                    self.driver_rest_call_mock.assert_has_calls(calls)
-                    #Test DB
-                    new_vip = self.plugin_instance.get_vip(
-                        context.get_admin_context(),
-                        vip['id']
-                    )
-                    self.assertEqual(constants.ACTIVE, new_vip['status'])
-
-                    # Test that PIP neutron port was created
-                    pip_port_filter = {
-                        'name': ['pip_' + vip['id']],
-                    }
-                    plugin = manager.NeutronManager.get_plugin()
-                    num_ports = plugin.get_ports_count(
-                        context.get_admin_context(), filters=pip_port_filter)
-                    self.assertTrue(num_ports > 0)
-
-                    # Delete VIP
-                    self.plugin_instance.delete_vip(
-                        context.get_admin_context(), vip['id'])
-
-                    # Test deletion REST calls
-                    calls = [
-                        mock.call('DELETE', u'/api/workflow/' +
-                                  pool['pool']['id'], None, None)
-                    ]
-                    self.driver_rest_call_mock.assert_has_calls(calls)
-
-    def test_update_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           do_delete=False,
-                           subnet_id=subnet['subnet']['id']) as pool:
-                vip_data = {
-                    'name': 'vip1',
-                    'subnet_id': subnet['subnet']['id'],
-                    'pool_id': pool['pool']['id'],
-                    'description': '',
-                    'protocol_port': 80,
-                    'protocol': 'HTTP',
-                    'connection_limit': -1,
-                    'admin_state_up': True,
-                    'status': constants.PENDING_CREATE,
-                    'tenant_id': self._tenant_id,
-                    'session_persistence': ''
-                }
-
-                vip = self.plugin_instance.create_vip(
-                    context.get_admin_context(), {'vip': vip_data})
-
-                vip_data['status'] = constants.PENDING_UPDATE
-                self.plugin_instance.update_vip(
-                    context.get_admin_context(),
-                    vip['id'], {'vip': vip_data})
-
-                # Test REST calls
-                calls = [
-                    mock.call('POST', '/api/workflow/' + pool['pool']['id'] +
-                              '/action/BaseCreate',
-                              mock.ANY, driver.TEMPLATE_HEADER),
-                ]
-                self.driver_rest_call_mock.assert_has_calls(
-                    calls, any_order=True)
-
-                updated_vip = self.plugin_instance.get_vip(
-                    context.get_admin_context(), vip['id'])
-                self.assertEqual(constants.ACTIVE, updated_vip['status'])
-
-                # delete VIP
-                self.plugin_instance.delete_vip(
-                    context.get_admin_context(), vip['id'])
-
-    def test_update_vip_2_leg(self):
-        """Test update of a VIP where Alteon VIP and PIP are different."""
-
-        with self.subnet(cidr='10.0.0.0/24') as subnet:
-            with self.subnet(cidr='10.0.1.0/24') as pool_subnet:
-                with self.pool(provider='radware',
-                               subnet_id=pool_subnet['subnet']['id']) as pool:
-                    vip_data = {
-                        'name': 'vip1',
-                        'subnet_id': subnet['subnet']['id'],
-                        'pool_id': pool['pool']['id'],
-                        'description': '',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'connection_limit': -1,
-                        'admin_state_up': True,
-                        'status': constants.PENDING_CREATE,
-                        'tenant_id': self._tenant_id,
-                        'session_persistence': ''
-                    }
-
-                    vip = self.plugin_instance.create_vip(
-                        context.get_admin_context(), {'vip': vip_data})
-
-                    self.plugin_instance.update_vip(
-                        context.get_admin_context(),
-                        vip['id'], {'vip': vip_data})
-
-                    # Test REST calls
-                    calls = [
-                        mock.call('POST', '/api/workflow/' +
-                                  pool['pool']['id'] + '/action/BaseCreate',
-                                  mock.ANY, driver.TEMPLATE_HEADER),
-                    ]
-                    self.driver_rest_call_mock.assert_has_calls(calls)
-
-                    updated_vip = self.plugin_instance.get_vip(
-                        context.get_admin_context(), vip['id'])
-                    self.assertEqual(constants.ACTIVE, updated_vip['status'])
-
-                    # delete VIP
-                    self.plugin_instance.delete_vip(
-                        context.get_admin_context(), vip['id'])
-
-    def test_delete_vip_failure(self):
-        plugin = self.plugin_instance
-
-        with self.network() as network:
-            with self.subnet(network=network) as subnet:
-                with self.pool(do_delete=False,
-                               provider='radware',
-                               subnet_id=subnet['subnet']['id']) as pool:
-                    with contextlib.nested(
-                        self.member(pool_id=pool['pool']['id'],
-                                    do_delete=False),
-                        self.member(pool_id=pool['pool']['id'],
-                                    address='192.168.1.101',
-                                    do_delete=False),
-                        self.health_monitor(do_delete=False),
-                        self.vip(pool=pool, subnet=subnet, do_delete=False)
-                    ) as (mem1, mem2, hm, vip):
-
-                        plugin.create_pool_health_monitor(
-                            context.get_admin_context(), hm, pool['pool']['id']
-                        )
-
-                        rest_call_function_mock.__dict__.update(
-                            {'RESPOND_WITH_ERROR': True})
-
-                        plugin.delete_vip(
-                            context.get_admin_context(), vip['vip']['id'])
-
-                        u_vip = plugin.get_vip(
-                            context.get_admin_context(), vip['vip']['id'])
-                        u_pool = plugin.get_pool(
-                            context.get_admin_context(), pool['pool']['id'])
-                        u_mem1 = plugin.get_member(
-                            context.get_admin_context(), mem1['member']['id'])
-                        u_mem2 = plugin.get_member(
-                            context.get_admin_context(), mem2['member']['id'])
-                        u_phm = plugin.get_pool_health_monitor(
-                            context.get_admin_context(),
-                            hm['health_monitor']['id'], pool['pool']['id'])
-
-                        self.assertEqual(constants.ERROR, u_vip['status'])
-                        self.assertEqual(constants.ACTIVE, u_pool['status'])
-                        self.assertEqual(constants.ACTIVE, u_mem1['status'])
-                        self.assertEqual(constants.ACTIVE, u_mem2['status'])
-                        self.assertEqual(constants.ACTIVE, u_phm['status'])
-
-    def test_delete_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           do_delete=False,
-                           subnet_id=subnet['subnet']['id']) as pool:
-                vip_data = {
-                    'name': 'vip1',
-                    'subnet_id': subnet['subnet']['id'],
-                    'pool_id': pool['pool']['id'],
-                    'description': '',
-                    'protocol_port': 80,
-                    'protocol': 'HTTP',
-                    'connection_limit': -1,
-                    'admin_state_up': True,
-                    'status': constants.PENDING_CREATE,
-                    'tenant_id': self._tenant_id,
-                    'session_persistence': ''
-                }
-
-                vip = self.plugin_instance.create_vip(
-                    context.get_admin_context(), {'vip': vip_data})
-
-                self.plugin_instance.delete_vip(
-                    context.get_admin_context(), vip['id'])
-
-                calls = [
-                    mock.call('DELETE', '/api/workflow/' + pool['pool']['id'],
-                              None, None)
-                ]
-                self.driver_rest_call_mock.assert_has_calls(
-                    calls, any_order=True)
-
-                self.assertRaises(loadbalancer.VipNotFound,
-                                  self.plugin_instance.get_vip,
-                                  context.get_admin_context(), vip['id'])
-
-    def test_delete_vip_2_leg(self):
-        """Test deletion of a VIP where Alteon VIP and PIP are different."""
-
-        self.driver_rest_call_mock.reset_mock()
-        with self.subnet(cidr='10.0.0.0/24') as subnet:
-            with self.subnet(cidr='10.0.1.0/24') as pool_subnet:
-                with self.pool(provider='radware',
-                               do_delete=False,
-                               subnet_id=pool_subnet['subnet']['id']) as pool:
-                    vip_data = {
-                        'name': 'vip1',
-                        'subnet_id': subnet['subnet']['id'],
-                        'pool_id': pool['pool']['id'],
-                        'description': '',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'connection_limit': -1,
-                        'admin_state_up': True,
-                        'status': constants.PENDING_CREATE,
-                        'tenant_id': self._tenant_id,
-                        'session_persistence': ''
-                    }
-
-                    vip = self.plugin_instance.create_vip(
-                        context.get_admin_context(), {'vip': vip_data})
-
-                    self.plugin_instance.delete_vip(
-                        context.get_admin_context(), vip['id'])
-
-                    calls = [
-                        mock.call('DELETE', '/api/workflow/' +
-                                  pool['pool']['id'], None, None)
-                    ]
-                    self.driver_rest_call_mock.assert_has_calls(calls)
-
-                    # Test that PIP neutron port was deleted
-                    pip_port_filter = {
-                        'name': ['pip_' + vip['id']],
-                    }
-                    plugin = manager.NeutronManager.get_plugin()
-                    num_ports = plugin.get_ports_count(
-                        context.get_admin_context(), filters=pip_port_filter)
-                    self.assertTrue(num_ports == 0)
-
-                    self.assertRaises(loadbalancer.VipNotFound,
-                                      self.plugin_instance.get_vip,
-                                      context.get_admin_context(), vip['id'])
-
-    def test_update_pool(self):
-        with self.subnet():
-            with self.pool() as pool:
-                del pool['pool']['provider']
-                del pool['pool']['status']
-                self.plugin_instance.update_pool(
-                    context.get_admin_context(),
-                    pool['pool']['id'], pool)
-                pool_db = self.plugin_instance.get_pool(
-                    context.get_admin_context(), pool['pool']['id'])
-                self.assertEqual(constants.PENDING_UPDATE, pool_db['status'])
-
-    def test_delete_pool_with_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           do_delete=False,
-                           subnet_id=subnet['subnet']['id']) as pool:
-                with self.vip(pool=pool, subnet=subnet):
-                    self.assertRaises(loadbalancer.PoolInUse,
-                                      self.plugin_instance.delete_pool,
-                                      context.get_admin_context(),
-                                      pool['pool']['id'])
-
-    def test_create_member_with_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           subnet_id=subnet['subnet']['id']) as p:
-                with self.vip(pool=p, subnet=subnet):
-                    with self.member(pool_id=p['pool']['id']):
-                        calls = [
-                            mock.call(
-                                'POST', '/api/workflow/' + p['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            ),
-                            mock.call(
-                                'POST', '/api/workflow/' + p['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            )
-                        ]
-                        self.driver_rest_call_mock.assert_has_calls(
-                            calls, any_order=True)
-
-    def test_create_member_on_different_subnets(self):
-        with contextlib.nested(
-            self.subnet(),
-            self.subnet(cidr='20.0.0.0/24'),
-            self.subnet(cidr='30.0.0.0/24')
-        ) as (vip_sub, pool_sub, member_sub):
-            with self.pool(provider='radware',
-                           subnet_id=pool_sub['subnet']['id']) as pool:
-                with contextlib.nested(
-                    self.port(subnet=vip_sub,
-                              fixed_ips=[{'ip_address': '10.0.0.2'}]),
-                    self.port(subnet=pool_sub,
-                              fixed_ips=[{'ip_address': '20.0.0.2'}]),
-                    self.port(subnet=member_sub,
-                              fixed_ips=[{'ip_address': '30.0.0.2'}])
-                ):
-                    with contextlib.nested(
-                        self.member(pool_id=pool['pool']['id'],
-                                    address='10.0.0.2'),
-                        self.member(pool_id=pool['pool']['id'],
-                                    address='20.0.0.2'),
-                        self.member(pool_id=pool['pool']['id'],
-                                    address='30.0.0.2')
-                    ) as (member_vip, member_pool, member_out):
-                        with self.vip(pool=pool, subnet=vip_sub):
-                            calls = [
-                                mock.call(
-                                    'POST', '/api/workflow/' +
-                                    pool['pool']['id'] +
-                                    '/action/BaseCreate',
-                                    mock.ANY, driver.TEMPLATE_HEADER
-                                )
-                            ]
-                            self.driver_rest_call_mock.assert_has_calls(
-                                calls, any_order=True)
-
-                            mock_calls = self.driver_rest_call_mock.mock_calls
-                            params = mock_calls[-2][1][2]['parameters']
-                            member_subnet_array = params['member_subnet_array']
-                            member_mask_array = params['member_mask_array']
-                            member_gw_array = params['member_gw_array']
-                            self.assertEqual(['10.0.0.0',
-                                              '255.255.255.255',
-                                              '30.0.0.0'],
-                                             member_subnet_array)
-                            self.assertEqual(['255.255.255.0',
-                                              '255.255.255.255',
-                                              '255.255.255.0'],
-                                             member_mask_array)
-                            self.assertEqual(
-                                [pool_sub['subnet']['gateway_ip'],
-                                 '255.255.255.255',
-                                 pool_sub['subnet']['gateway_ip']],
-                                member_gw_array)
-
-    def test_create_member_on_different_subnet_no_port(self):
-        with contextlib.nested(
-            self.subnet(),
-            self.subnet(cidr='20.0.0.0/24'),
-            self.subnet(cidr='30.0.0.0/24')
-        ) as (vip_sub, pool_sub, member_sub):
-            with self.pool(provider='radware',
-                           subnet_id=pool_sub['subnet']['id']) as pool:
-                with self.member(pool_id=pool['pool']['id'],
-                                 address='30.0.0.2'):
-                    with self.vip(pool=pool, subnet=vip_sub):
-                        calls = [
-                            mock.call(
-                                'POST', '/api/workflow/' +
-                                pool['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            )
-                        ]
-                        self.driver_rest_call_mock.assert_has_calls(
-                            calls, any_order=True)
-
-                        mock_calls = self.driver_rest_call_mock.mock_calls
-                        params = mock_calls[-2][1][2]['parameters']
-                        member_subnet_array = params['member_subnet_array']
-                        member_mask_array = params['member_mask_array']
-                        member_gw_array = params['member_gw_array']
-                        self.assertEqual(['30.0.0.2'],
-                                         member_subnet_array)
-                        self.assertEqual(['255.255.255.255'],
-                                         member_mask_array)
-                        self.assertEqual([pool_sub['subnet']['gateway_ip']],
-                                         member_gw_array)
-
-    def test_create_member_on_different_subnet_multiple_ports(self):
-        cfg.CONF.set_override("allow_overlapping_ips", 'true')
-        with self.network() as other_net:
-            with contextlib.nested(
-                self.subnet(),
-                self.subnet(cidr='20.0.0.0/24'),
-                self.subnet(cidr='30.0.0.0/24'),
-                self.subnet(network=other_net, cidr='30.0.0.0/24')
-            ) as (vip_sub, pool_sub, member_sub1, member_sub2):
-                with self.pool(provider='radware',
-                               subnet_id=pool_sub['subnet']['id']) as pool:
-                    with contextlib.nested(
-                        self.port(subnet=member_sub1,
-                                  fixed_ips=[{'ip_address': '30.0.0.2'}]),
-                        self.port(subnet=member_sub2,
-                                  fixed_ips=[{'ip_address': '30.0.0.2'}])):
-                        with self.member(pool_id=pool['pool']['id'],
-                                         address='30.0.0.2'):
-                            with self.vip(pool=pool, subnet=vip_sub):
-                                calls = [
-                                    mock.call(
-                                        'POST', '/api/workflow/' +
-                                        pool['pool']['id'] +
-                                        '/action/BaseCreate',
-                                        mock.ANY, driver.TEMPLATE_HEADER
-                                    )
-                                ]
-                                self.driver_rest_call_mock.assert_has_calls(
-                                    calls, any_order=True)
-
-                                calls = self.driver_rest_call_mock.mock_calls
-                                params = calls[-2][1][2]['parameters']
-                                m_sub_array = params['member_subnet_array']
-                                m_mask_array = params['member_mask_array']
-                                m_gw_array = params['member_gw_array']
-                                self.assertEqual(['30.0.0.2'],
-                                                 m_sub_array)
-                                self.assertEqual(['255.255.255.255'],
-                                                 m_mask_array)
-                                self.assertEqual(
-                                    [pool_sub['subnet']['gateway_ip']],
-                                    m_gw_array)
-
-    def test_update_member_with_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           subnet_id=subnet['subnet']['id']) as p:
-                with self.member(pool_id=p['pool']['id']) as member:
-                    with self.vip(pool=p, subnet=subnet):
-                        self.plugin_instance.update_member(
-                            context.get_admin_context(),
-                            member['member']['id'], member
-                        )
-                        calls = [
-                            mock.call(
-                                'POST', '/api/workflow/' + p['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            ),
-                            mock.call(
-                                'POST', '/api/workflow/' + p['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            )
-                        ]
-                        self.driver_rest_call_mock.assert_has_calls(
-                            calls, any_order=True)
-
-                        updated_member = self.plugin_instance.get_member(
-                            context.get_admin_context(),
-                            member['member']['id']
-                        )
-
-                        updated_member = self.plugin_instance.get_member(
-                            context.get_admin_context(),
-                            member['member']['id']
-                        )
-                        self.assertEqual(constants.ACTIVE,
-                                         updated_member['status'])
-
-    def test_update_member_without_vip(self):
-        with self.subnet():
-            with self.pool(provider='radware') as pool:
-                with self.member(pool_id=pool['pool']['id']) as member:
-                    member['member']['status'] = constants.PENDING_UPDATE
-                    updated_member = self.plugin_instance.update_member(
-                        context.get_admin_context(),
-                        member['member']['id'], member
-                    )
-                    self.assertEqual(constants.PENDING_UPDATE,
-                                     updated_member['status'])
-
-    def test_delete_member_with_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(provider='radware',
-                           subnet_id=subnet['subnet']['id']) as p:
-                with self.member(pool_id=p['pool']['id'],
-                                 do_delete=False) as m:
-                    with self.vip(pool=p, subnet=subnet):
-
-                        # Reset mock and
-                        # wait for being sure the member
-                        # Changed status from PENDING-CREATE
-                        # to ACTIVE
-
-                        self.plugin_instance.delete_member(
-                            context.get_admin_context(),
-                            m['member']['id']
-                        )
-
-                        name, args, kwargs = (
-                            self.driver_rest_call_mock.mock_calls[-2]
-                        )
-                        deletion_post_graph = str(args[2])
-
-                        self.assertTrue(re.search(
-                            r'.*\'member_address_array\': \[\].*',
-                            deletion_post_graph
-                        ))
-
-                        calls = [
-                            mock.call(
-                                'POST', '/api/workflow/' + p['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            )
-                        ]
-                        self.driver_rest_call_mock.assert_has_calls(
-                            calls, any_order=True)
-
-                        self.assertRaises(loadbalancer.MemberNotFound,
-                                          self.plugin_instance.get_member,
-                                          context.get_admin_context(),
-                                          m['member']['id'])
-
-    def test_delete_member_without_vip(self):
-        with self.subnet():
-            with self.pool(provider='radware') as p:
-                with self.member(pool_id=p['pool']['id'],
-                                 do_delete=False) as m:
-                    self.plugin_instance.delete_member(
-                        context.get_admin_context(), m['member']['id']
-                    )
-                    self.assertRaises(loadbalancer.MemberNotFound,
-                                      self.plugin_instance.get_member,
-                                      context.get_admin_context(),
-                                      m['member']['id'])
-
-    def test_create_hm_with_vip(self):
-        with self.subnet() as subnet:
-            with self.health_monitor() as hm:
-                with self.pool(provider='radware',
-                               subnet_id=subnet['subnet']['id']) as pool:
-                    with self.vip(pool=pool, subnet=subnet):
-
-                        self.plugin_instance.create_pool_health_monitor(
-                            context.get_admin_context(),
-                            hm, pool['pool']['id']
-                        )
-
-                        # Test REST calls
-                        calls = [
-                            mock.call(
-                                'POST', '/api/workflow/' + pool['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            ),
-                            mock.call(
-                                'POST', '/api/workflow/' + pool['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            )
-                        ]
-                        self.driver_rest_call_mock.assert_has_calls(
-                            calls, any_order=True)
-
-                        phm = self.plugin_instance.get_pool_health_monitor(
-                            context.get_admin_context(),
-                            hm['health_monitor']['id'], pool['pool']['id']
-                        )
-                        self.assertEqual(constants.ACTIVE, phm['status'])
-
-    def test_delete_pool_hm_with_vip(self):
-        with self.subnet() as subnet:
-            with self.health_monitor(do_delete=False) as hm:
-                with self.pool(provider='radware',
-                               subnet_id=subnet['subnet']['id']) as pool:
-                    with self.vip(pool=pool, subnet=subnet):
-                        self.plugin_instance.create_pool_health_monitor(
-                            context.get_admin_context(),
-                            hm, pool['pool']['id']
-                        )
-
-                        self.plugin_instance.delete_pool_health_monitor(
-                            context.get_admin_context(),
-                            hm['health_monitor']['id'],
-                            pool['pool']['id']
-                        )
-
-                        name, args, kwargs = (
-                            self.driver_rest_call_mock.mock_calls[-2]
-                        )
-                        deletion_post_graph = str(args[2])
-
-                        self.assertTrue(re.search(
-                            r'.*\'hm_uuid_array\': \[\].*',
-                            deletion_post_graph
-                        ))
-
-                        calls = [
-                            mock.call(
-                                'POST', '/api/workflow/' + pool['pool']['id'] +
-                                '/action/BaseCreate',
-                                mock.ANY, driver.TEMPLATE_HEADER
-                            )
-                        ]
-                        self.driver_rest_call_mock.assert_has_calls(
-                            calls, any_order=True)
-
-                        self.assertRaises(
-                            loadbalancer.PoolMonitorAssociationNotFound,
-                            self.plugin_instance.get_pool_health_monitor,
-                            context.get_admin_context(),
-                            hm['health_monitor']['id'],
-                            pool['pool']['id']
-                        )
diff --git a/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py b/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py
deleted file mode 100644
index f799e9e..0000000
--- a/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py
+++ /dev/null
@@ -1,749 +0,0 @@
-# Copyright 2013 New Dream Network, LLC (DreamHost)
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-
-import mock
-from neutron import context
-from neutron.db import servicetype_db as st_db
-from neutron.extensions import portbindings
-from neutron import manager
-from neutron.plugins.common import constants
-from neutron.tests.unit import testlib_api
-from oslo_utils import uuidutils
-import six
-from six import moves
-from webob import exc
-
-from neutron_lbaas.db.loadbalancer import loadbalancer_db as ldb
-from neutron_lbaas.extensions import loadbalancer
-from neutron_lbaas.services.loadbalancer.drivers.common \
-    import agent_driver_base
-from neutron_lbaas.tests import base
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-
-class TestLoadBalancerPluginBase(
-    test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-
-    def setUp(self):
-        def reset_device_driver():
-            agent_driver_base.AgentDriverBase.device_driver = None
-        self.addCleanup(reset_device_driver)
-
-        self.mock_importer = mock.patch.object(
-            agent_driver_base, 'importutils').start()
-
-        # needed to reload provider configuration
-        st_db.ServiceTypeManager._instance = None
-        agent_driver_base.AgentDriverBase.device_driver = 'dummy'
-        super(TestLoadBalancerPluginBase, self).setUp(
-            lbaas_provider=('LOADBALANCER:lbaas:neutron_lbaas.services.'
-                            'loadbalancer.drivers.common.agent_driver_base.'
-                            'AgentDriverBase:default'))
-
-        # we need access to loaded plugins to modify models
-        loaded_plugins = manager.NeutronManager().get_service_plugins()
-
-        self.plugin_instance = loaded_plugins[constants.LOADBALANCER]
-
-
-class TestLoadBalancerCallbacks(TestLoadBalancerPluginBase):
-    def setUp(self):
-        super(TestLoadBalancerCallbacks, self).setUp()
-
-        self.callbacks = agent_driver_base.LoadBalancerCallbacks(
-            self.plugin_instance
-        )
-        get_lbaas_agents_patcher = mock.patch(
-            'neutron_lbaas.services.loadbalancer.agent_scheduler'
-            '.LbaasAgentSchedulerDbMixin.get_lbaas_agents')
-        get_lbaas_agents_patcher.start()
-
-    def test_get_ready_devices(self):
-        with self.vip() as vip:
-            with mock.patch('neutron_lbaas.services.loadbalancer.'
-                            'agent_scheduler.LbaasAgentSchedulerDbMixin.'
-                            'list_pools_on_lbaas_agent') as mock_agent_pools:
-                mock_agent_pools.return_value = {
-                    'pools': [{'id': vip['vip']['pool_id']}]}
-                ready = self.callbacks.get_ready_devices(
-                    context.get_admin_context(),
-                )
-                self.assertEqual([vip['vip']['pool_id']], ready)
-
-    def test_get_ready_devices_multiple_vips_and_pools(self):
-        ctx = context.get_admin_context()
-
-        # add 3 pools and 2 vips directly to DB
-        # to create 2 "ready" devices and one pool without vip
-        pools = []
-        for i in moves.range(3):
-            pools.append(ldb.Pool(id=uuidutils.generate_uuid(),
-                                  subnet_id=self._subnet_id,
-                                  protocol="HTTP",
-                                  lb_method="ROUND_ROBIN",
-                                  status=constants.ACTIVE,
-                                  admin_state_up=True))
-            ctx.session.add(pools[i])
-
-        vip0 = ldb.Vip(id=uuidutils.generate_uuid(),
-                       protocol_port=80,
-                       protocol="HTTP",
-                       pool_id=pools[0].id,
-                       status=constants.ACTIVE,
-                       admin_state_up=True,
-                       connection_limit=3)
-        ctx.session.add(vip0)
-        pools[0].vip_id = vip0.id
-
-        vip1 = ldb.Vip(id=uuidutils.generate_uuid(),
-                       protocol_port=80,
-                       protocol="HTTP",
-                       pool_id=pools[1].id,
-                       status=constants.ACTIVE,
-                       admin_state_up=True,
-                       connection_limit=3)
-        ctx.session.add(vip1)
-        pools[1].vip_id = vip1.id
-
-        ctx.session.flush()
-
-        self.assertEqual(3, ctx.session.query(ldb.Pool).count())
-        self.assertEqual(2, ctx.session.query(ldb.Vip).count())
-        with mock.patch('neutron_lbaas.services.loadbalancer.agent_scheduler'
-                        '.LbaasAgentSchedulerDbMixin'
-                        '.list_pools_on_lbaas_agent') as mock_agent_pools:
-            mock_agent_pools.return_value = {'pools': [{'id': pools[0].id},
-                                                       {'id': pools[1].id},
-                                                       {'id': pools[2].id}]}
-            ready = self.callbacks.get_ready_devices(ctx)
-            self.assertEqual(3, len(ready))
-            self.assertIn(pools[0].id, ready)
-            self.assertIn(pools[1].id, ready)
-            self.assertIn(pools[2].id, ready)
-        # cleanup
-        ctx.session.query(ldb.Pool).delete()
-        ctx.session.query(ldb.Vip).delete()
-
-    def test_get_ready_devices_inactive_vip(self):
-        with self.vip() as vip:
-
-            # set the vip inactive need to use plugin directly since
-            # status is not tenant mutable
-            self.plugin_instance.update_vip(
-                context.get_admin_context(),
-                vip['vip']['id'],
-                {'vip': {'status': constants.INACTIVE}}
-            )
-            with mock.patch('neutron_lbaas.services.loadbalancer.'
-                            'agent_scheduler.LbaasAgentSchedulerDbMixin.'
-                            'list_pools_on_lbaas_agent') as mock_agent_pools:
-                mock_agent_pools.return_value = {
-                    'pools': [{'id': vip['vip']['pool_id']}]}
-                ready = self.callbacks.get_ready_devices(
-                    context.get_admin_context(),
-                )
-                self.assertEqual([vip['vip']['pool_id']], ready)
-
-    def test_get_ready_devices_inactive_pool(self):
-        with self.vip() as vip:
-
-            # set the pool inactive need to use plugin directly since
-            # status is not tenant mutable
-            self.plugin_instance.update_pool(
-                context.get_admin_context(),
-                vip['vip']['pool_id'],
-                {'pool': {'status': constants.INACTIVE}}
-            )
-            with mock.patch('neutron_lbaas.services.loadbalancer.'
-                            'agent_scheduler.LbaasAgentSchedulerDbMixin.'
-                            'list_pools_on_lbaas_agent') as mock_agent_pools:
-                mock_agent_pools.return_value = {
-                    'pools': [{'id': vip['vip']['pool_id']}]}
-                ready = self.callbacks.get_ready_devices(
-                    context.get_admin_context(),
-                )
-                self.assertFalse(ready)
-
-    def test_get_logical_device_non_active(self):
-        with self.pool() as pool:
-            ctx = context.get_admin_context()
-            for status in ('INACTIVE', 'PENDING_CREATE', 'PENDING_UPDATE'):
-                self.plugin_instance.update_status(
-                    ctx, ldb.Pool, pool['pool']['id'], status)
-                pool['pool']['status'] = status
-                expected = {
-                    'pool': pool['pool'],
-                    'members': [],
-                    'healthmonitors': [],
-                    'driver': 'dummy'
-                }
-
-                logical_config = self.callbacks.get_logical_device(
-                    ctx, pool['pool']['id']
-                )
-
-                self.assertEqual(expected, logical_config)
-
-    def test_get_logical_device_active(self):
-        with self.pool() as pool:
-            with self.vip(pool=pool) as vip:
-                with self.member(pool_id=vip['vip']['pool_id']) as member:
-                    ctx = context.get_admin_context()
-                    # activate objects
-                    self.plugin_instance.update_status(
-                        ctx, ldb.Pool, pool['pool']['id'], 'ACTIVE')
-                    self.plugin_instance.update_status(
-                        ctx, ldb.Member, member['member']['id'], 'ACTIVE')
-                    self.plugin_instance.update_status(
-                        ctx, ldb.Vip, vip['vip']['id'], 'ACTIVE')
-
-                    # build the expected
-                    port = self.plugin_instance._core_plugin.get_port(
-                        ctx, vip['vip']['port_id']
-                    )
-                    subnet = self.plugin_instance._core_plugin.get_subnet(
-                        ctx, vip['vip']['subnet_id']
-                    )
-                    port['fixed_ips'][0]['subnet'] = subnet
-
-                    # reload pool to add members and vip
-                    pool = self.plugin_instance.get_pool(
-                        ctx, pool['pool']['id']
-                    )
-
-                    pool['status'] = constants.ACTIVE
-                    vip['vip']['status'] = constants.ACTIVE
-                    vip['vip']['port'] = port
-                    member['member']['status'] = constants.ACTIVE
-
-                    expected = {
-                        'pool': pool,
-                        'vip': vip['vip'],
-                        'members': [member['member']],
-                        'healthmonitors': [],
-                        'driver': 'dummy'
-                    }
-
-                    logical_config = self.callbacks.get_logical_device(
-                        ctx, pool['id']
-                    )
-
-                    self.assertEqual(expected, logical_config)
-
-    def test_get_logical_device_inactive_member(self):
-        with self.pool() as pool:
-            with self.vip(pool=pool) as vip:
-                with self.member(pool_id=vip['vip']['pool_id']) as member:
-                    ctx = context.get_admin_context()
-                    self.plugin_instance.update_status(ctx, ldb.Pool,
-                                                       pool['pool']['id'],
-                                                       'ACTIVE')
-                    self.plugin_instance.update_status(ctx, ldb.Vip,
-                                                       vip['vip']['id'],
-                                                       'ACTIVE')
-                    self.plugin_instance.update_status(ctx, ldb.Member,
-                                                       member['member']['id'],
-                                                       'INACTIVE')
-
-                    logical_config = self.callbacks.get_logical_device(
-                        ctx, pool['pool']['id'])
-
-                    member['member']['status'] = constants.INACTIVE
-                    self.assertEqual([member['member']],
-                                     logical_config['members'])
-
-    def test_get_logical_device_pending_create_member(self):
-        with self.pool() as pool:
-            with self.vip(pool=pool) as vip:
-                with self.member(pool_id=vip['vip']['pool_id']) as member:
-                    ctx = context.get_admin_context()
-                    self.plugin_instance.update_status(ctx, ldb.Pool,
-                                                       pool['pool']['id'],
-                                                       'ACTIVE')
-                    self.plugin_instance.update_status(ctx, ldb.Vip,
-                                                       vip['vip']['id'],
-                                                       'ACTIVE')
-
-                    member = self.plugin_instance.get_member(
-                        ctx, member['member']['id'])
-                    self.assertEqual('PENDING_CREATE',
-                                     member['status'])
-                    logical_config = self.callbacks.get_logical_device(
-                        ctx, pool['pool']['id'])
-
-                    self.assertEqual([member], logical_config['members'])
-
-    def test_get_logical_device_pending_create_health_monitor(self):
-        with self.health_monitor() as monitor:
-            with self.pool() as pool:
-                with self.vip(pool=pool) as vip:
-                    ctx = context.get_admin_context()
-                    self.plugin_instance.update_status(ctx, ldb.Pool,
-                                                       pool['pool']['id'],
-                                                       'ACTIVE')
-                    self.plugin_instance.update_status(ctx, ldb.Vip,
-                                                       vip['vip']['id'],
-                                                       'ACTIVE')
-                    self.plugin_instance.create_pool_health_monitor(
-                        ctx, monitor, pool['pool']['id'])
-                    pool = self.plugin_instance.get_pool(
-                        ctx, pool['pool']['id'])
-                    monitor = self.plugin_instance.get_health_monitor(
-                        ctx, monitor['health_monitor']['id'])
-
-                    self.assertEqual(
-                        'PENDING_CREATE',
-                        pool['health_monitors_status'][0]['status'])
-                    logical_config = self.callbacks.get_logical_device(
-                        ctx, pool['id'])
-
-                    self.assertEqual([monitor],
-                                     logical_config['healthmonitors'])
-
-    def _update_port_test_helper(self, expected, func, **kwargs):
-        core = self.plugin_instance._core_plugin
-
-        with self.pool() as pool:
-            with self.vip(pool=pool) as vip:
-                with self.member(pool_id=vip['vip']['pool_id']):
-                    ctx = context.get_admin_context()
-                    func(ctx, port_id=vip['vip']['port_id'], **kwargs)
-
-                    db_port = core.get_port(ctx, vip['vip']['port_id'])
-
-                    for k, v in six.iteritems(expected):
-                        self.assertEqual(v, db_port[k])
-
-    def test_plug_vip_port(self):
-        exp = {
-            'device_owner': 'neutron:' + constants.LOADBALANCER,
-            'admin_state_up': True
-        }
-        self._update_port_test_helper(
-            exp,
-            self.callbacks.plug_vip_port,
-            host='host'
-        )
-
-    def test_plug_vip_port_mock_with_host(self):
-        exp = {
-            'device_owner': 'neutron:' + constants.LOADBALANCER,
-            'admin_state_up': True,
-            portbindings.HOST_ID: 'host'
-        }
-        with mock.patch.object(
-            self.plugin._core_plugin, 'update_port') as mock_update_port:
-            with self.pool() as pool:
-                with self.vip(pool=pool) as vip:
-                    ctx = context.get_admin_context()
-                    self.callbacks.plug_vip_port(
-                        ctx, port_id=vip['vip']['port_id'], host='host')
-            mock_update_port.assert_called_once_with(
-                ctx, vip['vip']['port_id'],
-                {'port': testlib_api.SubDictMatch(exp)})
-
-    def test_unplug_vip_port(self):
-        exp = {
-            'device_owner': '',
-            'device_id': '',
-            'admin_state_up': False
-        }
-        self._update_port_test_helper(
-            exp,
-            self.callbacks.unplug_vip_port,
-            host='host'
-        )
-
-    def test_pool_deployed(self):
-        with self.pool() as pool:
-            with self.vip(pool=pool) as vip:
-                with self.member(pool_id=vip['vip']['pool_id']) as member:
-                    ctx = context.get_admin_context()
-                    p = self.plugin_instance.get_pool(ctx, pool['pool']['id'])
-                    self.assertEqual('PENDING_CREATE', p['status'])
-                    v = self.plugin_instance.get_vip(ctx, vip['vip']['id'])
-                    self.assertEqual('PENDING_CREATE', v['status'])
-                    m = self.plugin_instance.get_member(
-                        ctx, member['member']['id'])
-                    self.assertEqual('PENDING_CREATE', m['status'])
-
-                    self.callbacks.pool_deployed(ctx, pool['pool']['id'])
-
-                    p = self.plugin_instance.get_pool(ctx, pool['pool']['id'])
-                    self.assertEqual('ACTIVE', p['status'])
-                    v = self.plugin_instance.get_vip(ctx, vip['vip']['id'])
-                    self.assertEqual('ACTIVE', v['status'])
-                    m = self.plugin_instance.get_member(
-                        ctx, member['member']['id'])
-                    self.assertEqual('ACTIVE', m['status'])
-
-    def test_update_status_pool(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            p = self.plugin_instance.get_pool(ctx, pool_id)
-            self.assertEqual('PENDING_CREATE', p['status'])
-            self.callbacks.update_status(ctx, 'pool', pool_id, 'ACTIVE')
-            p = self.plugin_instance.get_pool(ctx, pool_id)
-            self.assertEqual('ACTIVE', p['status'])
-
-    def test_update_status_pool_deleted_already(self):
-        with mock.patch.object(agent_driver_base, 'LOG') as mock_log:
-            pool_id = 'deleted_pool'
-            ctx = context.get_admin_context()
-            self.assertRaises(loadbalancer.PoolNotFound,
-                              self.plugin_instance.get_pool, ctx, pool_id)
-            self.callbacks.update_status(ctx, 'pool', pool_id, 'ACTIVE')
-            self.assertTrue(mock_log.warning.called)
-
-    def test_update_status_health_monitor(self):
-        with contextlib.nested(
-            self.health_monitor(),
-            self.pool()
-        ) as (hm, pool):
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            self.plugin_instance.create_pool_health_monitor(ctx, hm, pool_id)
-            hm_id = hm['health_monitor']['id']
-            h = self.plugin_instance.get_pool_health_monitor(ctx, hm_id,
-                                                             pool_id)
-            self.assertEqual('PENDING_CREATE', h['status'])
-            self.callbacks.update_status(
-                ctx, 'health_monitor',
-                {'monitor_id': hm_id, 'pool_id': pool_id}, 'ACTIVE')
-            h = self.plugin_instance.get_pool_health_monitor(ctx, hm_id,
-                                                             pool_id)
-            self.assertEqual('ACTIVE', h['status'])
-
-
-class TestLoadBalancerAgentApi(base.BaseTestCase):
-    def setUp(self):
-        super(TestLoadBalancerAgentApi, self).setUp()
-
-        self.api = agent_driver_base.LoadBalancerAgentApi('topic')
-
-    def test_init(self):
-        self.assertEqual('topic', self.api.client.target.topic)
-
-    def _call_test_helper(self, method_name, method_args):
-        with contextlib.nested(
-            mock.patch.object(self.api.client, 'cast'),
-            mock.patch.object(self.api.client, 'prepare'),
-        ) as (
-            rpc_mock, prepare_mock
-        ):
-            prepare_mock.return_value = self.api.client
-            getattr(self.api, method_name)(mock.sentinel.context,
-                                           host='host',
-                                           **method_args)
-
-        prepare_args = {'server': 'host'}
-        prepare_mock.assert_called_once_with(**prepare_args)
-
-        if method_name == 'agent_updated':
-            method_args = {'payload': method_args}
-        rpc_mock.assert_called_once_with(mock.sentinel.context, method_name,
-                                         **method_args)
-
-    def test_agent_updated(self):
-        self._call_test_helper('agent_updated', {'admin_state_up': 'test'})
-
-    def test_create_pool(self):
-        self._call_test_helper('create_pool', {'pool': 'test',
-                                               'driver_name': 'dummy'})
-
-    def test_update_pool(self):
-        self._call_test_helper('update_pool', {'old_pool': 'test',
-                                               'pool': 'test'})
-
-    def test_delete_pool(self):
-        self._call_test_helper('delete_pool', {'pool': 'test'})
-
-    def test_create_vip(self):
-        self._call_test_helper('create_vip', {'vip': 'test'})
-
-    def test_update_vip(self):
-        self._call_test_helper('update_vip', {'old_vip': 'test',
-                                              'vip': 'test'})
-
-    def test_delete_vip(self):
-        self._call_test_helper('delete_vip', {'vip': 'test'})
-
-    def test_create_member(self):
-        self._call_test_helper('create_member', {'member': 'test'})
-
-    def test_update_member(self):
-        self._call_test_helper('update_member', {'old_member': 'test',
-                                                 'member': 'test'})
-
-    def test_delete_member(self):
-        self._call_test_helper('delete_member', {'member': 'test'})
-
-    def test_create_monitor(self):
-        self._call_test_helper('create_pool_health_monitor',
-                               {'health_monitor': 'test', 'pool_id': 'test'})
-
-    def test_update_monitor(self):
-        self._call_test_helper('update_pool_health_monitor',
-                               {'old_health_monitor': 'test',
-                                'health_monitor': 'test',
-                                'pool_id': 'test'})
-
-    def test_delete_monitor(self):
-        self._call_test_helper('delete_pool_health_monitor',
-                               {'health_monitor': 'test', 'pool_id': 'test'})
-
-
-class TestLoadBalancerPluginNotificationWrapper(TestLoadBalancerPluginBase):
-    def setUp(self):
-        self.log = mock.patch.object(agent_driver_base, 'LOG')
-        api_cls = mock.patch.object(agent_driver_base,
-                                    'LoadBalancerAgentApi').start()
-        super(TestLoadBalancerPluginNotificationWrapper, self).setUp()
-        self.mock_api = api_cls.return_value
-
-        self.mock_get_driver = mock.patch.object(self.plugin_instance,
-                                                 '_get_driver')
-        self.mock_get_driver.return_value = (agent_driver_base.
-                                             AgentDriverBase(
-                                                 self.plugin_instance
-                                             ))
-
-    def test_create_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(subnet=subnet) as pool:
-                with self.vip(pool=pool, subnet=subnet) as vip:
-                    self.mock_api.create_vip.assert_called_once_with(
-                        mock.ANY,
-                        vip['vip'],
-                        'host'
-                    )
-
-    def test_update_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(subnet=subnet) as pool:
-                with self.vip(pool=pool, subnet=subnet) as vip:
-                    ctx = context.get_admin_context()
-                    old_vip = vip['vip'].copy()
-                    vip['vip'].pop('status')
-                    new_vip = self.plugin_instance.update_vip(
-                        ctx,
-                        vip['vip']['id'],
-                        vip
-                    )
-
-                    self.mock_api.update_vip.assert_called_once_with(
-                        mock.ANY,
-                        old_vip,
-                        new_vip,
-                        'host'
-                    )
-
-                    self.assertEqual(
-                        constants.PENDING_UPDATE,
-                        new_vip['status']
-                    )
-
-    def test_delete_vip(self):
-        with self.subnet() as subnet:
-            with self.pool(subnet=subnet) as pool:
-                with self.vip(pool=pool, subnet=subnet,
-                              do_delete=False) as vip:
-                    ctx = context.get_admin_context()
-                    self.plugin_instance.delete_vip(ctx, vip['vip']['id'])
-                    vip['vip']['status'] = 'PENDING_DELETE'
-                    self.mock_api.delete_vip.assert_called_once_with(
-                        mock.ANY,
-                        vip['vip'],
-                        'host'
-                    )
-
-    def test_create_pool(self):
-        with self.pool() as pool:
-            self.mock_api.create_pool.assert_called_once_with(
-                mock.ANY,
-                pool['pool'],
-                mock.ANY,
-                'dummy'
-            )
-
-    def test_update_pool_non_active(self):
-        with self.pool() as pool:
-            pool['pool']['status'] = 'INACTIVE'
-            ctx = context.get_admin_context()
-            orig_pool = pool['pool'].copy()
-            del pool['pool']['provider']
-            self.plugin_instance.update_pool(ctx, pool['pool']['id'], pool)
-            self.mock_api.delete_pool.assert_called_once_with(
-                mock.ANY, orig_pool, 'host')
-
-    def test_update_pool_no_vip_id(self):
-        with self.pool() as pool:
-            ctx = context.get_admin_context()
-            orig_pool = pool['pool'].copy()
-            del pool['pool']['provider']
-            updated = self.plugin_instance.update_pool(
-                ctx, pool['pool']['id'], pool)
-            self.mock_api.update_pool.assert_called_once_with(
-                mock.ANY, orig_pool, updated, 'host')
-
-    def test_update_pool_with_vip_id(self):
-        with self.pool() as pool:
-            with self.vip(pool=pool) as vip:
-                ctx = context.get_admin_context()
-                old_pool = pool['pool'].copy()
-                old_pool['vip_id'] = vip['vip']['id']
-                del pool['pool']['provider']
-                updated = self.plugin_instance.update_pool(
-                    ctx, pool['pool']['id'], pool)
-                self.mock_api.update_pool.assert_called_once_with(
-                    mock.ANY, old_pool, updated, 'host')
-
-    def test_delete_pool(self):
-        with self.pool(do_delete=False) as pool:
-            req = self.new_delete_request('pools',
-                                          pool['pool']['id'])
-            res = req.get_response(self.ext_api)
-            self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-            pool['pool']['status'] = 'PENDING_DELETE'
-            self.mock_api.delete_pool.assert_called_once_with(
-                mock.ANY, pool['pool'], 'host')
-
-    def test_create_member(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            with self.member(pool_id=pool_id) as member:
-                self.mock_api.create_member.assert_called_once_with(
-                    mock.ANY, member['member'], 'host')
-
-    def test_update_member(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            with self.member(pool_id=pool_id) as member:
-                ctx = context.get_admin_context()
-                updated = self.plugin_instance.update_member(
-                    ctx, member['member']['id'], member)
-                self.mock_api.update_member.assert_called_once_with(
-                    mock.ANY, member['member'], updated, 'host')
-
-    def test_update_member_new_pool(self):
-        with self.pool() as pool1:
-            pool1_id = pool1['pool']['id']
-            with self.pool() as pool2:
-                pool2_id = pool2['pool']['id']
-                with self.member(pool_id=pool1_id) as member:
-                    self.mock_api.create_member.reset_mock()
-                    ctx = context.get_admin_context()
-                    old_member = member['member'].copy()
-                    member['member']['pool_id'] = pool2_id
-                    updated = self.plugin_instance.update_member(
-                        ctx, member['member']['id'], member)
-                    self.mock_api.delete_member.assert_called_once_with(
-                        mock.ANY, old_member, 'host')
-                    self.mock_api.create_member.assert_called_once_with(
-                        mock.ANY, updated, 'host')
-
-    def test_delete_member(self):
-        with self.pool() as pool:
-            pool_id = pool['pool']['id']
-            with self.member(pool_id=pool_id,
-                             do_delete=False) as member:
-                req = self.new_delete_request('members',
-                                              member['member']['id'])
-                res = req.get_response(self.ext_api)
-                self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-                member['member']['status'] = 'PENDING_DELETE'
-                self.mock_api.delete_member.assert_called_once_with(
-                    mock.ANY, member['member'], 'host')
-
-    def test_create_pool_health_monitor(self):
-        with contextlib.nested(
-            self.health_monitor(),
-            self.pool(),
-        ) as (hm, pool):
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            self.plugin_instance.create_pool_health_monitor(ctx, hm, pool_id)
-            # hm now has a ref to the pool with which it is associated
-            hm = self.plugin.get_health_monitor(
-                ctx, hm['health_monitor']['id'])
-            self.mock_api.create_pool_health_monitor.assert_called_once_with(
-                mock.ANY, hm, pool_id, 'host')
-
-    def test_delete_pool_health_monitor(self):
-        with contextlib.nested(
-            self.pool(),
-            self.health_monitor()
-        ) as (pool, hm):
-            pool_id = pool['pool']['id']
-            ctx = context.get_admin_context()
-            self.plugin_instance.create_pool_health_monitor(ctx, hm, pool_id)
-            # hm now has a ref to the pool with which it is associated
-            hm = self.plugin.get_health_monitor(
-                ctx, hm['health_monitor']['id'])
-            hm['pools'][0]['status'] = 'PENDING_DELETE'
-            self.plugin_instance.delete_pool_health_monitor(
-                ctx, hm['id'], pool_id)
-            self.mock_api.delete_pool_health_monitor.assert_called_once_with(
-                mock.ANY, hm, pool_id, 'host')
-
-    def test_update_health_monitor_associated_with_pool(self):
-        with contextlib.nested(
-            self.health_monitor(type='HTTP'),
-            self.pool()
-        ) as (monitor, pool):
-            data = {
-                'health_monitor': {
-                    'id': monitor['health_monitor']['id'],
-                    'tenant_id': self._tenant_id
-                }
-            }
-            req = self.new_create_request(
-                'pools',
-                data,
-                fmt=self.fmt,
-                id=pool['pool']['id'],
-                subresource='health_monitors')
-            res = req.get_response(self.ext_api)
-            self.assertEqual(exc.HTTPCreated.code, res.status_int)
-            # hm now has a ref to the pool with which it is associated
-            ctx = context.get_admin_context()
-            hm = self.plugin.get_health_monitor(
-                ctx, monitor['health_monitor']['id'])
-            self.mock_api.create_pool_health_monitor.assert_called_once_with(
-                mock.ANY,
-                hm,
-                pool['pool']['id'],
-                'host'
-            )
-
-            self.mock_api.reset_mock()
-            data = {'health_monitor': {'delay': 20,
-                                       'timeout': 20,
-                                       'max_retries': 2,
-                                       'admin_state_up': False}}
-            updated = hm.copy()
-            updated.update(data['health_monitor'])
-            req = self.new_update_request("health_monitors",
-                                          data,
-                                          monitor['health_monitor']['id'])
-            req.get_response(self.ext_api)
-            self.mock_api.update_pool_health_monitor.assert_called_once_with(
-                mock.ANY,
-                hm,
-                updated,
-                pool['pool']['id'],
-                'host')
diff --git a/tests/unit/services/loadbalancer/drivers/test_driver_base.py b/tests/unit/services/loadbalancer/drivers/test_driver_base.py
deleted file mode 100644
index 8122bd1..0000000
--- a/tests/unit/services/loadbalancer/drivers/test_driver_base.py
+++ /dev/null
@@ -1,160 +0,0 @@
-# Copyright 2015 Rackspace
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-#
-
-import mock
-from neutron.api.v2 import attributes
-from neutron import context as ncontext
-from neutron.plugins.common import constants
-
-from neutron_lbaas.drivers import driver_mixins
-from neutron_lbaas.extensions import loadbalancerv2
-from neutron_lbaas.services.loadbalancer import constants as lb_const
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-
-class DummyManager(driver_mixins.BaseManagerMixin):
-
-    def __init__(self, driver):
-        super(DummyManager, self).__init__(driver)
-        self.driver = driver
-        self._db_delete_method = None
-
-    @property
-    def db_delete_method(self):
-        return self._db_delete_method
-
-    def delete(self, context, obj):
-        pass
-
-    def update(self, context, obj_old, obj):
-        pass
-
-    def create(self, context, obj):
-        pass
-
-
-class TestBaseManager(test_db_loadbalancerv2.LbaasPluginDbTestCase):
-
-    def _setup_db_data(self, context):
-        hm = self.plugin.db.create_healthmonitor(
-            context, {'admin_state_up': True,
-                      'type': lb_const.HEALTH_MONITOR_HTTP,
-                      'delay': 1, 'timeout': 1, 'max_retries': 1})
-        lb = self.plugin.db.create_loadbalancer(
-            context, {'vip_address': '10.0.0.1',
-                      'vip_subnet_id': self.subnet_id,
-                      'admin_state_up': True})
-        pool = self.plugin.db.create_pool(
-            context, {'protocol': lb_const.PROTOCOL_HTTP,
-                      'session_persistence': None,
-                      'lb_algorithm': lb_const.LB_METHOD_ROUND_ROBIN,
-                      'admin_state_up': True, 'healthmonitor_id': hm.id,
-                      'loadbalancer_id': lb.id})
-        self.plugin.db.create_pool_member(
-            context, {'address': '10.0.0.1', 'protocol_port': 80,
-                      'admin_state_up': True}, pool.id)
-        listener = self.plugin.db.create_listener(
-            context, {'protocol_port': 80, 'protocol': lb_const.PROTOCOL_HTTP,
-                      'admin_state_up': True, 'loadbalancer_id': lb.id,
-                      'default_pool_id': pool.id, 'sni_container_ids': []})
-        return listener
-
-    def setUp(self):
-        super(TestBaseManager, self).setUp()
-        self.context = ncontext.get_admin_context()
-        self.driver = mock.Mock()
-        self.driver.plugin = self.plugin
-        self.manager = DummyManager(self.driver)
-        network = self._make_network(self.fmt, 'test-net', True)
-        self.subnet = self._make_subnet(
-            self.fmt, network, gateway=attributes.ATTR_NOT_SPECIFIED,
-            cidr='10.0.0.0/24')
-        self.subnet_id = self.subnet['subnet']['id']
-        self.listener = self._setup_db_data(self.context)
-
-
-class TestLBManager(TestBaseManager):
-
-    def setUp(self):
-        super(TestLBManager, self).setUp()
-        self.manager._db_delete_method = self.plugin.db.delete_loadbalancer
-
-    def test_success_completion(self):
-        self.manager.successful_completion(self.context,
-                                           self.listener.loadbalancer)
-        lb = self.plugin.db.get_loadbalancer(self.context,
-                                             self.listener.loadbalancer.id)
-        self.assertEqual(constants.ACTIVE, lb.provisioning_status)
-        self.assertEqual(lb_const.ONLINE, lb.operating_status)
-
-    def test_success_completion_delete(self):
-        self.plugin.db.delete_listener(self.context, self.listener.id)
-        self.manager.successful_completion(self.context,
-                                           self.listener.loadbalancer,
-                                           delete=True)
-        self.assertRaises(loadbalancerv2.EntityNotFound,
-                          self.plugin.db.get_loadbalancer,
-                          self.context,
-                          self.listener.loadbalancer.id)
-
-    def test_failed_completion(self):
-        self.manager.failed_completion(self.context,
-                                       self.listener.loadbalancer)
-        lb = self.plugin.db.get_loadbalancer(self.context,
-                                             self.listener.loadbalancer.id)
-        self.assertEqual(constants.ERROR, lb.provisioning_status)
-        self.assertEqual(lb_const.OFFLINE, lb.operating_status)
-        listener = self.plugin.db.get_listener(self.context, self.listener.id)
-        self.assertEqual(constants.PENDING_CREATE,
-                         listener.provisioning_status)
-        self.assertEqual(lb_const.OFFLINE, listener.operating_status)
-
-
-class TestListenerManager(TestBaseManager):
-    """This should also cover Pool, Member, and Health Monitor cases."""
-
-    def setUp(self):
-        super(TestListenerManager, self).setUp()
-        self.manager._db_delete_method = self.plugin.db.delete_listener
-
-    def test_success_completion(self):
-        self.manager.successful_completion(self.context, self.listener)
-        listener = self.plugin.db.get_listener(self.context, self.listener.id)
-        self.assertEqual(constants.ACTIVE, listener.provisioning_status)
-        self.assertEqual(lb_const.ONLINE, listener.operating_status)
-        self.assertEqual(constants.ACTIVE,
-                         listener.loadbalancer.provisioning_status)
-        # because the load balancer's original operating status was OFFLINE
-        self.assertEqual(lb_const.OFFLINE,
-                         listener.loadbalancer.operating_status)
-
-    def test_success_completion_delete(self):
-        self.manager.successful_completion(self.context,
-                                           self.listener,
-                                           delete=True)
-        self.assertRaises(loadbalancerv2.EntityNotFound,
-                          self.plugin.db.get_listener,
-                          self.context,
-                          self.listener.loadbalancer.id)
-
-    def test_failed_completion(self):
-        self.manager.failed_completion(self.context, self.listener)
-        lb = self.plugin.db.get_loadbalancer(self.context,
-                                             self.listener.loadbalancer.id)
-        self.assertEqual(constants.ACTIVE, lb.provisioning_status)
-        self.assertEqual(lb_const.OFFLINE, lb.operating_status)
-        listener = self.plugin.db.get_listener(self.context, self.listener.id)
-        self.assertEqual(constants.ERROR, listener.provisioning_status)
-        self.assertEqual(lb_const.OFFLINE, listener.operating_status)
diff --git a/tests/unit/services/loadbalancer/drivers/vmware/__init__.py b/tests/unit/services/loadbalancer/drivers/vmware/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/tests/unit/services/loadbalancer/drivers/vmware/test_edge_driver.py b/tests/unit/services/loadbalancer/drivers/vmware/test_edge_driver.py
deleted file mode 100644
index 0d6fbb1..0000000
--- a/tests/unit/services/loadbalancer/drivers/vmware/test_edge_driver.py
+++ /dev/null
@@ -1,502 +0,0 @@
-# Copyright 2015 VMware, Inc.
-# All Rights Reserved
-#
-# Licensed under the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-import contextlib
-import mock
-
-from neutron import context
-from neutron.plugins.common import constants
-
-from neutron import manager
-from neutron_lbaas.db.loadbalancer import loadbalancer_db as lb_db
-from neutron_lbaas.services.loadbalancer.drivers.vmware import db
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-
-EDGE_PROVIDER = ('LOADBALANCER:vmwareedge:neutron_lbaas.services.'
-                 'loadbalancer.drivers.vmware.edge_driver.'
-                 'EdgeLoadbalancerDriver:default')
-
-HEALTHMON_ID = 'cb297614-66c9-4048-8838-7e87231569ae'
-POOL_ID = 'b3dfb476-6fdf-4ddd-b6bd-e86ae78dc30b'
-TENANT_ID = 'f9135d3a908842bd8d785816c2c90d36'
-SUBNET_ID = 'c8924d77-ff57-406f-a13c-a8c5def01fc9'
-VIP_ID = 'f6393b95-34b0-4299-9001-cbc21e32bf03'
-VIP_PORT_ID = '49c547e3-6775-42ea-a607-91e8f1a07432'
-MEMBER_ID = '90dacafd-9c11-4af7-9d89-234e2d1fedb1'
-
-EDGE_ID = 'edge-x'
-EDGE_POOL_ID = '111'
-EDGE_VSE_ID = '222'
-APP_PROFILE_ID = '333'
-EDGE_MON_ID = '444'
-EDGE_FW_RULE_ID = '555'
-
-
-class TestLoadBalancerPluginBase(
-    test_db_loadbalancer.LoadBalancerPluginDbTestCase):
-    def setUp(self):
-        super(TestLoadBalancerPluginBase, self).setUp(
-            lbaas_provider=EDGE_PROVIDER)
-
-        loaded_plugins = manager.NeutronManager().get_service_plugins()
-        self.service_plugin = loaded_plugins[constants.LOADBALANCER]
-        self.edge_driver = self.service_plugin.drivers['vmwareedge']
-        self.service_plugin._core_plugin.nsx_v = mock.Mock()
-
-
-class TestEdgeLoadBalancerPlugin(TestLoadBalancerPluginBase):
-    def setUp(self):
-        super(TestEdgeLoadBalancerPlugin, self).setUp()
-        self.context = context.get_admin_context()
-
-    def test_create_pool_successful(self):
-        pool = {'id': POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'add_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.edge_driver, 'pool_successful')
-        ) as (mock_add_pool, mock_pool_successful):
-            self.edge_driver.create_pool_successful(self.context,
-                                                    pool,
-                                                    EDGE_ID, EDGE_POOL_ID)
-            mock_add_pool.assert_called_with(self.context, POOL_ID, EDGE_ID,
-                                             EDGE_POOL_ID)
-            mock_pool_successful.assert_called_with(self.context, pool)
-
-    def test_delete_pool_successful(self):
-        pool = {'id': POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(self.service_plugin, '_delete_db_pool'),
-            mock.patch.object(db, 'delete_nsxv_edge_pool_mapping')
-        ) as (mock_del_db_pool, mock_del_mapping):
-            self.edge_driver.delete_pool_successful(self.context, pool)
-            mock_del_db_pool.assert_called_with(self.context, POOL_ID)
-            mock_del_mapping.assert_called_with(self.context, POOL_ID)
-
-    def test_pool_successful(self):
-        pool = {'id': POOL_ID}
-
-        with mock.patch.object(self.service_plugin, 'update_status') as (
-                mock_update_status):
-            self.edge_driver.pool_successful(self.context, pool)
-            mock_update_status.assert_called_with(self.context, lb_db.Pool,
-                                                  pool['id'], constants.ACTIVE)
-
-    def test_pool_failed(self):
-        pool = {'id': POOL_ID}
-
-        with mock.patch.object(self.service_plugin, 'update_status') as (
-                mock_update_status):
-            self.edge_driver.pool_failed(self.context, pool)
-            mock_update_status.assert_called_with(self.context, lb_db.Pool,
-                                                  pool['id'], constants.ERROR)
-
-    def test_create_pool(self):
-        lbaas_pool = {
-            'status': 'PENDING_CREATE', 'lb_method': 'ROUND_ROBIN',
-            'protocol': 'HTTP', 'description': '', 'health_monitors': [],
-            'members': [], 'status_description': None, 'id': POOL_ID,
-            'vip_id': None, 'name': 'testpool', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'health_monitors_status': [], 'provider': 'vmwareedge'}
-
-        with mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                               'create_pool') as mock_create_pool:
-
-            self.edge_driver.create_pool(self.context, lbaas_pool)
-            mock_create_pool.assert_called_with(self.context, lbaas_pool)
-
-    def test_update_pool(self):
-        from_pool = {
-            'status': 'ACTIVE', 'lb_method': 'ROUND_ROBIN',
-            'protocol': 'HTTP', 'description': '', 'health_monitors': [],
-            'members': [], 'status_description': None, 'id': POOL_ID,
-            'vip_id': None, 'name': 'testpool2', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'health_monitors_status': [], 'provider': 'vmwareedge'}
-
-        to_pool = {
-            'status': 'PENDING_UPDATE', 'lb_method': 'LEAST_CONNECTIONS',
-            'protocol': 'HTTP', 'description': '', 'health_monitors': [],
-            'members': [], 'status_description': None, 'id': POOL_ID,
-            'vip_id': None, 'name': 'testpool2', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'health_monitors_status': [], 'provider': 'vmwareedge'}
-
-        mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'update_pool')
-        ) as (mock_get_mapping, mock_update_pool):
-
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.update_pool(self.context, from_pool, to_pool)
-            mock_update_pool.assert_called_with(self.context, from_pool,
-                                                to_pool, mapping)
-
-    def test_delete_pool(self):
-        lbaas_pool = {
-            'status': 'PENDING_CREATE', 'lb_method': 'ROUND_ROBIN',
-            'protocol': 'HTTP', 'description': '', 'health_monitors': [],
-            'members': [], 'status_description': None, 'id': POOL_ID,
-            'vip_id': None, 'name': 'testpool', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'health_monitors_status': [], 'provider': 'vmwareedge'}
-        mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.service_plugin, 'get_pool',
-                              return_value={}),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'delete_pool')
-        ) as (mock_get_mapping, mock_get_pool, mock_delete_pool):
-
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.delete_pool(self.context, lbaas_pool)
-            mock_delete_pool.assert_called_with(self.context, lbaas_pool,
-                                                mapping)
-
-    def test_create_vip_successful(self):
-        vip = {'pool_id': POOL_ID}
-        with contextlib.nested(
-            mock.patch.object(db, 'add_nsxv_edge_vip_mapping'),
-            mock.patch.object(self.edge_driver, 'vip_successful')
-        ) as (mock_add_vip_mapping, mock_vip_successful):
-
-            self.edge_driver.create_vip_successful(
-                self.context, vip, EDGE_ID, APP_PROFILE_ID, EDGE_VSE_ID,
-                EDGE_FW_RULE_ID)
-
-            mock_add_vip_mapping.assert_called_with(
-                self.context, POOL_ID, EDGE_ID, APP_PROFILE_ID,
-                EDGE_VSE_ID, EDGE_FW_RULE_ID)
-            mock_vip_successful.assert_called_with(self.context, vip)
-
-    def test_delete_vip_successful(self):
-        vip = {'pool_id': POOL_ID, 'id': VIP_ID}
-        with contextlib.nested(
-            mock.patch.object(db, 'delete_nsxv_edge_vip_mapping'),
-            mock.patch.object(self.service_plugin, '_delete_db_vip')
-        ) as (mock_del_vip_mapping, mock_del_vip):
-
-            self.edge_driver.delete_vip_successful(self.context, vip)
-            mock_del_vip_mapping.assert_called_with(self.context, POOL_ID)
-            mock_del_vip.assert_called_with(self.context, VIP_ID)
-
-    def test_vip_successful(self):
-        vip = {'pool_id': POOL_ID, 'id': VIP_ID}
-        with mock.patch.object(self.service_plugin, 'update_status') as (
-                mock_update_status):
-            self.edge_driver.vip_successful(self.context, vip)
-            mock_update_status.assert_called_with(
-                self.context, lb_db.Vip, VIP_ID, constants.ACTIVE)
-
-    def test_vip_failed(self):
-        vip = {'pool_id': POOL_ID, 'id': VIP_ID}
-        with mock.patch.object(self.service_plugin, 'update_status') as (
-                mock_update_status):
-            self.edge_driver.vip_failed(self.context, vip)
-            mock_update_status.assert_called_with(
-                self.context, lb_db.Vip, VIP_ID, constants.ERROR)
-
-    def test_create_vip(self):
-        lbaas_vip = {
-            'status': 'PENDING_CREATE', 'protocol': 'HTTP',
-            'description': '', 'address': '10.0.0.8', 'protocol_port': 555,
-            'port_id': VIP_PORT_ID, 'id': VIP_ID, 'status_description': None,
-            'name': 'testvip1', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'connection_limit': -1, 'pool_id': POOL_ID,
-            'session_persistence': {'type': 'SOURCE_IP'}}
-        mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'create_vip')
-        ) as (mock_get_mapping, mock_create_vip):
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.create_vip(self.context, lbaas_vip)
-            mock_create_vip.assert_called_with(self.context, lbaas_vip,
-                                               mapping)
-
-    def test_update_vip(self):
-        vip_from = {
-            'status': 'ACTIVE', 'protocol': 'HTTP', 'description': '',
-            'address': '10.0.0.8', 'protocol_port': 555L,
-            'port_id': VIP_PORT_ID, 'id': VIP_ID, 'status_description': None,
-            'name': 'testvip1', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'connection_limit': -1L, 'pool_id': POOL_ID,
-            'session_persistence': {'type': 'SOURCE_IP'}}
-        vip_to = {
-            'status': 'PENDING_UPDATE', 'protocol': 'HTTP',
-            'description': '', 'address': '10.0.0.8', 'protocol_port': 555L,
-            'port_id': VIP_PORT_ID, 'id': VIP_ID, 'status_description': None,
-            'name': 'testvip1', 'admin_state_up': True,
-            'subnet_id': SUBNET_ID, 'tenant_id': TENANT_ID,
-            'connection_limit': -1, 'pool_id': POOL_ID,
-            'session_persistence': {'type': 'HTTP_COOKIE'}}
-        pool_mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-        vip_mapping = {'edge_id': EDGE_ID, 'edge_vse_id': EDGE_VSE_ID,
-                       'edge_app_profile_id': APP_PROFILE_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(db, 'get_nsxv_edge_vip_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'update_vip')
-        ) as (mock_get_pool_mapping, mock_get_vip_mapping, mock_upd_vip):
-
-            mock_get_pool_mapping.return_value = pool_mapping
-            mock_get_vip_mapping.return_value = vip_mapping
-            self.edge_driver.update_vip(self.context, vip_from, vip_to)
-            mock_upd_vip.assert_called_with(self.context, vip_from, vip_to,
-                                            pool_mapping, vip_mapping)
-
-    def test_delete_vip(self):
-        lbaas_vip = {
-            'status': 'PENDING_DELETE', 'protocol': 'HTTP',
-            'description': '', 'address': '10.0.0.11', 'protocol_port': 555L,
-            'port_id': VIP_PORT_ID, 'id': VIP_ID, 'status_description': None,
-            'name': 'testvip', 'admin_state_up': True, 'subnet_id': SUBNET_ID,
-            'tenant_id': TENANT_ID, 'connection_limit': -1L,
-            'pool_id': POOL_ID, 'session_persistence': None}
-        mapping = {'edge_id': EDGE_ID, 'edge_vse_id': EDGE_VSE_ID,
-                   'edge_app_profile_id': APP_PROFILE_ID,
-                   'edge_fw_rule_id': EDGE_FW_RULE_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_vip_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'delete_vip')
-        ) as (mock_get_mapping, mock_del_vip):
-
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.delete_vip(self.context, lbaas_vip)
-            mock_del_vip.assert_called_with(self.context, lbaas_vip, mapping)
-
-    def test_member_successful(self):
-        member = {'id': MEMBER_ID}
-        with mock.patch.object(self.service_plugin, 'update_status') as (
-                mock_update_status):
-            self.edge_driver.member_successful(self.context, member)
-            mock_update_status.assert_called_with(
-                self.context, lb_db.Member, member['id'], constants.ACTIVE)
-
-    def test_member_failed(self):
-        member = {'id': MEMBER_ID}
-        with mock.patch.object(self.service_plugin, 'update_status') as (
-                mock_update_status):
-            self.edge_driver.member_failed(self.context, member)
-            mock_update_status.assert_called_with(
-                self.context, lb_db.Member, member['id'], constants.ERROR)
-
-    def test_create_member(self):
-        lbaas_member = {
-            'admin_state_up': True, 'status': 'PENDING_CREATE',
-            'status_description': None, 'weight': 5, 'address': '10.0.0.4',
-            'tenant_id': TENANT_ID, 'protocol_port': 555, 'id': MEMBER_ID,
-            'pool_id': POOL_ID}
-        mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'create_member')
-        ) as (mock_get_mapping, mock_create_member):
-
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.create_member(self.context, lbaas_member)
-            mock_create_member.assert_called_with(self.context, lbaas_member,
-                                                  mapping)
-
-    def test_update_member(self):
-        member_from = {
-            'admin_state_up': True, 'status': 'PENDING_UPDATE',
-            'status_description': None, 'weight': 5, 'address': '10.0.0.4',
-            'tenant_id': TENANT_ID, 'protocol_port': 555, 'id': MEMBER_ID,
-            'pool_id': POOL_ID}
-        member_to = {
-            'admin_state_up': True, 'status': 'ACTIVE',
-            'status_description': None, 'weight': 10, 'address': '10.0.0.4',
-            'tenant_id': TENANT_ID, 'protocol_port': 555, 'id': MEMBER_ID,
-            'pool_id': POOL_ID}
-        mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'update_member')
-        ) as (mock_get_mapping, mock_update_member):
-
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.update_member(self.context, member_from,
-                                           member_to)
-            mock_update_member.assert_called_with(self.context, member_from,
-                                                  member_to, mapping)
-
-    def test_delete_member(self):
-        lbaas_member = {
-            'admin_state_up': True, 'status': 'PENDING_DELETE',
-            'status_description': None, 'weight': 5, 'address': '10.0.0.4',
-            'tenant_id': TENANT_ID, 'protocol_port': 555, 'id': MEMBER_ID,
-            'pool_id': POOL_ID}
-        mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'delete_member')
-        ) as (mock_get_mapping, mock_delete_member):
-
-            mock_get_mapping.return_value = mapping
-            self.edge_driver.delete_member(self.context, lbaas_member)
-            mock_delete_member.assert_called_with(self.context, lbaas_member,
-                                                  mapping)
-
-    def test_create_pool_health_monitor_successful(self):
-        hmon = {'id': HEALTHMON_ID}
-        with contextlib.nested(
-            mock.patch.object(db, 'add_nsxv_edge_monitor_mapping'),
-            mock.patch.object(self.edge_driver,
-                              'pool_health_monitor_successful')
-        ) as (mock_add_pool_mon_mapping, mock_pool_hmon_successful):
-            self.edge_driver.create_pool_health_monitor_successful(
-                self.context, hmon, POOL_ID, EDGE_ID, EDGE_MON_ID)
-            mock_add_pool_mon_mapping.assert_called_with(
-                self.context, HEALTHMON_ID, EDGE_ID, EDGE_MON_ID)
-            mock_pool_hmon_successful.assert_called_with(self.context,
-                                                         hmon, POOL_ID)
-
-    def test_delete_pool_health_monitor_successful(self):
-        hmon = {'id': HEALTHMON_ID, 'pool_id': POOL_ID}
-        hmon_mapping = {'edge_id': EDGE_ID}
-        with contextlib.nested(
-            mock.patch.object(db, 'delete_nsxv_edge_monitor_mapping'),
-            mock.patch.object(self.service_plugin,
-                              '_delete_db_pool_health_monitor')
-        ) as (mock_del_pool_hmon_mapping, mock_del_db_pool_hmon):
-
-            self.edge_driver.delete_pool_health_monitor_successful(
-                self.context, hmon, POOL_ID, hmon_mapping)
-            mock_del_pool_hmon_mapping.assert_called_with(
-                self.context, HEALTHMON_ID, EDGE_ID)
-            mock_del_db_pool_hmon.assert_called_with(
-                self.context, HEALTHMON_ID, POOL_ID)
-
-    def test_pool_health_monitor_successful(self):
-        hmon = {'id': HEALTHMON_ID}
-        with mock.patch.object(self.service_plugin,
-                               'update_pool_health_monitor') as (
-                mock_update_hmon):
-            self.edge_driver.pool_health_monitor_successful(self.context,
-                                                            hmon, POOL_ID)
-            mock_update_hmon.assert_called_with(
-                self.context, HEALTHMON_ID, POOL_ID, constants.ACTIVE, '')
-
-    def test_pool_health_monitor_failed(self):
-        hmon = {'id': HEALTHMON_ID}
-        with mock.patch.object(self.service_plugin,
-                               'update_pool_health_monitor') as (
-                mock_update_hmon):
-            self.edge_driver.pool_health_monitor_failed(self.context, hmon,
-                                                        POOL_ID)
-            mock_update_hmon.assert_called_with(
-                self.context, HEALTHMON_ID, POOL_ID, constants.ERROR, '')
-
-    def test_create_pool_health_monitor(self):
-        hmon = {
-            'admin_state_up': True, 'tenant_id': TENANT_ID, 'delay': 5L,
-            'max_retries': 5L, 'timeout': 5L, 'pools': [
-                {'status': 'PENDING_CREATE', 'status_description': None,
-                 'pool_id': POOL_ID}],
-            'type': 'PING', 'id': HEALTHMON_ID}
-        pool_mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(db, 'get_nsxv_edge_monitor_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'create_pool_health_monitor')
-        ) as (mock_get_pool_mapping, mock_get_mon_mapping,
-              mock_create_pool_hm):
-
-            mock_get_pool_mapping.return_value = pool_mapping
-            mock_get_mon_mapping.return_value = None
-            self.edge_driver.create_pool_health_monitor(self.context,
-                                                        hmon, POOL_ID)
-            mock_create_pool_hm.assert_called_with(self.context, hmon, POOL_ID,
-                                                   pool_mapping, None)
-
-    def test_update_pool_health_monitor(self):
-        from_hmon = {
-            'admin_state_up': True, 'tenant_id': TENANT_ID, 'delay': 5L,
-            'max_retries': 5L, 'timeout': 5L, 'pools': [
-                {'status': 'PENDING_UPDATE', 'status_description': None,
-                 'pool_id': POOL_ID}],
-            'type': 'PING', 'id': HEALTHMON_ID}
-        to_hmon = {
-            'admin_state_up': True, 'tenant_id': TENANT_ID, 'delay': 5L,
-            'max_retries': 10L, 'timeout': 5L, 'pools': [
-                {'status': 'ACTIVE', 'status_description': None,
-                 'pool_id': POOL_ID}],
-            'type': 'PING', 'id': HEALTHMON_ID}
-        pool_mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-        mon_mapping = {'edge_id': EDGE_ID, 'edge_monitor_id': EDGE_MON_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(db, 'get_nsxv_edge_monitor_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'update_pool_health_monitor')
-        ) as (mock_get_pool_mapping, mock_get_mon_mapping, mock_upd_pool_hm):
-
-            mock_get_pool_mapping.return_value = pool_mapping
-            mock_get_mon_mapping.return_value = mon_mapping
-            self.edge_driver.update_pool_health_monitor(
-                self.context, from_hmon, to_hmon, POOL_ID)
-
-            mock_upd_pool_hm.assert_called_with(
-                self.context, from_hmon, to_hmon, POOL_ID, mon_mapping)
-
-    def test_delete_pool_health_monitor(self):
-        hmon = {
-            'admin_state_up': True, 'tenant_id': TENANT_ID, 'delay': 5L,
-            'max_retries': 5L, 'timeout': 5L, 'pools': [
-                {'status': 'PENDING_DELETE', 'status_description': None,
-                 'pool_id': POOL_ID}],
-            'type': 'PING', 'id': HEALTHMON_ID}
-        pool_mapping = {'edge_id': EDGE_ID, 'edge_pool_id': EDGE_POOL_ID}
-        mon_mapping = {'edge_id': EDGE_ID, 'edge_monitor_id': EDGE_MON_ID}
-
-        with contextlib.nested(
-            mock.patch.object(db, 'get_nsxv_edge_pool_mapping'),
-            mock.patch.object(db, 'get_nsxv_edge_monitor_mapping'),
-            mock.patch.object(self.service_plugin._core_plugin.nsx_v,
-                              'delete_pool_health_monitor')
-        ) as (mock_get_pool_mapping, mock_get_mon_mapping, mock_del_pool_hm):
-
-            mock_get_pool_mapping.return_value = pool_mapping
-            mock_get_mon_mapping.return_value = mon_mapping
-            self.edge_driver.delete_pool_health_monitor(self.context, hmon,
-                                                        POOL_ID)
-            mock_del_pool_hm.assert_called_with(self.context, hmon, POOL_ID,
-                                                pool_mapping, mon_mapping)
diff --git a/tests/unit/services/loadbalancer/test_agent_scheduler.py b/tests/unit/services/loadbalancer/test_agent_scheduler.py
deleted file mode 100644
index d2b312f..0000000
--- a/tests/unit/services/loadbalancer/test_agent_scheduler.py
+++ /dev/null
@@ -1,224 +0,0 @@
-# Copyright (c) 2013 OpenStack Foundation.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-# implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-import mock
-from neutron.api import extensions
-from neutron.api.v2 import attributes
-from neutron import context
-from neutron.extensions import agent
-from neutron import manager
-from neutron.plugins.common import constants as plugin_const
-from neutron.tests.common import helpers
-from neutron.tests.unit.api import test_extensions
-from neutron.tests.unit.db import test_agentschedulers_db
-from neutron.tests.unit.extensions import test_agent
-from neutron_lib import constants
-from oslo_config import cfg
-import six
-from webob import exc
-
-from neutron_lbaas.extensions import lbaas_agentscheduler
-from neutron_lbaas.extensions import loadbalancer
-from neutron_lbaas.tests import base
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancer
-
-LBAAS_HOSTA = 'hosta'
-
-
-class AgentSchedulerTestMixIn(test_agentschedulers_db.AgentSchedulerTestMixIn):
-    def _list_pools_hosted_by_lbaas_agent(self, agent_id,
-                                          expected_code=exc.HTTPOk.code,
-                                          admin_context=True):
-        path = "/agents/%s/%s.%s" % (agent_id,
-                                     lbaas_agentscheduler.LOADBALANCER_POOLS,
-                                     self.fmt)
-        return self._request_list(path, expected_code=expected_code,
-                                  admin_context=admin_context)
-
-    def _get_lbaas_agent_hosting_pool(self, pool_id,
-                                      expected_code=exc.HTTPOk.code,
-                                      admin_context=True):
-        path = "/lb/pools/%s/%s.%s" % (pool_id,
-                                       lbaas_agentscheduler.LOADBALANCER_AGENT,
-                                       self.fmt)
-        return self._request_list(path, expected_code=expected_code,
-                                  admin_context=admin_context)
-
-
-class LBaaSAgentSchedulerTestCase(test_agent.AgentDBTestMixIn,
-                                  AgentSchedulerTestMixIn,
-                                  test_db_loadbalancer.LoadBalancerTestMixin,
-                                  base.NeutronDbPluginV2TestCase):
-    fmt = 'json'
-    plugin_str = 'neutron.plugins.ml2.plugin.Ml2Plugin'
-
-    def setUp(self):
-        # Save the global RESOURCE_ATTRIBUTE_MAP
-        self.saved_attr_map = {}
-        for res, attrs in six.iteritems(attributes.RESOURCE_ATTRIBUTE_MAP):
-            self.saved_attr_map[res] = attrs.copy()
-        service_plugins = {
-            'lb_plugin_name': test_db_loadbalancer.DB_LB_PLUGIN_KLASS}
-
-        # default provider should support agent scheduling
-        self.set_override([('LOADBALANCER:lbaas:neutron_lbaas.services.'
-              'loadbalancer.drivers.haproxy.plugin_driver.'
-              'HaproxyOnHostPluginDriver:default')])
-
-        super(LBaaSAgentSchedulerTestCase, self).setUp(
-            self.plugin_str, service_plugins=service_plugins)
-        ext_mgr = extensions.PluginAwareExtensionManager.get_instance()
-        self.ext_api = test_extensions.setup_extensions_middleware(ext_mgr)
-        self.adminContext = context.get_admin_context()
-        # Add the resources to the global attribute map
-        # This is done here as the setup process won't
-        # initialize the main API router which extends
-        # the global attribute map
-        attributes.RESOURCE_ATTRIBUTE_MAP.update(
-            agent.RESOURCE_ATTRIBUTE_MAP)
-        self.addCleanup(self.restore_attribute_map)
-
-    def restore_attribute_map(self):
-        # Restore the original RESOURCE_ATTRIBUTE_MAP
-        attributes.RESOURCE_ATTRIBUTE_MAP = self.saved_attr_map
-
-    def test_report_states(self):
-        self._register_agent_states(lbaas_agents=True)
-        agents = self._list_agents()
-        self.assertEqual(6, len(agents['agents']))
-
-    def test_pool_scheduling_on_pool_creation(self):
-        self._register_agent_states(lbaas_agents=True)
-        with self.pool() as pool:
-            lbaas_agent = self._get_lbaas_agent_hosting_pool(
-                pool['pool']['id'])
-            self.assertIsNotNone(lbaas_agent)
-            self.assertEqual(constants.AGENT_TYPE_LOADBALANCER,
-                             lbaas_agent['agent']['agent_type'])
-            pools = self._list_pools_hosted_by_lbaas_agent(
-                lbaas_agent['agent']['id'])
-            self.assertEqual(1, len(pools['pools']))
-            self.assertEqual(pool['pool'], pools['pools'][0])
-
-    def test_schedule_pool_with_disabled_agent(self):
-        lbaas_hosta = {
-            'binary': 'neutron-loadbalancer-agent',
-            'host': LBAAS_HOSTA,
-            'topic': 'LOADBALANCER_AGENT',
-            'configurations': {'device_drivers': ['haproxy_ns']},
-            'agent_type': constants.AGENT_TYPE_LOADBALANCER}
-        helpers._register_agent(lbaas_hosta)
-        with self.pool() as pool:
-            lbaas_agent = self._get_lbaas_agent_hosting_pool(
-                pool['pool']['id'])
-            self.assertIsNotNone(lbaas_agent)
-
-        agents = self._list_agents()
-        self._disable_agent(agents['agents'][0]['id'])
-        pool = {'pool': {'name': 'test',
-                         'subnet_id': 'test',
-                         'lb_method': 'ROUND_ROBIN',
-                         'protocol': 'HTTP',
-                         'admin_state_up': True,
-                         'tenant_id': 'test',
-                         'description': 'test'}}
-        lbaas_plugin = manager.NeutronManager.get_service_plugins()[
-            plugin_const.LOADBALANCER]
-        self.assertRaises(loadbalancer.NoEligibleBackend,
-                          lbaas_plugin.create_pool, self.adminContext, pool)
-        pools = lbaas_plugin.get_pools(self.adminContext)
-        self.assertEqual('ERROR', pools[0]['status'])
-        self.assertEqual('No eligible backend',
-                         pools[0]['status_description'])
-
-    def test_schedule_pool_with_down_agent(self):
-        lbaas_hosta = {
-            'binary': 'neutron-loadbalancer-agent',
-            'host': LBAAS_HOSTA,
-            'topic': 'LOADBALANCER_AGENT',
-            'configurations': {'device_drivers': ['haproxy_ns']},
-            'agent_type': constants.AGENT_TYPE_LOADBALANCER}
-        helpers._register_agent(lbaas_hosta)
-        is_agent_down_str = 'neutron.db.agents_db.AgentDbMixin.is_agent_down'
-        with mock.patch(is_agent_down_str) as mock_is_agent_down:
-            mock_is_agent_down.return_value = False
-            with self.pool() as pool:
-                lbaas_agent = self._get_lbaas_agent_hosting_pool(
-                    pool['pool']['id'])
-            self.assertIsNotNone(lbaas_agent)
-        with mock.patch(is_agent_down_str) as mock_is_agent_down:
-            mock_is_agent_down.return_value = True
-            pool = {'pool': {'name': 'test',
-                             'subnet_id': 'test',
-                             'lb_method': 'ROUND_ROBIN',
-                             'protocol': 'HTTP',
-                             'provider': 'lbaas',
-                             'admin_state_up': True,
-                             'tenant_id': 'test',
-                             'description': 'test'}}
-            lbaas_plugin = manager.NeutronManager.get_service_plugins()[
-                plugin_const.LOADBALANCER]
-            self.assertRaises(loadbalancer.NoEligibleBackend,
-                              lbaas_plugin.create_pool,
-                              self.adminContext, pool)
-            pools = lbaas_plugin.get_pools(self.adminContext)
-            self.assertEqual('ERROR', pools[0]['status'])
-            self.assertEqual('No eligible backend',
-                             pools[0]['status_description'])
-
-    def test_pool_unscheduling_on_pool_deletion(self):
-        self._register_agent_states(lbaas_agents=True)
-        with self.pool(do_delete=False) as pool:
-            lbaas_agent = self._get_lbaas_agent_hosting_pool(
-                pool['pool']['id'])
-            self.assertIsNotNone(lbaas_agent)
-            self.assertEqual(constants.AGENT_TYPE_LOADBALANCER,
-                             lbaas_agent['agent']['agent_type'])
-            pools = self._list_pools_hosted_by_lbaas_agent(
-                lbaas_agent['agent']['id'])
-            self.assertEqual(1, len(pools['pools']))
-            self.assertEqual(pool['pool'], pools['pools'][0])
-
-            req = self.new_delete_request('pools',
-                                          pool['pool']['id'])
-            res = req.get_response(self.ext_api)
-            self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-            pools = self._list_pools_hosted_by_lbaas_agent(
-                lbaas_agent['agent']['id'])
-            self.assertEqual(0, len(pools['pools']))
-
-    def test_pool_scheduling_non_admin_access(self):
-        self._register_agent_states(lbaas_agents=True)
-        with self.pool() as pool:
-            self._get_lbaas_agent_hosting_pool(
-                pool['pool']['id'],
-                expected_code=exc.HTTPForbidden.code,
-                admin_context=False)
-            self._list_pools_hosted_by_lbaas_agent(
-                'fake_id',
-                expected_code=exc.HTTPForbidden.code,
-                admin_context=False)
-
-
-class LeastPoolAgentSchedulerTestCase(LBaaSAgentSchedulerTestCase):
-
-    def setUp(self):
-        # Setting LeastPoolAgentScheduler as scheduler
-        cfg.CONF.set_override(
-            'loadbalancer_pool_scheduler_driver',
-            'neutron_lbaas.services.loadbalancer.'
-            'agent_scheduler.LeastPoolAgentScheduler')
-
-        super(LeastPoolAgentSchedulerTestCase, self).setUp()
diff --git a/tests/unit/services/loadbalancer/test_data_models.py b/tests/unit/services/loadbalancer/test_data_models.py
deleted file mode 100644
index f5fdb60..0000000
--- a/tests/unit/services/loadbalancer/test_data_models.py
+++ /dev/null
@@ -1,97 +0,0 @@
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-# implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-import inspect
-
-import mock
-import testscenarios
-
-from neutron_lbaas.services.loadbalancer import data_models
-from neutron_lbaas.tests import base
-from neutron_lbaas.tests import tools
-
-load_tests = testscenarios.load_tests_apply_scenarios
-
-
-class TestBaseDataModel(base.BaseTestCase):
-
-    def _get_fake_model_cls(self, fields_):
-        class FakeModel(data_models.BaseDataModel):
-            fields = fields_
-
-            def __init__(self, **kwargs):
-                for k, v in kwargs.items():
-                    setattr(self, k, v)
-
-        return FakeModel
-
-    def test_from_dict(self):
-
-        fields_ = ['field1', 'field2']
-        dict_ = {field: tools.get_random_string()
-                 for field in fields_}
-
-        model_cls = self._get_fake_model_cls(fields_)
-        model = model_cls.from_dict(dict_)
-
-        for field in fields_:
-            self.assertEqual(dict_[field], getattr(model, field))
-
-    def test_from_dict_filters_by_fields(self):
-
-        fields_ = ['field1', 'field2']
-        dict_ = {field: tools.get_random_string()
-                 for field in fields_}
-        dict_['foo'] = 'bar'
-
-        model_cls = self._get_fake_model_cls(fields_)
-        model = model_cls.from_dict(dict_)
-        self.assertFalse(hasattr(model, 'foo'))
-
-
-def _get_models():
-    models = []
-    for name, obj in inspect.getmembers(data_models):
-        if inspect.isclass(obj):
-            if issubclass(obj, data_models.BaseDataModel):
-                if type(obj) != data_models.BaseDataModel:
-                    models.append(obj)
-    return models
-
-
-class TestModels(base.BaseTestCase):
-
-    scenarios = [
-        (model.__name__, {'model': model})
-        for model in _get_models()
-    ]
-
-    @staticmethod
-    def _get_iterable_mock(*args, **kwargs):
-        m = mock.create_autospec(dict, spec_set=True)
-
-        def _get_empty_iterator(*args, **kwargs):
-            return iter([])
-
-        m.__iter__ = _get_empty_iterator
-        m.pop = _get_empty_iterator
-        return m
-
-    def test_from_dict_filters_by_fields(self):
-
-        dict_ = {field: self._get_iterable_mock()
-                 for field in self.model.fields}
-        dict_['foo'] = 'bar'
-
-        model = self.model.from_dict(dict_)
-        self.assertFalse(hasattr(model, 'foo'))
diff --git a/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py b/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py
deleted file mode 100644
index 07bb7f0..0000000
--- a/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py
+++ /dev/null
@@ -1,1150 +0,0 @@
-# Copyright 2012 OpenStack Foundation.
-# All Rights Reserved.
-#
-#  Licensed under the Apache License, Version 2.0 (the "License"); you may
-#  not use this file except in compliance with the License. You may obtain
-#  a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#  License for the specific language governing permissions and limitations
-#  under the License.
-
-import copy
-
-import mock
-from neutron.api.v2 import attributes as attr
-from neutron.plugins.common import constants
-from neutron.tests.unit.api.v2 import test_base
-from oslo_utils import uuidutils
-from webob import exc
-
-from neutron_lbaas.extensions import loadbalancer
-from neutron_lbaas.extensions import loadbalancerv2
-from neutron_lbaas.extensions import sharedpools
-from neutron_lbaas.tests import base
-
-
-_uuid = uuidutils.generate_uuid
-_get_path = test_base._get_path
-
-
-class LoadBalancerExtensionTestCase(base.ExtensionTestCase):
-    fmt = 'json'
-
-    def setUp(self):
-        super(LoadBalancerExtensionTestCase, self).setUp()
-        self._setUpExtension(
-            'neutron_lbaas.extensions.loadbalancer.LoadBalancerPluginBase',
-            constants.LOADBALANCER, loadbalancer.RESOURCE_ATTRIBUTE_MAP,
-            loadbalancer.Loadbalancer, 'lb', use_quota=True)
-
-    def test_vip_create(self):
-        vip_id = _uuid()
-        data = {'vip': {'name': 'vip1',
-                        'description': 'descr_vip1',
-                        'subnet_id': _uuid(),
-                        'address': '127.0.0.1',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'pool_id': _uuid(),
-                        'session_persistence': {'type': 'HTTP_COOKIE'},
-                        'connection_limit': 100,
-                        'admin_state_up': True,
-                        'tenant_id': _uuid()}}
-        return_value = copy.copy(data['vip'])
-        return_value.update({'status': "ACTIVE", 'id': vip_id})
-
-        instance = self.plugin.return_value
-        instance.create_vip.return_value = return_value
-        res = self.api.post(_get_path('lb/vips', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        instance.create_vip.assert_called_with(mock.ANY,
-                                               vip=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('vip', res)
-        self.assertEqual(return_value, res['vip'])
-
-    def test_vip_create_with_connection_limit_smaller_than_min_value(self):
-        data = {'vip': {'name': 'vip1',
-                        'description': 'descr_vip1',
-                        'subnet_id': _uuid(),
-                        'address': '127.0.0.1',
-                        'protocol_port': 80,
-                        'protocol': 'HTTP',
-                        'pool_id': _uuid(),
-                        'session_persistence': {'type': 'HTTP_COOKIE'},
-                        'connection_limit': -4,
-                        'admin_state_up': True,
-                        'tenant_id': _uuid()}}
-        res = self.api.post(_get_path('lb/vips', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt,
-                            expect_errors=True)
-        self.assertEqual(exc.HTTPBadRequest.code, res.status_int)
-
-    def test_vip_list(self):
-        vip_id = _uuid()
-        return_value = [{'name': 'vip1',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': vip_id}]
-
-        instance = self.plugin.return_value
-        instance.get_vips.return_value = return_value
-
-        res = self.api.get(_get_path('lb/vips', fmt=self.fmt))
-
-        instance.get_vips.assert_called_with(mock.ANY, fields=mock.ANY,
-                                             filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_vip_update(self):
-        vip_id = _uuid()
-        update_data = {'vip': {'admin_state_up': False}}
-        return_value = {'name': 'vip1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': vip_id}
-
-        instance = self.plugin.return_value
-        instance.update_vip.return_value = return_value
-
-        res = self.api.put(_get_path('lb/vips', id=vip_id, fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_vip.assert_called_with(mock.ANY, vip_id,
-                                               vip=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('vip', res)
-        self.assertEqual(return_value, res['vip'])
-
-    def test_vip_update_with_connection_limit_smaller_than_min_value(self):
-        vip_id = _uuid()
-        data = {'vip': {'connection_limit': -4}}
-        res = self.api.put(_get_path('lb/vips', id=vip_id, fmt=self.fmt),
-                           self.serialize(data),
-                           content_type='application/%s' % self.fmt,
-                           expect_errors=True)
-        self.assertEqual(exc.HTTPBadRequest.code, res.status_int)
-
-    def test_vip_get(self):
-        vip_id = _uuid()
-        return_value = {'name': 'vip1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': vip_id}
-
-        instance = self.plugin.return_value
-        instance.get_vip.return_value = return_value
-
-        res = self.api.get(_get_path('lb/vips', id=vip_id, fmt=self.fmt))
-
-        instance.get_vip.assert_called_with(mock.ANY, vip_id,
-                                            fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('vip', res)
-        self.assertEqual(return_value, res['vip'])
-
-    def test_vip_delete(self):
-        self._test_entity_delete('vip')
-
-    def test_pool_create(self):
-        pool_id = _uuid()
-        hm_id = _uuid()
-        data = {'pool': {'name': 'pool1',
-                         'description': 'descr_pool1',
-                         'subnet_id': _uuid(),
-                         'protocol': 'HTTP',
-                         'lb_method': 'ROUND_ROBIN',
-                         'health_monitors': [hm_id],
-                         'admin_state_up': True,
-                         'tenant_id': _uuid()}}
-        return_value = copy.copy(data['pool'])
-        return_value['provider'] = 'lbaas'
-        return_value.update({'status': "ACTIVE", 'id': pool_id})
-
-        instance = self.plugin.return_value
-        instance.create_pool.return_value = return_value
-        res = self.api.post(_get_path('lb/pools', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        data['pool']['provider'] = attr.ATTR_NOT_SPECIFIED
-        instance.create_pool.assert_called_with(mock.ANY,
-                                                pool=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('pool', res)
-        self.assertEqual(return_value, res['pool'])
-
-    def test_pool_list(self):
-        pool_id = _uuid()
-        return_value = [{'name': 'pool1',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': pool_id}]
-
-        instance = self.plugin.return_value
-        instance.get_pools.return_value = return_value
-
-        res = self.api.get(_get_path('lb/pools', fmt=self.fmt))
-
-        instance.get_pools.assert_called_with(mock.ANY, fields=mock.ANY,
-                                              filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_pool_update(self):
-        pool_id = _uuid()
-        update_data = {'pool': {'admin_state_up': False}}
-        return_value = {'name': 'pool1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': pool_id}
-
-        instance = self.plugin.return_value
-        instance.update_pool.return_value = return_value
-
-        res = self.api.put(_get_path('lb/pools', id=pool_id, fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_pool.assert_called_with(mock.ANY, pool_id,
-                                                pool=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('pool', res)
-        self.assertEqual(return_value, res['pool'])
-
-    def test_pool_get(self):
-        pool_id = _uuid()
-        return_value = {'name': 'pool1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': pool_id}
-
-        instance = self.plugin.return_value
-        instance.get_pool.return_value = return_value
-
-        res = self.api.get(_get_path('lb/pools', id=pool_id, fmt=self.fmt))
-
-        instance.get_pool.assert_called_with(mock.ANY, pool_id,
-                                             fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('pool', res)
-        self.assertEqual(return_value, res['pool'])
-
-    def test_pool_delete(self):
-        self._test_entity_delete('pool')
-
-    def test_pool_stats(self):
-        pool_id = _uuid()
-
-        stats = {'stats': 'dummy'}
-        instance = self.plugin.return_value
-        instance.stats.return_value = stats
-
-        path = _get_path('lb/pools', id=pool_id,
-                         action="stats", fmt=self.fmt)
-        res = self.api.get(path)
-
-        instance.stats.assert_called_with(mock.ANY, pool_id)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('stats', res)
-        self.assertEqual(stats['stats'], res['stats'])
-
-    def test_member_create(self):
-        member_id = _uuid()
-        data = {'member': {'pool_id': _uuid(),
-                           'address': '127.0.0.1',
-                           'protocol_port': 80,
-                           'weight': 1,
-                           'admin_state_up': True,
-                           'tenant_id': _uuid()}}
-        return_value = copy.copy(data['member'])
-        return_value.update({'status': "ACTIVE", 'id': member_id})
-
-        instance = self.plugin.return_value
-        instance.create_member.return_value = return_value
-        res = self.api.post(_get_path('lb/members', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        instance.create_member.assert_called_with(mock.ANY,
-                                                  member=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('member', res)
-        self.assertEqual(return_value, res['member'])
-
-    def test_member_list(self):
-        member_id = _uuid()
-        return_value = [{'name': 'member1',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': member_id}]
-
-        instance = self.plugin.return_value
-        instance.get_members.return_value = return_value
-
-        res = self.api.get(_get_path('lb/members', fmt=self.fmt))
-
-        instance.get_members.assert_called_with(mock.ANY, fields=mock.ANY,
-                                                filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_member_update(self):
-        member_id = _uuid()
-        update_data = {'member': {'admin_state_up': False}}
-        return_value = {'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': member_id}
-
-        instance = self.plugin.return_value
-        instance.update_member.return_value = return_value
-
-        res = self.api.put(_get_path('lb/members', id=member_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_member.assert_called_with(mock.ANY, member_id,
-                                                  member=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('member', res)
-        self.assertEqual(return_value, res['member'])
-
-    def test_member_get(self):
-        member_id = _uuid()
-        return_value = {'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': member_id}
-
-        instance = self.plugin.return_value
-        instance.get_member.return_value = return_value
-
-        res = self.api.get(_get_path('lb/members', id=member_id,
-                                     fmt=self.fmt))
-
-        instance.get_member.assert_called_with(mock.ANY, member_id,
-                                               fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('member', res)
-        self.assertEqual(return_value, res['member'])
-
-    def test_member_delete(self):
-        self._test_entity_delete('member')
-
-    def test_health_monitor_create(self):
-        health_monitor_id = _uuid()
-        data = {'health_monitor': {'type': 'HTTP',
-                                   'delay': 2,
-                                   'timeout': 1,
-                                   'max_retries': 3,
-                                   'http_method': 'GET',
-                                   'url_path': '/path',
-                                   'expected_codes': '200-300',
-                                   'admin_state_up': True,
-                                   'tenant_id': _uuid()}}
-        return_value = copy.copy(data['health_monitor'])
-        return_value.update({'status': "ACTIVE", 'id': health_monitor_id})
-
-        instance = self.plugin.return_value
-        instance.create_health_monitor.return_value = return_value
-        res = self.api.post(_get_path('lb/health_monitors',
-                                      fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        instance.create_health_monitor.assert_called_with(mock.ANY,
-                                                          health_monitor=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('health_monitor', res)
-        self.assertEqual(return_value, res['health_monitor'])
-
-    def test_health_monitor_create_with_timeout_negative(self):
-        data = {'health_monitor': {'type': 'HTTP',
-                                   'delay': 2,
-                                   'timeout': -1,
-                                   'max_retries': 3,
-                                   'http_method': 'GET',
-                                   'url_path': '/path',
-                                   'expected_codes': '200-300',
-                                   'admin_state_up': True,
-                                   'tenant_id': _uuid()}}
-        res = self.api.post(_get_path('lb/health_monitors',
-                                      fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt,
-                            expect_errors=True)
-        self.assertEqual(400, res.status_int)
-
-    def test_health_monitor_list(self):
-        health_monitor_id = _uuid()
-        return_value = [{'type': 'HTTP',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': health_monitor_id}]
-
-        instance = self.plugin.return_value
-        instance.get_health_monitors.return_value = return_value
-
-        res = self.api.get(_get_path('lb/health_monitors', fmt=self.fmt))
-
-        instance.get_health_monitors.assert_called_with(
-            mock.ANY, fields=mock.ANY, filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_health_monitor_update(self):
-        health_monitor_id = _uuid()
-        update_data = {'health_monitor': {'admin_state_up': False}}
-        return_value = {'type': 'HTTP',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': health_monitor_id}
-
-        instance = self.plugin.return_value
-        instance.update_health_monitor.return_value = return_value
-
-        res = self.api.put(_get_path('lb/health_monitors',
-                                     id=health_monitor_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_health_monitor.assert_called_with(
-            mock.ANY, health_monitor_id, health_monitor=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('health_monitor', res)
-        self.assertEqual(return_value, res['health_monitor'])
-
-    def test_health_monitor_get(self):
-        health_monitor_id = _uuid()
-        return_value = {'type': 'HTTP',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'status': "ACTIVE",
-                        'id': health_monitor_id}
-
-        instance = self.plugin.return_value
-        instance.get_health_monitor.return_value = return_value
-
-        res = self.api.get(_get_path('lb/health_monitors',
-                                     id=health_monitor_id,
-                                     fmt=self.fmt))
-
-        instance.get_health_monitor.assert_called_with(
-            mock.ANY, health_monitor_id, fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('health_monitor', res)
-        self.assertEqual(return_value, res['health_monitor'])
-
-    def test_health_monitor_delete(self):
-        self._test_entity_delete('health_monitor')
-
-    def test_create_pool_health_monitor(self):
-        health_monitor_id = _uuid()
-        data = {'health_monitor': {'id': health_monitor_id,
-                                   'tenant_id': _uuid()}}
-
-        return_value = copy.copy(data['health_monitor'])
-        instance = self.plugin.return_value
-        instance.create_pool_health_monitor.return_value = return_value
-        res = self.api.post('/lb/pools/id1/health_monitors',
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        instance.create_pool_health_monitor.assert_called_with(
-            mock.ANY, pool_id='id1', health_monitor=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('health_monitor', res)
-        self.assertEqual(return_value, res['health_monitor'])
-
-    def test_delete_pool_health_monitor(self):
-        health_monitor_id = _uuid()
-
-        res = self.api.delete('/lb/pools/id1/health_monitors/%s' %
-                              health_monitor_id)
-
-        instance = self.plugin.return_value
-        instance.delete_pool_health_monitor.assert_called_with(
-            mock.ANY, health_monitor_id, pool_id='id1')
-        self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-
-
-class LoadBalancerExtensionV2TestCase(base.ExtensionTestCase):
-    fmt = 'json'
-
-    def setUp(self):
-        super(LoadBalancerExtensionV2TestCase, self).setUp()
-        resource_map = loadbalancerv2.RESOURCE_ATTRIBUTE_MAP.copy()
-        for k in sharedpools.EXTENDED_ATTRIBUTES_2_0.keys():
-            resource_map[k].update(sharedpools.EXTENDED_ATTRIBUTES_2_0[k])
-        self._setUpExtension(
-            'neutron_lbaas.extensions.loadbalancerv2.LoadBalancerPluginBaseV2',
-            constants.LOADBALANCERV2, resource_map,
-            loadbalancerv2.Loadbalancerv2, 'lbaas', use_quota=True)
-
-    def test_loadbalancer_create(self):
-        lb_id = _uuid()
-        data = {'loadbalancer': {'name': 'lb1',
-                                 'description': 'descr_lb1',
-                                 'tenant_id': _uuid(),
-                                 'vip_subnet_id': _uuid(),
-                                 'admin_state_up': True,
-                                 'vip_address': '127.0.0.1'}}
-        return_value = copy.copy(data['loadbalancer'])
-        return_value.update({'id': lb_id})
-
-        instance = self.plugin.return_value
-        instance.create_loadbalancer.return_value = return_value
-
-        res = self.api.post(_get_path('lbaas/loadbalancers', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/{0}'.format(self.fmt))
-        data['loadbalancer'].update({'provider': attr.ATTR_NOT_SPECIFIED,
-                                     'flavor_id': attr.ATTR_NOT_SPECIFIED})
-        instance.create_loadbalancer.assert_called_with(mock.ANY,
-                                                        loadbalancer=data)
-
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('loadbalancer', res)
-        self.assertEqual(return_value, res['loadbalancer'])
-
-    def test_loadbalancer_create_invalid_flavor(self):
-        data = {'loadbalancer': {'name': 'lb1',
-                                 'description': 'descr_lb1',
-                                 'tenant_id': _uuid(),
-                                 'vip_subnet_id': _uuid(),
-                                 'admin_state_up': True,
-                                 'flavor_id': 123,
-                                 'vip_address': '127.0.0.1'}}
-        res = self.api.post(_get_path('lbaas/loadbalancers', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/{0}'.format(self.fmt),
-                            expect_errors=True)
-        self.assertEqual(400, res.status_int)
-
-    def test_loadbalancer_create_valid_flavor(self):
-        data = {'loadbalancer': {'name': 'lb1',
-                                 'description': 'descr_lb1',
-                                 'tenant_id': _uuid(),
-                                 'vip_subnet_id': _uuid(),
-                                 'admin_state_up': True,
-                                 'flavor_id': _uuid(),
-                                 'vip_address': '127.0.0.1'}}
-        res = self.api.post(_get_path('lbaas/loadbalancers', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/{0}'.format(self.fmt),
-                            expect_errors=True)
-        self.assertEqual(201, res.status_int)
-
-    def test_loadbalancer_list(self):
-        lb_id = _uuid()
-        return_value = [{'name': 'lb1',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': lb_id}]
-
-        instance = self.plugin.return_value
-        instance.get_loadbalancers.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/loadbalancers', fmt=self.fmt))
-
-        instance.get_loadbalancers.assert_called_with(mock.ANY,
-                                                      fields=mock.ANY,
-                                                      filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_loadbalancer_update(self):
-        lb_id = _uuid()
-        update_data = {'loadbalancer': {'admin_state_up': False}}
-        return_value = {'name': 'lb1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': lb_id}
-
-        instance = self.plugin.return_value
-        instance.update_loadbalancer.return_value = return_value
-
-        res = self.api.put(_get_path('lbaas/loadbalancers',
-                                     id=lb_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_loadbalancer.assert_called_with(
-            mock.ANY, lb_id, loadbalancer=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('loadbalancer', res)
-        self.assertEqual(return_value, res['loadbalancer'])
-
-    def test_loadbalancer_get(self):
-        lb_id = _uuid()
-        return_value = {'name': 'lb1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': lb_id}
-
-        instance = self.plugin.return_value
-        instance.get_loadbalancer.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/loadbalancers',
-                                     id=lb_id,
-                                     fmt=self.fmt))
-
-        instance.get_loadbalancer.assert_called_with(mock.ANY, lb_id,
-                                                     fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('loadbalancer', res)
-        self.assertEqual(return_value, res['loadbalancer'])
-
-    def test_loadbalancer_delete(self):
-        self._test_entity_delete('loadbalancer')
-
-    def test_listener_create(self):
-        listener_id = _uuid()
-        data = {'listener': {'tenant_id': _uuid(),
-                             'name': 'listen-name-1',
-                             'description': 'listen-1-desc',
-                             'protocol': 'HTTP',
-                             'protocol_port': 80,
-                             'default_pool_id': None,
-                             'default_tls_container_ref': None,
-                             'sni_container_refs': [],
-                             'connection_limit': 100,
-                             'admin_state_up': True,
-                             'loadbalancer_id': _uuid()}}
-        return_value = copy.copy(data['listener'])
-        return_value.update({'id': listener_id})
-        del return_value['loadbalancer_id']
-
-        instance = self.plugin.return_value
-        instance.create_listener.return_value = return_value
-
-        res = self.api.post(_get_path('lbaas/listeners', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/{0}'.format(self.fmt))
-        instance.create_listener.assert_called_with(mock.ANY,
-                                                    listener=data)
-
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('listener', res)
-        self.assertEqual(return_value, res['listener'])
-
-    def test_listener_create_with_tls(self):
-        listener_id = _uuid()
-        tls_ref = 'http://example.ref/uuid'
-        sni_refs = ['http://example.ref/uuid',
-                    'http://example.ref/uuid1']
-        data = {'listener': {'tenant_id': _uuid(),
-                             'name': 'listen-name-1',
-                             'description': 'listen-1-desc',
-                             'protocol': 'HTTP',
-                             'protocol_port': 80,
-                             'default_pool_id': None,
-                             'default_tls_container_ref': tls_ref,
-                             'sni_container_refs': sni_refs,
-                             'connection_limit': 100,
-                             'admin_state_up': True,
-                             'loadbalancer_id': _uuid()}}
-        return_value = copy.copy(data['listener'])
-        return_value.update({'id': listener_id})
-        del return_value['loadbalancer_id']
-
-        instance = self.plugin.return_value
-        instance.create_listener.return_value = return_value
-
-        res = self.api.post(_get_path('lbaas/listeners', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/{0}'.format(self.fmt))
-        instance.create_listener.assert_called_with(mock.ANY,
-                                                    listener=data)
-
-        self.assertEqual(res.status_int, exc.HTTPCreated.code)
-        res = self.deserialize(res)
-        self.assertIn('listener', res)
-        self.assertEqual(res['listener'], return_value)
-
-    def test_listener_create_with_connection_limit_less_than_min_value(self):
-        data = {'listener': {'tenant_id': _uuid(),
-                             'name': 'listen-name-1',
-                             'description': 'listen-1-desc',
-                             'protocol': 'HTTP',
-                             'protocol_port': 80,
-                             'default_tls_container_ref': None,
-                             'sni_container_refs': [],
-                             'connection_limit': -4,
-                             'admin_state_up': True,
-                             'loadbalancer_id': _uuid()}}
-
-        res = self.api.post(_get_path('lbaas/listeners', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/{0}'.format(self.fmt),
-                            expect_errors=True)
-        self.assertEqual(exc.HTTPBadRequest.code, res.status_int)
-
-    def test_listener_list(self):
-        listener_id = _uuid()
-        return_value = [{'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': listener_id}]
-
-        instance = self.plugin.return_value
-        instance.get_listeners.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/listeners', fmt=self.fmt))
-
-        instance.get_listeners.assert_called_with(mock.ANY,
-                                                  fields=mock.ANY,
-                                                  filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_listener_update(self):
-        listener_id = _uuid()
-        update_data = {'listener': {'admin_state_up': False}}
-        return_value = {'name': 'listener1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': listener_id}
-
-        instance = self.plugin.return_value
-        instance.update_listener.return_value = return_value
-
-        res = self.api.put(_get_path('lbaas/listeners',
-                                     id=listener_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_listener.assert_called_with(
-            mock.ANY, listener_id, listener=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('listener', res)
-        self.assertEqual(return_value, res['listener'])
-
-    def test_listener_update_with_tls(self):
-        listener_id = _uuid()
-        tls_ref = 'http://example.ref/uuid'
-        sni_refs = ['http://example.ref/uuid',
-                    'http://example.ref/uuid1']
-        update_data = {'listener': {'admin_state_up': False}}
-        return_value = {'name': 'listener1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': listener_id,
-                        'default_tls_container_ref': tls_ref,
-                        'sni_container_refs': sni_refs}
-
-        instance = self.plugin.return_value
-        instance.update_listener.return_value = return_value
-
-        res = self.api.put(_get_path('lbaas/listeners',
-                                     id=listener_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_listener.assert_called_with(
-            mock.ANY, listener_id, listener=update_data)
-        self.assertEqual(res.status_int, exc.HTTPOk.code)
-        res = self.deserialize(res)
-        self.assertIn('listener', res)
-        self.assertEqual(res['listener'], return_value)
-
-    def test_listener_update_with_connection_limit_less_than_min_value(self):
-        listener_id = _uuid()
-        update_data = {'listener': {'connection_limit': -4}}
-        res = self.api.put(_get_path('lbaas/listeners',
-                                     id=listener_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data),
-                           expect_errors=True)
-        self.assertEqual(exc.HTTPBadRequest.code, res.status_int)
-
-    def test_listener_get(self):
-        listener_id = _uuid()
-        return_value = {'name': 'listener1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': listener_id}
-
-        instance = self.plugin.return_value
-        instance.get_listener.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/listeners',
-                                     id=listener_id,
-                                     fmt=self.fmt))
-
-        instance.get_listener.assert_called_with(mock.ANY, listener_id,
-                                                 fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('listener', res)
-        self.assertEqual(return_value, res['listener'])
-
-    def test_listener_delete(self):
-        self._test_entity_delete('listener')
-
-    def test_pool_create(self):
-        pool_id = _uuid()
-        data = {'pool': {'name': 'pool1',
-                         'description': 'descr_pool1',
-                         'protocol': 'HTTP',
-                         'lb_algorithm': 'ROUND_ROBIN',
-                         'admin_state_up': True,
-                         'loadbalancer_id': _uuid(),
-                         'listener_id': None,
-                         'tenant_id': _uuid(),
-                         'session_persistence': {}}}
-        return_value = copy.copy(data['pool'])
-        return_value.update({'id': pool_id})
-        return_value.pop('listener_id')
-
-        instance = self.plugin.return_value
-        instance.create_pool.return_value = return_value
-        res = self.api.post(_get_path('lbaas/pools', fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        instance.create_pool.assert_called_with(mock.ANY, pool=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('pool', res)
-        self.assertEqual(return_value, res['pool'])
-
-    def test_pool_list(self):
-        pool_id = _uuid()
-        return_value = [{'name': 'pool1',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': pool_id}]
-
-        instance = self.plugin.return_value
-        instance.get_pools.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/pools', fmt=self.fmt))
-
-        instance.get_pools.assert_called_with(mock.ANY, fields=mock.ANY,
-                                              filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_pool_update(self):
-        pool_id = _uuid()
-        update_data = {'pool': {'admin_state_up': False}}
-        return_value = {'name': 'pool1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': pool_id}
-
-        instance = self.plugin.return_value
-        instance.update_pool.return_value = return_value
-
-        res = self.api.put(_get_path('lbaas/pools', id=pool_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_pool.assert_called_with(mock.ANY, pool_id,
-                                                pool=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('pool', res)
-        self.assertEqual(return_value, res['pool'])
-
-    def test_pool_get(self):
-        pool_id = _uuid()
-        return_value = {'name': 'pool1',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': pool_id}
-
-        instance = self.plugin.return_value
-        instance.get_pool.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/pools', id=pool_id,
-                                     fmt=self.fmt))
-
-        instance.get_pool.assert_called_with(mock.ANY, pool_id,
-                                             fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('pool', res)
-        self.assertEqual(return_value, res['pool'])
-
-    def test_pool_delete(self):
-        self._test_entity_delete('pool')
-
-    def test_pool_member_create(self):
-        subnet_id = _uuid()
-        member_id = _uuid()
-        data = {'member': {'address': '10.0.0.1',
-                           'protocol_port': 80,
-                           'weight': 1,
-                           'subnet_id': subnet_id,
-                           'admin_state_up': True,
-                           'tenant_id': _uuid(),
-                           'name': 'member1'}}
-        return_value = copy.copy(data['member'])
-        return_value.update({'id': member_id})
-
-        instance = self.plugin.return_value
-        instance.create_pool_member.return_value = return_value
-        res = self.api.post(_get_path('lbaas/pools/pid1/members',
-                                      fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s'
-                                         % self.fmt)
-        instance.create_pool_member.assert_called_with(mock.ANY,
-                                                       pool_id='pid1',
-                                                       member=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('member', res)
-        self.assertEqual(return_value, res['member'])
-
-    def test_pool_member_list(self):
-        member_id = _uuid()
-        return_value = [{'name': 'member1',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': member_id,
-                         'name': 'member1'}]
-
-        instance = self.plugin.return_value
-        instance.get_pools.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/pools/pid1/members',
-                                     fmt=self.fmt))
-
-        instance.get_pool_members.assert_called_with(mock.ANY,
-                                                     fields=mock.ANY,
-                                                     filters=mock.ANY,
-                                                     pool_id='pid1')
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_pool_member_update(self):
-        member_id = _uuid()
-        update_data = {'member': {'admin_state_up': False}}
-        return_value = {'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': member_id,
-                        'name': 'member1'}
-
-        instance = self.plugin.return_value
-        instance.update_pool_member.return_value = return_value
-
-        res = self.api.put(_get_path('lbaas/pools/pid1/members',
-                                     id=member_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_pool_member.assert_called_with(
-            mock.ANY, member_id, pool_id='pid1',
-            member=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('member', res)
-        self.assertEqual(return_value, res['member'])
-
-    def test_pool_member_get(self):
-        member_id = _uuid()
-        return_value = {'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': member_id,
-                        'name': 'member1'}
-
-        instance = self.plugin.return_value
-        instance.get_pool_member.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/pools/pid1/members',
-                                     id=member_id, fmt=self.fmt))
-
-        instance.get_pool_member.assert_called_with(mock.ANY,
-                                                    member_id,
-                                                    fields=mock.ANY,
-                                                    pool_id='pid1')
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('member', res)
-        self.assertEqual(return_value, res['member'])
-
-    def test_pool_member_delete(self):
-        entity_id = _uuid()
-        res = self.api.delete(
-            test_base._get_path('lbaas/pools/pid1/members',
-                                id=entity_id, fmt=self.fmt))
-        delete_entity = getattr(self.plugin.return_value,
-                                "delete_pool_member")
-        delete_entity.assert_called_with(mock.ANY, entity_id,
-                                         pool_id='pid1')
-        self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-
-    def test_health_monitor_create(self):
-        health_monitor_id = _uuid()
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'delay': 2,
-                                  'timeout': 1,
-                                  'max_retries': 3,
-                                  'http_method': 'GET',
-                                  'url_path': '/path',
-                                  'expected_codes': '200-300',
-                                  'admin_state_up': True,
-                                  'tenant_id': _uuid(),
-                                  'pool_id': _uuid(),
-                                  'name': 'monitor1'}}
-        return_value = copy.copy(data['healthmonitor'])
-        return_value.update({'id': health_monitor_id})
-        del return_value['pool_id']
-
-        instance = self.plugin.return_value
-        instance.create_healthmonitor.return_value = return_value
-        res = self.api.post(_get_path('lbaas/healthmonitors',
-                                      fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt)
-        instance.create_healthmonitor.assert_called_with(
-            mock.ANY, healthmonitor=data)
-        self.assertEqual(exc.HTTPCreated.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('healthmonitor', res)
-        self.assertEqual(return_value, res['healthmonitor'])
-
-    def test_health_monitor_create_with_timeout_negative(self):
-        data = {'healthmonitor': {'type': 'HTTP',
-                                  'delay': 2,
-                                  'timeout': -1,
-                                  'max_retries': 3,
-                                  'http_method': 'GET',
-                                  'url_path': '/path',
-                                  'expected_codes': '200-300',
-                                  'admin_state_up': True,
-                                  'tenant_id': _uuid(),
-                                  'pool_id': _uuid(),
-                                  'name': 'monitor1'}}
-        res = self.api.post(_get_path('lbaas/healthmonitors',
-                                      fmt=self.fmt),
-                            self.serialize(data),
-                            content_type='application/%s' % self.fmt,
-                            expect_errors=True)
-        self.assertEqual(400, res.status_int)
-
-    def test_health_monitor_list(self):
-        health_monitor_id = _uuid()
-        return_value = [{'type': 'HTTP',
-                         'admin_state_up': True,
-                         'tenant_id': _uuid(),
-                         'id': health_monitor_id,
-                         'name': 'monitor1'}]
-
-        instance = self.plugin.return_value
-        instance.get_healthmonitors.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/healthmonitors', fmt=self.fmt))
-
-        instance.get_healthmonitors.assert_called_with(
-            mock.ANY, fields=mock.ANY, filters=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-
-    def test_health_monitor_update(self):
-        health_monitor_id = _uuid()
-        update_data = {'healthmonitor': {'admin_state_up': False}}
-        return_value = {'type': 'HTTP',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': health_monitor_id,
-                        'name': 'monitor1'}
-
-        instance = self.plugin.return_value
-        instance.update_healthmonitor.return_value = return_value
-
-        res = self.api.put(_get_path('lbaas/healthmonitors',
-                                     id=health_monitor_id,
-                                     fmt=self.fmt),
-                           self.serialize(update_data))
-
-        instance.update_healthmonitor.assert_called_with(
-            mock.ANY, health_monitor_id, healthmonitor=update_data)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('healthmonitor', res)
-        self.assertEqual(return_value, res['healthmonitor'])
-
-    def test_health_monitor_get(self):
-        health_monitor_id = _uuid()
-        return_value = {'type': 'HTTP',
-                        'admin_state_up': False,
-                        'tenant_id': _uuid(),
-                        'id': health_monitor_id,
-                        'name': 'monitor1'}
-
-        instance = self.plugin.return_value
-        instance.get_healthmonitor.return_value = return_value
-
-        res = self.api.get(_get_path('lbaas/healthmonitors',
-                                     id=health_monitor_id,
-                                     fmt=self.fmt))
-
-        instance.get_healthmonitor.assert_called_with(
-            mock.ANY, health_monitor_id, fields=mock.ANY)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('healthmonitor', res)
-        self.assertEqual(return_value, res['healthmonitor'])
-
-    def test_health_monitor_delete(self):
-        entity_id = _uuid()
-        res = self.api.delete(
-            test_base._get_path('lbaas/healthmonitors',
-                                id=entity_id, fmt=self.fmt))
-        delete_entity = getattr(self.plugin.return_value,
-                                "delete_healthmonitor")
-        delete_entity.assert_called_with(mock.ANY, entity_id)
-        self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-
-    def test_load_balancer_stats(self):
-        load_balancer_id = _uuid()
-
-        stats = {'stats': 'dummy'}
-        instance = self.plugin.return_value
-        instance.stats.return_value = stats
-
-        path = _get_path('lbaas/loadbalancers', id=load_balancer_id,
-                         action="stats", fmt=self.fmt)
-        res = self.api.get(path)
-
-        instance.stats.assert_called_with(mock.ANY, load_balancer_id)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('stats', res)
-        self.assertEqual(stats['stats'], res['stats'])
-
-    def test_load_balancer_statuses(self):
-        load_balancer_id = _uuid()
-
-        statuses = {'statuses': {'loadbalancer': {}}}
-        instance = self.plugin.return_value
-        instance.statuses.return_value = statuses
-        path = _get_path('lbaas/loadbalancers', id=load_balancer_id,
-                         action="statuses", fmt=self.fmt)
-        res = self.api.get(path)
-        instance.statuses.assert_called_with(mock.ANY, load_balancer_id)
-        self.assertEqual(exc.HTTPOk.code, res.status_int)
-        res = self.deserialize(res)
-        self.assertIn('statuses', res)
-        self.assertEqual(statuses['statuses'], res['statuses'])
diff --git a/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py b/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py
deleted file mode 100644
index cbba294..0000000
--- a/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py
+++ /dev/null
@@ -1,193 +0,0 @@
-# Copyright 2014 OpenStack Foundation.
-# All Rights Reserved.
-#
-#    Licensed under the Apache License, Version 2.0 (the "License"); you may
-#    not use this file except in compliance with the License. You may obtain
-#    a copy of the License at
-#
-#         http://www.apache.org/licenses/LICENSE-2.0
-#
-#    Unless required by applicable law or agreed to in writing, software
-#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
-#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
-#    License for the specific language governing permissions and limitations
-#    under the License.
-
-from neutron import context
-from neutron import quota
-from neutron.tests.unit.api.v2 import test_base
-from oslo_config import cfg
-
-from neutron_lbaas.tests import base
-
-_get_path = test_base._get_path
-
-
-class LBaaSQuotaExtensionTestCase(base.QuotaExtensionTestCase):
-
-    def setUp(self):
-        super(LBaaSQuotaExtensionTestCase, self).setUp()
-        cfg.CONF.set_override(
-            'quota_items',
-            ['vip', 'pool', 'member', 'health_monitor', 'extra1',
-             'loadbalancer', 'listener', 'healthmonitor'],
-            group='QUOTAS')
-        quota.register_resources_from_config()
-
-
-class LBaaSQuotaExtensionDbTestCase(LBaaSQuotaExtensionTestCase):
-    fmt = 'json'
-
-    def setUp(self):
-        cfg.CONF.set_override(
-            'quota_driver',
-            'neutron.db.quota_db.DbQuotaDriver',
-            group='QUOTAS')
-        super(LBaaSQuotaExtensionDbTestCase, self).setUp()
-
-    def test_quotas_loaded_right(self):
-        res = self.api.get(_get_path('quotas', fmt=self.fmt))
-        quota = self.deserialize(res)
-        self.assertEqual([], quota['quotas'])
-        self.assertEqual(200, res.status_int)
-
-    def test_quotas_default_values(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id)}
-        res = self.api.get(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           extra_environ=env)
-        quota = self.deserialize(res)
-        self.assertEqual(10, quota['quota']['vip'])
-        self.assertEqual(10, quota['quota']['pool'])
-        self.assertEqual(-1, quota['quota']['member'])
-        self.assertEqual(-1, quota['quota']['health_monitor'])
-        self.assertEqual(-1, quota['quota']['extra1'])
-        self.assertEqual(10, quota['quota']['loadbalancer'])
-        self.assertEqual(-1, quota['quota']['listener'])
-        self.assertEqual(-1, quota['quota']['healthmonitor'])
-
-    def test_show_quotas_with_admin(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id + '2',
-                                                  is_admin=True)}
-        res = self.api.get(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           extra_environ=env)
-        self.assertEqual(200, res.status_int)
-        quota = self.deserialize(res)
-        self.assertEqual(10, quota['quota']['vip'])
-        self.assertEqual(10, quota['quota']['pool'])
-        self.assertEqual(-1, quota['quota']['member'])
-        self.assertEqual(-1, quota['quota']['health_monitor'])
-        self.assertEqual(10, quota['quota']['loadbalancer'])
-        self.assertEqual(-1, quota['quota']['listener'])
-        self.assertEqual(-1, quota['quota']['healthmonitor'])
-
-    def test_show_quotas_with_owner_tenant(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id,
-                                                  is_admin=False)}
-        res = self.api.get(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           extra_environ=env)
-        self.assertEqual(200, res.status_int)
-        quota = self.deserialize(res)
-        self.assertEqual(10, quota['quota']['vip'])
-        self.assertEqual(10, quota['quota']['pool'])
-        self.assertEqual(-1, quota['quota']['member'])
-        self.assertEqual(-1, quota['quota']['health_monitor'])
-        self.assertEqual(10, quota['quota']['loadbalancer'])
-        self.assertEqual(-1, quota['quota']['listener'])
-        self.assertEqual(-1, quota['quota']['healthmonitor'])
-
-    def test_update_quotas_to_unlimited(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id,
-                                                  is_admin=True)}
-        quotas = {'quota': {'pool': -1}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas), extra_environ=env,
-                           expect_errors=False)
-        self.assertEqual(200, res.status_int)
-        quotas = {'quota': {'loadbalancer': -1}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas), extra_environ=env,
-                           expect_errors=False)
-        self.assertEqual(200, res.status_int)
-
-    def test_update_quotas_exceeding_current_limit(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id,
-                                                  is_admin=True)}
-        quotas = {'quota': {'pool': 120}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas), extra_environ=env,
-                           expect_errors=False)
-        self.assertEqual(200, res.status_int)
-        quotas = {'quota': {'loadbalancer': 120}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas), extra_environ=env,
-                           expect_errors=False)
-        self.assertEqual(200, res.status_int)
-
-    def test_update_quotas_with_admin(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id + '2',
-                                                  is_admin=True)}
-        quotas = {'quota': {'pool': 100}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas), extra_environ=env)
-        self.assertEqual(200, res.status_int)
-        quotas = {'quota': {'loadbalancer': 100}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas), extra_environ=env)
-        self.assertEqual(200, res.status_int)
-        env2 = {'neutron.context': context.Context('', tenant_id)}
-        res = self.api.get(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           extra_environ=env2)
-        quota = self.deserialize(res)
-        self.assertEqual(10, quota['quota']['vip'])
-        self.assertEqual(100, quota['quota']['pool'])
-        self.assertEqual(-1, quota['quota']['member'])
-        self.assertEqual(-1, quota['quota']['health_monitor'])
-        self.assertEqual(100, quota['quota']['loadbalancer'])
-        self.assertEqual(-1, quota['quota']['listener'])
-        self.assertEqual(-1, quota['quota']['healthmonitor'])
-
-
-class LBaaSQuotaExtensionCfgTestCase(
-    LBaaSQuotaExtensionTestCase):
-
-    def setUp(self):
-        cfg.CONF.set_override(
-            'quota_driver',
-            'neutron.quota.ConfDriver',
-            group='QUOTAS')
-        super(LBaaSQuotaExtensionCfgTestCase, self).setUp()
-
-    def test_quotas_default_values(self):
-        tenant_id = 'tenant_id1'
-        env = {'neutron.context': context.Context('', tenant_id)}
-        res = self.api.get(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           extra_environ=env)
-        quota = self.deserialize(res)
-        self.assertEqual(10, quota['quota']['vip'])
-        self.assertEqual(10, quota['quota']['pool'])
-        self.assertEqual(-1, quota['quota']['member'])
-        self.assertEqual(-1, quota['quota']['health_monitor'])
-        self.assertEqual(-1, quota['quota']['extra1'])
-        self.assertEqual(10, quota['quota']['loadbalancer'])
-        self.assertEqual(-1, quota['quota']['listener'])
-        self.assertEqual(-1, quota['quota']['healthmonitor'])
-
-    def test_update_quotas_forbidden(self):
-        tenant_id = 'tenant_id1'
-        quotas = {'quota': {'pool': 100}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas),
-                           expect_errors=True)
-        self.assertEqual(403, res.status_int)
-
-        quotas = {'quota': {'loadbalancer': 100}}
-        res = self.api.put(_get_path('quotas', id=tenant_id, fmt=self.fmt),
-                           self.serialize(quotas),
-                           expect_errors=True)
-        self.assertEqual(403, res.status_int)
diff --git a/tests/unit/test_agent_scheduler.py b/tests/unit/test_agent_scheduler.py
deleted file mode 100644
index f1b83cb..0000000
--- a/tests/unit/test_agent_scheduler.py
+++ /dev/null
@@ -1,256 +0,0 @@
-# Copyright (c) 2013 OpenStack Foundation.
-# Copyright 2015 Rackspace
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-# implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-import copy
-from datetime import datetime
-
-import mock
-from neutron.api import extensions
-from neutron.api.v2 import attributes
-from neutron import context
-from neutron.db import agents_db
-from neutron.extensions import agent
-from neutron import manager
-from neutron.plugins.common import constants as plugin_const
-from neutron.tests.common import helpers
-from neutron.tests.unit.api import test_extensions
-from neutron.tests.unit.db import test_agentschedulers_db
-import neutron.tests.unit.extensions
-from neutron.tests.unit.extensions import test_agent
-import six
-from webob import exc
-
-from neutron_lbaas.drivers.haproxy import plugin_driver
-from neutron_lbaas.extensions import lbaas_agentschedulerv2
-from neutron_lbaas.services.loadbalancer import constants as lb_const
-from neutron_lbaas.tests import base
-from neutron_lbaas.tests.unit.db.loadbalancer import test_db_loadbalancerv2
-
-LBAAS_HOSTA = 'hosta'
-extensions_path = ':'.join(neutron.tests.unit.extensions.__path__)
-
-
-class AgentSchedulerTestMixIn(test_agentschedulers_db.AgentSchedulerTestMixIn):
-    def _list_loadbalancers_hosted_by_agent(
-            self, agent_id, expected_code=exc.HTTPOk.code, admin_context=True):
-        path = "/agents/%s/%s.%s" % (agent_id,
-                                     lbaas_agentschedulerv2.LOADBALANCERS,
-                                     self.fmt)
-        return self._request_list(path, expected_code=expected_code,
-                                  admin_context=admin_context)
-
-    def _get_lbaas_agent_hosting_loadbalancer(self, loadbalancer_id,
-                                              expected_code=exc.HTTPOk.code,
-                                              admin_context=True):
-        path = "/lbaas/loadbalancers/%s/%s.%s" % (loadbalancer_id,
-                                                  lbaas_agentschedulerv2
-                                                  .LOADBALANCER_AGENT,
-                                                  self.fmt)
-        return self._request_list(path, expected_code=expected_code,
-                                  admin_context=admin_context)
-
-
-class LBaaSAgentSchedulerTestCase(test_agent.AgentDBTestMixIn,
-                                  AgentSchedulerTestMixIn,
-                                  test_db_loadbalancerv2.LbaasTestMixin,
-                                  base.NeutronDbPluginV2TestCase):
-    fmt = 'json'
-    plugin_str = 'neutron.plugins.ml2.plugin.Ml2Plugin'
-
-    def _register_agent_states(self, lbaas_agents=False):
-        res = super(LBaaSAgentSchedulerTestCase, self)._register_agent_states(
-            lbaas_agents=lbaas_agents)
-        if lbaas_agents:
-            lbaas_hosta = {
-                'binary': 'neutron-loadbalancer-agent',
-                'host': test_agent.LBAAS_HOSTA,
-                'topic': 'LOADBALANCER_AGENT',
-                'configurations': {'device_drivers': [
-                    plugin_driver.HaproxyOnHostPluginDriver.device_driver]},
-                'agent_type': lb_const.AGENT_TYPE_LOADBALANCERV2}
-            lbaas_hostb = copy.deepcopy(lbaas_hosta)
-            lbaas_hostb['host'] = test_agent.LBAAS_HOSTB
-            callback = agents_db.AgentExtRpcCallback()
-            callback.report_state(self.adminContext,
-                                  agent_state={'agent_state': lbaas_hosta},
-                                  time=datetime.utcnow().isoformat())
-            callback.report_state(self.adminContext,
-                                  agent_state={'agent_state': lbaas_hostb},
-                                  time=datetime.utcnow().isoformat())
-            res += [lbaas_hosta, lbaas_hostb]
-        return res
-
-    def setUp(self):
-        # Save the global RESOURCE_ATTRIBUTE_MAP
-        self.saved_attr_map = {}
-        for res, attrs in six.iteritems(attributes.RESOURCE_ATTRIBUTE_MAP):
-            self.saved_attr_map[res] = attrs.copy()
-        service_plugins = {
-            'lb_plugin_name': test_db_loadbalancerv2.DB_LB_PLUGIN_CLASS}
-
-        # default provider should support agent scheduling
-        self.set_override(
-            [('LOADBALANCERV2:lbaas:neutron_lbaas.drivers.haproxy.'
-              'plugin_driver.HaproxyOnHostPluginDriver:default')])
-
-        super(LBaaSAgentSchedulerTestCase, self).setUp(
-            self.plugin_str, service_plugins=service_plugins)
-        ext_mgr = extensions.PluginAwareExtensionManager.get_instance()
-        self.ext_api = test_extensions.setup_extensions_middleware(ext_mgr)
-        self.adminContext = context.get_admin_context()
-        # Add the resources to the global attribute map
-        # This is done here as the setup process won't
-        # initialize the main API router which extends
-        # the global attribute map
-        attributes.RESOURCE_ATTRIBUTE_MAP.update(
-            agent.RESOURCE_ATTRIBUTE_MAP)
-        self.lbaas_plugin = manager.NeutronManager.get_service_plugins()[
-            plugin_const.LOADBALANCERV2]
-        self.core_plugin = manager.NeutronManager.get_plugin()
-        self.addCleanup(self.restore_attribute_map)
-
-    def restore_attribute_map(self):
-        # Restore the original RESOURCE_ATTRIBUTE_MAP
-        attributes.RESOURCE_ATTRIBUTE_MAP = self.saved_attr_map
-
-    def test_report_states(self):
-        self._register_agent_states(lbaas_agents=True)
-        agents = self._list_agents()
-        self.assertEqual(8, len(agents['agents']))
-
-    def test_loadbalancer_scheduling_on_loadbalancer_creation(self):
-        self._register_agent_states(lbaas_agents=True)
-        with self.loadbalancer() as loadbalancer:
-            lbaas_agent = self._get_lbaas_agent_hosting_loadbalancer(
-                loadbalancer['loadbalancer']['id'])
-            self.assertIsNotNone(lbaas_agent)
-            self.assertEqual(lb_const.AGENT_TYPE_LOADBALANCERV2,
-                             lbaas_agent['agent']['agent_type'])
-            loadbalancers = self._list_loadbalancers_hosted_by_agent(
-                lbaas_agent['agent']['id'])
-            self.assertEqual(1, len(loadbalancers['loadbalancers']))
-            self.assertEqual(loadbalancer['loadbalancer'],
-                             loadbalancers['loadbalancers'][0])
-            self.lbaas_plugin.db.update_loadbalancer_provisioning_status(
-                self.adminContext, loadbalancer['loadbalancer']['id']
-            )
-
-    def test_schedule_loadbalancer_with_disabled_agent(self):
-        lbaas_hosta = {
-            'binary': 'neutron-loadbalancer-agent',
-            'host': LBAAS_HOSTA,
-            'topic': 'LOADBALANCER_AGENT',
-            'configurations': {'device_drivers': [
-                plugin_driver.HaproxyOnHostPluginDriver.device_driver
-            ]},
-            'agent_type': lb_const.AGENT_TYPE_LOADBALANCERV2}
-        helpers._register_agent(lbaas_hosta)
-        with self.loadbalancer() as loadbalancer:
-            lbaas_agent = self._get_lbaas_agent_hosting_loadbalancer(
-                loadbalancer['loadbalancer']['id'])
-            self.assertIsNotNone(lbaas_agent)
-            self.lbaas_plugin.db.update_loadbalancer_provisioning_status(
-                self.adminContext, loadbalancer['loadbalancer']['id']
-            )
-        agents = self._list_agents()
-        self._disable_agent(agents['agents'][0]['id'])
-        subnet = self.core_plugin.get_subnets(self.adminContext)[0]
-        lb = {
-            'loadbalancer': {
-                'vip_subnet_id': subnet['id'],
-                'provider': 'lbaas',
-                'flavor_id': attributes.ATTR_NOT_SPECIFIED,
-                'vip_address': attributes.ATTR_NOT_SPECIFIED,
-                'admin_state_up': True,
-                'tenant_id': self._tenant_id}}
-        self.assertRaises(lbaas_agentschedulerv2.NoEligibleLbaasAgent,
-                          self.lbaas_plugin.create_loadbalancer,
-                          self.adminContext, lb)
-
-    def test_schedule_loadbalancer_with_down_agent(self):
-        lbaas_hosta = {
-            'binary': 'neutron-loadbalancer-agent',
-            'host': LBAAS_HOSTA,
-            'topic': 'LOADBALANCER_AGENT',
-            'configurations': {'device_drivers': [
-                plugin_driver.HaproxyOnHostPluginDriver.device_driver
-            ]},
-            'agent_type': lb_const.AGENT_TYPE_LOADBALANCERV2}
-        helpers._register_agent(lbaas_hosta)
-        is_agent_down_str = 'neutron.db.agents_db.AgentDbMixin.is_agent_down'
-        with mock.patch(is_agent_down_str) as mock_is_agent_down:
-            mock_is_agent_down.return_value = False
-            with self.loadbalancer() as loadbalancer:
-                lbaas_agent = self._get_lbaas_agent_hosting_loadbalancer(
-                    loadbalancer['loadbalancer']['id'])
-                self.lbaas_plugin.db.update_loadbalancer_provisioning_status(
-                    self.adminContext, loadbalancer['loadbalancer']['id']
-                )
-            self.assertIsNotNone(lbaas_agent)
-        with mock.patch(is_agent_down_str) as mock_is_agent_down:
-            mock_is_agent_down.return_value = True
-            subnet = self.core_plugin.get_subnets(self.adminContext)[0]
-            lb = {
-                'loadbalancer': {
-                    'vip_subnet_id': subnet['id'],
-                    'provider': 'lbaas',
-                    'flavor_id': attributes.ATTR_NOT_SPECIFIED,
-                    'vip_address': attributes.ATTR_NOT_SPECIFIED,
-                    'admin_state_up': True,
-                    'tenant_id': self._tenant_id}}
-            self.assertRaises(lbaas_agentschedulerv2.NoEligibleLbaasAgent,
-                              self.lbaas_plugin.create_loadbalancer,
-                              self.adminContext, lb)
-
-    def test_loadbalancer_unscheduling_on_loadbalancer_deletion(self):
-        self._register_agent_states(lbaas_agents=True)
-        with self.loadbalancer(no_delete=True) as loadbalancer:
-            lb_id = loadbalancer['loadbalancer']['id']
-            lbaas_agent = self._get_lbaas_agent_hosting_loadbalancer(lb_id)
-            self.assertIsNotNone(lbaas_agent)
-            self.assertEqual(lb_const.AGENT_TYPE_LOADBALANCERV2,
-                             lbaas_agent['agent']['agent_type'])
-            loadbalancers = self._list_loadbalancers_hosted_by_agent(
-                lbaas_agent['agent']['id'])
-            self.assertEqual(1, len(loadbalancers['loadbalancers']))
-            self.assertEqual(loadbalancer['loadbalancer'],
-                             loadbalancers['loadbalancers'][0])
-
-            self.lbaas_plugin.db.update_loadbalancer_provisioning_status(
-                self.adminContext, lb_id
-            )
-
-            req = self.new_delete_request('loadbalancers', lb_id)
-            res = req.get_response(self.ext_api)
-            self.assertEqual(exc.HTTPNoContent.code, res.status_int)
-            loadbalancers = self._list_loadbalancers_hosted_by_agent(
-                lbaas_agent['agent']['id'])
-            self.assertEqual(0, len(loadbalancers['loadbalancers']))
-
-    def test_loadbalancer_scheduling_non_admin_access(self):
-        self._register_agent_states(lbaas_agents=True)
-        with self.loadbalancer() as loadbalancer:
-            self._get_lbaas_agent_hosting_loadbalancer(
-                loadbalancer['loadbalancer']['id'],
-                expected_code=exc.HTTPForbidden.code,
-                admin_context=False)
-            self._list_loadbalancers_hosted_by_agent(
-                'fake_id',
-                expected_code=exc.HTTPForbidden.code,
-                admin_context=False)
-            self.lbaas_plugin.db.update_loadbalancer_provisioning_status(
-                self.adminContext, loadbalancer['loadbalancer']['id']
-            )
